set foldmethod=indent foldlevel=2
vim: fdm=indent:fdl=2:

[valoud-reader: parts 1-3 =Listentime 11 hours (=1.10% speed)]


Starting Out:

---- lpy03-helpdoc.txt -- {{{
        Chapter 15 - The Documentation Interlude

            ----
        python's main documentation tool of interest **(!)
            {{{
            In particular, the PyDoc system covered here can
                render a module’s internal documentation as either
                    plain text in a shell, or
                    HTML in a web browser.
            --
            lpy3-p495
            }}}
        Python documentation sources (= list and table of the different tools) (***(*))
            {{{
            Table 15-1.
            --
            lpy3-p496
            }}}
        comments vs docstrings. * (@)
            {{{
            comments are accessible only in your source files,
            to code comments that are more widely available, you’ll need to use docstrings.
              .
            current best practice generally dictates that docstrings are best for larger functional documentation (e.g., “my file does this”),
            and  # comments are best limited to smaller code documentation (e.g., “this strange expression does that”) and are best limited in scope to a statement or small group of statements within a script or function.
            --
            lpy3-p496
            }}}
        explore objects (= grab a list of all the attributes available inside an object (i.e., its methods and simpler data items). ** @
            {{{
            import sys
            dir(sys)
            = can  be called on any object that has attributes, including imported modules and built-in types, as well as the name of a data type.
            --
            lpy3-p496
            }}}
        list variables in the caller’s scope. * (@)
            {{{
            dir()  (=w.out args)
            --
            lpy3-p496
            }}}
        Report number of different kinds of properties for an object (**(*))  (= methods etc) @(@)
            {{{
                # Number names in sys
            >>> len(dir(sys))
            78
                # Non __X names only
            >>> len([x for x in dir(sys) if not x.startswith('__')])
            69
                # Non underscore names
            >>> len([x for x in dir(sys) if not x[0] == '_'])
            62
              .
                (+ Some more examples, plus how to make a function out of it)
                    # See Part IV
            >>> def dir1(x): return [a for a in dir(x) if not a.startswith('__')]
            ...
            >>> dir1(tuple)
            ['count', 'index']
            --
            lpy3-p497
            }}}
        te: you can list built-in type attributes by passing a type name to dir instead of a literal  (+ why this works) *
            {{{
            are actually names of types in Python today; calling one of these invokes its constructor to generate an instance of that type.
            --
            lpy3-p498
            }}}
        List properties of objects in IDLE, similar to with dir()  *
            {{{
            . + Tab or wait
            --
            lpy3-p498
            }}}
            ----

            ----
        docstrings ** (@)
            {{{
            coded as strings at the tops of module files and function and class statements, before any other executable code (# comments, including Unix-style #!  lines are OK before them).
            ex|docstrings.py: Its docstrings appear at the beginning of the file and at the start of a function and a class within it.
            Here, I’ve used triple-quoted block strings for multiline comments in the file and the function, but any sort of string will work;
              .
            """
            Module documentation
            Words Go Here
            """
              .
            """
            function documentation
            can we have your liver then?
            """
              .
            "class documentation"
              .
            = your comments are retained for inspection in __doc__ attributes after the file is imported.
            --
            lpy3-p498,p499
            }}}
        display the docstrings associated with the module docstrings.py and its objects,a ***(*) @
            {{{
            >>> import docstrings
            >>> print(docstrings.__doc__)
              .
            print documentation just for certain functions and classes in the module:
            >>> print(docstrings.square.__doc__)
            >>> print(docstrings.Employee.__doc__)
            --
            lpy3-p499
            }}}
        nesting: fetch the docstring of a method function inside a class within a module, **
            {{{
            module.class.method.__doc__
            --
            lpy3-p499
            }}}
        common practice today recommends hash-mark comments for (!)  (+docstrings for ___) **(!)
            {{{
            only smaller-scale documentation about an expression, statement, or small group of statements.
              .
            Docstrings are better used for higher-level and broader functional documentation for a file, function, or class, and have become an expected part of Python software.
            --
            lpy3-p499
            }}}
        standard about what should go into the text of a docstring.
            {{{
            (= convincing Python programmers to document their code using handcoded HTML/XML ... )
            --
            lpy3-p500
            }}}
            ----

            ----
        Built-in docstrings  (= eg. for sys) ** @
            {{{
            >>> import sys
            >>> print(sys.__doc__)
            --
            lpy3-p500
            }}}
        Functions, classes, and methods within built-in modules have attached descriptions in their __doc__ attributes as well: ** (eg print docstring for getrefcount) **(*)**
            {{{
            >>> print(sys.getrefcount.__doc__)
            getrefcount(object) -> integer
              .
            >>> print(int.__doc__)
            int(x[, base]) -> integer
            --
            lpy3-p500
            }}}
        better way  of  getting  information about built-in tools (than) by inspecting their docstrings ****(*)
            {{{
            PyDoc (= the help function)
            = Python code that knows how to extract docstrings and associated structural information and format them into nicely arranged reports of various types.
            --
            lpy3-p501
            }}}
        tip  launching PyDoc, * (@)
            {{{
            including command-line script options that can save the resulting documentation for later viewing
            --
            lpy3-p501
            }}}
        the two most prominent PyDoc interfaces ** (@)
            {{{
            the built-in help function
            and the PyDoc GUI- and web-based HTML report interfaces.
            --
            lpy3-p501
            }}}
        help text paging *
            {{{
            press the space bar to move to the next page, Enter to go to the next line, and Q to quit:
            --
            lpy3-p501
            }}}
            ----

            ----
        front help for sys' getrefcount **(!)*(*) @
            {{{
            >>> import sys
            >>> help(sys.getrefcount)
            --
            lpy3-p501
            }}}
        get help for a module you have not imported * (@)
            {{{
            = In Pythons 3.3 and 2.7,
             + quoting the module’s name as a string
            help('re'),
            help('email.message')
            --
            lpy3-p502
            }}}
        tip help for  built-ins (*)
            {{{
            Besides modules, you can also use help on built-in functions, methods, and types.
                Usage varies slightly across Python versions, but to get help for a built-in type, try either the type name (e.g., dict for dictionary, str for string, list for list); an actual object of the type (e.g., {}, '', []); or a method of an actual object or type name (e.g., str.join, 's'.join).
              .
            >>> help(dict)
            Help on class dict in module builtins:

            class dict(object)
             | dict() -> new empty dictionary.
             | dict(mapping) -> new dictionary initialized from a mapping object's
             ...more omitted...
              .
            >>> help(str.replace)
            Help on method_descriptor:
            --
            lpy3-p502
            }}}
        Start the interactive help mode, ***(*) @
            {{{
            help()
            --
            lpy3-p503
            }}}
        PyDoc: HTML Reports ** ** (!)
            {{{
            
            --
            lpy3-p504
            }}}
            ----

            ----
        run GUI client mode of PyDoc, (!)  (=pre Py 3)
            {{{
            pydoc -g  (cline)
            --
            lpy3-p505
            }}}
        launch the newer browser-only mode of PyDoc in Python 3.2 and later, (**) (??) (??) @
            {{{
            c:\code> python -m pydoc -b
            c:\code> py -3 -m pydoc -b
            c:\code> C:\python33\python -m pydoc -b
            --
            lpy3-p505
            }}}
        basic navigation and functions inside the PyDoc browser (**)
            {{{
            Figure 15-1.  Besides the module index, PyDoc’s web page also includes input fields at the top to request a specific module’s documentation page (Get) and search for related entries (Search),
            You can also click on this page’s links to go to the Module Index (the start page), Topics (general Python subjects), and Keywords (overviews of statements and some expressions).
            --
            lpy3-p506
            }}}
        'PyDoc is mostly intended for documenting (??) (!) (@)
            {{{
            importable modules, but can sometimes be used to show documentation for scripts too.
            --
            lpy3-p506
            }}}
        'The net effect is that the documentation page for a script will appear after it runs, and after its printed output shows up in the shell window.
            {{{
            and as we’ve learned, importing runs a file’s code. Modules normally just define tools when run, so this is usually irrelevant. (??) (!)
            --
            lpy3-p507
            }}}
        tip PyDoc: 'click your way through the documentation of related components in your application. ** (?@)
            {{{
            For instance, you’ll find links to open imported modules’ pages too.
            --
            lpy3-p507
            }}}
            ----

            ----
        set  PyDoc server port,
            {{{
            pydoc –p port
            --
            lpy3-p507
            }}}
        writes a module’s HTML documentation to a file named module.html ** @
            {{{
            pydoc -w module
            --
            lpy3-p507
            }}}
        generate simpler txt documentation file with PyDoc (*)
            {{{
            c:\code> py -3 -m pydoc timeit
              .
            c:\code> py -3
                # Interactive prompt text help
            >>> help("timeit")
            --
            lpy3-p507
            }}}
        Changing PyDoc’s Colors (!!)
            {{{
            PyDoc lives in the file pydoc.py in Python’s standard library, which is directory C:\Python33\Lib on Windows for Python 3.3. Its colors are hardcoded RGB value hex strings embedded throughout its code. For instance, its string '#eeaa77' specifies 2-byte (16-bit) values for red, green, and blue levels (decimal 238, 170, and 119), yielding a shade of orange for function banners.
            = To tailor, search for these color value strings and replace them with your preferences.
            In IDLE, an Edit/Find for regular expression #\w{6} will locate color strings (this matches six alphanumeric characters after a # per Python’s re module pattern syntax; see the library manual for details).
                To pick colors, in most programs with color selection dialogs you can map to and from RGB values; the book’s examples include a GUI script setcolor.py that does the same.
            --
            In fact, there already is an effort under way: issue 10716 on the Python developers’ list seeks to make PyDoc more user-customizable by changing it to support CSS style sheets.
            Today’s PyDoc in 3.3 already supports a CSS style sheet that offers some customization options, but only half-heartedly, and ships with one that is empty.
            --
            lpy3-p509
            }}}
        Enter a module's docs w. PyDoc(??) (@)
            {{{
            You can start this either by selecting the Module Docs item in Python’s Start button menu on Windows 7 and earlier, or by launching the pydoc.py script in Python’s standard library directory with a -g command-line argument: it lives in Lib on Windows, but you can use Python’s –m flag to avoid typing script paths here too:
              .
            Enter the name of a module you’re interested in, and press the Enter key; PyDoc will march down your module import search path (sys.path), looking for the requested module and references to it.
            Once you’ve found a promising entry, select it and click “go to selected.” PyDoc will spawn a web browser on your machine to display the report rendered in HTML format.
            Figure 15-4 shows the information PyDoc displays for the built-in glob module.
              .
            Notice the hyperlinks in the Modules section of this page - you can click these to jump to the PyDoc pages for related (imported) modules. For larger pages, PyDoc also generates hyperlinks to sections within the page.
            --
            lpy3-p510
            }}}
        'Make sure that the directory containing your module is on your module import search path
            {{{
            = as mentioned, PyDoc must be able to import a file to render its documentation.
              ), so you may need to extend your PYTHONPATH setting to get this to work.
            = On Pythons 3.2 and 2.7, I had to add “.” to my PYTHONPATH to get PyDoc’s GUI client mode to look in the directory it was started from by command line:
              .
            c:\code> set PYTHONPATH=.;%PYTYONPATH%
            c:\code> py -3.2 -m pydoc -g
                However, Python 3.3 automatically includes “.” in its index list, so no path setting is required to view files in the directory where PyDoc is started - a minor but noteworthy improvement.
            --
            lpy3-p510
            }}}
        PyDoc can be customized and launched in various ways we won’t cover here;
            {{{
            see its entry in Python’s standard library manual for more details.
            --
            lpy3-p512
            }}}
            ----

            ----
        PyDoc ...  provides an easy way to access ** (!)
            {{{
            PyDoc helps only for objects like functions and modules, but it provides an easy way to access a middle level of documentation for such tools -
            its reports are more useful than raw attribute lists, and less exhaustive than the standard manuals.
            --
            lpy3-p512
            }}}
        PyDoc GUI client trick of the day: ** ** @
            {{{
            If you press the “open browser” button in Figure 15-3’s window, PyDoc will produce an index page containing a hyperlink to every module you can possibly import on your computer.
            This includes Python standard library modules, modules of installed third-party extensions, user-defined modules on your import search path, and even statically or dynamically linked-in C-coded modules.
                On Python 3.2, you’ll want to do this immediately after the GUI opens, as it may not fully work after searches.
            --
            lpy3-p513
            }}}
        Beyond docstrings: ** (@)
            {{{
            Sphinx
            If you’re looking for a way to document your Python system in a more sophisticated way, you may wish to check out Sphinx (currently at http://sphinx-doc.org).
                It uses simple reStructuredText as its markup language, and inherits much from the Docutils suite of reStructuredText parsing and translating tools.
            Among other things, Sphinx supports a variety of output formats (HTML including Windows HTML Help, LaTeX for printable PDF versions, manual pages, and plain text); extensive and automatic cross-references; hierarchical structure with automatic links to relatives; automatic indexes; automatic code highlighting using Pygments (itself a notable Python tool); and more.
            --
            lpy3-p513
            }}}
        the What’s New documents in this standard manual set chronicle (!) (@)
            {{{
            Python changes made in each release beginning with Python 2.0,
            useful for those porting older Python code, or older Python skills.
                + These documents are especially useful for uncovering additional details on the differences in the Python 2.X and 3.X language lines covered in this book, as well as in their standard libraries.
            --
            lpy3-p514
            }}}
        Py-documentation in other lang.s **(!)
            {{{
            = The (Py Documentation) site also lists non-English Python resources, and introductions scaled to different target audiences.
            --
            lpy3-p514
            }}}
            ----

        Common Python Coding Gotchas

            ----
        Python Coding Gotchas @
            {{{
            • Don’t forget the colons.
            • Start in column 1.
            • Blank lines matter at the interactive prompt.
                Blank lines in compound statements are always irrelevant and ignored in module files, but when you’re typing code at the interactive prompt, they end the statement.
                In other words, blank lines tell the interactive command line that you’ve finished a compound statement; if you want to continue, don’t hit the Enter key at the ...  prompt (or in IDLE) until you’re really done. This also means you can’t paste multiline code at this prompt; it must run one full statement at a time.
            • Indent consistently. Avoid mixing tabs and spaces in the indentation of a block, unless you know what your text editor does with tabs.
            - dont code in C/C++
                And remember, don’t embed assignment statements in while loop tests, and don’t use {} around blocks (indent your nested code blocks consistently instead).
            --
            • Use simple for loops instead of while or range. **
            • Beware of mutables in assignments. (??)(??)
                I mentioned this in Chapter 11: you need to be careful about using mutables in a multiple-target assignment (a = b = []), as well as in an augmented assignment (a += [1, 2]). (??)
            • Don’t expect results from functions that change objects in place. **(!)
                (+ 'A more devious example of this pops up in Python 2.X code when trying to step through dictionary items in a sorted fashion. (??) (!)
                 It’s fairly common to see code like for k in D.keys().sort():.
                   .
                 To code this correctly, either use the newer sorted built-in function, which returns the sorted list, or split the method calls out to statements: Ks = list(D.keys()), then Ks.sort(), and finally, for k in Ks:.
                 This, by the way, is one case where you may still want to call the keys method explicitly for looping, instead of relying on the dictionary iterators - iterators do not sort. (!!)
            • Always use parentheses to call a function.
                In classes, this problem seems to occur most often with files; it’s common to see beginners type file.close to close a file, rather than file.close().  Because it’s legal to reference a function without calling it, the first version with no parentheses succeeds silently, but it does not close the file!
            • Don’t use extensions or paths in imports and reloads.
                Python picks an extension automatically, and any platform-specific directory path syntax comes from module search path settings, not the import statement.
            + Be sure to also see the built-in type warnings at the end of the prior part, as they may qualify as coding issues too.
            There are additional “gotchas” that crop up commonly in Python coding - losing a built-in function by reassigning its name, hiding a library module by using its name for one of your own, changing mutable argument defaults, and so on - but we don’t have enough background to cover them yet.
              .
              .
            --
            lpy3-p515,p516
            }}}
        In the next part of this book, we’ll learn that functions are simply objects that have a special operation  (!)
            {{{
            - a call that you trigger with the parentheses.
            --
            lpy3-p517
            }}}
        the next part takes up the topic of functions - a tool used to
            {{{
            group statements for reuse.
            --
            lpy3-p517
            }}}
        When should you use documentation strings instead of hash-mark comments?
            {{{
            Documentation strings (docstrings) are considered best for larger, functional documentation, describing the use of modules, functions, classes, and methods in your code.
                    Hash-mark comments are today best limited to smaller-scale documentation about arcane expressions or statements at strategic points on your code.
            --
            lpy3-p518
            }}}
        Name three ways you can view documentation strings. @ @
            {{{
            You can see docstrings by printing an object’s __doc__ attribute, by passing it to PyDoc’s help function, and by selecting modules in PyDoc’s HTML-based user interfaces
                the -b allbrowser mode in Python 3.2 and later (and required as of 3.3).
            --
            lpy3-p518
            }}}
        How can you get a list of all available modules on your computer? (@)
            {{{
            4. In Python 3.2 and earlier, you can run the PyDoc GUI interface, and select “open browser”; this opens a web page containing a link to every module available to your programs.
            In Python 3.2 and later, you get the same functionality by running PyDoc’s newer all-browser mode with a -b command-line switch; the top-level start page displayed in a web browser in this newer mode has the same index page listing all available modules.
            --
            lpy3-p518
            }}}
            ----

            ----
        Consider the following code, which uses a while loop and found flag to search a list of powers of 2 for the value of 2 raised to the fifth power (32). (!=Tut) **
            {{{
              .
              .
              .
            Next, remove the loop completely by rewriting the example with a simple in operator membership expression.
            --
            lpy3-p519,p520
            }}}
        (Hint: to get the index of an item, (= a list item  *
            {{{
            use the list index method - L.index(X) returns the offset of the first X in list L.)
            --
            lpy3-p520
            }}}
        run a file compare on Windows)
            {{{
            (fc on Windows)
            --
            lpy3-p520
            }}}
            ----


        PART IV -- Functions and Generators

        Chapter 16 - Function Basics

            ----
        1
            {{{
            
            --
            lpy3-p525
            }}}
        2
            {{{
            
            --
            lpy3-p525
            }}}



        Todo: where they shine and what they're good at = that is different programming languages (****)

}}}
---- lpy04-functs_avanc.txt -- {{{
        PART IV -- Functions and Generators

        Chapter 16 - Function Basics

            ----
        'Table 16-1 previews the primary function-related tools we’ll study in this part of the book
            {{{
            =
            a set that includes call expressions,
            two ways to make functions
                (def and lambda)
            two ways to manage scope visibility
                (global and nonlocal)
            and two ways to send results back to caller
                (return and yield).
              .
            Table 16-1. Function-related statements and expressions
            --
            lpy3-p525
            }}}
        Call expression **(*) @
            {{{
            myfunc('spam', 'eggs', meat=ham, *rest)
            --
            lpy3-p525
            }}}
        other name or synonym for functions (!)
            {{{
            subroutines or procedures.
            --
            lpy3-p526
            }}}
        As a brief introduction, functions serve two primary development roles:
            {{{
            Maximizing code reuse and minimizing redundancy
            Procedural decomposition
                Functions also provide a tool for splitting systems into pieces that have well-defined roles.
            --
            lpy3-p526
            }}}
            ----

            ----
        'def is executable code. (T@)
            {{{
            Unlike functions in compiled languages such as C, def is an executable statement - your function does not exist until Python reaches and runs the def.
            In fact, it’s legal (and even occasionally useful) to nest def statements inside if statements, while loops, and even other defs.
            --
            lpy3-p527
            }}}
        In typical operation, def statements are coded in **(!) @(@)
            {{{
            module files and are naturally run to generate functions when the module file they reside in is first imported.
            --
            lpy3-p527
            }}}
        def (= does what when run?) * (T@)
            {{{
            creates an object and assigns it to a name.
                + As with all assignments, the function name becomes a reference to the function object.
            --
            lpy3-p527
            }}}
        Function objects may also have ____ to record data.
            {{{
            = arbitrary user-defined attributes attached to them
            --
            lpy3-p527
            }}}
        • lambda (= does what?)
            {{{
            creates an object but returns it as a result.
            --
            lpy3-p527
            }}}
        when a function is called, (= ie. what happens to the caller?)
            {{{
            the caller stops until the function finishes its work and returns control to the caller.
            --
            lpy3-p527
            }}}
        A return without a value simply returns to the caller (and sends back (!) (T@)
            {{{
            None, the default result).
            --
            lpy3-p527
            }}}
            ----

            ----
        • yield sends a result object back to the caller, but (= also) (!)
            {{{
            remembers where it left off.
            --
            lpy3-p527
            }}}
        Functions known as generators (!)
            {{{
            may also use the yield statement to send back a value and suspend their state such that they may be resumed later, to produce a series of results over time.
            --
            lpy3-p528
            }}}
        'assignments bind names to
            {{{
            scopes
            --
            lpy3-p528
            }}}
        the nonlocal statement added in Python 3.X allows a function to assign a name that * (@)
            {{{
            exists in the scope of a syntactically enclosing def statement.
              = This allows enclosing functions to serve as a place to retain state - information remembered between function calls - without using shared global names.
            --
            lpy3-p528
            }}}
        In Python, arguments are passed to functions by (!) **
            {{{
            assignment (which, as we’ve learned, means by object reference). (??) (!)
            --
            lpy3-p528
            }}}
        'As you’ll see, in Python’s model the caller and function share objects by references, but there is no name aliasing. (??) (??)
            {{{
            (= 'Changing an argument name within a function does not also change the corresponding name in the caller, but changing passed-in mutable objects in place can change objects shared by the caller, and serve as a function result.
            --
            lpy3-p528
            }}}
                ----

                ----
        As one consequence, a single function can often be applied to a variety of object types - any objects that sport a compatible interface (methods and expressions) will do, regardless of their specific types. ** (!) @(@)
            {{{
            = As with everything in Python, there are no type constraints on functions. In fact, nothing about a function needs to be declared ahead of time: you can pass in arguments of any type, return any kind of object, and so on.
                # Functions are "typeless"
            >>> times('Ni', 4)
            'NiNiNiNi'
            This is a core idea in Python (and perhaps the key to using the language well), which merits a bit of expansion here.
            (+the section 'Polymorphism in Python
            --
            lpy3-p528,p531
            }}}
        create a function object and assigns it to a name. ** (!)
            {{{
            the def Statement
              .
            def name(arg1, arg2,... argN):
                statements
            --
            lpy3-p528
            }}}
        Function definition w. a return statement (**) @
            {{{
            def name(arg1, arg2,... argN):
                ...
                return value
            --
            lpy3-p529
            }}}
        The return statement consists of  (+ what is the default value?) *(*)
            {{{
            consists of an optional object value expression that gives the function’s result.
            If the value is omitted, return sends back a None.
                The return statement itself is optional too; if it’s not present, the function exits when the control flow falls off the end of the function body.
                Technically, a function without a return statement also returns the None object automatically, but this return value is usually ignored at the call.
            --
            lpy3-p529
            }}}
        when a def is run (*(*)) (@)
            {{{
            Because it(=def) is a statement, a def can appear anywhere a statement can - even nested in other statements.
              although defs normally are run when the module enclosing them is imported, it’s also completely legal to nest a function def inside an if statement to select between alternative definitions:
            (+ 'One way to understand this code is to realize that the def is much like an = statement:
            --
            lpy3-p529
            }}}
        (assigning a function to another name etc **)
            {{{
            Because function definition happens at runtime, there’s nothing special about the function name. What’s important is the object to which it refers:
            othername = func	# Assign function object
            othername()			# Call func again
            --
            lpy3-p530
            }}}
        ('functions allow arbitrary attributes to be attached to record information for later use: @
            {{{
            def func(): ...
              .
            func()
            func.attr = value
            --
            lpy3-p530
            }}}
                ----

                ----
        define a first function 'times' (= multiplies two arguments) **  (= from the interactive prompt) @
            {{{
            >>> def times(x, y):	# Create and assign function
            ...     return x * y	# Body executed when called
            ...
                Typically, such a statement is coded in a module file and runs when the enclosing file is imported; for something this small, though, the interactive prompt suffices.
            --
            lpy3-p530
            }}}
        if we needed to use  the value produced by a function call  later **(!) (@@)
            {{{
                # Save the result object
            >>> x = times(3.14, 4)
            >>> x
            12.56
            --
            lpy3-p531
            }}}
        'Polymorphism in Python
            {{{
            'By and large, we code to object interfaces in Python, not data types.1
                (= duck typing)
             --
            Python leaves it up to the objects to do something reasonable for the syntax. Really, * is just a dispatch mechanism that routes control to the objects being processed.
              .
            This sort of type-dependent behavior is known as polymorphism, a term we first met in Chapter 4 that essentially means that the meaning of an operation depends on the objects being operated upon.
              Because it’s a dynamically typed language, polymorphism runs rampant in Python.
            --
            A single function, for instance, can generally be applied to a whole category of object types automatically.
            As long as those objects support the expected interface (a.k.a.  protocol), the function can process them. That is, if the objects passed into a function have the expected methods and expression operators, they are plug-and-play compatible with the function’s logic.
            Even in our simple times function, this means that any two objects that support a * will work, no matter what they may be, and no matter when they are coded.
            --
            lpy3-p531
            }}}
        Python and error handling with respect to polymorphism ** (@)
            {{{
            Moreover, if the objects passed in do not support this expected interface, Python will detect the error when the * expression is run and raise an exception automatically.
            It’s therefore usually pointless to code error checking ourselves. In fact, doing so would limit our function’s utility, as it would be restricted to work only on objects whose types we test for.
            This turns out to be a crucial philosophical difference between Python and statically typed languages like C++ and Java: in Python, your code is not supposed to care about specific data types.
            If it does, it will be limited to working on just the types you anticipated when you wrote it,
            --
            (!!) Of course, some programs have unique requirements, and this polymorphic model of programming means we have to test our code to detect errors, rather than providing type declarations a compiler can use to detect some types of errors for us ahead of time.
            --
            lpy3-p532
            }}}
            ----

            ----
        where to put y. utility functions (**) (@)
            {{{
            • Coding the function in a module file means it can be imported and reused by any program run on your machine.
            --
            lpy3-p533
            }}}
        Code an intersect function (**!) (!!) (!@)
            {{{
            def intersect(seq1, seq2):
                res = []
                for x in seq1:
                    if x in seq2:
                        res.append(x)
                return res
              .
            # (using w.) Mixed types
        >>> x = intersect([1, 2, 3], (1, 4))
        >>> x		# Saved result object
        [1]
             .
            “for every item in the first argument, if that item is also in the second argument, append the item to the result.”
             .
            The transformation from the simple code of Chapter 13 to this function is straightforward; we’ve just nested the original logic under a def header and made the objects on which it operates passed-in parameter names.
            + Because this function computes a result, we’ve also added a return statement to send a result object back to the caller.
            --
            ++Note: 'To be fair, our intersect function is fairly slow (it executes nested loops), isn’t really mathematical intersection (there may be duplicates in the result), and isn’t required at all (as we’ve seen, Python’s set data type provides a built-in intersection operation).
            Indeed, the function could be replaced with a single list comprehension expression, as it exhibits the classic loop collector code pattern:
            >>> [x for x in s1 if x in s2]
            ['S', 'A', 'M']
            --
            lpy3-p533
            }}}
        running a def "indirectly" (**)
            {{{
            = coding it in a module file and importing the file.
            --
            lpy3-p533
            }}}
        (something about iterating over the contents of already opened files w. polymorphic functions)
            {{{
            Files must generally be rewound (e.g., with a file.seek(0) or another open) after they have been read to end-of-file once, and so are single-pass iterators.
                As we’ll see in Chapter 30 when we study operator overloading, objects implement the in operator either by providing the specific __contains__ method or by supporting the general iteration protocol with the __iter__ or older __getitem__ methods; classes can code these methods arbitrarily to define what iteration means for their data.
            --
            lpy3-p534
            }}}
        local variable  inside a function  = exists when and for how long? **(!)
            {{{
            = exists only while the function runs.
                • Arguments are passed by assignment, so seq1 and seq2 (= for intersect() ) are, too.
                • The for loop assigns items to a variable, so the name x is also local.
            --
            lpy3-p535
            }}}
        te: assignment means ____ in Python,
            {{{
            object reference
            which, as we learned in Chapter 6, really means pointer internally),
            --
            lpy3-p535
            }}}
        2. When is a function's def run in Python? **(!)
            {{{
            A function is created when Python reaches and runs the def statement; this statement creates a function object and assigns it the function’s name.
            --
            lpy3-p536
            }}}
        The term (eg. function) interface means **
            {{{
            the set of methods and expression operators the function’s code runs.)
              (ie. "what interface does it support?")
            --
            lpy3-p536
            }}}
            ----

        Chapter 17 - Scopes

            ----
        On the plus side, we’ll learn that scopes can (@)
            {{{
            provide a way to retain state information between function calls,
                and offer an alternative to classes in some roles.
            --
            lpy3-p537
            }}}
        How the association and scopes of names are determined in Python (!) @(@)
            {{{
            Because names are not declared ahead of time, Python uses the location of the assignment of a name to associate it with (i.e., bind it to) a particular namespace.
            In other words, the place where you assign a name in your source code determines the namespace it will live in, and hence its scope of visibility.
            --
            lpy3-p537
            }}}
        the scope of a variable (= what that means) (**) (T!!@)
            {{{
            = where it can be used)
            --
            lpy3-p538
            }}}
        We call this lexical scoping because *
            {{{
            variable scopes are determined entirely by the locations of the variables in the source code of your program files, not by function calls.
            --
            lpy3-p538
            }}}
        Global (module) scope vs Local (function) scope * (@)
            {{{
            --
            lpy3-p538
            }}}
            ----

        Scope Details

            ----
        Technically, the interactive prompt is a module named (!)
            {{{
            __main__ that prints results and doesn’t save its code; in all other ways, though, it’s like the top level of a module file.
            --
            lpy3-p538
            }}}
        Functions define a local scope and modules define a global scope with the following properties: *(!@)
            {{{
            • The enclosing module is a global
            scope. Each module is a global
            scope - that is, a namespace in
            which variables created (assigned)
            at the top level of the module file
            live. Global variables become
            attributes of a module object to
            the outside world after imports but
            can also be used as simple
            variables within the module file
            itself
            --
            lpy3-p538,p539
            }}}
        te: There is really no notion of a single, all-encompassing global file-based scope in Python. *(*) (+ what global actually means in Python)
            {{{
            Instead, names are partitioned into modules, and you must always import a module explicitly if you want to be able to use the names its file defines.
            = When you hear “global” in Python, think “module.”
            --
            lpy3-p539
            }}}
        Recursion is useful in functions we write as well, to process * (@)
            {{{
            structures whose shapes can’t be predicted ahead of time;
                = Python allows functions to call themselves to loop
                - each active call receives its own copy of the function’s local variables.
            --
            lpy3-p539
            }}}
        'Conversely, in-place changes to objects do not classify names as locals; only actual name assignments do. (????)
            {{{
            For instance, if the name L is assigned to a list at the top level of a module, a statement L = X within a function will classify L as a local, but L.append(X) will not. (!)
                = 'As usual, it helps to keep the distinction between names and objects clear: changing an object is not an assignment to a name.
            --
            lpy3-p540
            }}}
        Name Resolution: The LEGB Rule ** (!) @
            {{{
            • Name references search at most four scopes: local, then enclosing functions (if any), then global, then built-in.
            --
            lpy3-p540
            }}}
        using and changing names assigned in syntactically enclosing functions and the global scope, **
            {{{
            = 'Functions can freely use names assigned in syntactically enclosing functions and the global scope, but they must declare such nonlocals and globals in order to change them.
            --
            lpy3-p540
            }}}
        a qualified attribute name (**)
            {{{
            e.g. object.spam
            --
            lpy3-p541
            }}}
            ----

            ----
        Though obscure at this point in the book, there are technically three more scopes in Python (!) (@)
            {{{
            - temporary loop variables in some comprehensions, exception reference variables in some try handlers, and local scopes in class statements.
                The first two of these are special cases that rarely impact real code, and the third falls under the LEGB umbrella rule.
            (+ ' • Comprehension variables - the variable X used to refer to the current iteration item in a comprehension expression such as [X for X in I].
              .
            In 2.X, they are local to generator expressions and set and dictionary compressions(=comprehensions), but not to list comprehensions that map their names to the scope outside the expression.
              ( +
            (By contrast, for loop statements never localize their variables to the statement block in any Python.
            --
            lpy3-p541
            }}}
        Scope Example  = 'Let’s step through a larger example that demonstrates scope ideas.
            {{{
              .
              .
            Y and Z are local to the function (and exist only while the function runs) because they are both assigned values in the function definition: Z by virtue of the = statement, and Y because arguments are always passed by assignment.
            --
            lpy3-p542
            }}}
        The Built-in Scope (=query it etc)  * (@@)
            {{{
            Really, the built-in scope is just a built-in module called builtins, but you have to import builtins to query built-ins because the name builtins is not itself built in...
                (+ 'The Python 3.X builtins module used here is named __builtin__ in Python 2.X.
              .
            >>> import builtins
            >>> dir(builtins)
            ['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException',
              ...
              ...
            'ord', 'pow', 'print', 'property', 'quit', 'range', 'repr', 'reversed',
            'round', 'set', 'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum',
            'super', 'tuple', 'type', 'vars', 'zip']
                The names in this list constitute the built-in scope in Python; roughly the first half are built-in exceptions, and the second half are built-in functions.
            Because Python automatically searches this module last in its LEGB lookup, you get all the names in this list “for free” - that is, you can use them without importing any modules.
              .
            >>> import builtins		# The hard way: for customizations
            >>> builtins.zip
            <class 'zip'>
            --
            lpy3-p544
            }}}
        renaming built-in names on purpose (**!)
            {{{
            In fact, there are times in advanced programming where you may really want to replace a built-in name by redefining it in your code - to define a custom open that verifies access attempts, for instance (see this chapter’s sidebar “Breaking the Universe in Python 2.X” on page 494 for more on this thread).
            --
            lpy3-p545
            }}}
        tools that can help you guard against unintentionally renaming Python built-in names * @
            {{{
            Tools like PyChecker (see the Web)
            --
            lpy3-p545
            }}}
        If you accidentally reassign a built-in name at the interactive prompt this way, you can either (!!)
            {{{
            restart your session or run a del name statement to remove the redefinition from your scope,
                thereby restoring the original in the built-in scope.
            --
            lpy3-p545
            }}}
        (+ the special __builtins__ name (*))
            {{{
              ...
              ...
               .
            2.X, but we are advised to use builtins for real work and customization in 3.X, and __builtin__ for the same in 2.X.
            --
            lpy3-p546
            }}}
        'Breaking the Universe in Python 2.X
            {{{
            '- because the names True and False in 2.X are just variables in the built-in scope and are not reserved, ...
              ...
              ...
            'This technique can be useful, however, both to illustrate the underlying namespace model, and for tool writers who must change built-ins such as open to customized functions.
            --
            lpy3-p546
            }}}
            ----

            ----
        Some linting tools for Python (**(?)) @@
            {{{
            PyChecker, and others such as PyLint,
                = 'It’s not a bad idea to run your first few Python programs through tools like these to see what they point out.
            --
            lpy3-p546
            }}}
        The global statement and its nonlocal 3.X cousin are the (sort of) ____ declaration statements
            {{{
            = namespace declarations.
            --
            lpy3-p546
            }}}
        The global statement tells Python that **
            {{{
            a function plans to change one or more global names - that is, names that live in the enclosing module’s scope (namespace).
            --
            lpy3-p546
            }}}
        The global statement consists of ** (!) (!! ?????)
            {{{
            the keyword global, followed by one or more names separated by commas.
              .
            y, z = 1, 2			# Global variables in module
            def all_global():
                global x		# Declare globals assigned
                x = y + z		# No need to declare y, z: LEGB rule
            --
            lpy3-p547
            }}}
        design tips (concerning) functions and globals * @
            {{{
            (= reducing coupling, etc)
                (+ plus sometimes and especially if expected, globals can be a good method for retaining state)
              .
            'Program Design: Minimize Cross-File Changes
                Here’s another scope-related design issue: although we can change variables in another file directly, we usually shouldn’t.
                  .
                Here again, the best prescription is generally to not do this - the best way to communicate across file boundaries is to call functions, passing in arguments and getting back return values.
              In this specific case, we would probably be better off coding an accessor function to manage the change:
                (+ 'Unlike modules, classes can also intercept attribute fetches automatically with operator overloading, even when accessors aren’t used by their clients. (??)
            --
            lpy3-p548
            }}}
        (Threading is commonly used for (@)
            {{{
            long-running tasks in GUIs,
            to implement nonblocking operations in general and
            to maximize CPU capacity.
            --
            lpy3-p549
            }}}
                ----

                ----
        'Other Ways to Access Globals
            {{{
            emulate the global statement by importing the enclosing module and assigning to its attributes, as in the following example module file.
            Code in this file imports the enclosing module, first by name, and then by indexing the sys.modules loaded modules table (more on this table in Chapter 22 and Chapter 25):
                This works, and it illustrates the equivalence of globals to module attributes, but it’s much more work than using the global statement to make your intentions explicit.
            --
            lpy3-p550,p551
            }}}
        Scopes and Nested Functions (@)
            {{{
                relatively uncommon to encounter it in practice.
            sometimes also called statically nested scopes.
              (+Ex: p552
               = 'Because functions can access names in all physically enclosing def statements, the X in f2 is automatically mapped to the X in f1, by the LEGB lookup rule.
               This enclosing scope lookup works even if the enclosing function has already returned.
            --
            lpy3-p551--p553
            }}}
        'For example, the following code defines a function that makes and returns another function, and represents a more common usage pattern: @
            {{{
            def f1():
                X = 88
                def f2():
                    print(X)	# Remembers X in enclosing def scope
                return f2		# Return f2 but don't call it
              .
            action = f1()		# Make, return function
            action()		# Call it now: prints 88
              .
            In this code, the call to action is really running the function we named f2 when f1 ran.
            This works because functions are objects in Python like everything else, and can be passed back as return values from other functions.
                Most importantly, f2 remembers the enclosing scope’s X in f1, even though f1 is no longer active - ((which leads us to the next topic. (=closures))
            --
            lpy3-p553
            }}}
        another name for closures (**) (+ their characteristics) (@)
            {{{
            this sort of behavior is also sometimes called a closure or a factory function - the former describing a functional programming technique, and the latter denoting a design pattern.
                Whatever the label, the function object in question remembers values in enclosing scopes regardless of whether those scopes are still present in memory.
            In effect, they have attached packets of memory (a.k.a. state retention), which are local to each copy of the nested function created, and often provide a simple alternative to classes in this role.
            --
            lpy3-p553
            }}}
        A simple function factory + Ex. usage (*(*)) (@)
            {{{
            sometimes used by programs that need to generate event handlers on the fly in response to conditions at runtime.
            For instance, imagine a GUI that must define actions according to user inputs that cannot be anticipated when the GUI is built.
                In such cases, we need a function that creates and returns another function, with information that may vary per function made.
              .
            >>> def maker(N):
                def action(X):		# Make and return action
                    return X ** N	# action retains N from enclosing scope
                return action
              .
            This defines an outer function that simply generates and returns a nested function, without calling it - maker makes action, but simply returns action without running it.
              ...
              ...
            In other words, we’re calling the nested function that maker created and passed back.
               +
               +
            Perhaps the most unusual part of this, though, is that the nested function remembers integer 2, the value of the variable N in maker, even though maker has returned and exited by the time we call action.
            In effect, N from the enclosing local scope is retained as state information attached to the generated action, which is why we get back its argument squared when it is later called.
              .
            >>> g = maker(3)	# g remembers 3, f remembers 2
            >>> g(4)			# 4 ** 3
            64
            >>> f(4)		# 4 ** 2
            16
            --
            For example, a lambda would serve in place of a def in our example:
              .
            >>> def maker(N):
                    # lambda functions retain state too
                return lambda X: X ** N
              .
            >>> h = maker(3)
            >>> h(4)			# 4 ** 3 again
            64
            --
            lpy3-p553,p554
            }}}
        Closures versus classes, round 1 (!) (@)
            {{{
            they make their memory more explicit with attribute assignments. Classes also directly support additional tools that closure functions do not,
                 = customization by inheritance and operator overloading, and more naturally implement multiple behaviors in the form of methods.
            Still, closure functions often provide a lighter-weight and viable alternative when retaining state is the only goal.
            --
            lpy3-p555
            }}}
        'From a broader perspective, there are multiple ways for Python functions to retain state between calls.
            {{{
            Although the values of normal local variables go away when a function returns, values can be retained from call to call
                in global variables; in class instance attributes; in the enclosing scope references we’ve met here; and in argument defaults and function attributes.
                Some might include mutable default arguments to this list too (though others may wish they didn’t).
            --
            lpy3-p555
            }}}
            ----

            ----
        Closures can also be created when a class is nested in a def: (!) (@)
            {{{
            eg. becomes a "class factory"
            --
            lpy3-p556
            }}}
        Retaining Enclosing Scope State with Defaults
            {{{
            (= party because the first versions of Python didn't search the enclosing scope)
              .
            def f1():
                x = 88
                def f2(x=x):  # Remember enclosing scope X with defaults
                    print(x)
                f2()
              .
            f1()		# Prints 88
              .
            In fact, it’s still required for loop variables, as we’ll see in a moment, which is why it remains worth studying today.
              .
              .
            Of course, the best prescription for much code is simply to avoid nesting defs within defs, as it will make your programs much simpler - in the Pythonic view, flat is generally better than nested.
              .
              .
            >>> def f1():
            x = 88		# Pass x along instead of nesting
            f2(x)		# Forward reference OK
              .
            >>> def f2(x):
                print(x)	# Flat is still often better than nested!
              .
            >>> f1()
            88
            --
            lpy3-p556,p557
            }}}
        The use of lambdas (=exposé 1) *
            {{{
            'Because it’s an expression, though, it can be used in places that def cannot, such as within list and dictionary literals.
                ': in most cases, it is no longer necessary to pass values into lambdas with defaults.
            --
            lpy3-p557
            }}}
        Loop variables may require defaults, not scopes (!) (@)
            {{{
            if a lambda or def defined within a function is nested inside a loop, and the nested function references an enclosing scope variable that is changed by that loop,
                all functions generated within the loop will have the same value - the value the referenced variable had in the last loop iteration.
            In such cases, you must still use defaults to save the variable’s current value instead.
              .
            This may seem a fairly obscure case, but it can come up in practice more often than you may think, especially in code that generates callback handler functions for a number of widgets in a GUI - for instance, handlers for button-clicks for all the buttons in a row.
            If these are created in a loop, you may need to be careful to save state with defaults, or all your buttons’ callbacks may wind up doing the same thing. (!!) **
              .
            + Ex: 'Here’s an illustration of this phenomenon reduced to simple code: the following attempts to build up a list of functions that each remember the current variable i from the enclosing scope:
              .
            >>>	acts[0](2)	# All are 4 ** 2, 4=value of last i
              .
              .
            >>> def makeActions():
                acts = []
                for i in range(5):		# Use defaults instead
                    acts.append(lambda x, i=i: i ** x)  # Remember current i
                return acts
              .
            >>> acts = makeActions()
            >>> acts[0](2)  # 0 ** 2
            0
            >>> acts[1](2)  # 1 ** 2
            1
            >>> acts[2](2)  # 2 ** 2
            4
            >>> acts[4](2)  # 4 ** 2
            16
            --
            + 'This seems an implementation artifact that is prone to change, and may become more important as you start writing larger programs.
            --
            lpy3-p558,p559
            }}}
        'This makes nested scope closures more useful, by providing changeable state information.
            {{{
            The nonlocal statement
                Also unlike global, nonlocal names must already exist in the enclosing function’s scope when declared - they can exist only in enclosing functions and cannot be created by a first assignment in a nested def.
            --
            lpy3-p560
            }}}
        more/basics of nonlocal (*)
            {{{
            'That is, nonlocal also means “skip my local scope entirely.” In fact, the names listed in a nonlocal must have been previously defined in an enclosing def when the nonlocal is reached, or an error is raised.
            --
            lpy3-p561
            }}}
        the 'tester' example (!)
            {{{
            ((SEE MORE))
            --
            lpy3-p562--p563
            }}}
        subtleties to be aware of. (= w. nonlocals (!!)
            {{{
            must have previously been assigned in an enclosing def’s scope when a nonlocal is evaluated,
            --
            lpy3-p563
            }}}
        Why nonlocal? State Retention Options (@)
            {{{
            =  , many applications require such values to differ per context of use.
            It(=nonlocals) addresses simple state retention needs where classes may not be warranted and global variables do not apply, though function attributes can often serve similar roles more portably.
            --
            lpy3-p564
            }}}
            ----

            ----
        state retention options in Pythons earlier than 3 (*)
            {{{
            State with Globals: A Single Copy Only
                requires global declarations in both functions and is prone to name collisions in the global scope
                only allows for a single shared copy of the state information in the module scope
            State with Classes: Explicit Attributes (Preview)
                To make sense of this code, you need to know that a def within a class like this works exactly like a normal def, except that the function’s self argument automatically receives the implied subject of the call (an instance object created by calling the class itself). The function named __init__ is run automatically when the class is called:
                With just slightly more magic - which we’ll delve into later in this book - we could also make our class objects look like callable functions using operator overloading.  __call__ intercepts direct calls on an instance, so we don’t need to call a named method:
              While using classes for state information is generally a good rule of thumb to follow, they might also be overkill in cases like this, where state is a single counter.
              Such trivial state cases are more common than you might think; in such contexts, nested defs are sometimes more lightweight than coding classes, especially if you’re not familiar with OOP yet.
            --
            lpy3-p565
            }}}
        State with Function Attributes: 3.X and 2.X (@)
            {{{
            can also sometimes achieve the same effect as nonlocals with function attributes - user-defined names attached to functions directly.
                = When you attach user-defined attributes to nested functions generated by enclosing factory functions, they can also serve as per-call, multiple copy, and writeable state, just like nonlocal scope closures and class attributes.
            Such user-defined attribute names won’t clash with names Python creates itself, and as for nonlocal, need be used only for state variables that must be changed; other scope references are retained and work normally.
            Crucially, this scheme is portable - like classes, but unlike nonlocal, function attributes work in both Python 3.X and 2.X.
              .
            Moreover, function attributes allow state variables to be accessed outside the nested function, like class attributes; with nonlocal, state variables can be seen directly only within the nested def. If you need to access a call counter externally, it’s a simple function attribute fetch in this model.
              .
            >>> def tester(start):
                def nested(label):
                        # nested is in enclosing scope
                    print(label, nested.state)
                    nested.state += 1	# Change attr, not nested itself
                nested.state = start	# Initial state after func defined
                return nested
              .
            >>> F = tester(0)
            >>> F('spam')		# F is a 'nested' with state attached
            spam 0
            >>> F('ham')
            ham 1
            >>> F.state			# Can access state outside functions too
            2
              .
            This scheme may not seem as intuitive to some at first glance; you access state though the function’s name instead of as simple variables, and must initialize after the nested def.
            Still, it’s far more portable, allows state to be accessed externally, and saves a line by not requiring a nonlocal declaration:
              .
            Because each call to the outer function produces a new nested function object, this scheme supports multiple copy per-call changeable data just like nonlocal closures and classes - a usage mode that global variables cannot provide:
              (+ Test-Ex.  )
            Subjective factors aside, function attributes’ utility does overlap with the newer nonlocal in 3.X, making the latter technically redundant and far less portable.
            --
            lpy3-p566--p568
            }}}
        ((State with mutables: Obscure ghost of Pythons past? (@)
            {{{
            On a related note, it’s also possible to change a mutable object in the enclosing scope in 2.X and 3.X without declaring its name nonlocal. (??)
              .
              .
            You’re probably better off using named function attributes than lists and numeric offsets this way, though this may show up in code you must use.
        We’ll revisit all the state options introduced here in Chapter 39 in a more realistic context - decorators, a tool that by nature involves multilevel state retention.
            --
            lpy3-p569
            }}}
        time code speed (!)
            {{{
            Chapter 21).
            --
            lpy3-p569
            }}}
        changing the built-in open call to a custom version, as suggested in this chapter’s earlier sidebar “Breaking the Universe in Python 2.X” (!)(**)
            {{{
            If the custom version needs to call the original, it must save it before changing it, and retain it for later use - a classic state retention scenario.
            Moreover, if we wish to support multiple customizations to the same function, globals won’t do: we need per-customizer state.
              .
            import builtins
            def makeopen(id):
                original = builtins.open
                def custom(*kargs, **pargs):
                    print('Custom open call %r:' % id , kargs, pargs)
                    return original(*kargs, **pargs)
                builtins.open = custom
              .
            To change open for every module in a process, this code reassigns it in the built-in scope to a custom version coded with a nested def, after it saving the original in the enclosing scope so the customization can call it later.
            --
            lpy3-p569
            }}}
        questions and answers about functions, variables and scope (**)!
            {{{
            --
            lpy3-p572,p573
            }}}
            ----

        Chapter 18 - Arguments

            ----
        Python argument passing
            {{{
            - the way that objects are sent to functions as inputs.
                As we’ll see, arguments (a.k.a. parameters) are assigned to names in a function, but they have more to do with object references than with variable scopes.
            --
            lpy3-p575
            }}}
        Argument-Passing Basics (@
            {{{
            Earlier in this part of the book, I noted that arguments are passed by assignment.
            • Arguments are passed by automatically assigning objects to local variable names.
              .
              .
            Because references are implemented as pointers, all arguments are, in effect, passed by pointer. Objects passed as arguments are never automatically copied.
            • Assigning to argument names inside a function does not affect the caller.
            • Changing a mutable object argument in a function may impact the caller.
            --
            lpy3-p575
            }}}
        • Immutable arguments are effectively passed (!)
            {{{
            “by value.”
            • Immutable arguments are effectively passed “by value.” Objects such as integers and strings are passed by object reference instead of by copying, but because you can’t change immutable objects in place anyhow, the effect is much like making a copy.
            --
            lpy3-p576
            }}}
        • Mutable arguments are effectively passed (!)
            {{{
            “by pointer.”
                Objects such as lists and dictionaries are also passed by object reference, which is similar to the way C passes arrays as pointers - mutable objects can be changed in place in the function, much like C arrays.
            --
            lpy3-p576
            }}}
        Arguments and Shared References * (@)
            {{{
            'To illustrate argument-passing properties at work, consider the following code:
            'In this example the variable a is assigned the object 88 at the moment the function is called with f(b), but a lives only within the called function. Changing a inside the function has no effect on the place where the function is called; it simply resets the local variable a to a completely different object.
            That’s what is meant by a lack of name aliasing - assignment to an argument name inside a function (e.g., a=99) does not magically change a variable like b in the scope of the function call. (!) (??)
                When arguments are passed mutable objects like lists and dictionaries, we also need to be aware that inplace changes to such objects may live on after a function exits, and hence impact callers.
             (+ Ex. )
              .
              .
              .
            This in-place change impacts the caller only because the changed object outlives the function call.
            + 'In effect, the list name L serves as both input to and output from the function.
            (+ 'If this example is still confusing, it may help to notice that the effect of the automatic assignments of the passed-in arguments is the same as running a series of simple assignment statements.
            --
            lpy3-p576
            }}}
        Avoiding Mutable Argument Changes @
            {{{
            This behavior of in-place changes to mutable arguments isn’t a bug - it’s simply the way argument passing works in Python, and turns out to be widely useful in practice.
            (Eg. Classes (*)
                If we don’t want in-place changes within functions to impact objects we pass to them, though, we can simply make explicit copies of mutable objects, as we learned in Chapter 6.
              .
            L = [1, 2]
                # Pass a copy, so our 'L' does not change
            changer(X, L[:])
              .
            We can also copy within the function itself, if we never want to change passed-in objects, regardless of how the function is called:
              .
            def changer(a, b):
                b = b[:]	# Copy input list so we don't impact caller
                a = 2
                b[0] = 'spam'	# Changes our list copy only
              .
            To really prevent changes, we can always convert to immutable objects to force the issue. Tuples, for example, raise an exception when changes are attempted:
            L = [1, 2]
                # Pass a tuple, so changes are errors
            changer(X, tuple(L))
            --
            lpy3-p578
            }}}
        Simulating Output Parameters and Multiple Results (@)
            {{{
            'In fact, although Python doesn’t support what some languages label “call by reference” argument passing, we can usually simulate it by returning tuples and assigning the results back to the original argument names in the caller:
              .
            The net effect of this coding pattern is to both send back multiple results and simulate the output parameters of other languages by explicit assignments.
                (+ 'In Python 2.X, it’s also possible to automatically unpack tuples in arguments passed to a function.
              .
            This def syntax is no longer supported in Python 3.X.  Instead, code this function as:
            def f(T): (a, (b, c)) = T
                to unpack in an explicit assignment statement.
            --
            lpy3-p578
            }}}
                ----

                ----
        Argument Matching Basics (+Extras) ** @
            {{{
            By default, arguments are matched by position, from left to right, and you must pass exactly as many arguments as there are argument names in the function header.
            However, you can also specify matching by name, provide default values, and use collectors for extra arguments.
                In fact, some of these tools are intended more for people writing libraries than for application developers.
            --
            lpy3-p581
            }}}
          the most commonly used (= of these special forms) in Python code. @
            {{{
            keyword arguments (= like previously used to specify options to the print command)  and defaults
            --
            lpy3-p582
            }}}
        Keywords: matched by argument name @
            {{{
            name=value
            --
            lpy3-p581
            }}}
        Defaults: specify values for optional arguments that aren’t passed @
            {{{
            again using the name=value syntax.
            --
            lpy3-p581
            }}}
        Varargs collecting: collect arbitrarily many positional or keyword arguments * @(@)
            {{{
            Functions can use special arguments preceded with one or two * characters to collect an arbitrary number of possibly extra arguments.
                in Python, the arguments are collected in a normal object.
            --
            lpy3-p581
            }}}
        Varargs unpacking: pass arbitrarily many positional or keyword arguments @@
            {{{
            use the * syntax to unpack argument collections into separate arguments.
                inverse of a * in a function header
            - in the header it means collect arbitrarily many arguments, while
            in the call it means unpack arbitrarily many arguments, and pass them individually as discrete values.
            --
            lpy3-p581
            }}}
        Keyword-only arguments: arguments that must be passed by name (=Py 3) (@)
            {{{
            typically used to define configuration options in addition to actual arguments.
            --
            lpy3-p581
            }}}
        Table that summarizes the syntax that invokes the special argument-matching modes.
            {{{
            18-1
            --
            lpy3-p582
            }}}
            ----

            ----
        Pass all objects in iterable as individual positional arguments * @
            {{{
            func(*iterable)
            --
            lpy3-p582
            }}}
        Pass all key/value pairs in dict as individual keyword arguments * @
            {{{
            func(**dict)
            --
            lpy3-p582
            }}}
        Matches and collects remaining positional arguments in a tuple / dictionary @
            {{{
            def func(*name)
              .
            def func(**name)
            --
            lpy3-p582
            }}}
        Arguments that must be passed by keyword only in calls (3.X) (*) (@)
            {{{
            def func(*other, name)
              .
            def func(*, name=value)
            --
            lpy3-p582
            }}}
        In Python 3.X, any normal or defaulted argument names following a *name or a bare * are (!) (@)
            {{{
            keyword-only arguments and must be passed by keyword in calls.
            --
            lpy3-p582
            }}}
            ----

            ----
        - keywords (= ) allow us to
            {{{
            label any argument with its name, to make calls more informational.
            --
            lpy3-p582
            }}}
        • We met defaults earlier, too, (= ) as (@)
            {{{
            a way to pass in values from the enclosing function’s scope,
                + allow us to make any argument optional, providing its default value in a function definition.
            --
            lpy3-p582
            }}}
        'The Gritty Details'  (= 'If you choose to use and combine the special argument-matching modes, Python will ask you to follow these ordering rules among the modes’ optional components: (@)
            {{{
            • In a function call,
                pos
                keyw  *it
                **dict
                  **args
            • In a function header,
                name
                def.
                *name
                name|name=val
                **name
                  **args
              .
            1. Assign nonkeyword arguments by position.
            2. Assign keyword arguments by matching names.
            3. Assign extra nonkeyword arguments to *name tuple.
            4. Assign extra keyword arguments to **name dictionary.
            5. Assign default values to unassigned arguments in header.
            --
            lpy3-p583
            }}}
        Py 3: function header argument name annotation values | function annotation value (**) (??@)
            {{{
            name:value (or name:value=default when defaults are present).
              .
            The function itself can also have an annotation value, given as def f()->value.
            --
            lpy3-p584
            }}}
        keyword arguments: Call function with arguments a, b and c in mixed order ** (@)
            {{{
            >>> f(c=3, b=2, a=1)
            1 2 3
              .
                # a gets 1 by position, b and c passed by name
            >>> f(1, c=3, b=2)
            --
            lpy3-p584
            }}}
        Keywords' roles  = make your calls a bit more selfdocumenting ( * (@)
            {{{
            func(name='Bob', age=40, job='dev')
            - the keywords serve as labels for the data in the call.
            --
            lpy3-p584
            }}}
                ----

                ----
        function that requires one argument and defaults two: ** @
            {{{
                # a required, b and c optional
            >>> def f(a, b=2, c=3): print(a, b, c)
              .
              .
            >>> f(1, 4)		# Override defaults
            1 4 3
            >>> f(1, 4, 5)  # -"- both def.s
            1 4 5
            --
            lpy3-p585
            }}}
        'Finally, here is how the keyword and default features interact. (??) ** (@)
            {{{
            Because they subvert the normal left-to-right positional mapping, keywords allow us to essentially skip over arguments with defaults:
              .
            >>> f(1, c=6)		# Choose defaults
            1 2 6
            --
            lpy3-p585
            }}}
        Be careful not to confuse the special name=value syntax in a function header and a function call; (!!) ****(**) @
            {{{
            in the call it means a match-by-name keyword argument, while in the header it specifies a default for an optional argument.
            --
            lpy3-p585
            }}}
        'Here is a slightly larger example that demonstrates keywords and defaults in action. (SSSS) (@)
            {{{
            the caller must always pass at least two arguments (to match spam and eggs), but the other two are optional.
            --
            lpy3-p585,p586
            }}}
        Beware mutable defaults: (!!)
            {{{
            As footnoted in the prior chapter, if you code a default to be a mutable object (e.g., def f(a=[])), the same, single mutable object is reused every time the function is later called - even if it is changed in place within the function.
              .
              .
            The net effect is that the argument’s default retains its value from the prior call, and is not reset to its original value coded in the def header.
                To reset anew on each call, move the assignment into the function body instead.
            [[Mutable defaults allow state retention, but this is often a surprise. Since this is such a common trap, we’ll postpone further exploration until this part’s “gotchas” list at the end of Chapter 21.
            --
            lpy3-p586
            }}}
            ----

            ----
        Arbitrary Arguments Examples: 'The last two matching extensions, * and **, are designed to
            {{{
            support functions that take any number of arguments.
            --
            lpy3-p586
            }}}
        Headers: (= )Collecting arguments
            {{{
            collects unmatched positional arguments into a tuple:
                >>> def f(*args): print(args)
            When this function is called, Python collects all the positional arguments into a new tuple and assigns the variable args to that tuple.
            --
            lpy3-p586
            }}}
        The ** feature (@)
            {{{
            only works for keyword arguments
                - it collects them into a new dictionary, which can then be processed with normal dictionary tools.
              .
            >>> def f(**args): print(args)
              .
            >>> f()
            {}
            >>> f(a=1, b=2)
            {'a': 1, 'b': 2}
            --
            lpy3-p587
            }}}
        'Finally, function headers can combine normal arguments, the *, and the ** to implement wildly flexible call signatures.
            {{{
            >>> def f(a, *pargs, **kargs): print(a, pargs, kargs)
              .
            >>> f(1, 2, 3, x=1, y=2)
            1 (2, 3) {'y': 2, 'x': 1}
              .
            Such code is rare, but shows up in functions that need to support multiple call patterns (for backward compatibility, for instance).
            --
            lpy3-p587
            }}}
        * | ** in function calls  (*) @(@)
            {{{
            In all recent Python releases, we can use the * syntax when we call a function, too.
            In this context, its meaning is the inverse of its meaning in the function definition - it unpacks a collection of arguments,
              .
            >>> def func(a, b, c, d): print(a, b, c, d)
              .
            >>> args = (1, 2)
            >>> args += (3, 4)
            >>> func(*args)		# Same as func(1, 2, 3, 4)
            1 2 3 4
              .
              .
            >>> args = {'a': 1, 'b': 2, 'c': 3}
            >>> args['d'] = 4
              .
                # Same as func(a=1, b=2, c=3, d=4)
            >>> func(**args)
            1 2 3 4
            --
            lpy3-p587
            }}}
        'Again, we can combine normal, positional, and keyword arguments in the call in very flexible ways: (SSS) * (@)
            {{{
              .
              .
              .
              .
              .
            + 'This sort of code is convenient when you cannot predict the number of arguments that will be passed to a function when you write your script; you can build up a collection of arguments at runtime instead and call the function generically this way.
            --
            lpy3-p588
            }}}
        te: In both (=header and call) , one star means ____, and two (stars) applies to ____. *(*)
            {{{
            In both,
               one star means positionals, and
               two applies to keywords.
            --
            lpy3-p588
            }}}
            ----

          ((crap: p-nums = 589))

            ----
        Tip(!): the *pargs form in a call is an iteration context, (**) @
            {{{
            a file object works after the *, and unpacks its lines into individual arguments
                (e.g., func(*open('fname')).
            ( This generality is supported in both Python 3.X and 2.X, but it holds true only for calls -
            --
            lpy3-p588
            }}}
        ''The prior section’s examples may seem academic (if not downright esoteric),  (=argument unpacking etc **)
            {{{
            used more often than you might expect. Some programs need to call arbitrary functions in a generic fashion, without knowing their names or arguments ahead of time.
                = the real power of the special “varargs” call syntax is that you don’t need to know how many arguments a function call requires before you write a script.
            For example, you can use if logic to select from a set of functions and argument lists, and call any of them generically (functions in some of the following examples are hypothetical):
            if sometest:
                    # Call func1 with one arg in this case
                action, args = func1, (1,)
            else:
                    # Call func2 with three args here
                action, args = func2, (1, 2, 3)
            ...etc...
            action(*args)	# Dispatch generically
            = ''This leverages both the * form, and the fact that functions are objects that may be both referenced by, and called through, any variable. (??)
            If your user selects an arbitrary function via a user interface, for instance, you may be unable to hardcode a function call when writing your script. **
            ( 'To work around this, simply build up the arguments list with sequence operations, and call it with starred-argument syntax to unpack the arguments: (SSS **)
            --
            lpy3-p588
            }}}
        Tip: ''Because the arguments list is passed in as a tuple here, the program can build it at runtime.'' (=good use case for) (!) (@)
            {{{
            = 'This technique also comes in handy for functions that test or time other functions.
            For instance, in the following code we support any function with any arguments by passing along whatever arguments were sent in (this is file tracer0.py in the book examples package): (SS Ee *!)
            --
            lpy3-p588
            }}}
        the  __name__ attribute attached to every function (!)
            {{{
            = the function’s name string),
            --
            lpy3-p588
            }}}
        -- The defunct apply built-in (Python 2.X) (@)
            {{{
            Prior to Python 3.X, the effect of the *args and **args varargs call syntax could be achieved with a built-in function named apply.
                ((This original technique has been removed in 3.X because it is now redundant (3.X cleans up many such dusty tools that have been subsumed over the years).
              .
                # Newer call syntax: func(*sequence, **dict)
            func(*pargs, **kargs)
                # Defunct built-in: apply(func, sequence, dict)
            apply(func, pargs, kargs)
            --
            lpy3-p590
            }}}
                ----

                ----
        the newer preferred syntax variant of  apply(pow, (2, 100)) ** (!) !@@
            {{{
            >>> pow(*(2, 100))
            --
            lpy3-p590
            }}}
        Advantages of the newer unpacking syntax (**)
            {{{
            symmetry with the * collector forms in def headers,
            newer call syntax also allows us to pass along additional arguments without having to manually extend argument sequences or dictionaries:
              .
                # Normal, keyword, *sequence, **dictionary
            >>> echo(0, c=5, *pargs, **kargs)
            (0, 1, 2) {'a': 3, 'c': 5, 'b': 4}
            'That is, the call syntax form is more general.
            --
            lpy3-p590
            }}}
        reasons to know about and still use apply (!)
            {{{
            maintaining Python 2 code
            --
            lpy3-p590
            }}}
        Tip (=Py 3): 'if we want a function to both process any number of arguments and accept possibly optional configuration options. * @
            {{{
            Python 3.X generalizes the ordering rules in function headers to allow us to specify keyword-only arguments - arguments that must be passed by keyword only and will never be filled in by a positional argument.
                = coded as named arguments that may appear after *args in the arguments list.
            ' a may be passed by name or position, b collects any extra positional arguments, and c must be passed by keyword only.
            >>> def kwonly(a, *b, c):
                print(a, b, c)
            --
            lpy3-p591
            }}}
        'We can also use a * character by itself in the arguments list to indicate that ** (@)
            {{{
            a function does not accept a variable-length argument list but still expects all arguments following the * to be passed as keywords.
              .
            >>> def kwonly(a, *, b, c):
                print(a, b, c)
            --
            lpy3-p591
            }}}
        (('In the following code, a may be passed by name or position, and b and c are optional but must be passed by keyword if used:
            {{{
            >>> def kwonly(a, *, b='spam', c='ham'):
                print(a, b, c)
            --
            lpy3-p591
            }}}
        (('In fact, keyword-only arguments with defaults are optional, but those without defaults effectively become required keywords for the function: (ssss !! (??) @
            {{{
            >>> def kwonly(a, *, b, c='spam'):
                print(a, b, c)
            --
            lpy3-p592
            }}}
        ('Ordering rules (SsssSsss) (@)
            {{{
              .
              .
              .
            ('This means that in a function header, keyword-only arguments must be coded before the **args arbitrary keywords form and after the *args arbitrary positional form, when both are present.
              .
              .
            They may appear to be worst cases in the artificial examples here, but they can come up in real practice, especially for people who write libraries and tools for other Python programmers to use.
            --
            lpy3-p592
            }}}
                ----

                ----
        te: Why keyword-only arguments? * @
            {{{
            In short, they make it easier to allow a function to accept both any number of positional arguments to be processed, and configuration options passed as keywords.
            process(X, Y, Z)	# Use flag's default
            process(X, Y, notify=True)	# Override flag default
            Without keyword-only arguments we have to use both *args and **args and manually inspect the keywords, but with keyword-only arguments less code is required.
            The following guarantees that no positional argument will be incorrectly matched against notify and requires that it be a keyword if passed:
            def process(*args, notify=False): ...
            --
            Since we’re going to see a more realistic example of this later in this chapter, in “Emulating the Python 3.X print Function,” I’ll postpone the rest of this story until then.
            For an additional example of keyword-only arguments in action, see the iteration options timing case study in Chapter 21.
            --
            lpy3-p593
            }}}
        an exercise that demonstrates a practical application of argument-matching tools. **(!) (SSSS)
            {{{
            The min Wakeup Call!
            That is, the function should accept zero or more arguments, as many as you wish to pass. Moreover, the function should work for all kinds of Python object types: numbers, strings, lists, lists of dictionaries, files, and even None.
                'The first requirement provides a natural example of how the * feature can be put to good use - we can collect arguments into a tuple and step over each of them in turn with a simple for loop.
              ...
              ...
              .
              .
            The following file shows three ways to code this operation, at least one of which was suggested by a student in one of my courses (this example is often a group exercise to circumvent dozing after lunch):
              (+ Explanations of how the three functions work **)
            + 'Notice that none of these three variants tests for the case where no arguments are passed in. They could, but there’s no point in doing so here - in all three solutions, Python will automatically raise an exception if no arguments are passed in.
            (= '- because these functions support any data type, there is no valid sentinel value that we could pass back to designate an error,
            [[+ for an exact (=timing) analysis, you should time the alternatives with the time or timeit modules - we’ll see how in Chapter 21.
            --
            lpy3-p594--p595
            }}}
        [minmax.py ((*))  (+Easily generalizing functions) **(!!) @(@)
            {{{
            def minmax(test, *args):
                res = args[0]
                for arg in args[1:]:
                    if test(arg, res):
                        res = arg
                return res
              .
                # See also: lambda, eval
            def lessthan(x, y): return x < y
            def grtrthan(x, y): return x > y
              .
                # Self-test code
            print(minmax(lessthan, 4, 2, 1, 5, 6, 3))
            print(minmax(grtrthan, 4, 2, 1, 5, 6, 3))
              .
              .
            To make this a max (or other) function, for example, we simply pass in the right sort of test function.
            This may seem like extra work, but the main point of generalizing functions this way - instead of cutting and pasting to change just a single character - is that we’ll only have one version to change in the future, not two. **
            --
            lpy3-p595,p596
            }}}
        Ex: 'Generalized Set Functions (!!) (SSs)  (+ coding function for testing the function(!) p598)
            {{{
            At the end of Chapter 16, we wrote a function that returned the intersection of two sequences (it picked out items that appeared in both). Here is a version that intersects an arbitrary number of sequences (one or more) by using the varargs matching form *args to collect all the passed-in arguments.
                + 'Just for fun, we’ll code a union function that also accepts an arbitrary number of arguments to collect items that appear in any of the operands:
              (+Note: The example has many good comments(!))
            --
            lpy3-p597
            }}}
        Storing Functions (eg. the generalized set functions in prev. ex.) in library|utility modules (**!!) (@)
            {{{
            Because these are tools potentially worth reusing (and they’re too big to retype interactively), we’ll store the functions in a module file called inter2.py
                (if you’ve forgotten how modules and imports work, see the introduction in Chapter 3, or stay tuned for in-depth coverage in Part V).
            --
            lpy3-p597
            }}}
        (some notes about the testing function and improvements (*!))
            {{{
            'The argument scrambling here doesn’t generate all possible argument orders (that would require a full permutation, and 24 orderings for 4 arguments), but suffices to check if argument order impacts results here.
            Also notice that the argument scrambling in our tester function might be a generally useful tool, and the tester would be simpler if we delegated this to another function, one that would be free to create or generate argument combinations as it saw fit: **
                ('In fact we will - watch for this example to be revised in Chapter 20 to address this last point, after we’ve learned how to code user-defined generators.
            --
            lpy3-p598,p599
            }}}
        (Emulating the Python 3.X print Function  = one last example of argument matching at work. (Ee) (SSss!!!!!)
            {{{
            'The code you’ll see here is intended for use in Python 2.X or earlier (it works in 3.X, too, but is pointless there): it uses both the *args arbitrary positional tuple and the **args arbitrary keyword-arguments dictionary to simulate most of what the Python 3.X print function does.
                As we learned in Chapter 11, this isn’t actually required, because 2.X programmers can always enable the 3.X print function with an import of this form (available in 2.6 and 2.7):
            from __future__ import print_function
            To demonstrate argument matching in general, though, the following file, print3.py, does the same job in a small amount of reusable code, by building up the print string and routing it per configuration arguments:
              .
              .
              .
            + 'To test it, import this into another file or the interactive prompt, and use it like the 3.X print function.
                + 'Here is a test script, testprint3.py (notice that the function must be called “print3”, because “print” is a reserved word in 2.X):
            --
            lpy3-p599
            }}}
                ----

                ----
        term: Call Signature (**) (@)
            {{{
            (+= see more useful progr.terms (!!! (SsssE)
            --
            lpy3-p599
            }}}
        + 'this example could be coded with Python 3.X keyword-only arguments, ... , to automatically validate configuration arguments. The following variant, in the file print3_alt1.py, illustrates: (@)
            {{{
            def print3(*args, sep=' ', end='\n', file=sys.stdout):
                (+ commenting on the original script version: 'That’s almost sufficient, but any extra keyword arguments are silently ignored.
            --
            lpy3-p600
            }}}
        trigger(ing) a built-in exception  = which works just as though Python had done so @
            {{{
            a raise statement,
              .
            if kargs: raise TypeError('extra keywords: %s' % kargs)
            --
            lpy3-p601
            }}}
        Use-case where  keywordonly arguments can simplify a specific category of functions (=in Py 3) **(!) @
            {{{
            keywordonly arguments can simplify a specific category of functions that accept both arguments and options.
            --
            lpy3-p601
            }}}
        Why You Will Care: Keyword Arguments (!) @(@)
            {{{
            because some Python tools make use of them, some general knowledge of these modes is important.
                For example, keyword arguments play an important role in tkinter, **
            = in terms of its call patterns, keyword arguments set configuration options when GUI components are built.
            eg:
              .
            from tkinter import *
            widget = Button(text="Press me", command=someFunction)
                = creates a new button and specifies its text and callback function, using the text and command keyword arguments.
            = 'Since the number of configuration options for a widget can be large, keyword arguments let you pick and choose which to apply. *
              .
              .
              .
            + Many built-in functions in Python expect us to use keywords for usage-mode options as well, which may or may not have defaults.
            sorted(iterable, key=None, reverse=False)
              .
              .
            + 'As we’ve also seen, the dict, str.format, and 3.X print calls accept keywords as well
            --
            lpy3-p602
            }}}
        Many of these (= advanced function-related) concepts (in Python) stem from the fact that
            {{{
                (eg. function annotations, recursion, lambdas, and functional tools such as map and filter )
            functions are normal objects in Python, and so support some advanced and very flexible processing modes.
            --
            lpy3-p603
            }}}
        "The function arguments and keywords" quiz (**!) (Ss(!)) (@)
            {{{
            --
            lpy3-p603
            }}}
            ----


        Chapter 19 - Advanced Function Topics

            ----
        common use case for  lambdas (in Py) *(*) (@)
            {{{
            regularly used w. GUIs (*)
            --
            lpy3-p605
            }}}
        Part of the art of using functions lies in * (@)
            {{{
            the interfaces between them,
              (eg. how well they're designed
            --
            lpy3-p605
            }}}
        Function Design Concepts (**)
            {{{
            how to decompose a task into purposeful functions (known as cohesion),
            how your functions should communicate (called coupling),
                and so on.
            --
            lpy3-p605
            }}}
        • Coupling: design tips (@)
            {{{
            use arguments for inputs and return for outputs.
                = Generally, you should strive to make a function independent of things outside of it.
            use global variables only when truly necessary.
                Global variables (i.e., names in the enclosing module) are usually a poor way for functions to communicate.
            don’t change mutable arguments unless the caller expects it.
            --
            lpy3-p605,p606
            }}}
        • Cohesion: design tips  (+concerning size) (@)
            {{{
            each function should have a single, unified purpose.
                = When designed well, each of your functions should do one thing - something you can summarize in a simple declarative sentence.
                (ie. summary is to broad, or contains too many ands = is a code smell (!))
               .
            • Size: each function should be relatively small.
                This naturally follows from the preceding goal, but if your functions start spanning multiple pages on your display, it’s probably time to split them. Especially given that Python code is so concise to begin with, a long or deeply nested function is often a symptom of design problems.
              .
            avoid changing variables in another module file directly.
                similar to how global variables couple functions - the modules become difficult to understand and reuse.
                [= 'Use accessor functions whenever possible, instead of direct assignment statements.
            --
            lpy3-p606
            }}}
        (some)  exceptions to the preceding design rules,
            {{{
            = 'including some related to Python’s OOP support.
                    ( Moreover, if classes are not used, global variables are often the most straightforward way for functions in modules to retain single-copy state between calls.
            --
            lpy3-p606
            }}}
                ----

                ----
        Recursive Functions (!!) (=tip and use cases) @
            {{{
            relatively rare to see in Python,
              .
            **(**)  it’s a useful technique to know about, as it allows programs to traverse structures that have arbitrary and unpredictable shapes and depths - planning travel routes, analyzing language, and crawling links on the Web, for example.
            --
            lpy3-p607
            }}}
        Ex: Summation with Recursion (@)
            {{{
            >>> def mysum(L):
                    if not L:
                        return 0
                    else:
                        # Call myself recursively
                        return L[0] + mysum(L[1:])
            --
            lpy3-p607
            }}}
        Coding Alternatives (=coding a "recursive loop") [= using  Python’s if/else ternary expression (??) (!) @
            {{{
            (+ also using Py 3.X ext seq assign  (*/?/!)
            --
            lpy3-p608,p609
            }}}
        (+Some more pointers about recursion) (**
            {{{
            'Keep in mind that recursion can be direct, as in the examples so far, or indirect, as in the following (a function that calls another function, which calls back to its caller).
              (+Ex.
            --
            lpy3-p609
            }}}
        [Loop Statements Versus Recursion @
            {{{
            'The while, for example, often makes things a bit more concrete, and it doesn’t require that a function be defined to allow recursive calls:
              .
            >>> L = [1, 2, 3, 4, 5]
            >>> sum = 0
            >>> while L:
                    sum += L[0]
                    L = L[1:]
            >>> sum
            15
              .
            Better yet, for loops iterate for us automatically, making recursion largely extraneous in many cases (and, in all likelihood, less efficient in terms of memory space and execution time):
            >>> L = [1, 2, 3, 4, 5]
            >>> sum = 0
            >>> for x in L: sum += x
              .
            >>> sum
            15
                With looping statements, we don’t require a fresh copy of a local scope on the call stack for each iteration, and we avoid the speed costs associated with function calls in general.
                + '(Stay tuned for Chapter 21’s timer case study for ways to compare the execution times of alternatives like these.)
            --
            lpy3-p610
            }}}
            ----

            ----
        Handling Arbitrary Structures  (= w. Recursion) ** @
            {{{
            (or equivalent explicit stack-based algorithms we’ll meet shortly)
              .
            computing the sum of all the numbers in a nested sublists structure like this:
                # Arbitrarily nested sublists
            [1, [2, [3, 4], 5], 6, [7, 8]]
              .
              .
            # file sumtree.py
            def sumtree(L):
                tot = 0
                for x in L: 	# For each item at this level
                    if not isinstance(x, list):
                        tot += x  # Add numbers directly
                    else:
                        tot += sumtree(x)	# Recur for sublists
                return tot
                   .
            L = [1, [2, [3, 4], 5], 6, [7, 8]]		# Arbitrary nesting
            print(sumtree(L))					# Prints 36
            --
            lpy3-p610
            }}}
        (((Recursion versus queues and stacks (??) (??)  (= comparison-Ex.  (SSs EEe @
            {{{
           (( = simple recurring is generally better, once you understand|get it ))
                Python implements recursion by pushing information on a call stack at each recursive call, so it remembers where it must return and continue later.
            In fact, it’s generally possible to implement recursive-style procedures without recursive calls, by using an explicit stack or queue of your own to keep track of remaining steps. (??)
            ''For instance, the following computes the same sums as the prior example, but uses an explicit list to schedule when it will visit items in the subject, instead of issuing recursive calls; the item at the front of the list is always the next to be processed and summed:
            --
            lpy3-p611
            }}}
        once you get the hang of recursive calls, they are more natural than the explicit scheduling lists they automate, and are generally preferred unless you need to traverse structure in specialized ways. (=use case for explicit queues and stacks (**)) (@)
            {{{
            Some programs, for example, perform a bestfirst search that requires an explicit search queue ordered by relevance or other criteria.
            = If you think of a web crawler that scores pages visited by content, the applications may start to become clearer.
            --
            lpy3-p612
            }}}
        'Cycles, paths, and stack limits (??) (!)
            {{{
            As is, these programs suffice for our example, but larger recursive applications can sometimes require a bit more infrastructure than shown here: they may need to avoid cycles or repeats, record paths taken for later use, and expand stack space when using recursive calls instead of explicit queues or stacks.
            [=when straight traversal is not enough: 'If data can be a cyclic graph, though, both these schemes will fail: the recursive call version will fall into an infinite recursive loop (and may run out of call-stack space), and the others will fall into simple infinite loops, re-adding the same items to their lists (and may or may not run out of general memory).
                Some programs also need to avoid repeated processing for a state reached more than once, even if that wouldn’t lead to a loop.
            To do better, the recursive call version could simply keep and pass a set, dictionary, or list of states visited so far and check for repeats as it goes. We will use this scheme in later recursive examples in this book: (!!) (+Ex. (!) )
             ...
             ...
            --
            lpy3-p612
            }}}
        (('Note that checking for duplicates already on the items list would avoid scheduling a state twice, but would not prevent revisiting a state traversed earlier and hence removed from that list: (@)
            {{{
            This model doesn’t quite apply to this section’s use case that simply adds numbers in lists, but larger applications will be able to identify repeated states - a URL of a previously visited web page, for instance.
            --
            lpy3-p612,p613
            }}}
        ''Some programs may also need to record complete paths for each state followed so they can report solutions when finished.
            {{{
            In such cases, each item in the nonrecursive scheme’s stack or queue may be a full path list that suffices for a record of states visited, and contains the next item to explore at either end.
            --
            lpy3-p613
            }}}
        [['Also note that standard Python limits the depth of its runtime call stack - crucial to recursive call programs - to trap infinite recursion errors. To expand it, (!) @
            {{{
            = use the sys module:
              .
                # 1000 calls deep default
            >>> sys.getrecursionlimit()
            1000
                # Allow deeper nesting
            >>> sys.setrecursionlimit(10000)
                # Read more about it
            >>> help(sys.setrecursionlimit)
            --
            lpy3-p613
            }}}
        Although this (=Recursion) section’s example is artificial, it is representative of a larger class of programs; (!)
            {{{
            inheritance trees and module import chains, for example, can exhibit similarly general structures, and computing structures such as permutations can require arbitrarily many nested loops.
              .
            • In Chapter 20’s permute.py, to shuffle arbitrary sequences
            • In Chapter 25’s reloadall.py, to traverse import chains
            • In Chapter 29’s classtree.py, to traverse class inheritance trees
            • In Chapter 31’s lister.py, to traverse class inheritance trees again
            • In Appendix D’s solutions to two exercises at the end of this part of the book: countdowns and factorials
            --
            lpy3-p613
            }}}
        + you sometimes need to be aware of the potential of unintended recursion in your programs.
            {{{
            some operator overloading methods in classes such as __setattr__ and __getattribute__ and even __repr__ have the potential to recursively loop if used incorrectly.
            --
            lpy3-p613
            }}}
            ----

            ----
        Function Objects: Attributes and Annotations (!) (@)
            {{{
            functions in Python are much more than code-generation specifications for a compiler - Python functions are full-blown objects, stored in pieces of memory all their own.
              As such, they can be freely passed around a program and called indirectly.
                +|= They also support operations that have little to do with calls at all - attribute storage and annotation.
            --
            lpy3-p614
            }}}
        another way to say Indirect Function Calls: (**) (@)
            {{{
            “First Class” Objects (??)
                may be assigned to other names, passed to other functions, embedded in data structures, returned from one function to another, and more, as if they were simple numbers or strings.
              (= belong to the same general category as other objects, but can also be called, = by giving it arguments)
              .
              .
            After a def runs, the function name is simply a reference to an object - you can reassign that object to other names freely and call it through any reference:
            .
            .
                    # Call object through original name
            >>> echo('Direct call')
            Direct call
              .
              .
                    # Now x references the function too
            >>> x = echo
                    # Call object through name by adding ()
            >>> x('Indirect call!')
            Indirect call!
            --
            lpy3-p614
            }}}
        te: 'Because ____, it’s just as easy to pass functions to other functions as arguments. (@)
            {{{
            arguments are passed by assigning objects,
              .
            >>> def indirect(func, arg):
                    func(arg)		# Call the passed-in object by adding ()
              .
                    # Pass the function to another function
            >>> indirect(echo, 'Argument call!')
            Argument call!
            --
            lpy3-p614
            }}}
        embed  function twice in a list of tuples, as a sort of actions table. ** @
            {{{
            >>> schedule = [ (echo, 'Spam!'), (echo, 'Ham!') ]
            >>> for (func, arg) in schedule:  # note: uses tuple unpacking
                    func(arg)	# Call functions embedded in containers
            --
            lpy3-p614
            }}}
        functions can also be created and returned for use elsewhere - (= ) the closure created in this mode also retains state from the enclosing scope:
            {{{
            >>> def make(label):
                    def echo(message):
                        print(label + ':' + message)
                    return echo
              .
                # Label in enclosing scope is retained
            >>> F = make('Spam')
                # Call the function that make returned
            >>> F('Ham!')
            Spam:Ham!
            >>> F('Eggs!')
            Spam:Eggs!
            --
            lpy3-p614
            }}}
        Function Introspection  = inspect function attributes (??) @
            {{{
            >>> func.__name__
            'func'
            >>> dir(func)
            ['__annotations__', '__call__', '__class__', '__closure__', '__code__',
            ...more omitted: 34 total...
            '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']
              .
              (????(?))
            >>> func.__code__
            <code object func at 0x00000000021A6030, file "<stdin>", line 1>
              .
            >>> dir(func.__code__)
            ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__',
            ...more omitted: 37 total...
            'co_argcount', 'co_cellvars', 'co_code', 'co_consts', 'co_filename',
            'co_firstlineno', 'co_flags', 'co_freevars', 'co_kwonlyargcount', 'co_lnotab',
            'co_name', 'co_names', 'co_nlocals', 'co_stacksize', 'co_varnames']
              .
            >>> func.__code__.co_varnames
            ('a', 'b')
            >>> func.__code__.co_argcount
            1
        = 'Tool writers can make use of such information to manage functions (in fact, ...
            --
            lpy3-p615
            }}}
        attach arbitrary userdefined attributes to  functions (**)
            {{{
            >>> func
            <function func at 0x000000000296A1E0>
            >>> func.count = 0
            >>> func.count += 1
            >>> func.count
            1
            >>> func.handles = 'Button-Press'
            >>> func.handles
            'Button-Press'
            >>> dir(func)
            ['__annotations__', '__call__', '__class__', '__closure__', '__code__',
            ...and more: in 3.X all others have double underscores so your names won't clash...
            __str__', '__subclasshook__', 'count', 'handles']
                In 3.X, all function internals’ names have leading and trailing double underscores (“__X__”); 2.X follows the same scheme, but also assigns some names that begin with “func_X”:
            As we saw in that chapter, such attributes can be used to attach state information to function objects directly, instead of using other techniques such as globals, nonlocals, and classes.
            Unlike nonlocals, such attributes are accessible anywhere the function itself is, even from outside its code.
                [(sort of)  way to emulate “static locals” in other languages
                    - variables whose names are local to a function, but whose values are retained after a function exits.
                [[[Attributes are related to objects instead of scopes (and must be referenced through the function name within its code), but the net effect is similar. (??) (??)
            [[Moreover, as we learned in Chapter 17, when attributes are attached to functions generated by other factory functions, they also support multiple copy, per-call, and writeable state retention, much like nonlocal closures and class instance attributes. (??) (??) (??) (!)
            --
            lpy3-p616,p617
            }}}
        Function Annotations in 3.X (!!) @
            {{{
            In Python 3.X (but not 2.X), it’s also possible to attach annotation information - arbitrary user-defined data about a function’s arguments and result - to a function object.
                = attached to the function object’s __annotations__ attribute for use by other tools.
            (For instance, such a tool might use annotations in the context of error testing.
              .
            >>> def func(a: 'spam', b: (1, 10), c: float) -> int:
                    return a + b + c
              .
            >>> func(1, 2, 3)
              .
            Calls to an annotated function work as usual, but when annotations are present Python collects them in a dictionary and attaches it to the function object itself.
              .
            >>> func.__annotations__
            {'c': <class 'float'>, 'b': (1, 10), 'a': 'spam', 'return': <class 'int'>}
              .
              .
            >>> for arg in func.__annotations__:
                    print(arg, '=>', func.__annotations__[arg])
            --
            [['two fine points to note here.
                can still use defaults for arguments if you code annotations
                    a: 'spam' = 4,
                you can use spaces between components in function headers or not,
                    >>> def func(a:'spam'=4, b:(1,10)=5, c:float=6)->int:
              --
            Use case ideas: It’s easy to imagine annotations being used to specify constraints for argument types or values, though, and larger APIs might use this feature as a way to register function interface information.
            --
            lpy3-p618,p619
            }}}
        'we’ll look at annotations as an alternative to function decorator arguments - a more general concept in which information (@)
            {{{
            is coded outside the function header and so is not limited to a single role.
            --
            lpy3-p619
            }}}
            ----

            ----
        about  lambda functions (**) @
            {{{
            this expression creates a function to be called later,
            but it returns the function instead of assigning it to a name.
                = inline a function definition, or to defer execution of a piece of code.
            --
            lpy3-p619
            }}}
        lambda syntax (**) (@)
            {{{
            lambda argument1, argument2,... argumentN : expression using arguments
            --
            lpy3-p620
            }}}
        lambdas can appear (= as opposed to defs) *
            {{{
            - inside a list literal or a function call’s arguments, for example.
                [[= With def, functions can be referenced by name but must be created elsewhere.
            ['The lambda’s body is similar to what you’d put in a def body’s return statement; you simply type the result as a naked expression, instead of explicitly returning it.
            --
            lpy3-p620
            }}}
        lambda version of  def func(x, y, z): return x + y + z   * @
            {{{
            >>> f = lambda x, y, z: x + y + z
            >>> f(2, 3, 4)
                Here, f is assigned the function object the lambda expression creates; this is how def works, too, but its assignment is automatic.
               [+defaults work **
            >>> x = (lambda a="fee", b="fie", c="foe": a + b + c)
            >>> x("wee")
            'weefiefoe'
            --
            lpy3-p620
            }}}
        (are) frequently coded as inline lambda expressions (@)
            {{{
            callback handlers
                (= embedded directly in a registration call’s arguments list,
            also commonly used to code jump tables, which are lists or dictionaries of actions to be performed on demand.
              .
            L = [lambda x: x ** 2,	# Inline function definition
                 lambda x: x ** 3,
                 lambda x: x ** 4]	# A list of three callable functions
              .
            for f in L:
                print(f(2))		# Prints 4, 8, 16
              .
            print(L[0](3))		# Prints 9
            --
            lpy3-p621
            }}}
        Multiway branch switches: The finale (??) ** (@)
            {{{
            >>> key = 'got'
            >>> {'already': (lambda: 2 + 2),
                 'got':		(lambda: 2 * 4),
                 'one':		(lambda: 2 ** 6)}[key]()
            8
            Here, when Python makes the temporary dictionary, each of the nested lambdas generates and leaves behind a function to be called later.
            Indexing by key fetches one of those functions, and parentheses force the fetched function to be called.
              .
            = especially useful for functions that will only be used in a single context - if the three functions here are not useful anywhere else, it makes sense to embed their definitions within the dictionary as lambdas.
            [although note: 'jump tables are generally subsumed by polymorphic method dispatch in Python: (??) (!)
              --  +
            in function-call argument lists as a way to inline temporary function definitions not used anywhere else in your program;
            --
            lpy3-p622
            }}}
        watch it! (= trying to do too much in a lambda)
            {{{
            Because expressions like these can be placed inside a lambda, they may be used to implement selection logic within a lambda function:
              +using maps, etc
            --
            lpy3-p623
            }}}
        'lambdas are the main beneficiaries of nested function scope lookup (the E in the LEGB scope rule we studied in Chapter 17).
            {{{
            = 'lambdas Can Be Nested Too
            = 'As a review, in the following the lambda appears inside a def - the typical case - and so can access the value that the name x had in the enclosing function’s scope at the time that the enclosing function was called:
            --
            lpy3-p624
            }}}
        Coding a Tkinter button printing a message in the console (= w. a lambda (!!)) (@)
            {{{
            import sys
            from tkinter import Button, mainloop  # Tkinter in 2.X
            x = Button(
                    text='Press me',
                                            # 3.X: print()
                    command=(lambda:sys.stdout.write('Spam\n')))
            x.pack()
            mainloop()	# This may be optional in console mode
              .
              .
              .
            Because the nested function scope rules apply to lambdas as well, they are also easier to use as callback handlers, as of Python 2.2 - they automatically see names in the functions in which they are coded and no longer require passed-in defaults in most cases.
              .
            + 'This is especially handy for accessing the special self instance argument that is a local variable in enclosing class method functions (more on classes in Part VI):
            class MyGui:
                def makewidgets(self):
                    Button(command=(lambda: self.onPress("spam")))
                def onPress(self, message):
                    ...use message...
               +
               +
               As we’ll see later, class objects with __call__ and bound methods often serve in callback roles too - watch for coverage of these in Chapter 30 and Chapter 31.
            --
            lpy3-p624
            }}}
            ----

        Functional Programming Tools

            ----
        Python includes a set of built-ins used for functional programming
            {{{
            - tools that apply functions to sequences and other iterables.
                call functions on an iterable’s items (map);
                filter out items based on a test function (filter);
                and apply functions to pairs of items and running results (reduce).
            Though the boundaries are sometimes a bit grey, by most definitions Python’s functional programming arsenal also includes the first-class object model explored earlier, the nested scope closures and anonymous function lambdas we met earlier in this part of the book, the generators and comprehensions we’ll be expanding on in the next chapter, and perhaps the function and class decorators of this book’s final part.
            --
            lpy3-p624
            }}}
        'One of the more common things programs do with lists and other sequences is (@)
            {{{
            apply an operation to each item and collect the results - selecting columns in database tables, incrementing pay fields of employees in a company, parsing email attachments, and so on.
            --
            lpy3-p626
            }}}
        processing all items in a list with map (=instead of with a for loop) ** @
            {{{
            = returns a list containing all the function call results.
              .
            >>> def inc(x): return x + 10
            >>> list(map(inc, counters))
            [11, 12, 13, 14]
            NOTE: map is iterable (=therefore, use w. list)
            Because map expects a function to be passed in and applied, it also happens to be one of the places where lambda commonly appears:
              .
                    # Function expression
            >>> list(map((lambda x: x + 3), counters))
                    = as this little function isn’t needed elsewhere, it was written inline as a lambda.
            --
            lpy3-p626,p627
            }}}
        (cod(ing) a general mapping utility yourself: (= w. a for-loop) (@)
            {{{
            >>> def mymap(func, seq):
                    res = []
                    for x in seq: res.append(func(x))
                    return res
            --
            lpy3-p627
            }}}
        more advanced ways  to use map:  send items  fr. seq.s in parallel (as  arg.s to eg. pow ***) (@
            {{{
            >>> list(map(pow, [1, 2, 3], [2, 3, 4]))
            [1, 8, 81]
                (note: check that it matches argument pattern, ie. two for pow.)
            [+ can  simulate this multiple-sequence generality in code, (too)
            --
            lpy3-p627
            }}}
        [apply the inc()-call w. a list compr. (*)] @
            {{{
            >>> [inc(x) for x in [1, 2, 3, 4]]
            [11, 12, 13, 14]
            --
            lpy3-p627
            }}}
        creates an object that generates values on request to save memory and increase responsiveness, (= w. list comprehensions and like 3.X map) (****) @@
            {{{
            = 'wrapping a comprehension in parentheses instead of square brackets creates an object that generates values on request to save memory and increase responsiveness,
            --
            lpy3-p628
            }}}
            ----

            ----
        Selecting Items in Iterables: * @
            {{{
            filter
                (+returns an iterable =requires list for direct display)
            = 'Items in the sequence or iterable for which the function returns a true result are added to the result list.
            --
            lpy3-p628
            }}}
        apply functions to item pairs, | Combining Items in Iterables: (@)
            {{{
            reduce
                (+returns an iterable =requires list for direct display)
            --
            lpy3-p628
            }}}
        filter: pick  out items in a sequence that are greater than zero: ** @
            {{{
            >>> list(filter((lambda x: x > 0), range(−5, 5)))
            [1, 2, 3, 4]
            --
            lpy3-p628
            }}}
        [2 Simple alternatives to filter] * @
            {{{
            filter can be emulated by list comprehension syntax with often-simpler results (especially when it can avoid creating a new function),
            and with a similar generator expression when delayed production of results is desired
                    # Use () to generate items
            >>> [x for x in range(−5, 5) if x > 0]
            [1, 2, 3, 4]
            --
            lpy3-p628
            }}}
        reduce **(*)*: compute the sum | product of the items in a list: @
            {{{
                    # Import in 3.X, not in 2.X
            >>> from functools import reduce
            >>> reduce((lambda x, y: x + y), [1, 2, 3, 4])
            10
            >>> reduce((lambda x, y: x * y), [1, 2, 3, 4])
            24
                (+the optional third argument)
            --
            lpy3-p629
            }}}
        [coating(=coding) a custom 'myreduce'] ((SSSS)) (@)
            {{{
            [=Study loops more(!!) (=can be hard and abstract to grasp)]
            --
            lpy3-p629
            }}}
        module, which provides functions that correspond to builtin expressions  (=  comes in handy for some uses of functional tools) (@)
            {{{
            'operator'  (+functools (?|*))
              .
            >>> import operator, functools
                        # Function-based +
            >>> functools.reduce(operator.add, [2, 4, 6])
            12
            >>> functools.reduce((lambda x, y: x + y), [2, 4, 6])
            12
            --
            lpy3-p629
            }}}
        1.  How are lambda expressions and def statements related? (= sim.s and diff.s) *
            {{{
            Both lambda and def create function objects to be called later. Because lambda is an expression, though, it returns a function object instead of assigning it to a name, and
            --
            lpy3-p630
            }}}
        2.  What’s the point of using lambda? (@)
            {{{
            allow us to “inline” small units of executable code,
            defer its execution, and
            provide it with state in the form of default arguments and enclosing scope variables.
                (+eg. GUIs
                + natural affinity with functional tools like map and filter that expect a processing function.
            --
            lpy3-p630
            }}}
        7.  how  functions can communicate results to a caller. * (@)
            {{{
            with return statements, by changing passed-in mutable arguments, and by setting global variables.
            Globals are generally frowned upon (except for very special cases, like multithreaded programs)
              .
            return statements are usually best, but changing mutables is fine (and even useful), if expected.
              .
            + 'Functions may also communicate results with system devices such as files and sockets,
            --
            lpy3-p631
            }}}
            ----

        [Chapter 20 - Comprehensions and Generations]

            ----
        origins(?) of  the list comprehension *  (+Uses and Flavors) (***(!))
            {{{
            as a compressed easy alternative to Py.s functional tools (eg. map, filter, reduce)(**)
                (= inspired by a similar tool in the functional programming language Haskell, around the time of Python 2.0.
            = 'apply an arbitrary expression to items in an iterable, rather than applying a function.
            In later releases, the comprehension was extended to other roles - sets, dictionaries, and even the value generator expressions we’ll explore in this chapter.
            --
            lpy3-p633
            }}}
        comprehension version of  res = []; for x in 'spam': res.append(ord(x))  and  res = list(map(ord, 'spam'))  (***(!))
            {{{
            [note: map maps a function over an iterable, list comprehensions map an expression over a sequence or other iterable:
              .
            res = [ord(x) for x in 'spam']
            --
            lpy3-p634
            }}}
        compreh: square numbers fr. 0 to 9 (+collect as a list)  **(!)
            {{{
            >>> [x ** 2 for x in range(10)]
            [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
              .
            + 'To do similar work with a map call, we would probably need to invent a little function to implement the square operation.
                 .
            >>> list(map((lambda x: x ** 2), range(10)))
            [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
               (= not much more complex than the comprehension in this case, but very often it can be(!))
            [eg. if:s etc can be used in the compreh. (*)]
            --
            lpy3-p635
            }}}
        produced list of the even numbers below five **(=w. compreh, map, for-loop)(*) @
            {{{
            >>> [x for x in range(5) if x % 2 == 0]
            [0, 2, 4]
              .
              .
            >>> list(filter((lambda x: x % 2 == 0), range(5)))
            [0, 2, 4]
              .
              .
            >>> res = []
            >>> for x in range(5):
                    if x % 2 == 0:
                        res.append(x)
              .
            >>> res
            [0, 2, 4]
            --
            lpy3-p635
            }}}
        compreh: collect the squares of the even numbers from 0 through 9: **(*) (= like combining map and filter) ** @
            {{{
            >>> [x ** 2 for x in range(10) if x % 2 == 0]
            [0, 4, 16, 36, 64]
               (+ the more complex map and filter version)
            --
            lpy3-p636
            }}}
        te: name of the first expression in a comprehension (**!) @T(@)
            {{{
            accumulation expression
            --
            lpy3-p636
            }}}
        te: syntax of a comprehension written as formal syntax (*) (T@)
            {{{
            [ expression for target in iterable ]
            --
            lpy3-p636
            }}}
        'the dictionary comprehension begins with
            {{{
            two expressions separated by a colon (for key and value).
            --
            lpy3-p636
            }}}
        compreh. version of  res = []; for x in [0, 1, 2]: for y in [100, 200, 300]: res.append(x + y)  (!!) @
            {{{
            res = [x + y for x in [0, 1, 2] for y in [100, 200, 300]]
              .
            (+ex. 2: collect pieces from strings)
            >>> [x + y for x in 'spam' for y in 'SPAM']
            --
            lpy3-p636
            }}}
        plus more convoluted example (= collect and combine certain pieces|combinations from two strings) ((!!))
            {{{
            >>> [x + y for x in 'spam' if x in 'sm' for y in 'SPAM' if y in ('P', 'A')]
              (= maybe(??) useful for multi-dimensional arrays)
              .
            >>> [x + y + z for x in 'spam' if x in 'sm'
                           for y in 'SPAM' if y in ('P', 'A')
                           for z in '123' if z > '1']
            --
            lpy3-p637
            }}}
        compreh: attached if selections on nested for clauses applied to numeric objects  = combine even numbers from 0 through 4 with odd numbers from 0 through 4. (**) @(@)
            {{{
            >>> [(x, y) for x in range(5) if x % 2 == 0 for y in range(5) if y % 2 == 1]
            [(0, 1), (0, 3), (2, 1), (2, 3), (4, 1), (4, 3)]
              .
              . (+ the statement based version:
            >>> res = []
            >>> for x in range(5):
                    if x % 2 == 0:
                        for y in range(5):
                            if y % 2 == 1:
                                res.append((x, y))
              .
            >>> res
            [(0, 1), (0, 3), (2, 1), (2, 3), (4, 1), (4, 3)]
            --
            lpy3-p637
            }}}
            ----

            ----
        Tip: 'Recall that if you’re confused about what a complex list comprehension does, you can always @
            {{{
            nest the list comprehension’s for and if clauses inside each other
                like this - indenting each clause successively further to the right -
            to derive the equivalent statements.
            --
            lpy3-p637
            }}}
        another good use for nested list comprehensions (** M) @
            {{{
            = process matrixes (*)
            --
            lpy3-p638
            }}}
        list compreh. + matrixes: Pull out second column from the example matrix **(!) @(@)
            {{{
              # the matrix plus basic indexing of it
            >>> M = [[1, 2, 3],
                     [4, 5, 6],
                     [7, 8, 9]]
            >>> N = [[2, 2, 2],
                     [3, 3, 3],
                     [4, 4, 4]]
              .
            >>> M[1]
            [4, 5, 6]		# Row 2
              .
            >>> M[1][2]		# Row 2, item 3
            6
              .
              .
            >>> [row[1] for row in M]		# Column 2
            [2, 5, 8]
              .
            >>> [M[row][1] for row in (0, 1, 2)]  # Using offsets
            [2, 5, 8]
            --
            lpy3-p638
            }}}
        compreh. + matr: pulling out a diagonal. **(!) (SSSS) @
            {{{
                    # Diagonals
            >>> [M[i][i] for i in range(len(M))]
            [1, 5, 9]
            >>> [M[i][len(M)-1-i] for i in range(len(M))]
            [3, 5, 7]
            --
            lpy3-p638
            }}}
        Change matr. in place (+ why easiest to use a for loop instead of a comprehension) **(*!) (SSSSssss) @
            {{{
            >>> L = [[1, 2, 3], [4, 5, 6]]
            >>> for i in range(len(L)):
                    # Update in place
                    for j in range(len(L[i])):
                        L[i][j] += 10
              .
            >>> L
            [[11, 12, 13], [14, 15, 16]]
              .
            We can’t really do the same with list comprehensions, as they make new lists, but we could always assign their results to the original name for a similar effect.
            --
            lpy3-p638,p639
            }}}
        [+ the comprehension version of changing matrix in place, + the expanded statement version for comparison] [!]
            {{{
            We can’t really do the same with list comprehensions, as they make new lists, but we could always assign their results to the original name for a similar effect.
              .
            # Assign to M to retain new value
            >>> [col + 10 for row in M for col in row]
            [11, 12, 13, 14, 15, 16, 17, 18, 19]
              .
            >>> [[col + 10 for col in row] for row in M]
            [[11, 12, 13], [14, 15, 16], [17, 18, 19]]
            --
            lpy3-p639
            }}}
        [[['As its statement equivalent makes clearer, the second expression in the preceding works because the row iteration is an outer loop: for each row, it runs the nested column iteration to build up one row of the result matrix: (???? | (SSSs
            {{{
            --
            lpy3-p639
            }}}
        [[use list comprehensions to combine values of multiple matrixes.  ((*(****))) (SSss
            {{{
            'The following first builds a flat list that contains the result of multiplying the matrixes pairwise, and then builds a nested list structure having the same values by nesting list comprehensions again:
              .
              .
              .
              .
              .
            (+ the equivalent in statement code
            --
            lpy3-p639,p640
            }}}
        ([+ one more example: pair items from the two matrices to be multiplied with zip) (*(*****) (SSSs  (+ Concerning using tricky comprehensions in real code) @
            {{{
              .
              .
            [Disadvantage: Can be tricky to understand
                list comprehensions can quickly become, well, incomprehensible, especially when nested.
             Advantage(!): might run substantially faster for large matrixes,
              .
            This book demonstrates advanced comprehensions to teach, but in the real world, using complicated and tricky code where not warranted is both bad engineering and bad software citizenship.
              .
            = 'If you have to translate code to statements to understand it, it should probably be statements in the first place. ****(!!)
            'However, in this case, there is currently a substantial performance advantage to the extra complexity: based on tests run under Python today, map calls can be twice as fast as equivalent for loops, and list comprehensions are often faster than map calls.
            + 'Because map and list comprehensions are both expressions, they also can show up syntactically in places that for loop statements cannot, such as in the bodies of lambda functions, within list and dictionary literals, and more.
        Because of this, list comprehensions and map calls are worth knowing and using for simpler kinds of iterations, especially if your application’s speed is an important consideration.
            Still, because for loops make logic more explicit, they are generally recommended on the grounds of simplicity, and often make for more straightforward code.
            (+ the speed can depend on called pattern etc
             = 'Recent Python releases have sped up the simple for loop statement, for example.
            --
            lpy3-p640--p642
            }}}
        WYWC: shave off newlines from every line in a file (=w. compreh. and map)  ((**)) @(@)
            {{{
              >>> [line.rstrip() for line in open('myfile').readlines()]
              ['aaa', 'bbb', 'ccc']
              .
            >>> [line.rstrip() for line in open('myfile')]
            ['aaa', 'bbb', 'ccc']
              .
            >>> list(map((lambda line: line.rstrip()), open('myfile')))
            ['aaa', 'bbb', 'ccc']
            --
            lpy3-p642
            }}}
        WYWC: Process results fr. Python’s standard SQL database API (='rows and columns')  (***(*)) (@)
            {{{
              # =the basic 'list'
            >>> listoftuple = [('bob', 35, 'mgr'), ('sue', 40, 'dev')]
              --
            >>> [age for (name, age, job) in listoftuple]   (****(!!))
            [35, 40]
              .
            >>> list(map((lambda row: row[1]), listoftuple))
            [35, 40]
                    The first of these makes use of tuple assignment to unpack row tuples in the list, and the second uses indexing.
                 (( +(!) tuple unpacking works for map in 2.X too ((()) )))
            --
            lpy3-p642,p643
            }}}
                ----

        Generator Functions and Expressions

                ----
        Generator Functions and Generator Expressions
            {{{
            = produce results only when needed, instead of all at once.
                [ = 'delay result creation whenever possible in user-defined operations:
            = 'Because neither constructs a result list all at once, they save memory space and allow computation time to be split across result requests.
            'As we’ll see, both of these ultimately perform their delayed-results magic by implementing the iteration protocol we studied in Chapter 14.
                    Python’s notion of generators owes much to other programming languages, especially Icon.
            --
            lpy3-p643
            }}}
        • Generator functions (@)
            {{{
            coded as normal def statements,
                but use yield statements to return results one at a time,
                  = suspending and resuming their state between each.
            --
            lpy3-p643
            }}}
        • Generator expressions (@)
            {{{
            similar to the list comprehensions of the prior section,
                but they return an object that produces results on demand
                  = instead of building a result list.
            --
            lpy3-p643
            }}}
        More te ab. generator function (**)  + ab. yield (*!!)
            {{{
            coded w. normal defs
            + 'However, when created, they are compiled specially into an object that supports the iteration protocol.
            + when called, they don’t return a result: they return a result generator that can appear in any iteration context.
              .
            Unlike normal functions that return a value and exit, generator functions automatically suspend and resume their execution and state around the point of value generation.
              .
            The state that generator functions retain when they are suspended includes both their code location, and their entire local scope.
                Hence, their local variables retain information between results, and make it available when the functions are resumed.
              .
            The chief code difference between generator and normal functions is that a generator yields a value, rather than returning one - the yield statement suspends the function and sends a value back to the caller, but retains enough state to enable the function to resume from where it left off.
            --
            lpy3-p644
            }}}
        generator functions + 'Iteration protocol integration'  (????) (!)
            {{{
            "g.functions are compiled especially as generators to support the iteration protocol" (??)
                = 'are built to return an object with the expected iteration protocol methods.
                'When later called, they return a generator object that supports the iteration interface with an automatically created method named __next__ to start or resume execution.
            'Generator functions may also have a return statement that, along with falling off the end of the def block, simply terminates the generation of values - technically, by raising a StopIteration exception after any normal function exit actions. (??)
             ...
             ...
            ''The net effect is that generator functions, coded as def statements containing yield statements, are automatically made to support the iteration object protocol and thus may be used in any iteration context to produce results over time and on demand.
            --
            lpy3-(p644),p645
            }}}
        define  a generator function  to generate  squares of  num.s over time: (***(*)) @(@)
            {{{
            >>> def gensquares(N):
                    for i in range(N):
                        # =Resume here later
                        yield i ** 2
            , when it’s used in the body of a for loop, the first iteration starts the function and gets its first result; thereafter, control returns to the function after its yield statement each time through the loop:
              .
            >>> for i in gensquares(5):	  # Resume the function
                    print(i, end=' : ')		  # Print last yielded value
              .
            0 : 1 : 4 : 9 : 16 :		#???
            >>>
              .
            To end the generation of values, functions either use a return statement with no value or simply allow control to fall off the end of the function body.
                [[+ 'If you really want to see what is going on inside the for, call the generator function directly:
            --
            lpy3-p645
            }}}
            ----

            ----
        Why generator functions? ** (!) (@)
            {{{
            'generators can be better in terms of both memory use and performance (= than loops, compreh, maps) in larger programs.
            They allow functions to avoid doing all the work up front, which is especially useful when the result lists are large or when it takes a lot of computation to produce each value.
              .
            Moreover, for more advanced uses, generators can provide a simpler alternative to manually saving the state between iterations in class objects - with generators, variables accessible in the function’s scopes are saved and restored automatically. (1) We’ll discuss class-based iterables in more detail in Part VI.
                'Generator functions are also much more broadly focused than implied so far. They can operate on and return any type of object, and as iterables may appear in any of Chapter 14’s iteration contexts, including tuple calls, enumerations, and dictionary comprehensions: (??) (**)
            [+ 'generator functions are also something of a “poor man’s” multithreading device ((**))
                Note that because control is routed explicitly at yield and next calls, generators are also not backtracking, but are more strongly related to coroutines - formal concepts that are both beyond this chapter’s scope.
              .
            +Ex:
            >>> def ups(line):
                    # Substring generator
                    for sub in line.split(','):
                        yield sub.upper()
              .
                # All iteration contexts
            >>> tuple(ups('aaa,bbb,ccc'))
            ('AAA', 'BBB', 'CCC')
              .
            >>> {i: s for (i, s) in enumerate(ups('aaa,bbb,ccc'))}
            {0: 'AAA', 1: 'BBB', 2: 'CCC'}
              .
              .
              .
            Later in this chapter we’ll also see that generators can sometimes make the impossible possible, by producing components of result sets that would be far too large to create all at once.
            --
            lpy3-p647,p648
            }}}
        Extended generator function protocol: send versus next (!) (SSSs)
            {{{
            The send method advances to the next item in the series of results, just like __next__, but also provides a way for the caller to communicate with the generator, to affect its operation.
                (+yield as "an expression form") (!!(??(!)))
            + 'When this extra protocol is used, values are sent into a generator G by calling G.send(value).  The generator’s code is then resumed, and the yield expression in the generator returns the value passed to send. (??) (!)
            --
            lpy3-p648
            }}}
        'The send method can be used, for example, (!) ** (@)
            {{{
            to code a generator that its caller can terminate by sending a termination code, or redirect by passing a new position in data being processed inside the generator.
            --
            lpy3-p649
            }}}
        raise an exception inside the generator at the latest yield,  + raise  a special GeneratorExit exception inside the generator to terminate the iteration entirely.
            {{{
            'In addition, generators in 2.5 and later also support a throw(type) method to raise an exception inside the generator at the latest yield, and a close method that raises a special GeneratorExit exception inside the generator to terminate the iteration entirely.
            --
            lpy3-p649
            }}}
        [['Note that while Python 3.X provides a next(X) convenience built-in that calls the X.__next__() method of an object, other generator methods, like send, must be called as methods of generator objects directly (e.g., G.send(X)). (!)
            {{{
            --
            lpy3-p649
            }}}
        + 'Python 3.3 introduces an extension to yield - a ___ clause (@)
            {{{
            from
                = allows generators to delegate to nested generators.
            --
            lpy3-p649
            }}}
            ----

            ----
        Generator Expressions: @(@)
            {{{
            = 'Iterables Meet Comprehensions
            Syntactically, generator expressions are just like normal list comprehensions, and support all their syntax - including if filters and loop nesting - but they are enclosed in parentheses instead of square brackets (like tuples, their enclosing parentheses are often optional):
              # List comprehension: build a list
            >>> [x ** 2 for x in range(4)]
            [0, 1, 4, 9]
              .
              # Generator expression: make an iterable
            >>> (x ** 2 for x in range(4))
            <generator object <genexpr> at 0x00000000029A8288>
            + 'This iterable object in turn supports the iteration protocol to yield one piece of the result list at a time in any iteration context.
                'The net effect is much like that of generator functions, but in the context of a comprehension expression: we get back an object that remembers where it left off after each part of its result is returned.
              .
            >>> G = (x ** 2 for x in range(4))
            >>> iter(G) is G	  # iter(G) optional: __iter__ returns self
            True
            >>> next(G)			# Generator objects: automatic methods
            0
            >>> next(G)
            1
             ...
              .
              .
            Again, we don’t typically see the next iterator machinery under the hood of a generator expression like this because for loops trigger it for us automatically:
            --
            lpy3-p649,p650
            }}}
        '''For example, the following deploys generator expressions in the string join method call and tuple assignment, iteration contexts both. In the first test here, join runs the generator and joins the substrings it produces with nothing between - to simply concatenate: (????? SSSSs (@)
            {{{
            --
            lpy3-p650
            }}}
        + 'Notice how the join call in the preceding doesn’t require extra parentheses around the generator.  (= in the prev. Ex (!)  (!!) (@)
            {{{
            Syntactically, parentheses are not required around a generator expression that is the sole item already enclosed in parentheses used for other purposes - like those of a function call.
            Parentheses are required in all other cases, however, even if they seem extra, as in the second call to sorted that follows:
             ...
             ...
                # Parens required (!!)
            >>> sorted((x ** 2 for x in range(4)), reverse=True)
            [9, 4, 1, 0]
                ((Like the often-optional parentheses in tuples, there is no widely accepted rule on this, though a generator expression does not have as clear a role as a fixed collection of other objects as a tuple, making extra parentheses seem perhaps more spurious here.
            --
            lpy3-p650
            }}}
        Why generator expressions? (!!) @(@)
            {{{
            Just like generator functions, generator expressions are a memory-space optimization - they do not require the entire result list to be constructed all at once, as the squarebracketed list comprehension does.
              .
            On the other hand, generator expressions may also run slightly slower than list comprehensions in practice, so they are probably best used only for very large result sets, or applications that cannot wait for full results generation.
            --
            -  One way to see the coding benefits of generator expressions is to compare them to other functional tools, as we did for list comprehensions. For example, generator expressions often are equivalent to 3.X map calls, because both generate result items on request.
            Like list comprehensions, though, generator expressions may be simpler to code when the operation applied is not a function call.
              (+2.x vs 3.x)
              .
              .
                # Map function on tuple
            >>> list(map(abs, (−1, −2, 3, 4)))
            [1, 2, 3, 4]
                # Generator expression
            >>> list(abs(x) for x in (−1, −2, 3, 4))
            [1, 2, 3, 4]
                # Nonfunction case
            >>> list(map(lambda x: x * 2, (1, 2, 3, 4)))
            [2, 4, 6, 8]
                # Simpler as generator?
            >>> list(x * 2 for x in (1, 2, 3, 4))
            [2, 4, 6, 8]
              .
              .
                    # Makes a pointless list
            >>> line = 'aaa,bbb,ccc'
            >>> ''.join([x.upper() for x in line.split(',')])
            'AAABBBCCC'
              .
                    # Generates results
            >>> ''.join(x.upper() for x in line.split(','))
            'AAABBBCCC'
                    # Generates results
            >>> ''.join(map(str.upper, line.split(',')))
            'AAABBBCCC'
              .
                    # Simpler as generator?
            >>> ''.join(x * 2 for x in line.split(','))
            'aaaaaabbbbbbcccccc'
            >>> ''.join(map(lambda x: x * 2, line.split(',')))
            'aaaaaabbbbbbcccccc'
            --
            Both map and generator expressions can also be arbitrarily nested, which supports general use in programs, and requires a list call or other iteration context to start the process of producing results.
            For example, the list comprehension in the following produces the same result as the 3.X map and generator equivalents that follow it, but makes two physical lists; the others generate just one integer at a time with nested generators, and the generator expression form may more clearly reflect its intent:
                # Nested comprehensions
            >>> [x * 2 for x in [abs(x) for x in (−1, −2, 3, 4)]]
            [2, 4, 6, 8]
              .
                # Nested maps
            >>> list(map(lambda x: x * 2, map(abs, (−1, −2, 3, 4))))
            [2, 4, 6, 8]
              .
                # Nested generators
            >>> list(x * 2 for x in (abs(x) for x in (−1, −2, 3, 4)))
            [2, 4, 6, 8]
            --
            lpy3-p650--652
            }}}
        Ex: 'In 3.X, the next example both nests and combines generators - the nested generator expression is activated by map, which in turn is only activated by list. ((******) (SSSSSSss)
            {{{
            >>> import math
                    # Nested combinations
            >>> list(map(math.sqrt, (x ** 2 for x in range(4))))
            [0.0, 1.0, 2.0, 3.0]
              .
              .
              .
              .
              .
              .
                # (+)Nesting gone bad?
            >>> list(map(abs, map(abs, map(abs, (−1, 0, 1)))))
            [1, 0, 1]
            >>> list(abs(x) for x in (abs(x) for x in (abs(x) for x in (−1, 0, 1))))
            [1, 0, 1]
              .
            'These last examples illustrate how general generators can be, but are also coded in an intentionally complex form to underscore that generator expressions have the same potential for abuse as the list comprehensions discussed earlier - as usual, you should keep them simple unless they must be complex, a theme we’ll revisit later in this chapter.
            '(!)When used well, though, generator expressions combine the expressiveness of list comprehensions with the space and time benefits of other iterables.
            --
            lpy3-p652,p653
            }}}
        'Here, for example, nonnested approaches provide simpler solutions but still leverage generators’ strengths - per a Python motto, flat is generally better than nested:
            {{{
                # Unnested equivalents
            >>> list(abs(x) * 2 for x in (−1, −2, 3, 4))
            [2, 4, 6, 8]
                # (=) Flat is often better
            >>> list(math.sqrt(x ** 2) for x in range(4))
            [0.0, 1.0, 2.0, 3.0]
            >>> list(abs(x) for x in (−1, 0, 1))
            [1, 0, 1]
            --
            lpy3-p653
            }}}
        [Generator expressions versus filter (!) @
            {{{
            Generator expressions also support all the usual list comprehension syntax - including if clauses, which work like the filter call we met earlier.
            >>> line = 'aa bbb c'
                # Generator with 'if'
            >>> ''.join(x for x in line.split() if len(x) > 1)
            'aabbb'
                # Similar to filter
            >>> ''.join(filter(lambda x: len(x) > 1, line.split()))
            'aabbb'
              .
            'As for list comprehensions, though, adding processing steps to filter results requires a map too, which makes filter noticeably more complex than a generator expression:
               # is simpler
            >>> ''.join(x.upper() for x in line.split() if len(x) > 1)
            'AABBB'
            >>> ''.join(map(str.upper, filter(lambda x: len(x) > 1, line.split())))
            'AABBB'
              .
              .
            In effect, generator expressions do for 3.X iterables like map and filter what list comprehensions do for the 2.X list-builder flavors of these calls - they provide more general coding structures that do not rely on functions, but still delay results production.
              .
            >>> ''.join(x.upper() for x in line.split() if len(x) > 1)
            'AABBB'
              .
            >>> res = ''  # Statement equivalent?
            >>> for x in line.split():	# This is also a join
                    if len(x) > 1:
                        res += x.upper()
            --
            lpy3-p653,p654
            }}}
            ----

            ----
        [[ 'Generator Functions Versus Generator Expressions (!) (@)
            {{{
            The following generator expression, for example, repeats each character in a string four times:
              .
                # Generator expression
            >>> G = (c * 4 for c in 'SPAM')
                # Force generator to produce all results
            >>> list(G)
            ['SSSS', 'PPPP', 'AAAA', 'MMMM']
            --
            lpy3-p654
            }}}
        generator expressions vs generator function (generally) *(*) @
            {{{
            = like lambdas and defs  = functions are more flexible, but requires more code
            'The equivalent generator function requires slightly more code, but as a multiple-statement function it will be able to code more logic and use more state information if needed.
            =the  tradeoff between lambda and def - expression conciseness versus statement power:
            --
            Both expressions and functions support both automatic and manual iteration - the prior list call iterates automatically, and the following iterate manually:
            >>> G = (c * 4 for c in 'SPAM')
                # Iterate manually (expression)
            >>> I = iter(G)
            >>> next(I)
            'SSSS'
            >>> next(I)
            'PPPP'
              .
            >>> G = timesfour('spam')
                # Iterate manually (function)
            >>> I = iter(G)
            >>> next(I)
            'ssss'
            >>> next(I)
            'pppp'
            --
            lpy3-p655
            }}}
        'A subtle but important point: both generator functions and generator expressions are their own iterators and thus support (@)
            {{{
            just one active iteration
              .
            - unlike some built-in types, you can’t have multiple iterators of either positioned at different locations in the set of results.
                Because of this, a generator’s iterator is .... (.)
                .
            , once any iteration runs to completion, all are exhausted - we have to make a new generator to start again:
            --
            lpy3-p656,p657
            }}}
        In general, objects that wish to support multiple scans will * (!) @
            {{{
            return supplemental class objects instead of themselves.
            --
            lpy3-p657
            }}}
        Python 3.3 introduces extended syntax for the yield statement that allows (!) (@)
            {{{
            delegation to a subgenerator with a from generator clause.
                'In simple cases, it’s the equivalent to a yielding for loop - the list here in the following forces the generator to produce all its values, and the comprehension in parentheses is a generator expression, covered in this chapter:
            The new 3.3 syntax makes this arguably more concise and explicit, and supports all the usual generator usage contexts:
              .
            >>> def both(N):
                    for i in range(N): yield i
                    for i in (x ** 2 for x in range(N)): yield i
                  .
                  . (vs)
                  .
            >>> def both(N):
                    yield from range(N)
                    yield from (x ** 2 for x in range(N))
            --
            lpy3-p657,p658
            }}}
        The new 3.3 syntax (= makes things easier|clearer, +makes what possible?) **
            {{{
            makes this (= the easier normal cases) arguably more concise and explicit, and supports all the usual generator usage contexts: (SSSs Ee)
              .
            In more advanced roles, however, this extension allows subgenerators to receive sent and thrown values directly from the calling scope, and return a final value to the outer generator.
                The net effect is to allow such generators to be split into multiple subgenerators much as a single function can be split into multiple subfunctions.
              .
            Since this is only available in 3.3 and later, and is beyond this chapter’s generator coverage in general, we’ll defer to Python 3.3’s manuals for additional details.
            For an additional yield from example, also see the solution to this part’s Exercise 11 described at the end of Chapter 21.
            --
            lpy3-p658
            }}}
        te: concerning built-in types and value generators **
            {{{
            Finally, although we’ve focused on coding value generators ourselves in this section, don’t forget that many built-in types behave in similar ways - as we saw in Chapter 14, for example, dictionaries are iterables with iterators that produce keys on each iteration:
            --
            lpy3-p658
            }}}
        Generators and library tools: Directory walkers (!) @(@)
            {{{
              (+ email parsers, etc)
              .
              .
            >>> import os
                # Directory walk generator
            >>> for (root, subs, files) in os.walk('.'):
                # A Python 'find' operation
                    for name in files:
                        if name.startswith('call'):
                            print(root, name)
              .
            . callables.py
            .\dualpkg callables.py
                (+SS)
            (By yielding results as it goes, the walker does not require its clients to wait for an entire tree to be scanned. See Python’s manuals and follow-up books such as Programming Python for more on this tool.
            --
            lpy3-p659
            }}}
                ----

                ----
        Generators and function application (= functions with starred arguments etc) (!!) (ssss)
            {{{
              (+for dicts(**(*)|??(?))|views)
            --
            lpy3-p660
            }}}
        unpacking the arguments from|to a print (= incl. with a generator expression) @
            {{{
            >>> for x in 'spam': print(x.upper(), end=' ')
            S P A M
              .
            >>> list(print(x.upper(), end=' ') for x in 'spam')
            S P A M [None, None, None, None]
              .
            >>> print(*(x.upper() for x in 'spam'))
            S P A M
            --
            lpy3-p660
            }}}
        'In Chapter 18, we wrote a testing function that scrambled the order of arguments used to test generalized intersection and union functions. There, I noted that this might be better coded as a generator of values. @
            {{{
              .
              .
              .
            As is, this code works on specific named variables only. To generalize, we can turn it into a simple function to work on any object passed to its argument and return a result;
                The preceding section’s simple approach works, but must build an entire result list in memory all at once (not great on memory usage if it’s massive), and requires the caller to wait until the entire list is complete (less than ideal if this takes a substantial amount of time).
            --
            lpy3-p661(?)--p663
            }}}
        (generator) expressions can often be more concise (=than g.functions) in specific use cases like this(=coding a scrambler functionality): +Because? ** @
            {{{
            = They’re not as flexible as full functions, but because they yield their values automatically, expressions can often be more concise in specific use cases like this:
              .
            >>> S
            'spam'
                # Generator expression equivalent
            >>> G = (S[i:] + S[:i] for i in range(len(S)))
            >>> list(G)
            ['spam', 'pams', 'amsp', 'mspa']
            --
            lpy3-p663
            }}}
        tip: To generalize a generator expression for an arbitrary subject, * @@ @@
            {{{
            wrap it in a simple function that takes an argument and returns a generator that uses it:
              .
            >>> F = lambda seq: (seq[i:] + seq[:i] for i in range(len(seq)))
            >>> F(S)
            <generator object <genexpr> at 0x00000000029883F0>
            >>>
            >>> list(F(S))
            ['spam', 'pams', 'amsp', 'mspa']
            >>> list(F([1, 2, 3]))
            [[1, 2, 3], [2, 3, 1], [3, 1, 2]]
              .
            >>> for x in F((1, 2, 3)):
                    print(x, end=' ')
              .
            (1, 2, 3) (2, 3, 1) (3, 1, 2)
              .
            [+ one more EE]
              [+ notes about packaging]
            + 'These techniques have many other real-world applications - consider generating attachments in an email message or points to be plotted in a GUI. (etc)  **(!!)
              .
            +EEE:
            'Both of these functions produce the same results, though the second defers much of its work until it is asked for a result.
              .
              .
              .
              .
            +Tip:
            'Study and test this code for more insight, and add prints to trace if it helps.
            --
            lpy3-p663--p665
            }}}
        'Still, as I’ll explain in a moment, there are cases where the generator approach can be highly useful. ** (!) (@)
            {{{
            = ''On the other hand: Space and time, conciseness, expressiveness
                Since the number of combinations is a factorial that explodes exponentially, the preceding permute1 recursive list-builder function will either introduce a noticeable and perhaps interminable pause or fail completely due to memory requirements, whereas the permute2 recursive generator will not - it returns each individual result quickly, and can handle very large result sets:
            In this case, the list builder pauses for 37 seconds on my computer to build a 3.6-million item list, but the generator can begin returning results immediately:
            --
            lpy3-p665;p667--p668
            }}}
        te: 'In fact, that’s why we need recursion here:
            {{{
            the number of nested loops is arbitrary, and depends on the length of the sequence permuted:
                Per Chapter 19, there are nonrecursive alternatives here too, using explicit stacks or queues, and other sequence orderings are common (e.g., fixed-size subsets and combinations that filter out duplicates of differing order), but these require coding extensions we’ll forgo here.
            --
            lpy3-p665
            }}}
            ----

            ----
        Example: Emulating zip and map with Iteration Tools (!) @
            {{{
            Once you know about comprehensions, generators, and other iteration tools, it turns out that emulating many of Python’s functional built-ins is both straightforward and instructive.
                'Coding your own map(func, ...)
            'We can code our map more concisely as an equivalent one-line list comprehension: (****(!!))
            --
            + 'Now that we know about generator functions and expressions, it’s simple to recode both these alternatives to produce results on demand instead: **
            --
            lpy3-p669
            }}}
        'Coding your own zip(...) and map(None, ...) @@
            {{{
              .
              .
              .
            Notice the use of the all and any built-ins here - these return True if all and any items in an iterable are True (or equivalently, nonempty), respectively. These built-ins are used to stop looping when any or all of the listified arguments become empty after deletions.
                ('Also note the use of the Python 3.X keyword-only argument, pad; unlike the 2.X map, our version will allow any pad object to be specified (if you’re using 2.X, use a (??) *
            --
            'Finally, here’s an alternative implementation of our zip and map emulators - rather than deleting arguments from lists with the pop method, the following versions do their job by calculating the minimum and maximum argument lengths. Armed with these lengths, it’s easy to code nested list comprehensions to step through argument index ranges:
                Armed with these lengths, it’s easy to code nested list comprehensions to step through argument index ranges:
            --
            +(!/?)
            'Consider the following clever alternative coding for this chapter’s zip emulation examples, adapted from one in Python’s manuals at the time I wrote these words:
             --
            lpy3-p671,p672;p673
            }}}
        Why You Will Care: One-Shot Iterations (!) (@)
            {{{
                    [['To make this work in 3.X, we need to use the list built-in function to create an object that can support multiple iterations:
                'Run this on your own to trace its operation. The lesson here: wrapping map calls in list calls in 3.X is not just for display!
            --
            lpy3-p673,p674
            }}}
        (+) two other comprehension expression forms available in both 3.X and 2.7: set and dictionary comprehensions. @(@)
            {{{
            We met these briefly in Chapter 5 and Chapter 8, but with our new knowledge of comprehensions and generators, you should now be able to grasp these extensions in full:
              --
            • For sets, the new literal form {1, 3, 2} is equivalent to set([1, 3, 2]), and the new set comprehension syntax {f(x) for x in S if P(x)} is like the generator expression set(f(x) for x in S if P(x)), where f(x) is an arbitrary expression.
            • For dictionaries, the new dictionary comprehension syntax {key: val for (key, val) in zip(keys, vals)} works like the form dict(zip(keys, vals)), and {x: f(x) for x in items} is like the generator expression dict((x, f(x)) for x in items).
              .  (+summary|examples)
            # List comprehension: builds list
        >>> [x * x for x in range(10)]
            # Like list(generator expr)
        [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]

            # Generator expression: produces items
        >>> (x * x for x in range(10))
            # Parens are often optional
        <generator object at 0x009E7328>

            # Set comprehension, 3.X and 2.7
        >>> {x * x for x in range(10)}
            # {x, y} is a set in these versions too
        {0, 1, 4, 81, 64, 9, 16, 49, 25, 36}

            # Dictionary comprehension, 3.X and 2.7
        >>> {x: x * x for x in range(10)}
        {0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81}
            --
            lpy3-p674
            }}}
        (Scopes and Comprehension Variables (@)
            {{{
             (!! (= sss))
                 = 'If you care about version portability, and symmetry with the for loop statement, use unique names for variables in comprehension expressions as a rule of thumb.
            --
            lpy3-p675,676
            }}}
        Comprehending Set and Dictionary Comprehensions (!!) ** @
            {{{
            In a sense, set and dictionary comprehensions are just syntactic sugar for passing generator expressions to the type names. (??) **
              (+EE
               ((+ 'As for list comprehensions, though, we can always build the result objects with manual code, too.
              .
            Notice that although both set and dictionary comprehensions accept and scan iterables, they have no notion of generating results on demand - both forms build complete objects all at once.
            (!!**) = 'If you mean to produce keys and values upon request, a generator expression is more appropriate:
            --
            lpy3-p676,p677
            }}}
        Extended Comprehension Syntax for Sets and Dictionaries (!!) (!!) * (SSSS) @(@)
            {{{
            'Like list comprehensions and generator expressions, both set and dictionary comprehensions support nested associated if clauses to filter items out of the result - the following collect squares of even items (i.e., items having no remainder for division by 2) in a range:
                + Nested for loops work as well, though the unordered and no-duplicates nature of both types of objects can make the results a bit less straightforward to decipher:
            + Like list comprehensions, the set and dictionary varieties can also iterate over any type of iterable - lists, strings, files, ranges, and anything else that supports the iteration protocol:  p678
              .
              .
            ''They may or may not have a performance advantage over the generator or for loop alternatives, but we would have to time their performance explicitly to be sure - which seems a natural segue to the next chapter.
            --
            lpy3-p677
            }}}
        generator expressions return a ___ which ___ **
            {{{
            generator expressions return a generator object, which yields one item in the result at a time when used in an iteration context.
            --
            lpy3-p679
            }}}
        Generators are ____
            {{{
            iterable objects that support the iteration protocol automatically - (= they have .....
            --
            lpy3-p679
            }}}
        In Python, we can code generator functions with ** (!) @
            {{{
            def and yield,
            generator expressions with parenthesized comprehensions, and
            generator objects with classes that define a special method named __iter__
            --
            lpy3-p679
            }}}
                ----

                ----
        ('In more advanced roles, the generator send method similarly resumes the generator, but can also pass a value that shows up as the yield expression’s value.
            {{{
            --
            lpy3-p679
            }}}
        compare map call to list comprehensions (= generality, what can be used with) (@)
            {{{
            Because of this, list comprehensions are more general; they can apply a function call expression like map, but map requires a function to apply other kinds of expressions.
            --
            lpy3-p679
            }}}
        facilities  that subsume the filter built-in (= for list comprehensions) *
            {{{
            extended syntax such as nested for loops and if clauses
            --
            lpy3-p679
            }}}
                ----





        Chapter 21 - The Benchmarking Interlude

                ----
        Timing Iteration Alternatives
            {{{
            'Now that we know about coding functions and iteration tools, we’re going to take a short side trip to put both of them to work. (??)
                (+ see more ee:s below)
            --
            lpy3-p681
            }}}
        (some general comparison remarks (= ab. diff. iter. alternatives)) (!)
            {{{
            In terms of performance, I’ve mentioned a few times that list comprehensions sometimes have a speed advantage over for loop statements, and that map calls can be faster or slower than both depending on call patterns.
            The generator functions and expressions of the preceding chapter tend to be slightly slower than list comprehensions, though they minimize memory space requirements and don’t delay result generation.
                [+ All that is generally true today, but relative performance can vary over time because Python’s internals are constantly being changed and optimized, and code structure can influence speed arbitrarily.
            --
            lpy3-p681
            }}}
        Timing Module: Homegrown (= simple first function for timing code) * (@)
            {{{
            = 'to get the total time taken to run multiple calls to a function with arbitrary positional arguments, the following firstcut function might suffice:
              .
            # File timer0.py
            import time
                # Simplistic timing function
            def timer(func, *args):
                start = time.clock()
                for i in range(1000):
                    func(*args)
                # Total elapsed time in seconds
                return time.clock() - start
              .
            This works - it fetches time values from Python’s time module, and subtracts the system start time from the stop time after running 1,000 calls to the passed-in function with the passed-in arguments.
              .
            >>> from timer0 import timer
                # Time to call pow(2, 1000) 1000 times
            >>> timer(pow, 2, 1000)
            0.00296260674205626
                # Time to call 'spam'.upper() 1000 times
            >>> timer(str.upper, 'spam')
            0.0005165746166859719
            --
            lpy3-p682
            }}}
        'Though simple, this timer is also fairly limited, and deliberately exhibits some classic mistakes in both function design and benchmarking. (****) (!@)
            {{{
            • Doesn’t support keyword arguments in the tested function call
            • Hardcodes the repetitions count
            • Charges the cost of range to the tested function’s time
            • Always uses time.clock, which might not be best outside Windows
            • Doesn’t give callers a way to verify that the tested function actually worked
            • Only gives total time, which might fluctuate on some heavily loaded machines
            --
            lpy3-p682
            }}}
        'still simple but more useful timer utility functions we can use both to * (!) @
            {{{
            see how iteration alternative options stack up now, and apply to other timing needs in the future. These functions are coded in a module file so they can be used in a variety of programs, and have docstrings giving some basic details that PyDoc can display on request -
            --
            lpy3-p682
            }}}
        timer.py (= Does total time, best-of time, and best-of-totals time ((SSSSS)) @
            {{{
            'In each, it times a call to any function with any positional and keyword arguments passed individually, by fetching the start time, calling the function, and subtracting the start time from the stop time.
                ''Points to notice about how this version addresses the shortcomings of its predecessor:
              - - - -
            ((+See also the sidebar “New Timer Calls in 3.3” on page 633 on other time options in 3.3 and later not used here for portability;
              .
              .
              ((+ 'This function’s code may be easier to understand if you remember that every function is a passable object, even the testing functions themselves.
            --
            From a larger perspective, because these functions are coded in a module file, they become generally useful tools anywhere we wish to import them. (****(**))
            --
            lpy3-p682--p684
            }}}
        usage examples of the timer.py (**!) (@)
            {{{
            >>> import timer
            # Compare to timer0 results above
            >>> timer.total(1000, pow, 2, 1000)[0]
            0.0029542985410557776
            # Returns (time, last call's result)
            >>> timer.total(1000, str.upper, 'spam')
            (0.000504845391709686, 'SPAM')
              .
            # 1/1000 as long as total time
            >>> timer.bestof(1000, str.upper, 'spam')
            (4.887177027512735e-07, 'SPAM')
            >>> timer.bestof(1000, pow, 2, 1000000)[0]
            0.00393515497972885
              .
            >>> timer.bestof(50, timer.total, 1000, str.upper, 'spam')
            (0.0005468751145372153, (0.0005004469323637295, 'SPAM'))
            >>> timer.bestoftotal(50, 1000, str.upper, 'spam')
            (0.000566912540591602, (0.0005195069228989269, 'SPAM'))
              .
              .
            Compare these last two results to the following generator-based alternative:
              .
            >>> min(timer.total(1000, str.upper, 'spam') for i in range(50))
            (0.0005155971812769167, 'SPAM')
            --
            lpy3-p684,p685
            }}}
            ----

            ----
        New Timer Calls in 3.3 **
            {{{
            Python 3.3 introduces new interfaces in this module that are designed to be more portable.
            Specifically, the behavior of this module’s clock and time calls varies per platform, but its new perf_counter and process_time functions have well-defined and platform-neutral semantics: *
              .
            • time.perf_counter() returns the value in fractional seconds of a performance counter, defined as a clock with the highest available resolution to measure a short duration. It includes time elapsed during sleep states and is system-wide.
            • time.process_time() returns the value in fractional seconds of the sum of the system and user CPU time of the current process. It does not include time elapsed during sleep, and is process-wide by definition.
                + 'For both of these calls, the reference point of the returned value is undefined, so that only the difference between the results of consecutive calls is valid. (??) (!)
                The perf_counter call can be thought of as wall time, and as of Python 3.3 is used by default for benchmarking in the timeit module discussed ahead; process_time gives CPU time portably.
            --
            lpy3-p685
            }}}
        detect a Python 3.3 or later with code * @
            {{{
            if sys.version_info[0] >= 3 and sys.version_info[1] >= 3:
                timer = time.perf_counter   # or process_time
            else:
                timer = time.clock if sys.platform[:3] == 'win' else time.time
            ((or an|the exception version (!!)  (Ee )
            --
            lpy3-p685
            }}}
        Now, to time iteration tool speed (our original goal), run the following script - it uses the timer module we wrote to time the relative speeds of the list construction techniques we’ve studied: (!) *
            {{{
            timeseqs.py
              (SSSs)
            --
            lpy3-p686;p687
            }}}
        Using function decorators for timing functions ((**(!))) (@)
            {{{
             = footnote 1 (!)
            --
            lpy3-p687
            }}}
        For comparison, following are the same tests’ speed results under the current PyPy, the optimized Python implementation discussed in Chapter 2, whose current 1.9 release implements the Python 2.7 language. (!)
            {{{
            PyPy is roughly 10X (an order of magnitude) quicker here; it will do even better when we revisit Python version comparisons later in this chapter using tools with different code structures (though it will lose on a few other tests as well):
            --
            lpy3-p688
            }}}
        [The impact of function calls: map]
            {{{
            --
            lpy3-p689
            }}}
            ----

            ----
        map appears to be slower simply because (!)
            {{{
            it requires function calls, and function calls are relatively slow in general.
            --
            lpy3-p690
            }}}
        'The following implements an alternative timer module that addresses these points, allowing the repeat count to be passed in as a keyword argument named _reps:  timer2.py (@)
            {{{
              .
              .
              .
            (+ the testing:
              .
            import sys, timer2
            ...
              .
              .
            - the results are again essentially the same as before, but we pass in the repetition counts as keywords that provide defaults if omitted; in Python 3.3:
            --
            lpy3-p691,p692
            }}}
        [[(??) Using keyword-only arguments in 3.X
            {{{
            'As we learned in Chapter 18, keywordonly arguments are ideal for configuration options such as our functions’ _reps argument. They must be coded after a * and before a ** in the function header, and in a function call they must be passed by keyword and appear before the ** if used.
                (+ 'If you want to compare 2.X and 3.X speed, or support programmers using either Python line, the prior version is likely a better choice.
            --
            lpy3-p693
            }}}
        The timer’s results can help you judge relative speeds of coding alternatives, though, and may be more meaningful for (!) *
            {{{
            operations that run longer or are repeated often.
            --
            lpy3-p694
            }}}
        Other Suggestions ** (!) (@)@
            {{{
            (For more insight, try modifying the repetition counts used by these modules, or explore the alternative timeit module in Python’s standard library, which automates timing of code, supports command-line usage modes, and finesses some platform-specific issues - in fact, we’ll put it to work in the next section.
            You might also want to look at the profile standard library module for a complete source code profiler tool.
              = In general, you should profile code to isolate bottlenecks before recoding and timing alternatives as we’ve done here. **
            --
            lpy3-p694
            }}}
        As mentioned there, the standard library also ships with a module named timeit that can be used in similar ways, but (=also) offers
            {{{
            --
            lpy3-p694
            }}}
                ----

                ----
        Basic timeit Usage **( = let’s move ahead to a tool that can automate much of our work. (@)
            {{{
            With timeit, tests are specified by either callable objects or statement strings;
                Tests may also give setup actions, and can be launched from both command lines and API calls, and from both scripts and the interactive prompt.
            --
            lpy3-p695
            }}}
        'For example, the timeit module’s repeat call returns a list giving the total time taken to run a test a number of times, for each of repeat runs - the min of this list yields the best time among the runs, and helps filter out system load fluctuations that can otherwise skew timing results artificially high.
            {{{
            - 'Interactive usage and API calls
              .
            >>> import timeit
            >>> min(timeit.repeat(stmt="[x ** 2 for x in range(1000)]", number=1000, repeat=5))
             ...
             ...
             ...
             ...
             ...
            --
            lpy3-p695
            }}}
        ['Command-line usage
            {{{
            The timeit module has reasonable defaults and can be also run as a script, ......
              .
              .
              .
            'As an example, we can use command lines to verify that choice of timer call doesn’t impact cross-version speed comparisons run in this chapter so far - 3.3 uses its new calls by default, and that might matter if timer precision differs widely.
            --
            lpy3-p696
            }}}
        [['Timing multiline statements (!)
            {{{
              .
              .
              .
              .
             (+ 'you can use the same pattern to time the file-line-reader alternatives in Chapter 14: (??|!
            --
            lpy3-p697
            }}}
        (tabs vs blanks in the timing reports =for indentation)
            {{{
            --
            lpy3-p698
            }}}
        'Other usage modes: Setup, totals, and objects (@)
            {{{
            The timeit module also allows you to provide setup code that is run in the main statement’s scope, but whose time is not charged to the main statement’s total - potentially useful for initialization code you wish to exclude from total time, such as imports of required modules, test function definition, and test data creation.
            Because they’re run in the same scope, any names created by setup code are available to the main test statement; names defined in the interactive shell generally are not.
                + 'To specify setup code, ....
            'This can focus tests more sharply, as in the following, which splits list initialization off to a setup statement to time just iteration.  As a rule of thumb, though, the more code you include in a test statement, the more applicable its results will generally be to realistic code:
            --
            lpy3-p698
            }}}
        'Here’s a setup example in API call mode: I used the following type of code to time the sort-based option in Chapter 18’s minimum value example - ....
            {{{
            --
            lpy3-p698
            }}}
        With timeit, you can also ask for just total time, use the module’s class API, time callable objects instead of strings, accept automatic loop counts, and use class-based techniques and additional command-line switches and API argument options
            {{{
            we don’t have space to show here - consult Python’s library manual for more details:
            --
            lpy3-p699
            }}}
        [['Benchmark Module and Script: timeit (!!) (@)
            {{{
            Rather than go into more details on this module, let’s study a program that deploys it to time both coding alternatives and Python versions.
                'The following file, pybench.py, is set up to time a set of statements coded in scripts that import and use it, under either the version running its code or all Python versions named in a list. ......
            --
            --
            'This file is really only half the picture, though. Testing scripts use this module’s function, passing in concrete though variable lists of statements and Pythons to be tested, as appropriate for the usage mode desired. For example, .....
            --
            lpy3-p699
            }}}
            ----

            ----
        note: direct API calls vs **
            {{{
            command lines
            --
            lpy3-p701
            }}}
        [more terms, notes etc (_÷÷^=×%%) (@)
            {{{
            garbage collection).
            baseline overhead,
                 +tip: 'To time the baseline overhead of each Python, run timeit with no statement argument, or equivalently, with a pass statement.
            --
            lpy3-p703
            }}}
        More Fun with Benchmarks (!!) * (@)
            {{{
            'For more insight, try running the script on other Python versions and other statement test strings. ....
            --
            lpy3-p703
            }}}
        Other Benchmarking Topics: pystones **
            {{{
            • pystone.py - a program designed for measuring Python speed across a range of code that ships with Python in its Lib\test directory
             ...
             ...
             ...
             ...
           + 'for pointers on options in related domains (e.g., testing), see Chapter 36’s review of Python development tools.
            --
            lpy3-p708
            }}}
            ----

        Function Gotchas (##)

            ----
        Local Names Are Detected Statically (??) (!) [******* ####### (SSSS !!!! @
            {{{
            = What you may not realize is that Python detects locals statically, when it compiles the def’s code, rather than by noticing assignments as they happen at runtime.
             ????
             ????
             ????
             ????
             ????
             ????
            Imports, =, nested defs, nested classes, and so on are all susceptible to this behavior.
            The problem occurs because assigned names are treated as locals everywhere in a function, not just after the statements where they’re assigned. (AHA!!)
            !!  Because Python treats X as a local everywhere, it’s seen as an error; if you mean to print the global X, you need to declare it in a global statement:
                = Within a function, you can’t use both local and global versions of the same simple name.
            If you really meant to print the global and then set a local of the same name, you’d need to import the enclosing module and use module attribute notation to get to the global version:
                (+ 'The interactive namespace is a module called __main__, so __main__.X reaches the global version of X. **
            --
            lpy3-p709,p710
            }}}
        Defaults and Mutable Objects (@@)
            {{{
            As noted briefly in Chapter 17 and Chapter 18, mutable values for default arguments can retain state between calls, though this is often unexpected.
            In general, default argument values are evaluated and saved once when a def statement is run, not each time the resulting function is later called.
              .
            For instance, the following function uses an empty list as a default value, and then changes it in place each time the function is called:
                .
            Some see this behavior as a feature - because mutable default arguments retain their state between function calls, they can serve some of the same roles as static local function variables in the C language.
            'In a sense, they work much like global variables, but their names are local to the functions and so will not clash with names elsewhere in a program. *
            !!!!() There are better ways to retain state between calls in Python (e.g., using the nested scope closures we met in this part and the classes we will study in Part VI).
             ...
             ...
             ...
            + 'As long as the value resides in code that’s actually executed each time the function runs, you’ll get a new object each time through:
            --
            'Today, another way to achieve the value retention effect of mutable defaults in a possibly less confusing way is to use the function attributes we discussed in Chapter 19:
            --
            lpy3-p710,p711;p712
            }}}
        'By the way, the if statement in this example could almost be replaced by @
            {{{
            the assignment x = x or [],
                which takes advantage of the fact that Python’s or returns one of its operand objects: if no argument was passed, x would default to None, so the or would return the new empty list on the right.
              (although,  !!!
            --
            lpy3-p711
            }}}
        Functions Without returns (@)
            {{{
            = In Python functions, return (and yield) statements are optional.
            When a function doesn’t return a value explicitly, the function exits when control falls off the end of the function body.
             --
            Functions such as this without a return are Python’s equivalent of what are called “procedures” in some languages. **
            They’re usually invoked as statements, and the None results are ignored, as they do their business without computing a useful result.
            --
            lpy3-p712
            }}}
        Enclosing scopes and loop variables: Factory functions (??)
            {{{
            closures), be careful about relying on enclosing function scope lookup for variables that are changed by enclosing loops - when a generated function is later called, all such references will remember the value of the last loop iteration in the enclosing function’s scope.
                  In this case, you must use defaults to save loop variable values instead of relying on automatic lookup in enclosing scopes.
            --
            lpy3-p713
            }}}
          Hiding built-ins by assignment: Shadowing
            {{{
            
            --
            lpy3-p713
            }}}
        1. What conclusions can you draw from this chapter about the relative speed of Python iteration tools?
            {{{
            1. In general, list comprehensions are usually the quickest of the bunch; map beats list comprehensions in Python only when all tools must call functions; for loops tend to be slower than comprehensions; and generator functions and expressions are slower than comprehensions by a constant factor.
            Under PyPy, some of these findings differ; map often turns in a different relative performance, for example, and list comprehensions seem always quickest, perhaps due to function-level optimizations.
                Use the homegrown timer or standard library timeit to test your use cases for more relevant results.
            --
            lpy3-p714
            }}}
        2. What conclusions can you draw from this chapter about the relative speed of the Pythons timed?
            {{{
            2. In general, PyPy 1.9 (implementing Python 2.7) is typically faster than CPython 2.7, and CPython 2.7 is often faster than CPython 3.3. In most cases timed, PyPy is some 10X faster than CPython, and CPython 2.7 is often a small constant faster than CPython 3.3. In cases that use integer math, ....
            In cases that use integer math, CPython 2.7 can be 10X faster than CPython 3.3, and PyPy can be 100X faster than 3.3.
            --
            lpy3-p714
            }}}
            ----

        Part IV Exercises
            = 'In these exercises, you’re going to start coding more sophisticated programs. **

            ----
        the primes function revisited (*)
            {{{
            Package this code as a reusable function in a module file (y should be a passed-in argument), and add some calls to the function at the bottom of your file.
            --
            lpy3-p716
            }}}
        2
            {{{
            
            --
            lpy3-p717
            }}}





        classes, tools that are largely (@)
            {{{
            packages of functions with special first arguments.
            --
            lpy3-p713
            }}}

}}}
---- lpy06-modules.txt -- {{{
        Part V - Modules and Packages
        Chapter 22 - Modules: The Big Picture

            ----
        the highest-level program organization unit(=in Python), which packages program code and data for reuse,
            {{{
            the Python module
                and provides selfcontained namespaces that minimize variable name clashes across your programs.
            --
            lpy3-p721
            }}}
        In concrete terms, modules typically correspond to (@)
            {{{
            Python program files.
                +(!!) Modules might also correspond to extensions coded in external languages such as C, Java, or C#, and even to directories in package imports.
            --
            lpy3-p721
            }}}
        modules import other modules to (@)
            {{{
            use the names they define.
            --
            lpy3-p721
            }}}
        import vs from (@)
            {{{
            import
                Lets a client (importer) fetch a module as a whole
              .
            from
                Allows clients to fetch particular names from a module
            --
            lpy3-p721
            }}}
        reload a module’s code without stopping Python
            {{{
            imp.reload (reload in 2.X)
            --
            lpy3-p721
            }}}
        modules and classes are really just (!)
            {{{
            glorified namespaces, *
            --
            lpy3-p721
            }}}
        ((modules provide an easy way to organize components into a system by serving as self-contained packages of variables known as
            {{{
            namespaces
              .
            = 'All the names defined the top level of a module file become attributes of the imported module object.
                ((That is, the module file’s global scope morphs into the module object’s attribute namespace when it is imported.
            --
            lpy3-p721,p722
            }}}
        'More specifically, modules have at least three roles:
            {{{
            Code reuse
                = define names, known as attributes,
            System namespace partitioning
                =the highest-level program organization unit in Python.
                - you can never see a name in another file, unless you explicitly import that file.
            Implementing shared services or data
                = if you need to provide a global object that’s used by more than one function or file, you can code it in a module that can then be imported by many clients.
            --
            lpy3-p722
            }}}
            ----

            ----
        Python Program Architecture
            {{{
            For all but the simplest scripts, your programs will take the form of multifile systems - as the code timing programs of the preceding chapter illustrate.
                ( (= even for simple ones,)  you will almost certainly wind up using external files that someone else has already written.
          [= 'This section introduces the general architecture of Python programs - the way you divide a program into a collection of source files (a.k.a.  modules) and link the parts into a whole.
            --
            lpy3-p722,p723
            }}}
        How to Structure a Program ** (= the basic structure of files for one program) (@)
            {{{
            a Python program consists of text files containing Python statements,
                with one main top-level file,
                and zero or more supplemental files known as modules.
            --
            lpy3-p723
            }}}
        The top-level (a.k.a. script) file contains  (+does what?) ** @
            {{{
            the main flow of control of your program -
            (+) this is the file you run to launch your application.
            --
            lpy3-p723
            }}}
        The module files are  (= what is their function in relation to main?) *(*) (@)
            {{{
            libraries of tools used to collect components used by the top-level file, and possibly elsewhere.
                ( Top-level files use tools defined in module files, and modules use tools defined in other modules.
            --
            lpy3-p723
            }}}
        what do modules files do when you run them? (*) @
            {{{
            'Although they are files of code too,
            module files generally don’t do anything when run directly;
                rather, they define tools intended for use in other files.
            --
            = 'the statements in modules usually just create objects to be used later.
            --
            lpy3-p723;p724
            }}}
        (summary of the function of modules in relation to the main function) (**)
            {{{
            A file imports a module to gain access to the tools it defines, which are known as its attributes - variable names attached to objects such as functions.  Ultimately, we import modules and access their attributes to use their tools.
            --
            lpy3-p723
            }}}
            ----

            ----
        import and use function spam from b.py (*!) (@)
            {{{
            import b		# File a.py
            b.spam('gumby')	# Prints "gumby spam"
            --
            lpy3-p723
            }}}
        Program architecture in Python. A program is ( a system of *
            {{{
            modules
            --
            lpy3-p724
            }}}
        'Python’s standard library provides *
            {{{
            = 'a collection of precoded modules.
            --
            lpy3-p724
            }}}
        The code 'import b' roughly means: (@)
            {{{
            Load the file b.py (unless it’s already loaded), and give me access to all its attributes through the name b.
                (+ 'To satisfy such goals, import (and, as you’ll see later, from) statements execute and load other files on request.
               .
            [[= imports find the designated file on the module search path, compile it to byte code, and execute all of its statements to generate its contents. (p737)
            --
            lpy3-p724
            }}}
        More formally, in Python, cross-file module linking is not resolved until ((!!!!!! (*******)))
            {{{
            such import statements are executed at runtime;
                their net effect is to assign module names - simple variables like b - to loaded module objects. (!!!!!!! (******)
            --
            lpy3-p724
            }}}
        In fact, the module name used in an import statement (=like b in b.py) serves two purposes: ***(*)(!!)
            {{{
            identifies the external file to be loaded,
            becomes a variable assigned to the loaded module.
            --
            lpy3-p724
            }}}
        Similarly, objects defined by a module are also created at runtime, as the import is executing: import (= does what in the target file to import?)
            {{{
            literally runs statements in the target file one at a time to create its contents.
            --
            lpy3-p724
            }}}
        most objects have ____ that are fetched with the “.” operator.
            {{{
            = useful attributes  (like simple values)
              .
            + Some reference callable objects like functions that take action
            --
            lpy3-p724
            }}}
        The notion of importing is also completely general throughout Python. Any file can import tools from any other file.
            {{{
            For instance, the file a.py may import b.py to call its function, but b.py might also import c.py to leverage different tools defined there.
                (+ Import chains can go as deep as you like: in this example, the module a can import b, which can import c, which can import b again, and so on.
            --
            lpy3-p725
            }}}
          Python automatically comes with a large collection of utility modules known as
            {{{
            the standard library.
            This collection, over 200 modules large at last count, contains platform-independent support for common programming tasks: operating system interfaces, object persistence, text pattern matching, network and Internet scripting, GUI construction, and much more.
                = 'None of these tools are part of the Python language itself, but you can use them by importing the appropriate modules on any standard Python installation. **
            --
            lpy3-p725
            }}}
            ----

        How Imports Work (** | !!)

            ----
        [compar(ing) the Python module import operation to a C #include, (!!) (@)
            {{{
            (=) in Python, imports are not just textual insertions of one file into another.
              (= are really runtime operations that perform three distinct steps
               .
            1. Find the module’s file.
            2. Compile it to byte code (if needed).
            3. Run the module’s code to build the objects it defines.
                (=note: 'only the first time a module is imported during a program’s execution; later imports of the same module in a program run bypass all of these steps and simply fetch the already loaded module object in memory.
            --
            lpy3-p726
            }}}
        Technically, Python does this by (= where it stores code for already loaded modules) (!!)(!!) * (@)
            {{{
            storing loaded modules in a table(=a dictionary(!! p728...)) named sys.modules and checking there at the start of an import operation.
            --
            lpy3-p726
            }}}
        imports  which  allow import statements to include part of the directory path
            {{{
            1. It’s syntactically illegal to include path and extension details in a standard import.
            However, package imports, which we’ll discuss in Chapter 24, allow import statements to include part of the directory path leading to a file
                as a set of period-separated names.
            --
            lpy3-p726
            }}}
        the (perhaps executed) byte compile step (= import step two, if executed) (@)
            {{{
              (checks file time stamps and Python version magic number (??))
            --
              ( this model is modified somewhat in Python 3.2 and later - byte code files are segregated in a __pycache__ subdirectory and named with their Python version to avoid contention and recompiles when multiple Pythons are installed. This obviates the need to check version numbers in the byte code, but the timestamp check is still used to detect changes in the source.
            --
            lpy3-p727
            }}}
        +if Python finds only a byte code file on the search path and no source, (=when importing the module (@)
            {{{
            it simply loads the byte code directly;
                    this means you can ship a program as just byte code files and avoid sending source.
            --
            lpy3-p727
            }}}
        (why)  you will not usually see a .pyc byte code file for the top-level file of your program, **(*!) (T@)
            {{{
            compilation happens when a file is being imported.  Because of this, you will not usually see a .pyc byte code file for the top-level file of your program, unless it is also imported elsewhere - only imported files leave behind .pyc files on your machine.
                The byte code of top-level files is used internally and discarded; byte code of imported files is saved in files to speed future imports.
            (++ 'it is possible to design a file that serves both as the top-level code of a program and as a module of tools to be imported.
                 (+Such a file may be both executed and imported, and thus does generate a .pyc.
            --
            lpy3-p727
            }}}
        learning more about how a main  file may be both executed and imported, *
            {{{
            watch for the discussion of the special __name__ attribute and __main__ in Chapter 25.
            --
            lpy3-p727
            }}}
        The final step of an import operation (= running through the code of the module to import) ((***(!!)))
            {{{
            = executes the byte code of the module.
            All statements in the file are run in turn, from top to bottom,
            and any assignments made to names during this step generate attributes of the resulting module object. **
             (= 'This is how the tools defined by the module’s code are created.
            --
            lpy3-p727
            }}}
            ----

            ----
        'Because this last import step actually runs the file’s code, if any top-level code in a module file does real work, you’ll see its results at import time. For example,
            {{{
            top-level print statements in a module show output when the file is imported.
              (but,  'Function def statements simply define objects for later use.
            --
            lpy3-p728
            }}}
        If you need to import a file again after it has already been loaded (for example, to support dynamic end-user customizations), you have to
            {{{
            force the issue with an imp.reload call
            --
            lpy3-p728
            }}}
          __pycache__ in Python 3.2+
            {{{
            ((First of all, if Python cannot write a file to save this on your computer for any reason, your program still runs fine - Python simply creates and uses the byte code in memory and discards it on exit.
              .
            To speed startups, though, it will try to save byte code in a file in order to skip the compile step next time around.
              Byte code is stored in files in the same directory as the corresponding source files, normally with the filename extension .pyc (e.g., module.pyc).
            the magic num|field: 'For instance, if you upgrade to a new Python whose byte code differs, all your byte code files will be recompiled automatically due to a version number mismatch, even if you haven’t changed your source code.
            --
            +In Python 3.2 and later
            Byte code is instead stored in files in a subdirectory named __pycache__, which Python creates if needed,
            + (the .pyc) files  are given more descriptive names that include text identifying the version of Python that created them (e.g., module.cpython-32.pyc).
        = 'In both models, Python always recreates the byte code file if you’ve changed the source code file since the last compile, but version differences are handled differently - by magic numbers and replacement prior to 3.2, and by filenames that allow for multiple copies in 3.2 and later.
            --
            lpy3-p728,p729
            }}}
        inspect what modules are loaded (=the sys.modules dict) **(!) @@
            {{{
            import sys and
            print list(sys.modules.keys()).
            --
            lpy3-p728
            }}}
        (+the two  Byte Code File Models in Action (!!) (@)
            {{{
             (= demonstration with mixing files versus separate directories)
            'However, in 3.2 and later byte code files are saved in the __pycache__ subdirectory and include versions and Python implementation details in their names to avoid clutter and contention among the Pythons on your computer:
                'Crucially, under the model used in 3.2 and later, importing the same file with a different Python creates a different byte code file, instead of overwriting the single file as done by the pre-3.2 model - in the newer model, each Python version and implementation has its own byte code files, ready to be loaded on the next program run (earlier Pythons will happily continue using their scheme on the same machine):
            Python 3.2’s newer byte code file model is probably superior, as it avoids recompiles when there is more than one Python on your machine - a common case in today’s mixed 2.X/3.X world.
            On the other hand, it is not without potential incompatibilities in programs that rely on the prior file and directory structure.
                This may be a compatibility issue in some tools programs, for instance, though most well-behaved tools should work as before. See Python 3.2’s “What’s New?” document for details on potential impacts.
            - it’s a side effect of running programs - and most programmers probably won’t care about or even notice the difference, apart from faster startups due to fewer recompiles.
            --
            lpy3-p729,p730
            }}}
            ----

            ----
        the part of the import procedure that most programmers will need to care about * @
            {{{
            = usually the first - locating the file to be imported (the “find it” part).
            = Because you may need to tell Python where to look to find files to import, you need to know how to tap into its search path in order to extend it.
            --
            lpy3-p730
            }}}
        when|why you may need to care about the search path of module imports (**(!!))
            {{{
            If you want to be able to import userdefined files across directory boundaries, though, you will need to know how the search path works in order to customize it.
               (= Some are preset by Python and some can (more easily?) be customized)
            --
            lpy3-p730,p731
            }}}
        The parts that are combined to make the path strings in the list sys.path **(!!(!)) (@)
            {{{
            1. The home directory of the program
            2. PYTHONPATH directories (if set)
            3. Standard library directories
            4. The contents of any .pth files (if present)
            5. The site-packages home of third-party extensions
                sys.path  = a mutable list of directory name strings
            --
            lpy3-p731
            }}}
        parts of the search path that are defined automatically
            {{{
            prog home dir +
            std lib dirs
            --
            lpy3-p731
            }}}
        good|common way of customizing the search path (*) @(@)
            {{{
            setting  PYTHONPATH dirs
              +  .pth files  (**)
            = can be used to extend the path to include your own source code directories. (because the path is concatenated from points 1 through 5 in the previous example's Paths-list)
            --
            lpy3-p731
            }}}
        the importpaths 'homedir' (*) (@)
            {{{
            the directory containing your program’s top-level script file.
                =When you’re running a program,
            the directory in which you are working (i.e., the current working directory).
                =When you’re working interactively,
            --
            Because this directory is always searched first, if a program is located entirely in a single directory, all of its imports will work automatically with no path configuration required.
            --
            lpy3-p731
            }}}
        module(??) names and hiding (= in the import home dir) (*|!)  (+one way to remedy this) (!@)
            {{{
            because this directory is searched first, its files will also override modules of the same name in directories elsewhere on the path; be careful not to accidentally hide library modules this way if you need them in your program,
                  (= or  use package tools we’ll meet later that can partially sidestep this issue.
            --
            lpy3-p731
            }}}
            ----

            ----
        2. PYTHONPATH
            {{{
            environment variable setting,
            = Python searches all directories listed in your PYTHONPATH environment variable setting, from left to right
                list of user-defined and platform-specific names of directories that contain Python code files.
            You can add all the directories from which you wish to be able to import, and Python will extend the module search path to include all the directories your PYTHONPATH lists.
            --
            lpy3-p731
            }}}
        when it is important or recommended to set the PYTHONPATH ** @(@)
            {{{
            Because Python searches the home directory first, this setting is only important when importing files across directory boundaries
            - that is, if you need to import a file that is stored in a different directory from the file that imports it. **
            You’ll probably want to set your PYTHONPATH variable once you start writing substantial programs, **(!)
            --
            lpy3-p731
            }}}
        [std lib dirs wh. importing](!)
            {{{
            Because these are always searched, they normally do not need to be added to your PYTHONPATH or included in path files
            --
            lpy3-p732
            }}}
        .pth ** (@)
            {{{
            path file directories (= directory specified in configurable path files)
              = 'allows users to add directories to the module search path by simply listing them, one per line, in a text file whose name ends with a .pth **
                 [These path configuration files are a somewhat advanced installation-related feature; we won’t cover them fully here, but they provide an alternative to PYTHONPATH settings.
            'In short, text files of directory names dropped in an appropriate directory can serve roughly the same role as the PYTHONPATH environment variable setting.
            For instance, if you’re running Windows and Python 3.3, a file named myconfig.pth may be placed at the top level of the Python install directory (C:\Python33) or in the sitepackages subdirectory of the standard library there (C:\Python33\Lib\site-packages) to extend the module search path. (!!!! ****)
              --
            On Unix-like systems, this file might be located in usr/local/lib/python3.3/site-packages or /usr/local/lib/site-python instead.
            - - - -
            When such a file is present, Python will add the directories listed on each line of the file, from first to last, near the end of the module search path list - currently, after PYTHONPATH and standard libraries, but before the site-packages directory where third-party extensions are often installed.
                In fact, Python will collect the directory names in all the .pth path files it finds and will filter out any duplicates and nonexistent directories.
            Because they are files rather than shell settings, path files can apply to all users of an installation, instead of just one user or shell.
            For more details, consult the Python library manual, and especially its documentation for the standard library module site - this module allows the locations of Python libraries and path files to be configured, and its documentation describes the expected locations of path files in general.
            --
            lpy3-p732
            }}}
        I recommend that beginners use (= for path setting customizations etc) **
            {{{
            use PYTHONPATH or perhaps a single .pth file, and then only if you must(,(=?)) import across directories.
            --
            lpy3-p732
            }}}
        'Path files are used more often by
            {{{
            third-party libraries, which commonly install a path file in Python’s site-packages,
            --
            lpy3-p732
            }}}
        directory of third-party extensions (automatic) (!) (@)
            {{{
            The Lib\site-packages directory (??)
              .
            Python automatically adds the site-packages subdirectory of its standard library to the module search path.
              (+ ????)
              ...
            --
            lpy3-p732
            }}}
            ----

            ----
        [[Configuring the Search Path (@)
            {{{
            
            --
            lpy3-p733
            }}}
        set environment variables / store path files  on Windows, (@)
            {{{
            you might use your Control Panel’s System icon to set PYTHONPATH to a list of directories separated by semicolons, like this:
            c:\pycode\utilities;d:\pycode\package1
              .
            Or you might instead create a text file called C:\Python33\pydirs.pth, which looks like this:
            c:\pycode\utilities
            d:\pycode\package1
            --
        + See Appendix A for pointers on extending your module search path with PYTHONPATH or .pth files on various platforms.
            ((= the exact configuration of the search path is prone to changing across platforms, Python releases, and even Python implementations.
                  (+ When you’re launching from a command line, the current working directory may not be the same as the home directory of your top-level file (i.e., the directory where your program file resides), which is always added.
            --
            lpy3-p733
            }}}
        (('Because the current working directory can vary each time your program runs, you normally shouldn’t depend on (@@)
            {{{
            its value for import purposes. See Chapter 3 for more on launching programs from command lines.3
            --
            lpy3-p733
            }}}
        Tip: see how your Python configures the module search path on your platform, (****(!!)) @
            {{{
            inspect sys.path
            --
            lpy3-p733
            }}}
        new relative import syntax and search rules in Python 3.X; (!!)(??) @
            {{{
            they modify the search path for from statements in files inside packages when “.” characters are used (e.g., from . import string). By default, a package’s own directory is not automatically searched by imports in Python 3.X, unless such relative imports are used by files in the package itself. (??) (??) (??)
            --
            lpy3-p733
            }}}
            ----

            ----
        Really, sys.path is **(!)
            {{{
            the module search path.
                Python configures it at program startup, automatically merging the home directory of the top-level file (or an empty string to designate the current working directory), any PYTHONPATH directories, the contents of any .pth file paths you’ve created, and all the standard library directories.
                ['The result is a list of directory name strings that Python searches on each import of a new file.
            --
            lpy3-p734
            }}}
        EE: For example, here is what my module search path looks like on Windows under Python 3.3, (****) @
            {{{
            with my PYTHONPATH set to C:\code and a C: \Python33\mypath.pth path file that lists C:\Users\mark.
            The empty string at the front means current directory, and my two settings are merged in;
                the rest are standard library directories and files and the site-packages home for third-party extensions:
            >>> import sys
            >>> sys.path
            ['', 'C:\\code', 'C:\\Windows\\system32\\python33.zip', 'C:\\Python33\\DLLs',
            'C:\\Python33\\lib', 'C:\\Python33', 'C:\\Users\\mark',
            'C:\\Python33\\lib\\site-packages']
            Second, if you know what you’re doing, this list provides a way for scripts to tailor their search paths manually.
            --
            lpy3-p734
            }}}
        ([[note ab. changing paths directly in sys.path]])
            {{{
            Such changes last only for the duration of the script, however; PYTHONPATH and .pth files offer more permanent ways to modify the path - the first per user, and the second per installation.
            --
            lpy3-p734
            }}}
        programs where it may be useful to change sys.path directly (**) (@)
            {{{
            Scripts that run on web servers, for example, often run as the user “nobody” to limit machine access.  Because such scripts cannot usually depend on “nobody” to have set PYTHONPATH in any particular way, they often set sys.path manually to include required source directories, prior to running any import statements. A sys.path.append or sys.path.insert will often suffice, though will endure for a single program run only
            --
            lpy3-p734
            }}}
        Module File Selection (= when importing) (!)
            {{{
            Python chooses the first file it can find on the search path that matches the imported name.
                [[For example, an import statement of the form import b might today load or resolve to:  .... (py, pyc, pyo (etc =c, jython  etc.....))
            --
            lpy3-p735
            }}}
        Selection priorities: eg.  b.py and a b.so in different directories,
            {{{
            the first (leftmost) directory of your module search path during the left-to-right search of sys.path.
            + if it finds both a b.py and a b.so in the same dir:
                (= Python follows a standard picking order, though this order is not guaranteed to stay the same over time or across implementations.
              = 'make your module names distinct, or configure your module search path to make your module selection preferences explicit. (!!)
            --
            lpy3-p735
            }}}
        redefine much of what an import operation does in Python, @
            {{{
            redefine much of what an import operation does in Python,
                = done w.  what are known as import hooks.
                == can be used to make imports do various useful things, such as loading files from archives, performing decryption, and so on.
            --
            lpy3-p735
            }}}
        import hooks and zip files (!)
            {{{
            = Python itself makes use of these hooks to enable files to be directly imported from ZIP archives:
                [= 'One of the standard library directories in the earlier sys.path display, for example, is a .zip file today.
            (+ For more details, see the Python standard library manual’s description of the built-in __import__ function, the customizable tool that import statements actually run.
            --
            Python 3.3’s “What’s New?” (= for import hooks)
                [= In short, in this version and later, the __import__ function is now implemented by importlib.__import__, in part to unify and more clearly expose its implementation.
            ([[The latter of these calls is also wrapped by importlib.import_module - a tool that, per Python’s current manuals, is generally preferred over __import__ for direct calls to import by name string, a technique discussed in Chapter 25.
             Both calls still work today, though the __import__ function supports customizing imports by replacement in the built-in scope (see Chapter 17), and other techniques support similar roles.
            --
            lpy3-p736
            }}}
        .pyo files (!) (@)
            {{{
            python -O
            (but pypy is more frequently used for speedups
            --
            lpy3-p736
            }}}
        Third-party extensions for Python typically use the ___ tools in the standard library to automatically install themselves, (@)
            {{{
            distutils
             (= 'so no path configuration is required to use their code.
               --
            (+for instance, it(=distutils) also provides ways to automatically compile C-coded extensions on the target machine).
              .
            [[+ 'there is some talk of deprecating distutils and replacing it with a newer distutils2 package in the Python standard library.
            --
            lpy3-p736
            }}}
        Systems that use distutils generally come with ____ to install them;
            {{{
            a setup.py script, which is run
            --
            lpy3-p736
            }}}
        + third-party open source system, which adds dependency checking for installed Python software.
            {{{
            eggs
            --
            lpy3-p736
            }}}
            ----

        [PERHAPS TODO: = include the summaries from page 737 back to the explanations above, perhaps even to complete the replace some of them (=seems shorter, clearer and better as quick summaries(!))


        'Of course, the whole point of imports and modules is to
            {{{
            provide a structure to your program, which divides its logic into self-contained software components.
            --
            lpy3-p737
            }}}
        1. How does a module source code file become a module object?
            {{{
            1. A module’s source code file automatically becomes a module object when that module is imported.
            Technically, the module’s source code is run during the im- port, one statement at a time, and all the names assigned in the process become attributes of the module object.
            --
            lpy3-p737,p738
            }}}
        5. What is a namespace, and what does a module’s namespace contain? @(@)
            {{{
            5. A namespace is a self-contained package of variables, which are known as the attributes of the namespace object. A module’s namespace contains all the names assigned by code at the top level of the module file (i.e., not nested in def or class statements).
            --
            lpy3-p737
            }}}


        Chapter 23 - Module Coding Basics

            ----
        Module Creation
            {{{
            type some Python code into a text file, and save it with a “.py” extension;
                any such file is automatically considered a Python module.
            --
            lpy3-p739
            }}}
        Why is it a best practice to always put the file ending py even on top level files (=are not going to be imported)?
            {{{
            consistency, +
            adding it in all cases makes your files’ types more obvious and allows you to import any of your files in the future.
            --
            lpy3-p740
            }}}
        module name tips (eg. why not if.py?) *(!)
            {{{
            Because module names become variable names inside a Python program (without the .py), they should also follow the normal variable name rules outlined in Chapter 11.
                For instance, you can create a module file named if.py, but you cannot import it because if is a reserved word - when you try to run import if, you’ll get a syntax error.
            +(!!) must also the observed for package imports(!)
              .
            = only letters, digits, and underscores. (**** (!!!))
              (+Python adds the path in front, and .py at the end
            --
            lpy3-p740
            }}}
        (importing) Other Kinds of Modules (C, Java etc) *  (+ what are such modules called?) (@)
            {{{
            When imported by Python code, extension modules look and feel the same as modules coded as Python source code files - they are accessed with import statements, and they provide functions and objects as module attributes.
              .
            Such modules are called extension modules, and they are generally used to wrap up external libraries for use in Python scripts.
            --
            lpy3-p740
            }}}
        from vs import (= they do what?) * T@
            {{{
            The chief difference is that import fetches the module as a whole, so you must qualify to fetch its names;
            in contrast, from fetches (or copies) specific names out of the module.  (= can then be used without having to qualify the name)
              .
            >>> import module1
            >>> module1.printer('Hello world!')
            Hello world!
              .
              .
# Copy out a variable (one or more)
            >>> from module1 import printer
# No need to qualify name
            >>> printer('Hello world!')
            Hello world!
              .
              .
              ((= it imports the module file as usual (running the full three-step procedure of the preceding chapter), but adds an extra step that copies one or more names (not objects) out of the file.))
            --
            lpy3-p740,p741
            }}}
        import several names fr. a module ** @
            {{{
            from module1 import f1,f2
            --
            lpy3-p741
            }}}
        get copies of all names assigned at the top level (= 'of the referenced(=a certain) module. (@)
            {{{
            >>> from module1 import *	# Copy out _all_ variables
            >>> printer('Hello world!')
            Hello world!
                Technically, both import and from statements invoke the same import operation; the from * form simply adds an extra step that copies all the names in the module into the importing scope.
            --
            lpy3-p741
            }}}
        get certain names(!) w. a module import (= like f* for f1-f5 (etc))  (!!) ** (@)
            {{{
            = like  pattern matching to select a subset of names
              .
            loop through a module’s __dict__, discussed ahead).
            --
            lpy3-p742
            }}}
        (('In Python 3.X, the from ...* statement form (@)
            {{{
              (can be used only at the top level of the module, which is the recommended best practice)
            --
            lpy3-p742
            }}}
            ----

            ----
        [[Imports Happen Only Once (!!)
            {{{
              (mainly because it is an expensive operation
            --
            lpy3-p742
            }}}
        tip(?): 'because top-level code in a module file is usually executed only once, you can use it to @
            {{{
            initialize variables.
              . .
            print('hello')
            spam = 1	# Initialize variable
              .
              .
            % python
            # First import: loads and runs file's code
            >>> import simple
            hello
            # Assignment makes an attribute
            >>> simple.spam
            1
              .
              .
# Change attribute in module
            >>> simple.spam = 2
# Just fetches already loaded module
            >>> import simple
# Code wasn't rerun: attribute unchanged
            >>> simple.spam
            2
            --
            lpy3-p742
            }}}
        'Just like def, import and from are executable statements, not compile-time declarations. (??) (??) (??)
            {{{
              .
              .
              .
            'In other words, imported modules and names are not available until their associated import or from statements run. (??)
            --
            lpy3-p742
            }}}
        'Changing mutables in modules' (= 'All the things we’ve already discussed about assignment apply to module access, too. (??) (!) ((!!!!! (******!!))) @
            {{{
            like def, the import and from are implicit assignments:
              .
            (''For instance, names copied with a from become references to shared objects; as with function arguments, reassigning a copied name has no effect on the module from which it was copied, but changing a shared mutable object through a copied name can also change it in the module from which it was imported.
               .
            To illustrate, consider the following file, small.py: (**)
            x = 1
            y = [1, 2]
            --
            lpy3-(p742?),p743
               (+Table|Figure for reference(!!))
            }}}
        [[Cross-file name changes(!)  (!!)
            {{{
            the assignment to x in the interactive session changed the name x in that scope only, not the x in the file - there is no link from a name copied with from back to the file it came from. To really change a global name in another file, you must use import: (??) (!!(!))
              .
                # Get module name
            >>> import small
                # Changes x in other module
            >>> small.x = 42
              (= 'generally good tip to avoid changes like this (because they can be confusing
                (= changing variables in other modules like this
            --
            lpy3-p744
            }}}
        from import is like (=wh. not using the from word)  ((!)) (@)
            {{{
              # Fetch the module object
            import module
              # Copy names out by assignment
            name1 = module.name1
            name2 = module.name2
              # Get rid of the module name
            del module
            --
            lpy3-p744
            }}}
        Potential Pitfalls of the from Statement (='implicity') @
            {{{
            ((-:)) Because the from statement makes the location of a variable more implicit and obscure (name is less meaningful to the reader than module.name), some Python users recommend using import instead of from most of the time.
            ((+:)) In practice, in realistic programs, it’s often convenient not to have to type a module’s name every time you wish to use one of its tools.
            This is especially true for large modules that provide many attributes - the standard library’s tkinter GUI module, for example.
            --
            lpy3-p745
            }}}
        (three real potential dangers with from (*)) (@)
            {{{
            = has the potential to corrupt namespaces, at least in principle - if you use it to import variables that happen to have the same names as existing variables in your scope, your variables will be silently overwritten.
               .
            As long as you understand and expect that this can happen when using from, though, this isn’t a major concern in practice,
               especially if you list the imported names explicitly (e.g., from module import x, y, z).
            --
            the from statement has more serious issues when used in conjunction with
                the reload call, as imported names might reference prior versions of objects. (!!) *
            --
            the from module import * form really can corrupt namespaces and make names difficult to understand, especially when applied to more than one file
                - in this case, there is no way to tell which module a name came from, short of searching the external source files.
                [[[= 'In effect, the from * form collapses one namespace into another, and so defeats the namespace partitioning feature of modules.
            --
            lpy3-p745
            }}}
        Best practices concerning import and from (****(*!)) (?@@)
            {{{
            - generally prefer import to from for simple modules,
            - to explicitly list the variables you want in most from statements, and
            - to limit the from * form to just one import per file.
                    That way, any undefined names can be assumed to live in the module referenced with the from *.
            --
            lpy3-p745
            }}}
            ----

            ----
        [when one  must use import instead of from **(!)]  (or can use aliasing) (*) @@(@)
            {{{
            when you must use the same name defined in two different modules.
              (= have to be fully qualified to disambiguate **)
              .
            or use:
            # O.py
              # Rename uniquely with "as"
            from M import func as mfunc
            from N import func as nfunc
              # Calls one or the other
            mfunc(); nfunc()
               --
            [[= not very likely, but may(!) happen]]
            --
            lpy3-p746
            }}}
        tip|use case using 'as'-aliasing wh. importing **(!) @
            {{{
            = give shorter easier name for ump-module (**)
            --
            lpy3-p746
            }}}
        'Module Namespaces' (??|(**)) (@)
            {{{
            Modules are probably best understood as simply packages of names - i.e., places to define names you want to make visible to the rest of a system.
            Technically, modules usually correspond to files, and Python creates a module object to contain all the names assigned in a module file.
            But (really/=simply put:
                    ('modules are just namespaces (places where names are created),
            --
            lpy3-p746,p747
            }}}
        ([['Files Generate Namespaces @(@)
            {{{
            'I’ve mentioned that files morph into namespaces, but how does this actually happen?
              (.....
              'For instance, given an assignment statement such as X = 1 at the top level of a module file M.py, the name X becomes an attribute of M, which we can refer to from outside the module as M.X.
                      (((((The name X also becomes a global variable to other code inside M.py, but we need to consider the notion of module loading and scopes a bit more formally to understand why:
              ...
              ...
              ...
              ...
               ...
            • Module namespaces can be accessed via the attribute __dict__ or dir(M).
                + may be inspected with the dir function.
            + 'Crucially, though, the module’s global scope becomes an attribute dictionary of a module object after the module has been loaded. (!!)
              (lives on, unlike a function scope)
            ((+ the ex. module2.py (??(!))))
            --
            lpy3-p747;p748
            }}}
        (bla bla =)  'import statements really assign module objects to names, and any type of assignment to a name at the top level of a file generates a module attribute.
            {{{
            --
            lpy3-p748
            }}}
        (!)  internally, module namespaces are stored as @@!
            {{{
            dictionary objects.
                = These are just normal dictionaries with all the usual methods.
                [When needed - for instance, to write tools that list module content generically as we will in Chapter 25 - we can access a module’s namespace dictionary through the module’s __dict__ attribute.
                  (+ including the 3.X list call...
            >>> list(module2.__dict__.keys())
              .
            + Python also adds some names in the module’s namespace for us; for instance, __file__ gives the name of the file the module was loaded from, and __name__ gives its name as known to importers (without the .py extension and directory path).
              .
            To see just the names your code assigns, filter out the double-underscore names as we’ve done before, in Chapter 15’s dir coverage and Chapter 17’s built-in scope coverage:
                .
            >>> list(name for name in module2.__dict__.keys() if not name.startswith('__'))
              (+ This time we’re filtering with a generator instead of a list comprehension, and can omit the .keys() because dictionaries generate their keys automatically though implicitly; the effect is the same.
            --
            lpy3-p748
            }}}
        (=object(??)) qualification syntax  (= other name for)  ** (@)
            {{{
            attribute fetch syntax
            --
            lpy3-p749
            }}}
        In Python, you can access the attributes of any object that has attributes using the ____ syntax
            {{{
            qualification (a.k.a.  attribute fetch) syntax
            ie, object.attribute
            --
            lpy3-p749
            }}}
        Qualification is really (= syntactically and operationally) (**) T@
            {{{
            an expression
            that returns the value assigned to an attribute name associated with an object.
            [= 'For example, the expression module2.sys in the previous example fetches the value assigned to sys in module2.  (**(!))
              .
            Similarly, if we have a built-in list object L, L.append returns the append method object associated with that list.
            --
            lpy3-p749
            }}}
            ----

            ----
        attribute qualification has nothing to do with the scope rules we studied in Chapter 17; it’s an independent concept. (!!!(!**)) (T@)
            {{{
            = 'When you use qualification to access names, you give Python an explicit object from which to fetch the specified names.
            The LEGB scope rule applies only to bare, unqualified names - it may be used for the leftmost name in a name path, but later names after dots search specific objects instead.
            --
            lpy3-p749
            }}}
        Qualification paths
            {{{
            = lookups like
            X.Y.Z
            --
            lpy3-p749
            }}}
        Qualification works on (!!!(*(!)))
            {{{
            all objects with attributes(!):
                (= modules, classes, C extension types, etc. (!!)
            --
            lpy3-p750
            }}}
        [[+see: 'When run, moda.f changes the X in moda, not the X in modb. (TT!@@)
            {{{
            = 'The global scope for moda.f is always the file enclosing it, regardless of which module it is ultimately called from:
              (= 'Imports Versus Scopes
             .
           In other words, import operations never give upward visibility to code in imported files - an imported file cannot see names in the importing file. (= = =
            • Functions can never see names in other functions, unless they are physically enclosing.
            • Module code can never see names in other modules, unless they are explicitly imported.
            --
            lpy3-p750
            }}}
        => lexical scoping notion - in Python,
            {{{
            the scopes surrounding a piece of code are completely determined by the code’s physical position in your file.
            Scopes are never influenced by function calls or module imports.1
            --
            lpy3-p751
            }}}
        'In some sense, although imports do not nest namespaces upward, they do nest downward. (!) (@)
            {{{
            That is, although an imported module never has direct access to names in a file that imports it, using attribute qualification paths it is possible to descend into arbitrarily nested modules and access their attributes.
            print(mod2.mod3.X)      # Nested mod3's X
            'The net effect is that mod1 can see the Xs in all three files, and hence has access to all three global scopes:
            --
            lpy3-p751
            }}}
        (1. Some languages act differently and provide for dynamic scoping, where scopes really may depend on
            {{{
            runtime calls.
            --
            lpy3-p751
            }}}
            ----

            ----
        why 'import mod2.mod3' is illegal as a 'recursive import' (**!) @
            {{{
            import mod2, and then mod2.mod3.X,
              is legal for this example (= mod2 has imported mod3 first)
              .
            but(!) import mod2.mod3 is a package(=directory) import (****(!!))
            --
            lpy3-p752
            }}}
        reloads ('can make your system more
            {{{
            dynamic
            = 'Why care about reloading modules?  In short, dynamic customization: the reload function allows parts of a program to be changed without stopping the whole program.
            --
            lpy3-p752
            }}}
        Specific use cases for quicker customisation with reloading (!) (@)
            {{{
            For instance, imagine a database program that must connect to a server on startup; because program changes or customizations can be tested immediately after reloads, you need to connect only once while debugging. Long-running servers can update themselves this way, too.
            = change parts of running programs without stopping.
            --
            lpy3-p752
            }}}
        dynamically load(ing) at runtime, (+reloading) I've compiled extension modules like in C (*)
            {{{
            compiled extension modules coded in a language such as C can be dynamically loaded at runtime, too, but they can’t be reloaded (though most users probably prefer to code customizations in Python anyhow!).
            --
            lpy3-p752
            }}}
        reloading in Py 2 and 3 (!) @(@)
            {{{
            reload, and imp.reload 
                (eg. import imp|from imp import reload)  #+can also be done in Py 2 for compatibility
            --
            lpy3-p753
            }}}
            ----

            ----
        typical usage pattern of reload (**(*!))(**(*))
            {{{
            import a module, then change its source code in a text editor, and then reload it.
            This can occur when working interactively, but also in larger programs that reload periodically.
            --
            lpy3-p753
            }}}
        Perhaps the most important thing to know about reload is that it changes a module object (??@)
            {{{
            in place; (=) it does not delete and re-create the module object.
            Because of that, every reference to an entire module object anywhere in your program is automatically affected by a reload.
                Here are the details: (...##########
                (ssssssssss.....(??))
              =...
               ...
            'the module’s current namespace.
            • Top-level assignments in the file replace names with new values. (?????)
            • Reloads impact all clients that use import to fetch modules. (!!) ((????))
            • Reloads impact future from clients only. (!!(?))
                (= 'Clients that used from to fetch attributes in the past won’t be affected by a reload;
               ...
               ...
               ...
               ...
            • Reloads apply to a single module only.
                = 'You must run them on each module you wish to update, unless you use code or tools that apply reloads transitively.
            --
            lpy3-p753,p754
            }}}
        reload Example
            {{{
            'To demonstrate, here’s a more concrete example of reload in action.
              (= changer.py
            --
            lpy3-p754,p755
            }}}
        code a function that applies it (=a reload) transitively to related modules **
            {{{
            case study near the end of Chapter 25.
            --
            lpy3-p755
            }}}
        Why You Will Care: Module Reloads * (@)
            {{{
            Besides allowing you to reload (and hence rerun) modules at the interactive prompt,
            module reloads are also useful in larger systems, especially when the cost of restarting the entire application is prohibitive.
            For instance, game servers and systems that must connect to servers over a network on startup are prime candidates for dynamic reloads.
                They’re also useful in GUI work (a widget’s callback action can be changed while the GUI remains active),
                and when Python is used as an embedded language in a C or C+ + program (the enclosing program can request a reload of the Python code it runs, without having to stop).
            More generally, reloads allow programs to provide highly dynamic interfaces.
            For instance, Python is often used as a customization language for larger systems -
                To be even more dynamic, though, such systems can automatically reload the Python customization code periodically at runtime. (= changes are picked up while the system is running)
            --
            lpy3-p755
            }}}
            ----

        Import operations load module files into module objects in memory.
        . The from statement can obscure the meaning of a variable (which module it is defined in), can have problems with the reload call (names may reference prior versions of objects), and can corrupt namespaces (it might silently overwrite names you are using in your scope). (note: from *  is worst)  (@)


        Chapter 24 - Module Packages

            ----
        a Python package  (**) @
            {{{
            = a directory of Python code
            --
            lpy3-p759
            }}}
        import model | variant relevant to code in packages only, **
            {{{
            relative imports (??)
            --
            lpy3-p759
            }}}
        Package Import Basics (!) (@)
            {{{
            import dir1.dir2.mod
              .
            from dir1.dir2.mod import x
              .
              .
            (+(!) imply that dir1 resides within some container directory dir0, which is a component of the normal Python module search path.
                 =  dir0\dir1\dir2\mod.py  # Or mod.pyc, mod.so, etc.
            --
            lpy3-p760
            }}}
        the leftmost component in a package import path is relative to (@)
            {{{
            included in the sys.path module search path list we explored in Chapter 22.
                (=^^ The container directory dir0 needs to be added to your module search path unless it’s the home directory of the top-level file, exactly as if dir1 were a simple module file.
            --
            requested path:  C:\mycode\dir1\dir2\mod
                = 'you can add C:\mycode to your PYTHONPATH variable or a .pth file, and say this in your script:
                    import dir1.dir2.mod
            --
            lpy3-p760
            }}}
        (+) If you choose to use package imports, there is one more constraint you must follow: at least until Python 3.3, @
            {{{
            each directory named within the path of a package import statement must contain a file named __init__.py,
               (=but not since Py 3.3(!!))
            That is, in the example we’ve been using, both dir1 and dir2 must contain a file called __init__.py;
                [+ the container directory dir0 does not require such a file because it’s not listed in the import statement itself.
            --
            lpy3-p761
            }}}
        The __init__.py files  contains  (!!) (@)
            {{{
            can contain Python code, just like normal module files.
                their code is run automatically the first time a Python program imports a directory,
                = and thus serves primarily as a hook for performing initialization steps required by the package.
              .
            + can also be completely empty, though,
            --
            lpy3-p762
            }}}
            ----

            ----
        advantage of using __init__.py files in package-dirs in 3.3 and later (**) (@)
            {{{
            = these files [also] provide a performance advantage when used.
            --
            lpy3-p762
            }}}
        Package initialization file roles (??) (@)
            {{{
            the __init__.py file serves as a hook for package initialization-time actions, declares a directory as a Python package, generates a module namespace for a directory, and implements the behavior of from * (i.e., from .. import *) statements when used with directory imports:
            --
            lpy3-p762
            }}}
        Package initialization (!) (@)
            {{{
            The first time a Python program imports through a directory, it automatically runs all the code in the directory’s __init__.py file.
                [= put code to initialize the state required by files in a package.
            eg. create required data files, open connections to databases, and so on.
                Typically, __init__.py files are not meant to be useful if executed directly; they are run automatically when a package is first accessed.
            --
            lpy3-p762
            }}}
        (how Py 3 does away with the need for package initialization files in p.dirs) (*)
            {{{
            = scans ahead|down for wanted module
            --
            lpy3-p763
            }}}
        [[[dir2’s __init__.py initialization file = 'Such files provide a namespace for module objects created for directories, which would otherwise have no real associated module file. (??) (??) [***(*)]
            {{{
            --
            lpy3-p763
            }}}
        As an advanced feature, you can use ____ to define what is exported when a directory is imported with the from * statement form. (**) (@)
            {{{
            use __all__ lists in __init__.py files
            = In an __init__.py file, the __all__ list is taken to be the list of submodule names that should be automatically imported when from * is used on the package (directory) name.
            --
            lpy3-p763
            }}}
        'For instance, the statement from submodule import X in a directory’s __init__.py makes the name X available in that directory’s namespace.
            {{{
             (?????)
            --
            lpy3-p763
            }}}
        [[Package Import Example]]
            {{{
            ((ss))
            --
            lpy3-p763,p764
            }}}
            ----

            ----
        force reexecution of package dir (*(*) (@)
            {{{
            >>> reload(dir1)
            --
            lpy3-p764
            }}}
        the var dir1.x (**!!) (@)
            {{{
            refers to the variable x assigned in dir1\__init__.py, much as mod.z refers to the variable z assigned in mod.py:
            --
            lpy3-p764
            }}}
        from Versus import with Packages @T
            {{{
            import statements can be somewhat inconvenient to use with packages,
                = may have to retype the paths frequently in your program.
            - often more convenient, therefore, to use the from statement with packages to avoid retyping the paths at each access.
                >>> from dir1.dir2 import mod
                >>> mod.z
            - +if you ever restructure your directory tree, the from statement requires just one path update in your code, whereas imports may require many.
              --
            + can use the  import as extension,
                = providing a shorter synonym for the full path  (+renaming tool when the same name appears in multiple modules:)
            --
            lpy3-p765
            }}}
        tip: package imports (= serves some useful roles) ((*)) @(@)
            {{{
            because package imports give some directory information in program files, they both make it easier to locate your files and serve as an organizational tool. Without package paths, you must often resort to consulting the module search path to find files.
            if you organize your files into subdirectories for functional areas, package imports make it more obvious what role a module plays, and so make your code more readable.
            import utilities
              vs
            import database.client.utilities
             --
            can also greatly simplify your PYTHONPATH and .pth file search path settings.
                = if you use explicit package imports for all your cross-directory imports, and you make those package imports relative to a common root directory where all your Python code is stored, you really only need a single entry on your search path: the common root.
               .
            ((+ resolve conflicts when the same module name appears in more than one place.
            --
            lpy3-p765,p766
            }}}
        [The only time package imports are actually required] ((+= the 'utilities'-Ex. (**!) ))
            {{{
            resolve ambiguities that may arise when multiple programs with same-named files are installed on a single machine.
                ((This is something of an install issue, but it can also become a concern in general practice - especially given the tendency of developers to use simple and similar names for module files.
              .
              .
            Now, add just the common root directory to your search path. If your code’s imports are all relative to this common root, you can import either system’s utility file with a package import - the enclosing directory name makes the path (and hence, the module reference) unique.
                ((In fact, you can import both utility files in the same module, as long as you use an import statement and repeat the full path each time you reference the utility modules:
            import system1.utilities
            import system2.utilities
            system1.utilities.function('spam')
            system2.utilities.function('eggs')
               ((or using 'as'))
            --
            lpy3-p766--p768
            }}}
        Why You Will Care: Module Packages (***) (@)
            {{{
            Because packages are a standard part of Python, it’s common to see larger third-party extensions shipped as sets of package directories, rather than flat lists of modules.
              eg. to load client-side COM tools,
            from win32com.client import constants, Dispatch
              .
            Package imports are also pervasive in code run under the Jython Java-based implementation of Python, because Java libraries are organized into hierarchies as well.
            In recent Python releases, the email and XML tools are likewise organized into package subdirectories in the standard library, and Python 3.X groups even more related modules into packages - including tkinter GUI tools, HTTP networking tools, and more.
            --
            The following imports access various standard library tools in 3.X (2.X usage may vary):
            from email.message import Message
            from tkinter.filedialog import askopenfilename
            from http.server import CGIHTTPRequestHandler
            --
            lpy3-p768,p769
            }}}
            ----

            ----
        Package Relative Imports (**) (@)
            {{{
            The way this works is version-dependent: Python 2.X implicitly searches package directories first on imports, while 3.X requires explicit relative import syntax in order to import from the package directory.
                ((note: normal package import paths may be a better option in many cases.))
            --
            lpy3-p769
            }}}
        p-rel. imports 3.X(!!) (!@)
            {{{
            skip(s) the package’s own directory by default.
                (= Imports check only paths on the sys.path search path. These are known as absolute imports.)
                     ((2.X: must be enabled as an option))
              .
              .
            from statements: extended syntax to
                allow them to explicitly request that imports search the package’s directory only, with leading dots. This is known as relative import syntax.
                    ((=also avail. in Py 2))
              .
            As we’ll see, in 3.X this can affect the way you will structure imports or directories for modules meant for use in both top-level programs and importable packages.
            --
            lpy3-p770
            }}}
        'In both Python 3.X and 2.X, from statements can now use leading dots (“.”) to specify that they require @
            {{{
            modules located within the same package (known as package relative imports), instead of modules located elsewhere on the module import search path (called absolute imports).
                In both Python 3.X and 2.X, you can use leading dots in from statements’ module names to indicate that imports should be relative-only to the containing package
                 .
                The net effect is that package modules override outside modules. **
            --
            lpy3-p770
            }}}
        Imports without dots: (**(!!)) (@)
            {{{
            Py 2: relative, then absolute
            Py 3: absol. by default (=needs dot for relative)  (!)
            --
            lpy3-p770,p771
            }}}
        from . import spam @
            {{{
            = import a module named spam located in the same package directory as the file in which this statement appears. (py2|3)
                (='searches this package only'(!))
            --
            lpy3-p771
            }}}
        from .spam import name
            {{{
            “from a module named spam located in the same package as the file that contains this statement, import the variable name.”
            --
            lpy3-p771
            }}}
        from spam import name (=py2 vs 3) (**) (@)
            {{{
            from spam import name
                # uses relative import
            --
            from __future__ import absolute_import
            from spam import name
                # now uses sys.pat-rel. import
            from .spam import name
                # to use relative import
            --
            lpy3-p771
            }}}
            ----

            ----
        'In Python 3.X, the import modname statement is always absolute-only, skipping the containing package’s directory.  In 2.X, this statement form
            {{{
            still performs relative imports, searching the package’s directory first.
              (+ bla bla bla ..............)
            --
            lpy3-p771
            }}}
        ('Other dot-based relative reference patterns are possible, too. Within a module file located in a package directory named mypkg, the following alternative import forms work as described: (LL) @
            {{{
            # Imports names from mypkg.string
            from .string import name1, name2
            # Imports mypkg.string
            from . import string
            # Imports string sibling of mypkg
            from .. import string  (=fr. Parent)
            --
            lpy3-p772
            }}}
        (the rationale for introducing the newer dot patterns for package imports) = 'Why Relative Imports? (@)
            {{{
            making intrapackage imports more explicit,
            allow scripts to resolve ambiguities that can arise when a same-named file appears in multiple places on the module search path.
             ...
             ...
             ...
             ...
            'Moreover, we cannot resolve this with full package import paths, because we cannot depend on any extra package directory structure above the standard library being present on every machine.
                ('In other words, simple imports in packages can be both ambiguous and error-prone.
            ((+'As one consequence, a local module or package can hide another hanging directly off of sys.path, whether intentionally or not.
            In practice, Python users can avoid reusing the names of standard library modules they need for modules of their own (if you need the standard string, don’t name a new module string!). But this doesn’t help if a package accidentally hides a standard module; moreover, Python might add a new standard library module in the future that has the same name as a module of your own.
            Code that relies on relative imports is also less easy to understand, because the reader may be confused about which module is intended to be used. It’s better if the resolution can be made explicit in code.
              .
              .
              .
            [[+To address this dilemma, imports run within packages have changed in Python 3.X to be absolute-only (and can be made so as an option in 2.X).
            --
            lpy3-p772,p773
            }}}
        Relative imports versus absolute package paths (@)
            {{{
            dot is handy
            absol. is safe, but verbose
            --
            lpy3-p774
            }}}
        ''The Scope of Relative Imports (! !!!) @
            {{{
            ="remember that they are intrapackage imports'
              .
            • Relative imports apply to the from statement only. (!!)
            --
            lpy3-p774
            }}}
        ([[Module Lookup Rules Summary
            {{{
            (( +the newer  namespace packages
            --
            lpy3-p775
            }}}
        [[Relative Imports in Action
            {{{
            --
            lpy3-p775,p776
            }}}
        [Imports outside packages
            {{{
            --
            lpy3-p776
            }}}
        Imports within packages (??)
            {{{
            --
            lpy3-p776,p777
            }}}
          'Imports are still relative to the CWD (????)
            {{{
              (= can clobber builtins(??))
            --
            lpy3-p776
            }}}
        Selecting modules with relative and absolute imports  (?????(!!@))  (SSSsss) @
            {{{
            --
            lpy3-p778,p779
            }}}
            ----

            ----
        Relative imports search (**(*!))
            {{{
            packages only
              .
                It’s also important to note that relative import syntax is really a binding declaration, not just a preference. If we delete the string.py file and any associated byte code in this example now, the relative import in spam.py fails in both 3.X and 2.X, instead of falling back on the standard library (or any other) version of this module:
            --
            lpy3-p779
            }}}
        'Because import resolution can depend on an enclosing context that may not be foreseen, though, absolute imports in 3.X are not a guarantee of finding a module in the standard library. (@)
            {{{
             (????)
            --
            lpy3-p780
            }}}
        keep testing and experimenting  + You should keep in mind, though, that imports in larger systems
            {{{
            may depend upon context of use, and the module import protocol is part of a successful library’s design.
            --
            lpy3-p780
            }}}
        Pitfalls of Package-Relative Imports: Mixed Use (**(!!)) (@(@)
            {{{
            Absolute package imports, with a complete directory path relative to a directory on sys.path, are still sometimes preferred over both implicit package-relative imports in Python 2.X, and explicit package-relative import dot syntax in both Python 2.X and 3.X.
             --
            'As we’ve seen, Python 3.X’s relative import syntax and absolute search rule default make intrapackage imports explicit and thus easier to notice and maintain, and allow explicit choice in some name conflict scenarios. However, there are also two major ramifications of this model that you should be aware of: (...... (!!!!
            • In both Python 3.X and 2.X, use of package-relative import statements implicitly binds a file to a package directory and role, and precludes it from being used in other ways.
            • In Python 3.X, the new relative search rule change means that a file can no longer serve as both script and package module as easily as it could in 2.X.
              .
              .
            Use of relative imports prevents you from creating directories that serve as both executable programs and externally importable packages in 3.X and 2.X.
              .
              .
            In terms of import statements, the
            rules pan out as follows - the
            first is for package mode only in
            both Pythons, and the second is for
            program mode only in 3.X:
              .
# Not allowed in nonpackage mode in both 2.X and 3.X
            from . import mod
# Does not search file's own directory in package mode in 3.X
            import mod
          !!!!!
        The net effect is that for files to be used in either 2.X or 3.X, you may need to choose a single usage mode - package (with relative imports) or program (with simple imports), and isolate true package module files in a subdirectory apart from top-level script files.
          !!!!!   (or, eg. can use full search paths)
            --
            lpy3-p781
            }}}
        The issue (!!!!)  (+Fixes) @
            {{{
            in Python 2.X it’s common to use the same single directory as both program and package, using normal undotted imports.
            --
        Fix 1: Package subdirectories
            The potential downside of this scheme is that you won’t be able to run package modules directly to test them with embedded self-test code, though tests can be coded separately in their parent directory instead:
          .
        Fix 2: Full path absolute import
                Most Python packages will either require this setting, or arrange for it to be handled automatically with install tools (such as distutils, which may store a package’s code in a directory on the default module search path such as the site-packages root; see Chapter 22 for more details):
            + Unlike the subdirectory fix, full path absolute imports like these also allow you to run your modules standalone to test: (**)
              .
              .
              .
              (+ Example: Application to module self-test code (preview)
            --
            lpy3-p782--p784
            }}}
        common fix to be able to use a file as both a program and to import it (******) @@
            {{{
            In short, a module’s __name__ attribute is the string “__main__” when it is being run as a top-level script, but not when it is being imported, which allows it to be used as both module and script:
            if __name__ == '__main__':
# Self-test or top-level script usage mode code
                somefunc()
            --
            lpy3-p784
            }}}
        In sum, (!!!!(*(*))) @@
            {{{
            unless you’re willing and able to isolate your modules in subdirectories below scripts, full package path imports are probably preferable to package-relative imports - though they’re more typing, they handle all cases, and they work the same in 2.X and 3.X.
            --
            lpy3-p785
            }}}
            ----

            ----
        Python 3.3 Namespace Packages (@)
            {{{
            allows packages to span multiple directories, and requires no initialization file, introduced in Python 3.3
                (=vs regular packages
             [[something of a fallback option, recognized only if normal modules and regular packages of the same name are not present on the module search path.
              .
            In short, though, they resolve a potential for collision of multiple __init__.py files when package parts are merged, by removing this file completely.
              (!!!! ????
            --
            lpy3-p786,p787
            }}}
        Namespace Package Semantics (@)
            {{{
            = not fundamentally different from a regular package; it is just a different way of creating packages.
            + still relative to sys.path at the top level: (...)
            + none of the directories that make up a namespace package can have an __init__.py, but the content nested within each of them is treated as a single package  (??(?))
            --
            lpy3-p787
            }}}
        'To truly understand namespace packages, we have to look under the hood to see how the import operation works in 3.3. (@)
            {{{
            During imports, Python still iterates over each directory in the module search path, sys.path,
            + for each directory in the module search path, Python tests for a wider variety of matching criteria,
              .
            regular package ?
            simple module ?
             if 'spam' is found as dir ( + cont.s scanning dirs (?|!)
            If none of the above was found, the scan continues with the next directory in the search path.
              .
        If the search path scan completes without returning a module or package by steps 1 or 2, and at least one directory was recorded by step 3, then a namespace package is created.
              .
              .
            The new namespace package has a __path__ attribute set to an iterable of the directory path strings that were found and recorded during the scan by step 3, but does not have a __file__.
              .
              .
            Viewed another way, the __path__ attribute of a namespace package serves the same role for lower-level components that sys.path does at the top for the leftmost component of package import paths; it becomes the “parent path” for accessing lower items using the same four-step procedure just sketched.
              .
            note: it supports everything we’ve learned for regular packages, including package-relative import syntax.
            --
            lpy3-p787,p788
            }}}
        n.s.packages: Impacts on Regular Packages: (@)
            {{{
            Optional __init__.py
            - when a single-directory package does not have this file, it will be treated as a single-directory namespace package, and no warning will be issued.
                = many packages require no initialization code, and it seemed extraneous to have to create an empty initialization file in such cases. This is finally no longer required as of 3.3.
             (=but standard __init__.py initialization still works also (**))
         + when it’s known that a package will never be a portion of a split namespace package, there is a performance advantage to coding it as a regular package with an __init__.py.
            --
            lpy3-p788
            }}}
        Namespace Packages in Action (SSs) [+ See especially this change’s PEP document for this change’s rationale, additional details, and more comprehensive examples.
            {{{
              .
              .
              .
              .
              .
            Now, when imported directly in 3.3 and later, the namespace package is the virtual concatenation of its individual directory components, and allows further nested parts to be accessed through its single, composite name with normal imports:
                [+ 'This is also true if we import through the namespace package name immediately - because the namespace package is made when first reached, the timing of path extensions is irrelevant: (??)(!)
            --
            = 'As you can see, namespace packages are like ordinary single-directory packages in every way, except for having a split physical storage - which is why single directory namespaces packages without __init__.py files are exactly like regular packages, but with no initialization logic to be run.
            --
            lpy3-p789,p790
            }}}
        Interestingly, relative imports work in namespace packages too - (??) (!)
            {{{
            = 'in the following, the relative import statement references a file in the package, even though the referenced file resides in a different directory:
            --
            lpy3-p790
            }}}
        'This nesting behavior holds true whether the lower component is a module, regular package, or another namespace package - by serving as new import search paths, namespace packages allow all three to be nested within them freely: (????) (@)
            {{{
              .
              .
              .
              .
              .
              .
            + 'As you can see, namespace packages integrate seamlessly into the former import models, and extend it with new functionality.
            --
            lpy3-p790/p791
            }}}
        Files Still Have Precedence over Directories (??)
            {{{
            'Because namespace packages do not require these special files, they would seem to invalidate this safeguard.
                This isn’t the case, though - because the namespace algorithm outlined earlier continues scanning the path after a namespace directory has been found, files later on the path still have priority over earlier directories with no __init__.py.
            For example, consider the following directories and modules: ((SS))
              ..
              ..
            (( ))    +'This directory can be imported under 3.3, though - it’s a namespace package directory in the current working directory, which is always the first item on the sys.path module search path irrespective of PYTHONPATH settings:
                  .
        But watch what happens when the
        directory containing a file of the
        same name as a namespace directory
        is added later on the search path,
        via PYTHONPATH settings - the file
        is used instead, because Python
        keeps searching later path entries
        after a namespace package directory
        is found. It stops searching only
        when a module or regular package is
        located, or the path has been
        completely scanned. Namespace
        packages are returned only if
        nothing else was found along the way:
            --
            lpy3-p792,p793
            }}}
        'In the following, for example, a namespace package called sub exists as the concatenation of same-named directories under dir1 and dir2 on the path: (!) (SS)
            {{{
            
            --
            lpy3-p793
            }}}
            ----

        Chapter 25 - Advanced Module Topics

            ----
        interesting byproducts of the advanced module topics chapter *(!!)
            {{{
            Along the way, we’ll build some larger and more useful tools than we have so far that combine functions and modules.
            = 'Like functions, modules are more effective when their interfaces are well defined, so this chapter also briefly reviews module design concepts, some of which we have explored in prior chapters.
            --
            lpy3-p797
            }}}
        Module Design Concepts (**) @
            {{{
            = you have to think about which functions go in which modules, module communication mechanisms, and so on.
            • You’re always in a module in Python. (even at the interactive prompt, =module __main__
                : the only unique things about the interactive prompt are that code runs and is discarded immediately, and expression results are printed automatically.
            • Minimize module coupling: global variables.
                As a rule of thumb, they should be as independent of global variables used within other modules as possible, except for functions and classes imported from them.
                => The only things a module should share with the outside world are the tools it uses, and the tools it defines.
            • Maximize module cohesion: unified purpose.
                if all the components of a module share a general purpose, you’re less likely to depend on external names.
            • Modules should rarely change other modules’ variables.
                There are exceptions, of course, but you should try to communicate results through devices such as function arguments and return values, not cross-module changes.
            --
            lpy3-p797,p798
            }}}
        Figure ___ sketches the environment in which modules operate.
            {{{
            25-1
            --
            lpy3-p798
            }}}
        Modules contain (!) (@)
            {{{
            variables, functions, classes, and other modules (if imported).
            --
            lpy3-p798
            }}}
        (xxxxx may contain functions etc, but)  At the top, though, programs are just
            {{{
            sets of modules.
            --
            lpy3-p798
            }}}
            ----

            ----
        Data Hiding in Modules (*)
            {{{
            In Python, data hiding in modules is a convention, not a syntactical constraint.
            --
            lpy3-p799
            }}}
        ['Some purists object to this liberal attitude toward data hiding, claiming that it means Python can’t implement encapsulation. (!) * (@)
            {{{
            encapsulation in Python is more about packaging than about restricting.
            = 'We’ll expand this idea in the next part in relation to classes, which also have no privacy syntax but can often emulate its effect in code.
            --
            lpy3-p799
            }}}
        'As a special case, (= way to)  prevent names  from being copied out when a client imports a module’s names with a from * statement. @
            {{{
            you can prefix names with a single underscore (e.g., _X)
                = is intended only to minimize namespace pollution; because from * copies out all names, the importer may get more than it’s bargained for (including names that overwrite names in the importer).
            --
            lpy3-p799
            }}}
        + 'When this feature is used, the from * statement will copy out only those names listed in the ____ list. *
            {{{
            = 'Alternatively, you can achieve a hiding effect similar to the _X naming convention by assigning a list of variable name strings to the variable __all__ at the top level of the module.
            --
            lpy3-p799
            }}}
        __future__  * @
            {{{
            Changes to the language that may potentially break existing code are usually introduced gradually in Python. They often initially appear as optional extensions, which are disabled by default.
            When used in a script, this statement must appear as the first executable statement in the file (possibly following a docstring or comment), because it enables special compilation of code on a per-module basis.
               (+tip =Use at the interactive prompt (=to experiment with new language features
            --
            lpy3-p800
            }}}
        For a list of futurisms you may import and turn on this way, run @
            {{{
            a dir call on the __future__ module after importing it, or see its library manual entry.
            --
            lpy3-p800
            }}}
        leaving legacy __future__-statements in code (!)
            {{{
            = 'none of its feature names will ever be removed, so it’s safe to leave in a __future__ import even in code run by a version of Python where the feature is present normally.
            --
            lpy3-p801
            }}}
            ----

            ----
        If the file is being run as a top-level program file, __name__ is set to the string ___ when it starts. (***(***))
            {{{
            "__main__"
              .
                (+ If the file is being imported instead, __name__ is set to the module’s name as known by its clients.
               .
            (= 'a module can test its own __name__ to determine whether it’s being run or imported.
               (+See the Ex. Script  tester.py (***(*!!!)) )
              .
              .
                  (= the function it defines is only run when the file is run as main, and not when it's imported)
            = 'But the module also includes code at the bottom that is set up to call the function automatically when this file is run as a program:
            In effect, a module’s __name__ variable serves as a usage mode flag, allowing its code to be leveraged as both an importable library and a top-level script.
            --
            lpy3-p801
            }}}
        'For instance, perhaps the most common way you’ll see the __name__(=__main__) test applied is for self-test code. ** (@)
            {{{
            = 'you can use the file in clients by importing it, but also test its logic by running it from the system shell or via another launching scheme.
               (+this also qualifies as: 'probably the most common and simplest unit-testing protocol in Python.
            = 'much more convenient than retyping all your tests at the interactive prompt.' (**!)
                (+ unittest, doctest 
            --
            lpy3-p801,p802
            }}}
        In addition, the __name__ trick is also commonly used when you’re writing files that can be used both as @(@)
            {{{
            command-line utilities and as tool libraries.
              .
            suppose you write a file-finder script in Python.
                You can get more mileage out of your code if you package it in functions and add a __name__ test in the file to automatically call those functions when the file is run standalone.
                That way, the script’s code becomes reusable in other programs.
            (= can then be used to stand alone and as a utility library (**)
            --
            lpy3-p802
            }}}
        Unit Tests with __name__ **(!) @(@)
            {{{
            minmax.py in “The min Wakeup Call!”):
            # Self-test code
        if __name__ == '__main__':
            print(minmax(lessthan, 4, 2, 1, 5, 6, 3))
            print(minmax(grtrthan, 4, 2, 1, 5, 6, 3))
              .
            = 'wrap up the self-test call in a __name__ check, so that it will be launched only when the file is run as a top-level script, not when it is imported
            --
            lpy3-p802
            }}}
        ((+ 'We’re also printing the value of __name__ at the top here to trace its value.  (SSs
            {{{
             ??? (= just a note about the name equals main test(??))
            = 'When we run this file as a top-level script, its name is set to __main__, so its self-test code kicks in automatically:
            --
            lpy3-p803
            }}}
        (+note: 'Per Chapter 24’s discussion of package relative imports, this section’s technique (name = main?) can also have some implications for imports run by files that are also used as package components in 3.X, but can still be leveraged with absolute package path imports and other techniques. (@)
            {{{
            --
            lpy3-p803
            }}}
        Example: Dual Mode Code:  = 'Here’s a more substantial module example that demonstrates another way that the prior section’s __name__ trick is commonly employed. (EEEEEE(!!)ee) (@)
            {{{
            = 'The following module, formats.py, defines string formatting utilities for importers, but also checks its name to see if it is being run as a top-level script; if so, it tests and uses arguments listed on the system command line to run a canned or passed-in test.
              .
              .
            'This file works identically in Python 2.X and 3.X. When run directly, it tests itself as before, but it uses options on the command line to control the test behavior.
              .
            'To test specific strings, pass them in on the command line along with a minimum field width; the script’s __main__ code ...
        + 'As before, because this code is instrumented for dual-mode usage, we can also import its tools normally to reuse them as library components in scripts, modules, and the interactive prompt:
            --
            lpy3-p803--p805
            }}}
        For more advanced command-line processing, see @
            {{{
            “Python CommandLine Arguments” on page 1432 in Appendix A, and the getopt, optparse, and argparse modules’ documentation in Python’s standard library manual.
                + 'In some scenarios, you might also use the built-in input function, used in Chapter 3 and Chapter 10, to prompt the shell user for test inputs instead of pulling them from the command line.
            --
            lpy3-p805,p806
            }}}
        formatting extension (that) separates thousands groups with commas much like the code here. (@)
            {{{
            = Also see Chapter 7’s discussion of the new {,d} string format method syntax added in Python 2.7 and 3.1;
            --
            lpy3-p806
            }}}
        Currency Symbols: Unicode in Action * (!)
            {{{
            This module’s money function defaults to dollars, but supports other currency symbols by allowing you to pass in non-ASCII Unicode characters. The Unicode ordinal with hexadecimal value 00A3, for example, is the pound symbol, and 00A5 is the yen. You can code these in a variety of forms, as:
                ( decoded u-code, raw, actual chr
            --
            lpy3-p806
            }}}
            ----

            ----
        use 3.X print function in 2.X (*) (@)
            {{{
            from __future__ import print_function
            --
            lpy3-p806
            }}}
        'If this works on your computer, you can probably skip the next few paragraphs.
            {{{
            Depending on your interface and system settings, though, getting this to run and display properly may require additional steps.
            On my machine, it behaves correctly when Python and the display medium are in sync, but the euro and generic currency symbols in the last two lines fail with errors in a basic Command Prompt on Windows.
              .
              .
            ''However, this doesn’t work in 2.X, because Python tries to encode printed text as ASCII by default.
                To show all the non-ASCII characters in a Windows Command Prompt window directly, on some computers you may need to change the Windows code page (used to render characters) as well as Python’s PYTHONIOENCODING environment variable (used as the encoding of text in standard streams, including the translation of characters to bytes when they are printed) to a common Unicode format such as UTF-8: (!!)
                (+ win config.s (....
               .
               .
            (removing the leading u makes the test work in 3.0 through 3.2 too, but breaks 2.X compatibility): (**(!))
            + 'The takeaway point here is that, operational issues aside, a carefully coded script can often manage to support Unicode in both 3.X and 2.X.
            --
            lpy3-p807(,p808)
            }}}
        teterm: code pages (@)
            {{{
             (=see more)
            --
            lpy3-p807
            }}}
        EE = 'Docstrings: Module Documentation at Work (@)
            {{{
            >>> import formats
            >>> help(formats)
            Help on module formats:
             ...
             ...
              (...)
              .
            Figure 25-2. PyDoc’s view of formats.py, obtained by running a “py -3 -m pydoc –b” command line in 3.2 and later and clicking on the file’s index entry (see Chapter 15) sys.path list.
            --
            lpy3-p808
            }}}
        (EE: 'Changing the Module Search Path (@)
            {{{
            What I haven’t shown you until now is how a Python program itself can actually change the search path by changing the built-in(=????)
            # Extend module search path
            >>> sys.path.append('C:\\sourcedir')
                += Once you’ve made such a change, it will impact all future imports anywhere while a Python program runs, as all importers share the same single sys.path list (there’s only one copy of a given module in memory during a program’s run - that’s why reload exists).
              .
            ((+ 'For this run (process) only (??) (??) (!)
                (+ the alternatives of setting PYTHONPATH and .pth
            --
            lpy3-p808(--p810
            }}}
        tip for 'import as' (**(!!)) (@)
            {{{
            This works in a from statement, too, to assign a name imported from a file to a different name in the importer’s scope;
            from modulename import attrname as name
                As discussed in Chapter 23, this extension is commonly used to provide short synonyms for longer names, and to avoid name clashes when you are already using a name in your script that would otherwise be overwritten by a normal import statement:
              .
                # Use shorter nickname
            import reallylongmodulename as name
            name.func()
             ...
             ...
            --
            lpy3-p810
            }}}
        from|import as((!!))
            {{{
            = 'also comes in handy for providing a short, simple name for an entire directory path and avoiding name collisions when using the package import feature described in Chapter 24:
              (...
               ...
                # Only list full path once
            import dir1.dir2.mod as mod
            mod.func()
              .
            # Rename to make unique if needed
            from dir1.dir2.mod import func as modfunc
            modfunc()
            --
            lpy3-p810
            }}}
        more tip import|from as @
            {{{
            This is also something of a hedge against name changes: if a new release of a library renames a module or tool your code uses extensively, or provides a new alternative you’d rather use instead, you can simply rename it to its prior name on import to avoid breaking your code:
              ...
              ...
              ...
              ...
            (('For example, this approach can address some 3.X library changes (e.g., 3.X’s tkinter versus 2.X’s Tkinter), though they’re often substantially more than just a new name!
            --
            lpy3-p810,p811
            }}}
            ----

            ----
        Example: Modules Are Objects (??) (@)
            {{{
            Because modules expose most of their interesting properties as built-in attributes, it’s easy to write programs that manage other programs.
            --
            lpy3-p811
            }}}
        We usually call such (program) manager programs
            {{{
            metaprograms because they work on top of other systems.
                + 'This is also referred to as introspection, because programs can see and process object internals.
                [[= 'can be useful for building programming tools.
            --
            lpy3-p811
            }}}
        introspection: 'For instance, to get to an attribute called name in a module called M, we can use ** @(@)
            {{{
            attribute qualification or index the module’s attribute dictionary, exposed in the built-in __dict__ attribute we met in Chapter 23.
            --
            lpy3-p811
            }}}
        Python also exports the list of all loaded modules as  (+ built-in  that lets us fetch attributes from their string names ) @
            {{{
            the sys.modules dictionary
            a built-in called getattr that lets us fetch attributes from their string names - it’s like saying object.attr, but attr is an expression that yields a string at runtime.
            --
            lpy3-p811
            }}}
        summary|list of the different methods of getting module attributes (=introspection) @@
            {{{
            # Qualify object by attribute
              M.name
            # Index namespace dictionary manually
              M.__dict__['name']
            # Index loaded-modules table manually
              sys.modules['M'].name
            # Call built-in fetch function
              getattr(M, 'name')
            --
            lpy3-p811
            }}}
        the effect of global X; X=0 can be simulated (albeit with much more typing!) by saying this inside a function: (@)
            {{{
            import sys; glob=sys.modules[__name__]; glob.X=0
                ((= 'This trick provides another way to change both local and global variables of the same name inside a function.
            --
            lpy3-p811
            }}}
        example(=of introspection),:  here is a module named mydir.py that puts these ideas to work to implement a customized version of the built-in dir function.
            {{{
            Notice the docstring at the top; as in the prior formats.py example, because we may want to use this as a general tool, the docstring provides functional information accessible via help and GUI/browser mode of PyDoc - a tool that uses similar introspection tools to do its job.
              .
              .
              .
              .
            + 'To use this as a tool for listing other modules, simply pass the modules in as objects to this file’s function.
            'Here it is listing attributes in the tkinter GUI module in the standard library (a.k.a. Tkinter in Python 2.X); it will technically work on any object with __name__, __file__, and __dict__ attributes:
                    [= 'Because Python exposes its internals, you can process objects generically.2
            --
            lpy3-p811--p813
            }}}
            ----

            ----
        Importing Modules by Name String (@)
            {{{
            The module name in an import or from statement is a hardcoded variable name.
            Sometimes, though, your program will get the name of a module to be imported as a string at runtime - from a user selection in a GUI, or a parse of an XML document, for instance.
                Unfortunately, you can’t use import statements directly to load a module given its name as a string - Python expects a variable name that’s taken literally and not evaluated, not a string or expression.
              .
              .
            'To get around this, you need to use special tools to load a module dynamically from a string that is generated at runtime.
            ((The most general approach is to construct an import statement as a string of Python code and pass it to the exec built-in function to run (exec is a statement in Python 2.X, but it can be used exactly as shown here - the parentheses are simply ignored):
            --
            lpy3-p813 4
            }}}
        [[2. You can preload tools such as mydir.listing and the reloader we’ll meet in a moment into the interactive namespace by importing them in the file referenced by the PYTHONSTARTUP environment variable. (??????) (SSSS (*****!!)
            {{{
            (**(!!)) = Because code in the startup file runs in the interactive namespace (module __main__), importing common tools in the startup file can save you some typing.
            --
            lpy3-p813
            }}}
        exec, and compiling and running strings as python code ** (@)
            {{{
            In Python, the byte code compiler is available at runtime, so you can write programs that construct and run other programs like this.
            By default, exec runs the code in the current scope, but you can get more specific by passing in optional namespace dictionaries if needed.
            --
            lpy3-p814
            }}}
        cont: = generating strings for exec and import (*!)  (= 'Direct Calls: Two Options @
            {{{
              ..
              ..
              ..
              ..
            + 'but in most cases it’s probably simpler and may run quicker to use the built-in __import__ function to load from a name string instead, as noted in Chapter 22.
               (+ "assign object to a name to keep it (!!)
            >>> modname = 'string'
            >>> string = __import__(modname)
            >>> string
            <module 'string' from 'C:\\Python33\\lib\\string.py'>
              .
              .
            + 'the newer call importlib.import_module does the same work, and is generally preferred in more recent Pythons for direct calls to import by name string - at least per the current “official” policy stated in Python’s manuals:
              (+EE (**)
            --
            lpy3-p814
            }}}
        [['Though both calls still work, in Pythons where both are available, the original __import__ is generally intended for
            {{{
            --
            lpy3-p815
            }}}
        Example: Transitive Module Reloads (!!!!) (EEEEEEeee) @
            {{{
            This section develops a module tool that ties together and applies some earlier topics, and serves as a larger case study to close out this chapter and part.
            We studied module reloads in Chapter 23, as a way to pick up changes in code without stopping and restarting a program.
            When you reload a module, though, Python reloads only that particular module’s file; it doesn’t automatically reload modules that the file being reloaded happens to import.
              .
              .
            By default, this means that you cannot depend on reloads to pick up changes in all the modules in your program transitively - instead, you must use multiple reload calls to update the subcomponents independently.
            This can require substantial work for large systems you’re testing interactively.
              .
            'A Recursive Reloader'
            = 'A better approach is to write a general tool to do transitive reloads automatically by scanning modules’ __dict__ namespace attributes and checking each item’s type to find nested modules to reload.
            Such a utility function could call itself recursively to navigate arbitrarily shaped and deep import dependency chains.
                = 'Module __dict__ attributes were introduced in Chapter 23 and employed earlier in this chapter, and the type call was presented in Chapter 9; we just need to combine the two tools.
            [(*) The module reloadall.py listed next defines a reload_all function that automatically reloads a module, every module that the module imports, and so on, all the way to the bottom of each import chain.
            It uses a dictionary to keep track of already reloaded modules, recursion to walk the import chains, and the standard library’s types module, which simply predefines type results for built-in types.
                The visited dictionary technique works to avoid cycles here when imports are recursive or redundant, because module objects are immutable and so can be dictionary keys; as we learned in Chapter 5 and Chapter 8, a set would offer similar functionality if we use visited.add(module) to insert:
              .
              .
            (([[One curious bit: notice how this code must wrap the basic reload call in a try statement to catch exceptions - in Python 3.3, reloads sometimes fail due to a rewrite of the import machinery.
            --
            lpy3-p815--p819
            }}}
        Example: Transitive Module Reloads  = Alternative Codings (=using recursion (!!(**)) ) (@)
            {{{
            For all the recursion fans in the audience, the following lists an alternative recursive coding for the function in the prior section - it uses a set instead of a dictionary to detect cycles, is marginally more direct because it eliminates a top-level loop, and serves to illustrate recursive function techniques in general (compare with the original to see how this differs).
             (...
              ...
            The following is one such transitive reloader; it uses a generator expression to filter out nonmodules and modules already visited in the current module’s namespace.
              .
              .
                (+ 'All three work on both Python 3.X and 2.X too - they’re careful to unify prints with formatting, and avoid using version-specific tools (
            + 'To ensure that all three are reloading the same modules irrespective of the order in which they do so, we can use sets (or sorts) to test for order-neutral equality of their printed messages - obtained here by running shell commands with the os.popen utility we met in Chapter 13 and used in Chapter 21: ((***(*!))
            [****(*): Run these scripts, study their code, and experiment on your own for more insight; these are the sort of importable tools you might want to add to your own source code library.
            + Watch for a similar testing technique in the coverage of class tree listers in Chapter 31, where we’ll apply it to passed class objects and extend it further.
            --
            ['More fundamentally, the transitive reloaders rely on the fact that module reloads update module objects in place, such that all references to those modules in any scope will see the updated version automatically.
                + [Tool impacts like this are perhaps another reason to prefer import to from - which brings us to the end of this chapter and part, and the standard set of warnings for this part’s topic.
            --
            lpy3-p819--p822
            }}}
            ----

        Module Gotchas ((**))

            ----
        Module Name Clashes: Package and Package-Relative Imports (@)
            {{{
            automatic   + 'This isn’t an issue if the module you prefer is in your top-level script’s directory; since that is always first in the module path, its contents will be located first automatically.
            + 'For cross-directory imports, however, the linear nature of the module search path means that same-named files can clash.
            ((To fix, either avoid same-named files or use the package imports feature of Chapter 24.
            (+'If you need to get to both same-named files,
                    (+ To fix, either avoid using the same name as another module you need or store your modules in a package directory and use Python 3.X’s package-relative import model, available in 2.X as an option.
                     In this model, normal imports skip the package directory (so you’ll get the library’s version), but special dotted import statements can still select the local version of the module if needed.
            --
            lpy3-p823
            }}}
        'Statement Order Matters in Top-Level Code  (+TIPS(!!!!(****))) @
            {{{
            As we’ve seen, when a module is first imported (or reloaded), Python executes its statements one by one, from the top of the file to the bottom.
            This has a few subtle implications regarding forward references that are worth underscoring here:
              • Code at the top level of a module file (not nested in a function) runs as soon as Python reaches it during an import; because of that, it cannot reference names assigned lower in the file.
              • Code inside a function body doesn’t run until the function is called; because names in a function aren’t resolved until the function actually runs, they can usually reference names anywhere in the file. (??) (!)
            + 'Generally, forward references are only a concern in top-level module code that executes immediately; functions can reference names arbitrarily. Here’s a file that illustrates forward reference dos and don’ts: (EEEe)
              |
              |
              |
            Mixing defs with top-level code is not only difficult to read, it’s also dependent on statement ordering.
            As a rule of thumb, if you need to mix immediate code with defs, put your defs at the top of the file and your top-level code at the bottom. (!!) **
            --
            lpy3-p823
            }}}
        'from Copies Names but does not (!)
            {{{
            Link
            = 'As we’ve learned, the from statement is really an assignment to names in the importer’s scope - a name-copy operation, not a name aliasing.
            (( 'The implications of this are the same as for all assignments in Python, but they’re subtle, especially given that the code that shares the objects lives in different files.
               (+Ee: 'If we import its two names using from in another module, nested2.py, we get copies of those names, not links to them.
                = Changing a name in the importer resets only the binding of the local version of that name, not the name in nested1.py:
            --
            lpy3-p824,p825
            }}}
        'from * Can Obscure the Meaning of Variables (!!) (@)
            {{{
            Because you don’t list the variables you want when using the from module import * statement form, it can accidentally overwrite names you’re already using in your scope.
            Worse, it can make it difficult to determine where a variable comes from.
              .
            The solution again is not to do this: try to explicitly list the attributes you want in your from statements, and restrict the from * form to at most one imported module per file.
              .
              .
            Even this example isn’t an absolute evil - it’s OK for a program to use this technique to collect names in a single space for convenience, as long as it’s well known.
            --
            lpy3-p825
            }}}
        reload May Not Impact from(-)Imports
            {{{
              .
            = 'To make reloads more effective, use import and name qualification instead of from.
            --
            lpy3-p825,p826
            }}}
        reload, from, and Interactive Testing (??) @
            {{{
            Chapter 3 warned that it’s usually better not to launch programs with imports and reloads because of the complexities involved.
                Things get even worse when from is brought into the mix.
            Python beginners most often stumble onto its issues in scenarios like this - imagine that after opening a module file in a text edit window, you launch an interactive session to load and test your module with from:
            from module import function
            function(1, 2, 3)
              (finding bug, correcting, reloading  (=doesn't work with from)
              .
              .
            To really get the new function, you must refer to it as module.function after the reload, or rerun the from: (??) (!)
             --
            The short story is that you should not expect reload and from to play together nicely.
            Again, the best policy is not to combine them at all - use reload with import, or launch your programs other ways, as suggested in Chapter 3: using the Run→Run Module menu option in IDLE, file icon clicks, system command lines, or the exec built-in function.
            --
            lpy3-p826,p827
            }}}
        ((obscure: 'Recursive from Imports May Not Work (@)
            {{{
            = 'Because imports execute a file’s statements from top to bottom, you need to be careful when using modules that import each other.
            This is often called recursive imports, but the recursion doesn’t really occur (in fact, circular may be a better term here) - such imports won’t get stuck in infinite importing loops.
                If you use import to fetch the module as a whole, this probably doesn’t matter; the module’s names won’t be accessed until you later use qualification to fetch their values, and by that time the module is likely complete.
               .
               .
               .
            ((Python avoids rerunning recur1’s statements when they are imported recursively from recur2 (otherwise the imports would send the script into an infinite loop that might require a Ctrl-C solution or worse), but recur1’s namespace is incomplete when it’s imported by recur2.
            Python won’t get stuck in a cycle if you do, but your programs will once again be dependent on the order of the statements in the modules.
              .
            • You can usually eliminate import cycles like this by careful design - maximizing cohesion and minimizing coupling are good first steps.
            • If you can’t break the cycles completely, postpone module name accesses by using import and attribute qualification (instead of from and direct names), or by running your froms either inside functions (instead of at the top level of the module) or near the bottom of your file to defer their execution.
            --
            lpy3-p827
            }}}
                ----

                ----
        3. If the user interactively types the name of a module to test, how can your code import it? @
            {{{
            . User input usually comes into a script as a string; to import the referenced module given its string name, you can build and run an import statement with exec, or pass the string name in a call to the __import__ or importlib.import_module.
            --
            lpy3-p829
            }}}
        top-level _vars cannot be from-imported(???), but  can still be accessed by
            {{{
            an import or the normal from statement form, though.
            --
            lpy3-p829
            }}}
        Changing sys.path only affects one running program (process), and is temporary - the change goes away when
            {{{
            the program ends.
            --
            lpy3-p829
            }}}
        exercise: write a custom wc () @(@)
            {{{
            (could use  for and file iterators to support massive files too).
            --
            lpy3-p830
            }}}
        file rewind). @@(@)
            {{{
            file.seek(0)
            --
            lpy3-p830
            }}}
        Circular imports are uncommon and rarely this bizarre in practice. On the other hand, (!)
            {{{
            if you can understand why they are a potential problem, you know a lot about Python’s import semantics.
            --
            lpy3-p831
            }}}
            ----


        IF IN DOUBT AB. SOME EXPLANATIONS, LOOK FOR BETTER MORE SUCCINCT EXPLANATIONS IN|FROM THE SUMMARY AND QUIZ PARTS
          eg. 
          'When Python finds these during an import search, and does not find a simple module or regular package first, it creates a namespace package that is the virtual concatenation of all found directories having the requested module name.
          =The effect is similar to a regular package, but content may be split across multiple directories.

}}}
---- lpy07-classes.txt -- {{{
        classes =tools that are largely
            {{{
            packages of functions with special first arguments.
            --
            lpy3-p713
            }}}
        attribute fetch (in classes) (??) (@)
            {{{
            =bit like dict indexing,  but  kicks off inheritance((??)(!))
            --
            lpy3-p749
            }}}

        Part VI - Classes and OOP
        Chapter 26 - OOP: The Big Picture

            ----
        ("we've used objects so far, but") For our code to qualify as being truly object-oriented (OO), though, (!)(!)
            {{{
            our objects will generally need to also participate in something called an inheritance hierarchy.
            --
            lpy3-p835
            }}}
        the Python class - a coding structure and device used to (T@)
            {{{
            implement new kinds of objects in Python that support inheritance.
            --
            lpy3-p835
            }}}
        In Python, classes are created with a new statement:
            {{{
            = the class.
            --
            lpy3-p835
            }}}
        (Classes are)  also employed in popular Python tools like
            {{{
            the tkinter GUI API,
            --
            lpy3-p835
            }}}
        (Why Use Classes?) (@)
            {{{
            programs “do things with stuff”
                + classes are just a way to define new sorts of stuff, reflecting real objects in a program’s domain.
            --
            lpy3-p836
            }}}
        For instance, for our robot to be successful, it might need arms to roll dough, motors to maneuver to the oven, and so on. In OOP parlance, our robot is an example of
            {{{
            composition; it contains other objects that it activates to do its bidding.
                Each component might be coded as a class, which defines its own behavior and relationships.
            --
            lpy3-p836
            }}}
        General OOP ideas like inheritance and composition apply to any application that can be decomposed into a set of objects. (=GUI systems example)
            {{{
            For example, in typical GUI systems, interfaces are written as collections of widgets - buttons, labels, and so on - which are all drawn when their container is drawn (composition).
                Moreover, we may be able to write our own custom widgets - buttons with unique fonts, labels with new color schemes, and the like - which are specialized versions of more general interface devices (inheritance).
            --
            lpy3-p836
            }}}
        classes also define new namespaces, much like modules.  But, compared to other program units we’ve already seen, classes have three critical distinctions that make them more useful when it comes to building new objects:
            {{{
            Multiple instances
                Every time we call a class, we generate a new object with a distinct namespace.
            Each object generated from a class has access to the class’s attributes and gets a namespace of its own for data that varies per object.
              (= similarly to per-call state retention in closures, but automatic)
            --
            lpy3-p836
            }}}
            ----

            ----
        classes (=has) Customization via
            {{{
            inheritance
            --
            lpy3-p837
            }}}
        Operator overloading (*) @
            {{{
            By providing special protocol methods, classes can define objects that respond to the sorts of operations we saw at work on built-in types.
            For instance, objects made with classes can be sliced, concatenated, indexed, and so on.
                (= Python provides hooks that classes can use to intercept and implement any built-in type operation.
            --
            lpy3-p837
            }}}
        At its base, the mechanism of OOP in Python is largely just two bits of magic: **(!) @
            {{{
            a special first argument in functions (to receive the subject of a call) and inheritance attribute search (to support programming by customization).
                ((+ Other than this, the model is largely just functions that ultimately process built-in types.
            --
            lpy3-p837
            }}}
          OOP from 30,000 Feet
            {{{
            ((= 'If you’ve never done anything object-oriented in your life before now, some of the terminology in this chapter may seem a bit perplexing on the first pass.
               .
                .
            --
            lpy3-p837
            }}}
        much of the OOP story in Python boils down to this expression:
            {{{
            object.attribute
            --
            lpy3-p837
            }}}
        When we say this(=obj.attr) to an object that is derived from a class statement,
            {{{
            the expression kicks off a search in Python - it searches a tree of linked objects, looking for the first appearance of attribute that it can find.
              .
        When classes are involved, the preceding Python expression effectively translates to the following in natural language:
            ''Find the first occurrence of attribute by looking in object, then in all classes above it, from bottom to top and left to right.
            --
            lpy3-p837
            }}}
        In other words, attribute fetches are simply (@)
            {{{
            tree searches.
            --
            lpy3-p838
            }}}
        The term inheritance is applied because objects lower in a tree *
            {{{
            inherit attributes attached to objects higher in that tree.
            --
            lpy3-p838
            }}}
        All of these objects(=up through a class tree) are (!) (T@)
            {{{
            namespaces (packages of variables),
            --
            lpy3-p838
            }}}
        + the inheritance search is simply a search of the tree from bottom to top looking for
            {{{
            the lowest occurrence of an attribute name.
            --
            lpy3-p838
            }}}
        ('Notice that in the Python object model, classes and the instances you generate from them are ____ object types: ((!!@)
            {{{
            = two distinct object types
            --
            lpy3-p838
            }}}
            ----

            ----
        (Classes) Serve as
            {{{
            instance factories.
            --
            lpy3-p838
            }}}
        Instances (r)epresent (@T@)
            {{{
            the concrete items in a program’s domain.
            Their attributes record data that varies per specific object (e.g., an employee’s Social Security number).
            --
            lpy3-p838
            }}}
        a class inherits attributes from * !@
            {{{
            all classes above it in the tree.
            --
            lpy3-p838
            }}}
        other name for  superclasses and subclasses,
            {{{
            base classes and derived classes
            --
            lpy3-p839
            }}}
        I2.w  (=this code does what?) (!!)
            {{{
            this code invokes inheritance. Because this is an object.attribute expression, it triggers a search of the tree in Figure 26-1 - Python will search for the attribute w by looking in I2 and above.
            Specifically, it will search the linked objects in this order:
                I2, C1, C2, C3
            In other words, I2.w resolves to C3.w by virtue of the automatic search. In OOP terminology, I2 “inherits” the attribute w from C3.
              .  (??)
            ((+ 'Ultimately, the two instances inherit four attributes from their classes: w, x, y, and z.
            --
            lpy3-p839
            }}}
        the heart of software customization in OOP *(*) (@)
            {{{
            - because C1 redefines the attribute x lower in the tree, it effectively replaces the version above it in C2.
                - by redefining and replacing the attribute, C1 effectively customizes what it inherits from its superclasses.
            --
            lpy3-p839
            }}}
        Although they are technically two separate object types in the Python model, the classes and instances we put in these trees are almost identical - each type’s main purpose is to serve as (@)
            {{{
            another kind of namespace - a package of variables, and a place where we can attach attributes.
                If classes and instances therefore sound like modules, they should; ((**))
            --
            lpy3-p840
            }}}
        however, the objects in class trees also have (=as opposed to modules which they're also similar to (=as packages of v.s) (**(*!))
            {{{
            the objects in class trees also have automatically searched links to other namespace objects, and
            classes correspond to statements, not entire files.
               +
            we only ever have one instance of a given module in memory (that’s why we have to reload a module to get its new code), but with classes, we can make as many instances as we need.
            --
            lpy3-p840
            }}}
            ----

            ----
        ['In fact, the object-oriented model is not that different from the classic data-processing model of programs plus records - in OOP, instances are like ____, and classes are the ____ (@)
            {{{
            - in OOP, instances are like records with “data,”
            and classes are the “programs” for processing those records.
            --
            lpy3-p840
            }}}
        If this I2.w reference is a function call, what it really means is **(!)
            {{{
            “call the C3.w function to process I2.”
            That is, Python will automatically map the call I2.w() into the call C3.w(I2), passing in the instance as the first argument to the inherited function.
            --
            lpy3-p840
            }}}
        As we’ll see later, Python passes in the implied instance to a special first argument in the method, called *
            {{{
            self by convention.
            Methods go through this argument to process the subject of the call.
            --
            lpy3-p840
            }}}
        As we’ll also learn, methods can be called through either @!
            {{{
            an instance - bob.giveRaise() -
                = Looks up giveRaise from bob, by inheritance search
                + Passes bob to the located giveRaise function, in the special self argument
              .
            or a class - Employee.giveRaise(bob) -
                (= here we do both steps explicitly ourselves)
             .
             .
                and both forms serve purposes in our scripts. (??)
            --
            lpy3-p841
            }}}
            ----

        (Actually) Coding Class Trees

            ----
        • Each class statement generates
            {{{
            a new class object.
            --
            lpy3-p841
            }}}
        • Each time a class is called, it generates
            {{{
            a new instance object.
            --
            lpy3-p841
            }}}
        • Instances are automatically linked
            {{{
            to the classes from which they are created.
            --
            lpy3-p841
            }}}
        • Classes are automatically linked to their superclasses according to ____, + the order in the class trees given by ____  (**(*)) @(@)
            {{{
            • Classes are automatically linked to their superclasses according to the way we list them in parentheses in a class header line;
            + the left-to-right order there gives the order in the class tree.
            --
            lpy3-p841
            }}}
        To build the tree in Figure 26-1, for example, we would run Python code of the following form. ((!!)) @
            {{{
                # Make class objects (ovals)
            class C2: ...
            class C3: ...
            class C1(C2, C3): ...
              .
                # Make instance objects (rectangles)
            I1 = C1()	# Linked to their classes
            I2 = C1()	# Linked to superclasses (in this order)
                (+Note: Uses multiple inheritance (!!(**)) )
            --
            lpy3-p841
            }}}
        Make two class objects (**) (@)
            {{{
            class C2: ...
            class C3: ...
            --
            lpy3-p841
            }}}
        Make a class object that inherits fr. two classes (**!!) @
            {{{
            class C1(C2, C3): ...
            --
            lpy3-p841
            }}}
        make two class instances fr. class C1 (=possibly that inherits from superclasses as well) (**) @(@)
            {{{
            I1 = C1()
            I2 = C1()
               (=call the class like it was a function)
               .
            (The instances remember the class they were made from, and the class C1 remembers its listed superclasses.
            --
            lpy3-p841
            }}}
        order the classes C2 and C3 (= in 'class C1(C2, C3): ...') will be searched for attributes by inheritance. ((***(*))) @!
            {{{
            their left-to-right order gives the order in which those superclasses will be searched for attributes by inheritance.
            --
            lpy3-p841,p842
            }}}
        'The leftmost version of a name is used by default, though you can always choose a name by asking for it from the class it lives in (e.g., C3.z). (????) (@)
            {{{
            --
            lpy3-p842
            }}}
            ----

            ----
        (('Because of the way inheritance searches proceed, the object to which you attach an attribute turns out to be crucial - it determines (??)(??) (@)
            {{{
            the name’s scope.
            --
            lpy3-p842
            }}}
        Attributes attached to instances vs attached to classes ((**)) @
            {{{
            Attributes attached to instances pertain only to those single instances, but attributes attached to classes are shared by all their subclasses and instances.
            --
            lpy3-p842
            }}}
        • Attributes are usually attached to classes by assignments made (= at what level and the class statement?) * (@)
            {{{
            at the top level in class statement blocks, and not nested inside function def statements there. (??) *
            --
            lpy3-p842
            }}}
        • Attributes are usually attached to instances by (= how|where it is coded?) * @
            {{{
            = assignments to the special argument passed to functions coded inside classes, called self.
            --
            lpy3-p842
            }}}
        classes provide behavior for their instances with (=how they are coded) (*****) @@(@)
            {{{
            method functions we create by coding def statements inside class statements.
              .
            class C1(C2, C3):	# Make and link class C1
                # Assign name: C1.setname
                def setname(self, who):
                    # Self is either I1 or I2
                    self.name = who
              .
                [[= 'Because such nested defs assign names within the class, they wind up attaching attributes to the class object that will be inherited by all instances and subclasses: (??) (**)
            --
            lpy3-p842
            }}}
        Make two instances of the class makename + set names to Bob and Sue (*****(!!)) @@
            {{{
            I1 = C1()		# Make two instances
            I2 = C1()
            I1.setname('bob')	# Sets I1.name to 'bob'
            I2.setname('sue')	# Sets I2.name to 'sue'
            print(I1.name)		# Prints 'bob'
            --
            lpy3-p842
            }}}
        special about a method operationally|syntactically (=as compared to a function) when coding|defining it (**) @
            {{{
            (= looks syntactically just like a function wh. coding it, +)
            = it automatically receives a special first argument - called self by convention - that provides a handle back to the instance to be processed.
              .
            + 'Any values you pass to the method yourself go to arguments after self (here, to who).2
            --
            lpy3-p842
            }}}
        (what the self argument is used for (??????))
            {{{
            their(=the classes')  methods usually go through this automatically passed-in self argument whenever they need to fetch or set attributes of the particular instance being processed by a method call.
               .
            ((+ 'In the preceding code, self is used to store a name in one(=??????????) of two instances.
            --
            lpy3-p842
            }}}
        When a method assigns to a self attribute, it (=does what, and where(=to what?)?) ((??(***)))
            {{{
            creates or changes an attribute in an instance at the bottom of the class tree (i.e., one of the rectangles in Figure 26-1) because self automatically refers to the instance being processed - the subject of the call.
            --
            lpy3-p842,p843
            }}}
        [['In fact, because all the objects in class trees are just namespace objects, we can fetch or set any of their attributes by  ((???????)) (@)
            {{{
            going through the appropriate names. Saying C1.setname is as valid as saying I1.setname, as long as the names C1 and I1 are in your code’s scopes. (???????)
            --
            lpy3-p843
            }}}
            ----

            ----
        If a class (like C1) wants to guarantee that an attribute like name is always set in its instances, (***(*******)!!(!)*) @
            {{{
            it more typically will fill out the attribute at construction time, like this:
            class C1(C2, C3):
                # Set name when constructed
                def __init__(self, who):
                    # Self is either I1 or I2
                    self.name = who
            --
            lpy3-p843
            }}}
        if  def __init__(self, var1)  is coded or inherited for a class  (*******) (???@)
            {{{
            , Python automatically calls a method named __init__ each time an instance is generated from a class.
            The new instance is passed in to the self argument of __init__ as usual, and any values listed in parentheses in the class call go to arguments two and beyond.
              .
            The effect here is to initialize instances when they are made, without requiring extra method calls.
            I1 = C1('bob')
              vs
            I1 = C1(); I1.setname('bob')
            --
            lpy3-p843
            }}}
        The __init__ method is known as ** @
            {{{
            the constructor ((because of when it is run.
            --
            lpy3-p843
            }}}
        the __init__-method belongs to a  class of methods called **(!) @(@)
            {{{
            = the  most commonly used representative of
            operator overloading methods,
            --
            lpy3-p843
            }}}
        ((how are op. overloading methods  run by Py?))
            {{{
            = ''Python runs them automatically when instances that support them appear in the corresponding operations, and they are mostly an alternative to using simple method calls. (??) (!!) *
            + 'They’re also optional: if omitted, the operations are not supported. If no __init__ is present, class calls return an empty instance, without initializing it. (**)
            --
            lpy3-p843
            }}}
            ----

            ----
        (a bit extra w. overloading, but otherwise)  By and large, though, OOP is about
            {{{
            looking up attributes in trees with a special first argument in functions.
            --
            lpy3-p844
            }}}
        The good thing w. Py Classes (=and their code reuse) [****] @
            {{{
            With classes, we code by customizing existing software, instead of either changing existing code in place or starting from scratch for each new project.
                At a fundamental level, classes are really just packages of functions and other names, much like modules.
                However, the automatic attribute inheritance search that we get with classes supports customization of software above and beyond what we can do with modules and functions.
            --
            lpy3-p844
            }}}
        te - ex. case: 'suppose you’re assigned the task of implementing an employee database application. (@)
            {{{
            As a Python OOP programmer, you might begin by coding a general superclass that defines default behaviors common to all the kinds of employees in your organization:
          .
        class Employee:	# General superclass
              # Common or default behaviors
            def computeSalary(self): ...
            def giveRaise(self): ...
            def promote(self): ...
            def retire(self): ...
              .
            Once you’ve coded this general behavior, you can specialize it for each specific kind of employee to reflect how the various types differ from the norm.
            That is, you can code subclasses that customize just the bits of behavior that differ per employee type; the rest of the employee types’ behavior will be inherited from the more general class.
              .
            # Specialized subclass
        class Engineer(Employee):
            # Something custom here
            def computeSalary(self): ...
              .
            You then create instances of the kinds of employee classes that the real employees belong to, to get the correct behavior:
            --
            lpy3-p844,p845
            }}}
        store class instance objects in variables for activation|computation at a later time (*(!!!)) @
            {{{
        bob = Employee() # Default behavior
        sue = Employee() # Default behavior
        tom = Engineer() # Custom salary calculator
            Ultimately, these three instance objects might wind up embedded in a larger container object - for instance, a list, or an instance of another class - that represents a department or company using the composition idea mentioned at the start of this chapter.
            When you later ask for these employees’ salaries, they will be computed according to the classes from which the objects were made, due to the principles of the inheritance search:
            # A composite object
        company = [bob, sue, tom]
        for emp in company:
            # Run this object's version: default or custom
            print(emp.computeSalary())
              ((# += "could be stored in a database with pickle, +maybe shelve (*)))
            --
            lpy3-p845
            }}}
        Recall that polymorphism means * (@)
            {{{
            that the meaning of an operation depends on the object being operated on.
                That is, code shouldn’t care about what an object is, only about what it does.
              .
              .
            [[for the above|prev. code:
             'Here, the method computeSalary is located by inheritance search in each object before it is called.
             The net effect is that we automatically run the correct version for the object being processed.
            --
            lpy3-p845
            }}}
        In other applications, polymorphism might also be used to hide (i.e., encapsulate) interface differences. 
            {{{
            For example, a program that processes data streams might be coded to expect objects with input and output methods, without caring what those methods actually do:
            .
        def processor(reader, converter, writer):
            while True:
                data = reader.read()
                if not data: break
                data = converter(data)
                writer.write(data)
              .
            By passing in instances of subclasses that specialize the required read and write method interfaces for various data sources, we can reuse the processor function for any data source we need to use, both now and in the future:
           .
        class Reader:
            # Default behavior and tools
            def read(self): ...
            def other(self): ...
        class FileReader(Reader):
            # Read from a local file
            def read(self): ...
        class SocketReader(Reader):
            # Read from a network socket
            def read(self): ...
        ...
           .
           .
        processor(FileReader(...), Converter, FileWriter(...))
        processor(SocketReader(...), Converter, TapeWriter(...))
        processor(FtpReader(...), Converter, XmlWriter(...))
            Moreover, because the internal implementations of those read and write methods have been factored into single locations, they can be changed without impacting code such as this that uses them.
            The processor function might even be a class itself to allow the conversion logic of converter to be filled in by inheritance, and to allow readers and writers to be embedded by composition (we’ll see how this works later in this part of the book).
            --
            lpy3-p846
            }}}
            ----

            ----
        Programming by customization (**)
            {{{
            when it’s time to write a new program, much of your work may already be done
            - your task largely becomes one of mixing together existing superclasses that already implement the behavior required by your program.
            --
            lpy3-p846
            }}}
        Progr. by customization ii: 'In fact, in many application domains, you can fetch or purchase collections of superclasses, known as @(@)
            {{{
            frameworks, that implement common programming tasks as classes, ready to be mixed into your applications.
                These frameworks might provide database interfaces, testing protocols, GUI toolkits, and so on.
                With frameworks, you often simply code a subclass that fills in an expected method or two; the framework classes higher in the tree do most of the work for you.
            Programming in such an OOP world is just a matter of combining and specializing already debugged code by writing subclasses of your own.
            --
            lpy3-p846
            }}}
        In practice, object-oriented work also entails substantial design work to fully realize the code reuse benefits of classes - @
            {{{
            - to this end, programmers have begun cataloging common OOP structures, known as design patterns, to help with design issues.
            --
            lpy3-p846
            }}}
        As we’ve seen, OOP is mostly about
            {{{
            an argument named self, and a search for attributes in trees of linked objects called inheritance.
                As we get deeper into Python classes, though, keep in mind that the OOP model in Python is very simple; as we’ve seen here, it’s really just about looking up attributes in object trees and a special function argument.
            --
            lpy3-p847
            }}}
        2. Where does an inheritance search look for an attribute? (@)
            {{{
            2. An inheritance search looks for an attribute first in the instance object, then in the class the instance was created from, then in all higher superclasses, progressing from the bottom to the top of the object tree, and from left to right (by default).
              .
            The search stops at the first place the attribute is found. Because the lowest version of a name found along the way wins, class hierarchies naturally support customization by extension in new subclasses.
            --
            lpy3-p847
            }}}
        3. What is the difference between a class object and an instance object? (@)
            {{{
            3. Both class and instance objects are namespaces (packages of variables that appear as attributes).
            The main difference between them is that classes are a kind of factory for creating multiple instances.
            Classes also support operator overloading methods, which instances inherit, and treat any functions nested in the class as methods for processing instances.
            --
            lpy3-p848
            }}}
        4. Why is the first argument in a class’s method function special?
            {{{
            4. The first argument in a class’s method function is special because it always receives the instance object that is the implied subject of the method call.
            It’s usually called self by convention.
                Because method functions always have this implied subject and object context by default, we say they are “object-oriented” (i.e., designed to process or change objects).
            --
            lpy3-p848
            }}}
        5. What is the __init__ method used for?
            {{{
            5. If the __init__ method is coded or inherited in a class, Python calls it automatically each time an instance of that class is created.
            It’s known as the constructor method; it is passed the new instance implicitly, as well as any arguments passed explicitly to the class name. (??) (!)
            It’s also the most commonly used operator overloading method.  If no __init__ method is present, instances simply begin life as empty namespaces.
            --
            lpy3-p848
            }}}
        6. How do you create a class instance? (*****(!!)) @@
            {{{
            6. You create a class instance by calling the class name as though it were a function; any arguments passed into the class name show up as arguments two and beyond in the __init__ constructor method. The new instance remembers the class it was created from for inheritance purposes.
            --
            lpy3-p848
            }}}
        7. How do you create a class? (!)
            {{{
            7. You create a class by running a class statement; like function definitions, these statements normally run when the enclosing module file is imported (more on this in the next chapter).
            --
            lpy3-p848
            }}}
        8. How do you specify a class’s superclasses? (**)
            {{{
            8. You specify a class’s superclasses by listing them in parentheses in the class statement, after the new class’s name.
            The left-to-right order in which the classes are listed in the parentheses gives the left-to-right inheritance search order in the class tree.
            --
            lpy3-p848
            }}}
            ----


        Chapter 27 - Class Coding Basics
        (=the actual(!!) Syntax) (!!)

            ----
        (but) in their basic form, Python classes are easy to understand. In fact, classes have just three primary distinctions.
            {{{
            At a base level, they are mostly just namespaces, much like the modules we studied in Part V.
              .
            Unlike modules, though, classes also have support for
                generating multiple objects, for
                namespace inheritance, and for
                operator overloading.
            --
            lpy3-p849
            }}}
        Class objects provide (@)
            {{{
            default behavior and serve as factories for instance objects.
            --
            lpy3-p849
            }}}
        Class objects come from ____, and instances come from ____; (!) @
            {{{
            Class objects come from statements, and
            instances come from calls;
            --
            lpy3-p849
            }}}
        each time you ____, you get a new instance of that class. (!!)
            {{{
            call a class
            --
            lpy3-p849
            }}}
        = 'With classes, each instance can have its own,
            {{{
            independent data, supporting multiple versions of the object that the class models.
            --
            lpy3-p849
            }}}
        combining OOP and function programming in Py (!!) @
            {{{
            We may combine them by using functional tools in methods, by coding methods that are themselves generators, by writing user-defined iterators (as we’ll see in Chapter 30), and so on.
            --
            lpy3-p850
            }}}
        When we ____, we get a class object. (!) (@)
            {{{
            run a class statement
            --
            lpy3-p850
            }}}
        • The class statement (= does what?) *
            {{{
            creates a class object and assigns it a name.
                Just like the function def statement, the Python class statement is an executable statement.
                When reached and run, it generates a new class object and assigns it to the name in the class header.
                (+ Also, like defs, class statements typically run when the files they are coded in are first imported.
            --
            lpy3-p850
            }}}
        • Assignments inside class statements make (!)
            {{{
            class attributes.
            Just like in module files, top-level assignments within a class statement (not nested in a def) generate attributes in a class object.
                Technically, the class statement defines a local scope that morphs into the attribute namespace of the class object, just like a module’s global scope.
             ...
             (...)
            --
            lpy3-p850
            }}}
        • Class attributes provide (!) @(@)
            {{{
            object state and behavior.
                Attributes of a class object record state information and behavior to be shared by all instances created from the class; function def statements nested inside a class generate methods, which process instances.
            --
            lpy3-p850
            }}}
            ----

            ----
        When we call a class object, we get
            {{{
            an instance object.
            --
            lpy3-p850
            }}}
        ____ makes a new (class) instance object.
            {{{
            Each time a class is called, it creates and returns a new instance object.
                Instances represent concrete items in your program’s domain.
            --
            lpy3-p850
            }}}
        • Each instance object inherits ___ + gets ___
            {{{
            inherits class attributes and gets its own namespace.
                = Instance objects created from classes are new namespaces; they start out empty but inherit attributes that live in the class objects from which they were generated.
            --
            lpy3-p851
            }}}
        ____ make per-instance attributes. (*****(!!(!)) ) @@
            {{{
            • Assignments to attributes of self in methods
                = 'assignments to attributes of self create or change data in the instance, not the class.
            --
            lpy3-p851
            }}}
        Instances reflect
            {{{
            (the actual)  concrete application entities, and record per-instance data that may vary per object.
            --
            lpy3-p851
            }}}
            ----

            ----
        Ex. (=Building a first class(!!)) (**(!!)) @@
            {{{
            # Define a class object
        >>> class FirstClass:
            # Define class's methods
                def setdata(self, value):
                    # self is the instance
                    self.data = value
                def display(self):
                    # self.data: per instance
                    print(self.data)
              .
            We’re working interactively here, but typically, such a statement would be run when the module file it is coded in is imported.
            Like functions created with defs, this class won’t even exist until Python reaches and runs this statement.
              .
            Here, the nested statements are defs; they define functions that implement the behavior the class means to export.
                Here, it assigns function objects to the names setdata and display in the class statement’s scope, and so generates attributes attached to the class
            --
            lpy3-p851
            }}}
        names of the class' objects for our first generated class (**(!)) (@)
            {{{
            - FirstClass.setdata and FirstClass.display.
            --
            lpy3-p851
            }}}
        any name assigned at the top level of the class’s nested block becomes (@)
            {{{
            an attribute of the class.
            --
            lpy3-p851
            }}}
        Functions inside a class (='methods') @
            {{{
            support everything we’ve learned about functions already (they can have defaults, return values, yield items on request, and so on).
                (+ recieves the implied instance object (='self') = the subject of the call))
            --
            lpy3-p851
            }}}
        generate two new class instances stored in the variables x and y @
            {{{
            >>> x = FirstClass()  # Make two instances
            >>> y = FirstClass()
            --
            lpy3-p851
            }}}
        instance objects  are (= technically) (!!) ((T@)
            {{{
            = namespaces that have access to their classes’ attributes.
            --
            lpy3-p851
            }}}
        finding attributes at different points when searching upwards in the class tree
            {{{
            Here, the “data” attribute is found in instances, but “setdata” and “display” are in the class above them.
            --
            lpy3-p852
            }}}
        [x and y here: = 'In OOP terms, we say that (@)
            {{{
            x “is a” FirstClass, as is y - they both inherit names attached to the class.
            --
            lpy3-p852
            }}}
        ['If we qualify an instance with the name of an attribute that lives in the class object, Python fetches the name from the class by inheritance search (unless it also lives in the instance): ????????
            {{{
            # Call methods: self is x
            >>> x.setdata("King Arthur")
            # Runs: FirstClass.setdata(y, 3.14159)
            >>> y.setdata(3.14159)
            --
            lpy3-p852
            }}}
            ----

            ----
        [['methods must go through the self argument to get to the instance to be processed.  ???????
            {{{
            When we call the class’s display method to print self.data, we see that it’s different in each instance; on the other hand, the name display itself is the same in x and y, as it comes (is inherited) from the class:
              .
            >>> x.display()		# self.data differs in each instance
            King Arthur
            >>> y.display()		# Runs: FirstClass.display(y)
            3.14159
            --
            lpy3-p852
            }}}
        instance attributes (=are  sometimes called
            {{{
            ((data)) members
                [+= don't need declarations  in Py  = they spring into existence the first time they are assigned values, just like simple variables.
            --
            lpy3-p852
            }}}
        (['As another way to appreciate how dynamic this model is, consider that we can change instance attributes (??)(!) (@)
            {{{
            in the class itself, by assigning to self in methods, or outside the class, by assigning to an explicit instance object:
                # Can get/set attributes
            >>> x.data = "New value"
                # Outside the class too
            >>> x.display()
            New value
              .
              .
            + 'Although less common, we could even generate an entirely new attribute in the instance’s namespace by assigning to its name outside the class’s method functions:
              .
            # Can set new attributes here too!
            >>> x.anothername = "spam"
              .
              .
            This would attach a new attribute called anothername, which may or may not be used by any of the class’s methods, to the instance object x.
            Classes usually create all of the instance’s attributes by assignment to the self argument, but they don’t have to - programs can fetch, change, or create attributes on any objects to which they have references. (??) (!)
            --
            lpy3-p853
            }}}
        prevent adding data that the class cannot use, (= which usually don't make much sense)  (!!) (@)
            {{{
            with extra “privacy” code based on attribute access operator overloading, as we’ll discuss later in this book (see Chapter 30 and Chapter 39).
            --
            lpy3-p853
            }}}
        cases where 'free attribute access' (like in prev.) can actually be useful (*) @
            {{{
            in coding data records of the sort we’ll see later in this chapter.
                (= 'free attribute access translates to less syntax,
            --
            lpy3-p853
            }}}
            ----

            ----
        classes also allow us to make changes by ____, instead of changing existing components in place.
            {{{
            introducing new (sub)components (called subclasses),
              ((='customizers'))
            --
            lpy3-p853
            }}}
        inheritance: In effect, the further down the hierarchy we go, the more ___ the software becomes.
            {{{
            specific
            --
            lpy3-p853
            }}}
        • Superclasses(=for a class) are listed in ____   + To make a class inherit attributes from another class, ____ ((*****(!!)))
            {{{
            Superclasses are listed in parentheses in a class header.
            To make a class inherit attributes from another class, just list the other class in parentheses in the new class statement’s header line.
            --
            lpy3-p853,p854
            }}}
        ('Just as instances inherit the attribute names defined in their classes, classes inherit (@)
            {{{
            all of the attribute names defined in their superclasses;
            --
            lpy3-p854
            }}}
        • Instances inherit attributes from (!!!!(**(*)))
            {{{
            all accessible classes.
            Each instance gets names from the class it’s generated from, as well as all of that class’s superclasses.
            = 'When looking for a name, Python checks the instance, then its class, then all superclasses.
            --
            lpy3-p854
            }}}
        ([[Each self.attr expression in a method invokes @
            {{{
            a new search for attr in self and above.
            --
            lpy3-p854
            }}}
        [[• Logic changes are made by @
            {{{
            subclassing[='overriding(??)'), not by changing superclasses.
            --
            lpy3-p854
            }}}
            ----

            ----
        A Second Example (=inheritance + overriding) **(!) @
            {{{
            # Inherits setdata
        >>> class SecondClass(FirstClass):
                # Changes display (=!!)
                def display(self):
                    print('Current value = "%s"' % self.data)
              .
            Figure 27-2. Specialization: overriding inherited names by redefining them in extensions lower in the class tree. Here, SecondClass redefines and so customizes the “display” method for its instances.
             --
            SecondClass defines the display method to print with a different format.
            = 'By defining an attribute with the same name as an attribute in FirstClass, SecondClass effectively replaces the display attribute in its superclass.
            --
            --
        >>> z = SecondClass()
            # Finds setdata in FirstClass
        >>> z.setdata(42)
            # Finds overridden method in SecondClass
        >>> z.display()
        Current value = "42"
            --
            lpy3-p855
            }}}
        Sometimes we call this act of replacing attributes by redefining them lower in the tree  (**(*!)) (T@)
            {{{
            overloading
            --
            lpy3-p855
            }}}
        rep: 'Classes Are (=actually|technically)  (!!))  (??) (??)
            {{{
            Attributes in Modules
                = remember that there’s nothing magic about a class name. It’s just a variable assigned to an object when the class statement runs, and the object can be referenced with any normal expression.
            'For instance, if our FirstClass were coded in a module file instead of being typed interactively, we could import it and use its name normally in a class header line:
                .
            # Copy name into my scope
        from modulename import FirstClass
            # Use class name directly
        class SecondClass(FirstClass):
            def display(self): ...
                 //
            # Access the whole module
        import modulename
            # Qualify to reference
        class SecondClass(modulename.FirstClass):
            def display(self): ...
            --
            lpy3-p856
            }}}
        [['Like everything else, class names always live within a module, so they must follow all the rules we studied in Part V. For example, (??) (!)
            {{{
            more than one class can be coded in a single module file - like other statements in a module, class statements are run during imports to define names, and these names become distinct module attributes.
            More generally, each module may arbitrarily mix any number of variables, functions, and classes, and all names in a module behave the same way.
              .
            # food.py
            var = 1				# food.var
            def func():			# food.func
            class spam:			# food.spam
            class ham:			# food.ham
            class eggs:			# food.eggs
            --
            lpy3-p856
            }}}
        [access class 'person' in module 'person' (*)]
            {{{
            class person: ...
              .
              .
            import person	# Import module
            x = person.person()	# Class within module
            --
            lpy3-p856
            }}}
        'As with any other variable, we can never see a class in a file without (!)
            {{{
            first importing and somehow fetching it from its enclosing file.
            --
            lpy3-p856
            }}}
        common convention in Python dictates that class names should  (= how should classes be named?) (***(*!)) @(@)
            {{{
            class names should begin with an uppercase letter, to help make them more distinct:
              .
            import person  # Lowercase for modules
            x = person.Person()  # Uppercase for classes
            --
            lpy3-p856
            }}}
        ([['Also, keep in mind that although classes and modules are both namespaces for attaching attributes, they correspond to very different source code structures: (T@)
            {{{
            a module reflects an entire file, but a class is a statement within a file.
            --
            lpy3-p857
            }}}
            ----

            ----
        operator overloading. (@)
            {{{
            = Classes Can Intercept Python Operators
                lets objects coded with classes intercept and respond to operations that work on built-in types: addition, slicing, printing, qualification, and so on.
              .
            It’s mostly just an automatic dispatch mechanism - expressions and other built-in operations route control to implementations in classes.
              .
            [[++ 'Although we could implement all class behavior as method functions, operator overloading lets objects be more tightly integrated with Python’s object model.
                Moreover, because operator overloading makes our own objects act like built-ins, it tends to foster object interfaces that are more consistent and easier to learn, and it allows class-based objects to be processed by code written to expect a built-in type’s interface.
            --
            lpy3-p857
            }}}
        the main ideas behind overloading operators: (!) @
            {{{
            • Methods named with double underscores (__X__) are special hooks.
                = In Python classes we implement operator overloading by providing specially named methods to intercept operations.
            . if an instance object inherits an __add__ method, that method is called whenever the object appears in a + expression.
            --
            lpy3-p857
            }}}
        • Classes may override most built-in type operations.
            {{{
            This includes expressions, but also basic operations like printing and object creation.
            --
            lpy3-p857
            }}}
        defaults for operator overloading methods, (!)
            {{{
            • New-style classes have some defaults, but not for common operations. In Python 3.X, and so-called “new style” classes in 2.X that we’ll define later, a root class named object does provide defaults for some __X__ methods, but not for many, and not for most commonly used operations.
            --
            lpy3-p857,857
            }}}
        Operator overloading is an optional feature; it’s used primarily by
            {{{
            people developing tools for other Python programmers, not by application developers.
            --
            lpy3-p858
            }}}
        op.overloading: = 'Unless a class ____, it should usually stick to simpler named methods.
            {{{
                = 'Unless a class needs to mimic built-in type interfaces, it should usually stick to simpler named methods.
            Why would an employee database application support expressions like * and +, for example?  Named methods like giveRaise and promote would usually make more sense.
            --
            lpy3-p858
            }}}
        Still, there is one operator overloading method you are likely to see in almost every realistic Python class:
            {{{
            the __init__ method, which is known as the constructor method and is used to initialize objects’ state.
                You should pay special attention to this method, because __init__, along with the self argument, turns out to be a key requirement to reading and understanding most OOP code in Python.
            --
            lpy3-p858
            }}}
        ex.class 3: subclass class 2 + use init, add, str(=for printing(!)) ((****))!! (SSSs) @
            {{{
            • __add__ is run when a ThirdClass instance appears in a + expression.
            • __str__ is run when an object is printed (technically, when it’s converted to its print string by the str built-in function or its Python internals equivalent).
              .
            # Inherit from SecondClass
        >>> class ThirdClass(SecondClass):
                # On "ThirdClass(value)"
                def __init__(self, value):
                    self.data = value
                # On "self + other"
                def __add__(self, other):
                    return ThirdClass(self.data + other)
                # On "print(self)", "str()"
                def __str__(self):
                    return '[ThirdClass: %s]' % self.data
                        # --
                # In-place change: named
                def mul(self, other):
                    self.data *= other
              .
            # __init__ called
        >>> a = ThirdClass('abc')
            # Inherited method called
        >>> a.display()
        Current value = "abc"
            # __str__: returns display string
        >>> print(a)
        [ThirdClass: abc]
              .
            # __add__: makes a new instance
        >>> b = a + 'xyz'
            # b has all ThirdClass methods
        >>> b.display()
        Current value = "abcxyz"
            # __str__: returns display string
        >>> print(b)
        [ThirdClass: abcxyz]
              .
            # mul: changes instance in place
        >>> a.mul(3)
        >>> print(a)
        [ThirdClass: abcabcabc]
            --
            'Further, ThirdClass objects can now show up in + expressions and print calls. **
               [+ MUCH MORE EXPLANATIONS ON THE TECHNICAL DETAILS OF THE DIFFERENT METHODS AND WHAT IS PASSED TO SELF ETC (**(!))]
               + 'With __str__ (or its more broadly relevant twin __repr__, which we’ll meet and use in the next chapter), we can use a normal print to display objects of this class, instead of calling the special display method.
            --
            lpy3-p858,p859
            }}}
        Figure 27-3. In operator overloading, expression operators and other built-in operations performed on class instances are (= how they help operate on the class instances)
            {{{
            are mapped back to specially named methods in the class. These special methods are optional and may be inherited as usual.
              (( 'Here, a + expression triggers the __add__ method.
            --
            lpy3-p859
            }}}
            ----

            ----
        are (s)pecially named methods such as __init__, __add__, and __str__  inherited by subclasses? (**)
            {{{
            Yes =
                just like any other names assigned in a class.
            = 'If they’re not coded in a class, Python looks for such names in all its superclasses, as usual. (**)
            --
            lpy3-p860
            }}}
        are (o)perator overloading method names   built-in or reserved words? (**)
            {{{
            No =
               they are just attributes that Python looks for when objects appear in various contexts.
            --
            lpy3-p860
            }}}
        ((Returning results, or not
            {{{
            Some operator overloading methods like __str__ require results, but others are more flexible. For example, notice how the __add__ method ....
            .
        + 'This is a common convention,
                = 'notice how the __add__ method makes and returns a new instance object of its class, by calling ThirdClass with the result value - which in turn triggers __init__ to initialize the result. (S(sss)
                    This is a common convention, and explains why b in the listing has a display method; it’s a ThirdClass object too, because that’s what + returns for this class’s objects.
                    This essentially propagates the type. (Ssssss (!!!!
                ((+ 'By contrast, mul changes the current instance object in place, by reassigning the self attribute.
                 ((+ more design tips and relation to mul(t)
            --
            lpy3-p860
            }}}
        operator overloading is really just an ____ mechanism (!)
            {{{
            expression-to-method dispatch mechanism,
            --
            lpy3-p860
            }}}
        Why Use Operator Overloading? (!!)
            {{{
            Your choice simply depends on how much you want your object to look and feel like built-in types.
              'Frankly, many operator overloading methods tend to be used only when you are implementing objects that are mathematical in nature; a vector or matrix class may ......
            --
            lpy3-p860
            }}}
        ['On the other hand, you might decide to use operator overloading if you need to pass a user-defined object to a function that was coded to expect
            {{{
            the operators available on a built-in type like a list or a dictionary. Implementing the same operator set in your class will ensure that your objects support the same expected object interface and so are compatible with the function.
            --
            lpy3-p860
            }}}
            ----

            ----
        In fact, even though instance attributes are not declared in Python, you can usually find out which attributes an instance will have by (@)
            {{{
            inspecting its class’s __init__ method.
            --
            lpy3-p861
            }}}
        a simple empty class in Py +w. attached val.s (= like a C struct or Pascal record) (@)
            {{{
            = 'The following statement makes a class with no attributes attached, an empty namespace object:
            >>> class rec: pass  # Empty namespace object
               .
            # Just objects with attributes
        >>> rec.name = 'Bob'
        >>> rec.age = 40
              .
            When used this way, a class is roughly similar to a “struct” in C, or a “record” in Pascal. It’s basically an object with field names attached to it (as we’ll see ahead, doing similar with dictionary keys requires extra characters):
              .
            # Like a C struct or a record
        >>> print(rec.name)
        Bob
            --
            lpy3-p861
            }}}
        + if we create instances from an empty class (where we've added values) (!)?????
            {{{
              # Instances inherit class names
            >>> x = rec()
            >>> y = rec()
              .
              # name is stored on the class only
            >>> x.name, y.name
            ('Bob', 'Bob')
            --
            lpy3-p862
            }}}
        the attributes of a namespace object are usually implemented as ____   and class inheritance trees are (generally speaking) just ____  **(!) (@)
            {{{
            dictionaries
                and class inheritance trees are (generally speaking) just dictionaries with links to other dictionaries.
            --
            lpy3-p862
            }}}
        ____ is the namespace dictionary for most class-based objects. @(@)
            {{{
            the __dict__ attribute
              (or may instead use __slots__
               .
            [= 'Normally, __dict__ literally is an instance’s attribute namespace.
            --
            To illustrate, the following was run in Python 3.3; the order of names and set of __X__ internal names present can vary from release to release, and we filter out builtins with a generator expression as we’ve done before, but the names we assigned are present in all:
              .
            >>> list(rec.__dict__.keys())
            ['age', '__module__', '__qualname__', '__weakref__', 'name', '__dict__', '__doc__']
              .
            >>> list(name for name in rec.__dict__ if not name.startswith('__'))
            ['age', 'name']
            >>> list(x.__dict__.keys())
            ['name']
               # list() not required in Python 2.X
            >>> list(y.__dict__.keys())
            []
            --
            lpy3-p862
            }}}
        [attribute fetch versus indexing for class dictionary lookups] @
            {{{
            = indexing does not trigger inheritance (??)
            --
            lpy3-p863
            }}}
        ((each instance has a link to its class that Python creates for us - it’s called @
            {{{
            __class__, if you want to inspect it:
            --
            lpy3-p863
            }}}
        Classes also have a ____ attribute, which is a tuple of references to their superclass objects - @
            {{{
            __bases__
            --
            lpy3-p863
            }}}
        ['The following, for example, defines a simple function outside of any class that takes one argument: (????)
            {{{
               .
               .
               .
            'If we assign this simple function to an attribute of our class, though, it becomes a method, (?? (= free floating objects later connected into a class)
                # Now it's a class's method!
            >>> rec.method = uppername
            --
            lpy3-p863(,p864)
            }}}
        Records Revisited: Classes Versus Dictionaries (!) (****) @@(@)
            {{{
            ....)  For example, Chapter 8 and Chapter 9 showed how to use dictionaries, tuples, and lists to record properties of entities in our programs, generically called records.
            = 'It turns out that classes can often serve better in this role - they package information like dictionaries, but can also bundle processing logic in the form of methods.
              .
            This code emulates tools like records in other languages. As we just saw, though, there are also multiple ways to do the same with classes. Perhaps the simplest is this - trading keys for attributes:
            >>> class rec: pass
              .
                # Class-based record
            >>> rec.name = 'Bob'
            >>> rec.age = 40.5
            >>> rec.jobs = ['dev', 'mgr']
            >>>
            >>> print(rec.name)
            Bob
            --
                This works, but a new class statement will be required for each distinct record we will need.
            Perhaps more typically, we can instead generate instances of an empty class to represent each distinct entity:
                # Instance-based records
            >>> pers1 = rec()
            >>> pers1.name = 'Bob'
            >>> pers1.jobs = ['dev', 'mgr']
            >>> pers1.age = 40.5
            >>>
            >>> pers2 = rec()
            >>> pers2.name = 'Sue'
            >>> pers2.jobs = ['dev', 'cto']
            >>>
            >>> pers1.name, pers2.name
            ('Bob', 'Sue')
                In fact, instances of the same class don’t even have to have the same set of attribute names; in this example, one has a unique age name.
              --
            Finally, we might instead code a more full-blown class to implement the record and its processing - something that data-oriented dictionaries do not directly support:
              .
            >>> class Person:
                    # class = data + logic
                    def __init__(self, name, jobs, age=None):
                        self.name = name
                        self.jobs = jobs
                        self.age = age
                    def info(self):
                        return (self.name, self.jobs)
                  .
                # Construction calls
            >>> rec1 = Person('Bob', ['dev', 'mgr'], 40.5)
            >>> rec2 = Person('Sue', ['dev', 'cto'])
            >>>
                # Attributes + methods
            >>> rec1.jobs, rec2.info()
            (['dev', 'mgr'], ('Sue', ['dev', 'cto']))
              .
            We could further extend this code by adding logic to compute salaries, parse names, and so on.  Ultimately, we might link the class into a larger hierarchy to inherit and customize an existing set of methods via the automatic attribute search of classes, or perhaps even store instances of the class in a file with Python object pickling to make them persistent.
            --
            lpy3-p864--p866
            }}}
        why  the self argument must always be explicit in Python methods @
            {{{
            - because methods can be created as simple functions independent of a class, they need to make the implied instance argument explicit.
              --
            They can be called as either functions or methods, and Python can neither guess nor assume that a simple function might eventually become a class’s method.
            The main reason for the explicit self argument, though, is to make the meanings of names more obvious: names not referenced through self are simple variables mapped to scopes, while names referenced through self with attribute notation are obviously instance attributes.
            --
            lpy3-p864
            }}}
            ----

        ((+ Check the quiz and questions after having studied the chapter itself again (!!)))

            ----
        [how are classes and instances made and created?] @
            {{{
            Classes are made by running class statements; instances are created by calling a class as though it were a function.
            --
            lpy3-p867
            }}}
        5. What does self mean in a Python class?
            {{{
            Python automatically fills it in with the instance object that is the implied subject of the method call. This argument need not be called self (though this is a very strong convention);
            its position is what is significant. (Ex C++ or Java programmers might prefer to call it this because (...)
            --
            lpy3-p867
            }}}
        Operator overloading is coded in a Python class with *
            {{{
            specially named methods; they all begin and end with double underscores to make them unique.
            Python just runs them automatically when an instance appears in the corresponding operation.
            --
            lpy3-p868
            }}}
        'Mimicking built-in type interfaces enables you to pass in class instances that also have (??) (!)  sssss
            {{{
            state information (i.e., attributes that remember data between operation calls).
            --
            lpy3-p868
            }}}
        The __init__ constructor method is the most commonly used; almost every class uses this method to ((****(!!)))
            {{{
            set initial values for instance attributes and perform other startup tasks. **
            --
            lpy3-p868
            }}}
        9. What are two key concepts required to understand Python OOP code? **(!) (@)
            {{{
            The special self argument in method functions and the __init__ constructor method are the two cornerstones of OOP code in Python;
            if you get these, you should be able to read the text of most OOP Python code - apart from these, it’s largely just packages of functions.
                The inheritance search matters too, of course, but self represents the automatic object argument, and __init__ is widespread.
            --
            As we’ve seen, Python tells a method which instance to process by automatically passing it in to the first argument, usually called self.  Specifically:
            • In the first call, bob.lastName(), bob is the implied subject passed to self.
            • In the second call, sue.lastName(), sue goes to self instead.
                + 'Trace through these calls to see how the instance winds up in self - it’s a key concept.
            --
            lpy3-p868;877
            }}}
            ----


        Chapter 28 - A More Realistic Example

            ----
        In this chapter, we’re going to build a set of classes that do something more concrete - recording and processing information about people. **(!)
            {{{
            As you’ll see, what we call instances and classes in Python programming can often serve the same roles as records and programs in more traditional terms.
                • Person - a class that creates and processes information about people
                • Manager - a customization of Person that modifies inherited behavior
            ((+ 'When we’re done, I’ll show you a nice example use case for classes - we’ll store our instances in a shelve object-oriented database, to make them permanent.
            --
            lpy3-p869
            }}}
        THE IMPLEMENTATION (*****)!!  [SSSSSSSSSSS] @
            {{{
            ((we’ll call our new module file person.py and our class within it Person,
            - constructors (=making the init section
              - testing(!!)
              ...
              ...
            --
            Step 2: Adding Behavior Methods
              p874--p875
            --
            Step 3: Operator Overloading
              p878--
            = 'As it stands, though, testing is still a bit less convenient than it needs to be - to trace our objects, we have to manually fetch and print individual attributes (e.g., bob.name, sue.pay).
             (= printing useful information about the object in better format via overloading)
            --
            Step 4: Customizing Behavior by Subclassing
              p880--
            --
            Step 5: Customizing Constructors, Too (???)
              p886--
            --
            lpy3-p870--
            }}}
        'Notice that the argument names appear twice here.
            {{{
            The job argument, for example, is a local variable in the scope of the __init__ function, but self.job is an attribute of the instance that’s the implied subject of the method call.
              = 'They are two different variables, which happen to have the same name.
            By assigning the job local to the self.job attribute with self.job=job, we save the passed-in job on the instance for later use.
                (('As usual in Python, where a name is assigned, or what object it is assigned to, determines what it means. (!)
            --
            lpy3-p870,p871
            }}}
        (__init__ is a normal function  (= @
            {{{
            = can be set with defaults etc
            'We can, for example, provide defaults for some of its arguments, so they need not be provided in cases where their values aren’t available or useful.
            (( 'To demonstrate, let’s make the job argument optional -
            --
            lpy3-p871
            }}}
        assigning values to attributes of self  (=does what??) (**(**)) @(@)
            {{{
            attaches them to the new instance. (??) (??) (!)
            --
            lpy3-p871
            }}}
        programming in Python is really a matter of incremental prototyping - (!) @@
            {{{
            - you write some code, test it, write more code, test again, and so on.
            --
            lpy3-p871
            }}}
        interactive testing has its limits (!)  (+ Common solution(*)) @(@)
            {{{
            - it gets tedious to have to reimport modules and retype test cases each time you start a new testing session.
                = More commonly, Python programmers use the interactive prompt for simple one-off tests but do more substantial testing by writing code at the bottom of the file that contains the objects to be tested, like this:
            --
              .
              .
            'You can also type this file’s test code at Python’s interactive prompt (assuming you import the Person class there first), but coding canned tests inside the module file like this makes it much easier to rerun them in the future.
            --
            lpy3-p871,p872
            }}}
            ----

            ----
        ([tuning the printing w. __repr__ and __str__ (!)])
            {{{
            --
            lpy3-p874
            }}}
        = 'what if you’ve hardcoded the last-name-extraction formula at many different places in your program? ((*****(!))) @
            {{{
            = What we really want to do here is employ a software design concept known as encapsulation - wrapping up operation logic behind interfaces, such that each operation is coded only once in our program.
            In Python terms, we want to code operations on objects in a class’s methods, instead of littering them throughout our program.
          .
        class Person:
            def __init__(self, name, job=None, pay=0):
                self.name = name
                self.job = job
                self.pay = pay
            # Behavior methods
            def lastName(self):
                # self is implied subject
                return self.name.split()[-1]
            def giveRaise(self, percent):
                # Must change here only
                self.pay = int(self.pay * (1 + percent))
            .
        if __name__ == '__main__':
            bob = Person('Bob Smith')
            sue = Person('Sue Jones', job='dev', pay=100000)
            print(bob.name, bob.pay)
            print(sue.name, sue.pay)
                # Use the new methods
            print(bob.lastName(), sue.lastName())
                # instead of hardcoding
            sue.giveRaise(.10)
            print(sue.pay)
            --
            lpy3-p876
            }}}
        (+ validating via decorators)
            {{{
             @decorator--syntax
             (= see later)
            --
            lpy3-p877|p878
            }}}
        __repr__ vs __str__ (= for print overloading)  ((!)) (@)
            {{{
            __repr__  as a reliable fallback (=??)
                (+ clients can provide alternative representation w. __str__)
              .
            # Added method
            def __repr__(self):
                # String to print
                return '[Person: %s, %s]' % (self.name, self.pay)
                  .
              (+ adding better default prints to the testing section)
            --
            'Sometimes classes provide both a __str__ for user-friendly displays and a __repr__ with extra details for developers to view.
            + 'Since __repr__ applies to more display cases, including nested appearances, and because we’re not interested in displaying two different formats, the all-inclusive __repr__ is sufficient for our class.
            --
            lpy3-p878--p880
            }}}
        [customizing by subclasses for the database application] ((*******(!!!))) @@(@)
            {{{
            For the purpose of this tutorial, we’ll define a subclass of Person called Manager that replaces the inherited giveRaise method with a more specialized version.
              .
            # Inherit Person attrs
        class Manager(Person):
            # Redefine to customize
            def giveRaise(self, percent, bonus=.10):
             --  (+cutpaste vs customize (!))
        class Manager(Person):
            def giveRaise(self, percent, bonus=.10):
                # Bad: cut and paste
                self.pay = int(self.pay * (1 + percent + bonus))
              .
              .
            The good way to do that in Python is by calling to the original version directly, with augmented arguments, like this:
              .
        class Manager(Person):
            def giveRaise(self, percent, bonus=.10):
                # Good: augment original
                Person.giveRaise(self, percent + bonus)
            --
            'This code leverages the fact that a class’s method can always be called either through an instance (the usual way, where Python sends the instance to the self argument automatically) or through the class (the less common scheme, where you must pass the instance manually).
              .
            instance.method(args...)
              .
            is automatically translated by Python into this equivalent form:
              .
            class.method(instance, args...)
                  .
            ((=  - you must remember to pass along the instance manually if you call through the class directly.
              .
              .
            The method always needs a subject instance one way or another, and Python provides it automatically only for calls made through an instance.
            ((For calls through the class name, you need to send an instance to self yourself; for code inside a method like giveRaise, self already is the subject of the call, and hence the instance to pass along. (??)
              .
            ((!!))  Calling through the class directly effectively subverts inheritance and kicks the call higher up the class tree to run a specific version. In our case, we can use this technique to invoke the default giveRaise in Person, even though it’s been redefined at the Manager level.
                In some sense, we must call through Person this way, because a self.giveRaise() inside Manager’s giveRaise code would loop - since self already is a Manager, self.giveRaise() would resolve again to Manager.giveRaise, and so on and so forth recursively until available memory is exhausted.
            (--
            [[(!) This “good” version may seem like a small difference in code, but it can make a huge difference for future code maintenance - because the giveRaise logic lives in just one place now (Person’s method), we have only one version to change in the future as needs evolve.
             = '# Call Person's version'
            --
            lpy3-p880--p883
            }}}
        Manager objects get this, lastName, and the __init__ constructor method’s code (= fr. where?) (**!)
            {{{
            “for free” from Person, by inheritance.
            --
            lpy3-p883
            }}}
        What About super? (*****) [=customizing|extending a superclass] @
            {{{
            To extend inherited methods, the examples in this chapter simply call the original through the superclass name: Person.giveRaise(...).
            This is the traditional and simplest scheme in Python, and the one used in most of this book.
               [= Python also has a super built-in function that allows calling back to a superclass’s methods more generically - but it (= can be cumbersome to use, differ between versions etc)
            --
            lpy3-p883
            }}}
        ((valid use case(!) for 'super')) (@)
            {{{
            cooperative same-named method dispatch in multiple inheritance trees((!!)) - but (.....
            --
            lpy3-p883
            }}}
            ----

            ----
        'Polymorphism in Action' ((!!)|??(??????)) @
            {{{
              .
              .
              .
            'In the added code, object is either a Person or a Manager, and Python runs the appropriate giveRaise automatically - our original version in Person for bob and sue, and our customized version in Manager for tom.
              .
            (=) - what giveRaise does depends on what you do it to.
            [aha(?):  = 'Passing any of our three objects to a function that calls a giveRaise method, for example, would have the same effect: the appropriate version would be run automatically, depending on which type of object was passed.
              (eg. managers automatically get the big raise(!(?))
            On the other hand, printing runs the same __repr__ for all three objects, because it’s coded just once in Person.
            --
            lpy3-p884--p885
            }}}
        ("even more than customization": =Extending ** @
            {{{
            For example, although we’re focused on customization here, we can also add unique methods to Manager that are not present in Person, if Managers require something completely different (Python namesake reference intended).
            = 'Here, giveRaise redefines a superclass’s method to customize it, but someThingElse defines something new to extend:
            tom.someThingElse() # Extension here
            --
            lpy3-p885,p886
            }}}
        Customizing constructors (too  **!) @
            {{{
            - it seems pointless to have to provide a mgr job name for Manager objects when we create them: this is already implied by the class itself.
            It would be better if we could somehow fill in this value automatically when a Manager is made.
              .
            And as in giveRaise customization, we also want to run the original __init__ in Person by calling through the class name, so it still initializes our objects’ state information attributes. ((****(!!)))
            .
        class Manager(Person):
            # Redefine constructor
            def __init__(self, name, pay):
                # Run original with 'mgr'
                Person.__init__(self, name, 'mgr', pay)
              ...
              ...
              ...
              ...
            # Job name not needed:
            tom = Manager('Tom Jones', 50000)
            # Implied/set by class
            tom.giveRaise(.10)
              .
              .
            Again, we’re using the same technique to augment the __init__ constructor here that we used for giveRaise earlier - running the superclass version by calling through the class name directly and passing the self instance along explicitly.
            Although the constructor has a strange name, the effect is identical. (??)
            Because we need Person’s construction logic to run too (to initialize instance attributes), we really have to call it this way; otherwise, instances would not have any attributes attached.
            --
            lpy3-p886,p887
            }}}
        ('Calling superclass constructors from redefinitions this way turns out to be a very common coding pattern in Python. ** [^^ SSSSSSSsss] @(@)
            {{{
            By itself, Python uses inheritance to look for and call only one __init__ method at construction time - the lowest one in the class tree.
            If you need higher __init__ methods to be run at construction time (and you usually do), you must call them manually, and usually through the superclass’s name.
            The upside to this is that you can be explicit about which argument to pass up to the superclass’s constructor and can choose to not call it at all: not calling the superclass constructor allows you to replace its logic altogether, rather than augmenting it. (!!)
            --
            lpy3-p887
            }}}
        , and despite their relatively small sizes, our classes capture nearly all the important concepts in Python’s OOP machinery: (!!) (@)
            {{{
            • Instance creation - filling out instance attributes
            • Behavior methods - encapsulating logic in a class’s methods
            • Operator overloading - providing behavior for built-in operations like printing
            • Customizing behavior - redefining methods in subclasses to specialize them
            • Customizing constructors - adding initialization logic to superclass steps
              .
            + 'For example, we wrapped up logic in methods and called back to superclass methods from extensions to avoid having multiple copies of the same code.
            --
            lpy3-p888
            }}}
        ++ "Beyond the basics":  Other Ways to Combine Classes
            {{{
            Having said that, I should also tell you that although the basic mechanics of OOP are simple in Python, some of the art in larger programs lies in the way that classes are put together.
                = We’re focusing on inheritance in this tutorial because that’s the mechanism the Python language provides, but programmers sometimes combine classes in other ways, too.
            --
            lpy3-p888
            }}}
        'For example, a common coding pattern involves nesting objects inside each other to build up composites. (!!) (@)
            {{{
            'As a quick example, though, we could use this composition idea to code our Manager extension by embedding a Person, instead of inheriting from it.
            The following alternative, coded in file person-composite.py, does so by using the __getattr__ operator overloading method to intercept undefined attribute fetches and delegate them to the embedded object with the getattr built-in.
                = 'In effect, Manager becomes a controller layer that passes calls down to the embedded object, rather than up to superclass methods:
            .
        class Manager:
            def __init__(self, name, pay):
                # Embed a Person object
                self.person = Person(name, 'mgr', pay)
            def giveRaise(self, percent, bonus=.10):
                # Intercept and delegate
                self.person.giveRaise(percent + bonus)
            def __getattr__(self, attr):
                # Delegate all other attrs
                return getattr(self.person, attr)
            def __repr__(self):
# Must overload again (in 3.X)
                return str(self.person)
                  .
        if __name__ == '__main__':
            ...same...
              .
              .
              .
            = 'delegation' - a composite-based structure that manages a wrapped object and propagates method calls to it.
              [Note: (= Overkill to use this technique in this specific case(!))
            --
            lpy3-p888,p889
            }}}
        'Still, object embedding, and design patterns based upon it, can be a very good fit when embedded objects require more limited interaction with the container than direct customization implies. @
            {{{
            A controller layer, or proxy, like this alternative Manager , for example, might come in handy if we want to adapt a class to an expected interface it does not support, or trace or validate calls to another object’s methods (indeed, we will use a nearly identical coding pattern when we study class decorators later in the book).
            Moreover, a hypothetical Department class like the following could aggregate other objects in order to treat them as a set.
              .
             ( = # 'Aggregate embedded objects into a composite'
            --
            As another example, a GUI might similarly use inheritance to customize the behavior or appearance of labels and buttons, but also composition to build up larger packages of embedded widgets, such as input forms, calculators, and text editors.
            --
            lpy3-p889,p890
            }}}
            ----

            ----
        1
            {{{
            
            --
            lpy3-p891
            }}}




          -- p891
            Catching Built-in Attributes in 3.X
                will not be able to intercept and delegate operator overloading method attributes like __repr__ without redefining them itself.  (=for delegating classes)  #classic vs new style classes
                - delegation-based new-style classes can generally redefine operator overloading methods to delegate them to wrapped objects, either manually or via tools or superclasses.
          -- p892
            Step 6: Using Introspection Tools
                would be more accurate to display an object with the most specific (that is, lowest) class possible:  automatically updating included attrib.s displayed w. __repr__  [__class__, __name__, __bases__
            __dict__  (for every attrib. attached to a namespace obj. (**)
          -- p893
            Notice how we load Person at the interactive prompt with a from statement here—class
                names live in and are imported from modules, exactly like function names and other variables:  ((or __slots__ in newer style classes))
          -- p894
            A Generic Display Tool  (classtools.py)
          -- p895
            we don’t see attributes inherited by the instance from classes above it in the tree
                If you ever do wish to include inherited attributes too,  (+using dir for simpler solut.)
          -- p896
            filter out most of the __X__ names
                list(name for name in dir(bob) if not name.startswith('__'))
            Name Considerations in Tool Classes
                eg. gatherAttrs
                If we really meant to provide a __repr__ only, though, this is less than ideal.
          -- p897
            To minimize the chances of name collisions like this, Python programmers often prefix methods not meant for external use with a single underscore:  @
                _gatherAttrs
                __gatherAttrs  =
                    Python automatically expands such names to include the enclosing class’s name, which makes them truly unique when looked up by the inheritance search. This is a feature usually called pseudoprivate class attributes,
          -- p898
            adding blank lines betw. methods for readability
          -- p899
            Step 7 (Final): Storing Objects in a Database
                =object persistence
            pickle, dbm,  shelve  @
          -- p900
            'by storing an object's pickle string on a file
            (USING THE 3 TOGETHER(**))
            shelve provides a simple database for storing and fetching native Python objects by keys,
            Storing Objects on a Shelve Database
            LET’S WRITE A NEW SCRIPT THAT THROWS OBJECTS OF OUR CLASSES ONTO A SHELVE.
                open a new file we’ll call makedb.py.
          -- p901
                (***) We simply import the shelve module, open a new shelve with an external filename, assign the objects to keys in the shelve, and close the shelve when we’re done because we’ve made changes:
            the key can be any string, including one we might create to be unique using tools such as process IDs and timestamps (available in the os and time standard library modules).  @
          -- p902
            glob.glob('person*')  @
            Here, the interactive prompt effectively becomes a database client:  **(!)
          -- p903
            (??)This works because when Python pickles a class instance, it records its self instance attributes, along with the name of the class it was created from and the module where the class lives.
            Updating Objects on a Shelve  (??|!)
          -- p905
            It stores a somewhat larger composite object in a flat file with pickle instead of shelve ,
            As is, we can only process our database with the interactive prompt’s commandbased interface, and scripts.
                tkinter (Tkinter in 2.X) standard library support, or third-party toolkits such as WxPython and PyQt.
            Websites
                or   web frameworks    (+can use shelve, pickle etc)
          -- p906
            Web services
                SOAP / XML-RPC
            Databases
                ZODB, MySQL..... 
                builtin support for SQLite  (+others can be installed for the web)
                MongoDB =JSON  (****)  @
            ORM  @
                Object-relational mappers  @
                SQLObject and SQLAlchemy can automatically map relational tables and rows to and from Python classes and instances, such that we can process the stored data using normal Python class syntax.
          -- p907
          -- p908
            'The class names listed in parentheses in a class statement’s header line provide the links to higher superclasses.
          -- p909
            Composition is well suited to scenarios where multiple objects are aggregated into a whole and directed by a controller layer class.  Inheritance passes calls up to reuse, and composition passes down to delegate.
            A method named sendmail , for example, might use Python’s standard library smptlib module to send an email to one of the contacts automatically when called (see Python’s manuals or appli- cation-level books for more details on such tools).  ******  @
          -- p910


          -- p911   (the Class Mechanics)  [Syntax, Details etc  [!!!!!]
          -- p912
          -- p913
            'but unlike in C++, Python’s class is not a declaration.
            General Form of the Python Class statement [**]
            'Because of this, classes resemble both modules and functions:
            Because class is a compound statement, any sort of statement can be nested inside its body— print , assignments, if , def , and so on. +
                All the statements inside the class state- ment run when the class statement itself runs (not when the class is later called to make an instance).
            (1) =a bit similar to c++ static data members
                (eg. a counter common to all class instances (**|!!))
            [['that stores the same name in two places
          -- p914
            When we make instances of this class, the name data is attached to those instances by the assignment to self.data in the constructor method:
            Although inheritance searches look up names for us, we can always get to an attribute anywhere in a tree by accessing the desired object directly.
                The next section describes one of the most common roles for such coding patterns, and explains more about the way we deployed it in the prior chapter.
            Method calls made through an instance, like this:  instance.method(args...)
                are automatically translated to class method function calls of this form:  class.method(instance, args...)
          -- p915
            the presence of this name makes it obvious that you are using instance attribute names in your script, not names in the local or global scope.
          -- p916
            If subclass constructors need to guarantee that superclass construction-time logic runs, too, they generally must call the superclass’s __init__ method explicitly through the class:
                This is one of the few contexts in which your code is likely to call an operator over- loading method directly.  (+see the prev. Manager class)
          -- p917
            2.2 static methods  (??(!!))
            (class method)
            [[Attribute Tree Construction]]
          -- p918
          -- p919
            In fact, you can build entire systems as hierarchies of classes, which you extend by adding new external subclasses rather than changing existing logic in place.
                The idea of redefining inherited names leads to a variety of specialization techniques.  For instance, subclasses may replace inherited attributes completely, provide attributes that a superclass expects to find, and extend superclass methods by calling back to the superclass from an overridden method.
            The Sub class replaces Super ’s method function with its own specialized version, but within the replacement, Sub calls back to the version exported by Super to carry out the default behavior.
                In other words, Sub.method just extends Super.method ’s behavior, rather than replacing it completely:  @
                [This extension coding pattern is also commonly used with constructors;]
            Class Interface Techniques [[***(******)]]  (--p920)  @@
                'Extension is only one way to interface with a superclass.
          -- p920
            for loop:  Because classes are objects, you can store them in a tuple and create instances generically with no extra syntax (more on this idea later).  #+'Provider may be most important to understand(!)  @
          -- p921
            Abstract Superclasses(([****]))  @
                This “filling in the blanks” sort of coding structure is typical of OOP frameworks. In a more realistic context, the method filled in this way might handle an event in a GUI, provide data to be rendered as part of a web page, process a tag’s text in an XML file, and so on—your subclass provides specific actions, but the framework handles the rest of the overall job.  (*******)  @
            Class coders sometimes make such subclass requirements more obvious with assert statements, or by raising the built-in NotImplementedError exception with raise statements.  @
          -- p922
            Abstract superclasses in Python 3.X and 2.6+:
                class Super(metaclass=ABCMeta): @abstractmethod  .....
          -- p923
                (Either way, the effect is the same—we can’t make an instance unless the method is defined lower in the class tree.
                Coded this way, a class with an abstract method cannot be instantiated (that is, we cannot create an instance by calling it) unless all of its abstract methods have been defined in subclasses.   (***   +expected interfaces etc)  @
          -- p924
            'Since scopes and namespaces are essential to understanding Python code, let’s summarize the rules in more detail.
          -- p925
            (('Assignments Classify Names'))  #Zen
                (=all 5(!)
          -- p926
          -- p927
            [Nested Classes: The LEGB Scopes Rule Revisited]
                variation on the factory functions
          -- p928
                (= the l-scope)     (+SSSSSSsss)
          -- p929
            Most importantly, the lookup rules for simple names like X never search enclosing class statements—just def s, modules, and built-ins (it’s the LEGB rule, not CLEGB!).
                In method1 , for example, X is found in a def outside the enclosing class that has the same name in its local scope. To get to names assigned in the class (e.g., methods), we must fetch them as class or instance object attributes, via self.X in this case.
                (+interesting use cases along w. decorators)
                ='In this role, the enclosing function usually both serves as a class factory and provides retained state for later use in the enclosed class or its methods.
          -- p930
            __dict__
                =the module namespace dict
            ''In fact, the inheritance tree is explicitly available in special attributes, which you can inspect. Instances have a __class__ attribute that links to their class, and classes have a __bases__ attribute that is a tuple containing links to higher superclasses (  (**!)
            ''and self is a hook into that namespace:   ****  @
          -- p931
            __doc__ holds the docstrings
            Because attributes are actually dictionary keys inside Python, there are really two ways to fetch and assign their values—by qualification, or by key indexing:
            ((+dir can be used for some handy inspection))
          -- p932
            'A Tree Climber'[!]  @
                The classtree function in this script is recursive—it prints a class’s name using __name__ , then climbs up to the superclasses by calling itself. This allows the function to traverse arbitrarily shaped class trees; the recursion climbs to the top, and stops at
          -- p933
                (+import for using as utility (!!(**)))
          -- p934
            [, the following file, docstr.py, provides a quick but comprehensive example that summarizes the places where docstrings can show up in your code.
          -- p935
            Documentation strings are available at runtime, but they are less flexible syntactically than # comments, which can appear anywhere in a program.
          -- p936
             [[<Classes Versus Modules>]]
          -- p937
            abstract superclasses
                = often used to by OOP frameworks
            Superclass constructors are usually called through the class name, passing in the self instance manually:  @
                Superclass.__init__(self, ...)
            To augment instead of completely replacing an inherited method,  @
                redefine it in a subclass, but call back to the superclass’s version of the method manually from the new version of the method in the subclass. That is, pass the self instance to the superclass’s version of the method manually: Superclass.method(self, ...) .
            

          Operator Overloading (*****)
          -- p939
            “operator overloading” simply means  **(!)
                intercepting built-in operations in a class’s methods—Python automatically invokes your methods when instances of the class appear in built-in operations, and your method’s return value becomes the result of the corresponding operation.  @
          -- p940
            __sub__
             __new__
             ('sometimes also used to customize creation of instances of mutable types.  @
          -- p941
            TABLE 30-1. COMMON OPERATOR OVERLOADING METHODS  [[**(**)]]  (+SHORT USE-EXAMPLES (****))  @
            init, del,
            add, or
            repr, str
            call (=function calls)
            getattr, setattr, getattribute,
            getitem (indexing, slicing etc), setitem, delitem
            len
            bool
            lt, gt, le, ge, eq, ne
            radd, iadd,   iter, next
            contains  (=in)
            index
            enter, exit,
            get, set, delete
             new
          -- p942
             (the automation may actually be slower (=since it calls a function))
             X[i], slice expressions
                __getitem__  @
            --
          -- p945
            2.X vs 3.X
          -- p946
            Here’s a hook that isn’t always obvious to beginners, but turns out to be surprisingly useful.
                __getitem__  (=for loop   iteration (**))
          -- p947
                + __iter__ and __next__  (=general iteration rather than indexing (!!))
            For example, the following file uses a class to define a user-defined iterable that generates squares on demand, instead of all at once (
            In more complex scenarios, the iterator object may be defined as a separate class and object with its own state information to support multiple active iterations over the same data (we’ll see an example of this in a moment).
            Single versus multiple scans
            -- p948
            -- p949
          -- p950
          -- p951
            Multiple Iterators on One Object
                'Earlier, I mentioned that the iterator object (with a __next__ ) produced by an iterable may be defined as a separate class with its own state information to more directly support multiple active iterations over the same data.
                To achieve the multiple-iterator effect, __iter__ simply needs to define a new stateful object for the iterator, instead of returning self for each iterator request.  @
          -- p952
            The following SkipObject class, for example, defines an iterable object that skips every other item on iterations.
                Because its iterator object is created anew from a supplemental class for each iteration, it supports multiple active loops directly (
                 (+3.X (vs 2.X))
          -- p953
            [(Classes versus slices)]
            Because user-defined iterables coded with classes can do anything a class can do, they are much more general than this example may imply. Though such generality is not required in all applications, user-defined iterables are a powerful tool—they allow us to make arbitrary objects look and feel like the other sequences and iterables we have met in this book. We could use this technique with a database object, for example, to support iterations over large database fetches, with multiple cursors into the same query result.  (***(*))  @
          -- p954
            __iter__ plus yield  (=implicit iteration (??(*)))
            'As an added bonus, generator functions coded as methods in classes have access to saved state in both instance attributes and local scope variables.'  (!!(*))
          -- p955
          -- p956
            See Chapter 20 for more on yield and generators if this is puzzling, and compare it with the more explicit __next__ version in squares.py earlier.
                Still, the __iter__ / yield technique may prove effective in cases where it applies. It also comes with a substantial advantage—as the next section explains.
                = it also supports multiple active iterators automatically.  @
          -- p957
                To do the same without yield requires a supplemental class that stores iterator state explicitly and manually, using techniques of the preceding section (and grows to 15 lines: 8 more than with yield ):
          -- p958
            Membership: __contains__, __iter__, and __getitem__
                ''classes may provide specific methods, or more general alternatives used as fallback options.  (??)
          -- p959
          -- p960
             'Now that you know about yield in iteration methods, you should be able to tell that the following is equivalent but allows multiple active scans—and judge for yourself whether its more implicit nature is worth the nested-scan support and six lines shaved
          -- p961
            In Python, classes can also intercept basic attribute access (a.k.a. qualification)  @
                __getattr__ and __setattr__
                Because of its behavior, __getattr__ is useful as a hook for responding to attribute requests in a generic fashion. It’s commonly used to delegate calls to embedded (or “wrapped”) objects from a proxy controller object—of the sort introduced in Chap- ter 28’s introduction to delegation. This method can also be used to adapt classes to an interface, or add accessors for data attributes after the fact—logic in a method that validates or computes an attribute after it’s already being used with simple dot notation.  [[****]]
          -- p962
            ((Attribute Assignment and Deletion))
                (Like __getattr__ , this allows your class to catch attribute changes, and validate or transform as desired.
          -- p963
          -- p964
            The property built-in function allows us to associate methods with fetch and set operations on a specific class attribute.  @
            Emulating Privacy for Instance Attributes: Part 1 ((#####))
                As another use case for such tools,
          -- p965
            ((Still, catching attribute references and assignments is generally a useful technique; it supports delegation, a design technique that allows controller objects to wrap up em- bedded objects, add new behaviors, and route other operations back to the wrapped objects.
          -- p966
          -- p967
            (('In effect, __str__ simply overrides __repr__ for more user-friendly display contexts:  (???)
          -- p968
           -- p969
            __radd__ and __iadd__
                Our next group of overloading methods extends the functionality of binary operator methods such as __add__ and __sub__
                To implement more general expressions, and hence support commutative-style opera- tors, code the __radd__ method as well. Python calls __radd__ only when the object on the right side of the + is your class instance, but the object on the left is not an instance of your class.
          -- p970
          -- p971
            Propagating class type
          -- p972
            To also implement += in-place augmented addition, code either an __iadd__ or an __add__ .  (***(*))  @
          -- p973
            On to our next overloading method: the __call__ method is called when your instance
            is called.
                This allows instances to conform to a functionbased API:
          -- p974
                The net effect is that classes and instances with a __call__ support the exact same argument syntax and semantics as normal functions and methods.
                Intercepting call expression like this allows class instances to emulate the look and feel of things like functions, but also retain state information for use during calls.
          -- p975
            Function Interfaces and Callback-Based Code  (********)  @
                As an example, the tkinter GUI toolkit (named Tkinter in Python 2.X) allows you to register functions as event handlers (a.k.a. callbacks)—when events occur, tkinter calls the registered objects. If you want an event handler to retain state between events, you can register either a class’s bound method, or an instance that conforms to the expected interface with __call__ .  (*****(!!))
                I’ll have more to say about bound methods in the next chapter, but for now, here’s a hypothetical example of __call__ applied to the GUI domain. The following class de- fines an object that supports a function-call interface, but also has state information that remembers the color a button should change to when it is later pressed:  !@!
          -- p976
                Now, in the context of a GUI, we can register instances of this class as event handlers for buttons, even though the GUI expects to be able to invoke event handlers as simple functions with no arguments:
                When the button is later pressed, the instance object is called as a simple function with no arguments, exactly like in the following calls. Because it retains state as instance attributes, though, it remembers what to do—it becomes a stateful function object:
                In fact, many consider such classes to be the best way to retain state information in the Python language (per generally accepted Pythonic principles, at least). With OOP, the state remembered is made explicit with attribute assignments.
                ((Before we move on, there are two other ways that Python programmers sometimes tie information to a callback function like this. One option is to use default arguments in lambda functions:  @
                The other is to use bound methods of a class— a bit of a preview, but simple enough to introduce here. A bound method object is a kind of object that remembers both the self instance and the referenced function. This object may therefore be called later as a simple function without an instance:
          -- p977
            function decorator  @
                a callable object often used to add a layer of logic on top of an embedded function.
          -- p978
          -- p979
            Boolean Tests: __bool__ and __len__
          -- p980
          -- p981
          -- p982
            ((This works, and it may be useful for implementing some cleanup activities, such as terminating a server connection.  @
                The destructor method works as documented, but it has some well-known caveats and a few outright dark corners that make it somewhat rare to see in Python code:
                Because of these downsides, it’s often better to code termination activities in an ex- plicitly called method (e.g., shutdown ).
          -- p983
          -- p984
            (When should you provide operator overloading?)
                When a class naturally matches, or needs to emulate, a built-in type’s interfaces. For example, collections might imitate sequence or mapping interfaces, and callables might be coded for use with an API that expects a function.  @


            Chapter 31 - (DESIGNING WITH CLASSES) (**!)
          -- p985
            common OOP design patterns in Python, such as inheritance, composition, delegation, and factories.  @!
                We’ll also investigate some designfocused class concepts, such as pseudoprivate attributes, multiple inheritance, and bound methods.
          -- p986
            Encapsulation means packaging in Python—that is, hiding implementation details behind an object’s interface. It does not mean enforced privacy, though that can be implemented with code, as we’ll see in Chapter 39.  @
            ''Polymorphism Means Interfaces, Not Call Signatures  @
                    Hence, there can be only one definition of a method name.
            As described in Chapter 16, you should write your code to expect only an object interface, not a specific data type.
          -- p987
            It’s also generally considered better to use distinct method names for distinct operations, rather than relying on call signatures (no matter what language you code in).  @
            From a designer’s point of view, inheritance is a way to specify set membership: a class defines a set of properties that may be inherited and customized by more specific sets (i.e., subclasses).
            The most general class, Employee , provides common behavior such as bumping up salaries ( giveRaise ) and printing ( __repr__ ). There are two kinds of employees, (....)
                +EEE(eee) =the pizza making robot class (**(!))
          -- p988
          -- p989
            (see Python’s interfaces to  devices such as serial ports, Arduino boards, and the Raspberry Pi if you’re taking this section much too literally!).  @
            From a programmer’s point of view, composition involves embedding other objects in a container object, and activating them to implement container methods.  @
                The composite class generally provides an interface all its own and implements it by directing the embedded objects. (**(*))
          -- p990
                The PizzaShop class is a container and controller; its constructor makes and embeds instances of the employee classes we wrote in the prior section, as well as an Oven class defined here.
            [[Also notice that employees are still involved in an inheritance relationship; composition and inheritance are complementary tools.  @
            As a rule of thumb, classes can represent just about any objects and relationships you can express in a sentence; just replace nouns with classes (e.g., Oven ), and verbs with methods (e.g., bake ), and you’ll have a first cut at a design.  @
            Stream Processors Revisited  [SSSS (EE)
          -- p991
                Rather than using a simple function here, we might code this as a class that uses composition to do its work in order to provide more structure and support inheritance.
                Here, the Uppercase class inherits the stream-processing loop logic (and anything else that may be coded in its superclasses). It needs to define only what is unique about it — the data conversion logic.  (***)  @
          -- p992
            'But, as suggested earlier, we could also pass in arbitrary objects coded as classes that define the required input and output method interfaces.
            If you trace through this example’s control flow, you’ll see that we get both uppercase conversion (by inheritance) and HTML formatting (by composition), even though the core processing logic in the original Processor superclass knows nothing about either step.
                The processing code only cares that writers have a write method and that a method named convert is defined; it doesn’t care what those methods do when they are called.  Such polymorphism and encapsulation of logic is behind much of the power of classes in Python.
            As is, the Processor superclass only provides a file-scanning loop. In more realistic work, we might extend it to support additional programming tools for its subclasses, and, in the process, turn it into a full-blown application framework.
                Even in this simple example, because so much is packaged and inherited with classes, all we had to code was the HTML formatting step; the rest was free.
          -- p993
            Why You Will Care: Classes and Persistence
                I’ve mentioned Python’s pickle and shelve object persistence support a few times in this part of the book because it works especially well with class instances. In fact, these tools are often compelling enough to motivate the use of classes in general—by pickling or shelving a class instance, we get data storage that contains both data and logic combined.  @!
            shelve
                dictionary-like interface
            To bring it back later in another session or program, a single step suffices as well.
                In fact, objects restored this way retain both state and behavior:
          -- p994
            OOP and Delegation: “Wrapper” Proxy Objects
                Beside inheritance and composition, object-oriented programmers often speak of delegation, which usually implies controller objects that embed other objects to which they pass off operation requests. The controllers can take care of administrative activities, such as logging or validating accesses, adding extra steps to interface components, or monitoring active instances.  @
                In a sense, delegation is a special form of composition, with a single embedded object managed by a wrapper (sometimes called a proxy) class that retains most or all of the embedded object’s interface. The notion of proxies sometimes applies to other mechanisms too, such as function calls; in delegation, we’re concerned with proxies for all of an object’s behavior, including method calls and other operations.  @
          -- p995
                (Here, the Wrapper class simply prints a trace message on each attribute access and delegates the attribute request to the embedded wrapped object:
                (The net effect is to augment the entire interface of the wrapped object, with additional code in the Wrapper class.
          -- p996  @
            (... operation method lookup differs in ways that may impact some delegation-based tools.  (=concerning new-style classes)
          -- p997
            name mangling  Pseudoprivate Attributes
                any names that start with two underscores but don’t end with two underscores are automatically expanded to include the name of the enclosing class at their front.  @!
                For example, in a class named Spam , a method named __meth is mangled to _Spam__meth , and an instance attribute reference self.__X is transformed to self._Spam__X .
          -- p998
          -- p999
            Don’t be tempted to clutter your code unnecessarily; only use this feature for names that truly need to be controlled by a single class.  @
          -- p1000
            Methods Are Objects: Bound or Unbound (??????????????) [[SSSSSssss]]  @
                Unbound (class) method objects: no self
                Bound (instance) method objects: self + function pairs  ((=instance + function))
                    Accessing a function attribute of a class by qualifying an instance returns a bound method object. Python automatically packages the instance with the function in the bound method object, so you don’t need to pass an instance to call the method.
                    (Both also require an instance in their first argument when run (i.e., a value for self ). This is why we’ve had to pass in an instance explicitly when calling superclass methods from subclass methods in previous examples (including this chapter’s employees.py); technically, such calls produce unbound method objects along the way.  @
            When calling a bound method object, Python provides an instance for you automatically—the instance used to create the bound method object. This means that bound method objects are usually interchangeable with simple function objects, and makes them especially useful for interfaces originally written for functions (see the sidebar “Why You Will Care: Bound Method Callbacks” on page 953 for a realistic use case in GUIs).
          -- p1001
            Most of the time, you call methods immediately after fetching them with attribute qualification, so you don’t always notice the method objects generated along the way.  But if you start writing code that calls objects generically, you need to be careful to treat unbound methods specially—they normally require an explicit instance object to be passed in.  @
            Like bound methods, static methods can masquerade as basic functions because they do not expect instances when called. Formally speaking, Python supports three kinds of class-level methods — instance, static, and class—and 3.X allows simple functions in classes, too.  (+metaclass methods (=class methods w. less scope)
          -- p1002
            In Python 3.X, the language has dropped the notion of unbound methods. What we describe as an unbound method here is treated as a simple function in 3.X.
                Programs that do explicit type testing might be impacted, though
                Moreover, in 3.X it is OK to call a method without an instance, as long as the method does not expect one and you call it only through the class and never through an instance. (+ That is, Python 3.X will pass along an instance to methods only for through-instance calls. When calling through a class, you must pass an instance manually only if the method expects one: (??))
                 # No instance: works in 3.X, fails in 2.X!
            The following two calls still fail in both 3.X and 2.X, though—the first (calling through an instance) automatically passes an instance to a method that does not expect one, while the second (calling through a class) does not pass an instance to a method that does expect one (error message text here is per 3.3):
          -- p1003
            Because of this change, the staticmethod built-in function and decorator described in the next chapter is not needed in 3.X for methods without a self argument that are called only through the class name, and never through an instance—such methods are run as simple functions, without receiving an instance argument.  @
            As mentioned earlier, bound methods can be processed as generic objects, just like simple functions—they can be passed around a program arbitrarily.  
          -- p1004
            In fact, bound methods are just one of a handful of callable object types in Python. As the following demonstrates, simple functions coded with a def or lambda , instances that inherit a __call__ , and bound instance methods can all be treated and called the same way:
          -- p1005
            Why You Will Care: Bound Method Callbacks
                Because bound methods automatically pair an instance with a class’s method function, you can use them anywhere a simple function is expected. One of the most common places you’ll see this idea put to work is in code that registers methods as event callback handlers in the tkinter GUI interface  @
                def handler():
                    ...use globals or closure scopes for state...
                ...
                widget = Button(text='spam', command=handler)
          -- p1006
            Sometimes, class-based designs require objects to be created in response to conditions that can’t be predicted when a program is written.
                The factory design pattern allows such a deferred approach.
            aClass( ??
          -- p1007
            And that’s the only factory function you’ll ever need to write in Python; it works for any class and any constructor arguments.  @
            In general, though, such a factory might allow code to be insulated from the details of dynamically configured object construction. (=Why Factories?)
          -- p1008
                In such a dynamic world, we might not be able to hardcode the creation of stream interface objects in our scripts, but might instead create them at runtime according to the contents of a configuration file.  (!@
            (The factory function may prove more useful in the presence of unknown argument lists, however, and the general factory coding pattern can improve the code’s flexibility.  @
            Multiple Inheritance: “Mix-in” Classes  (********(!!))
                Many class-based designs call for combining disparate sets of methods. As we’ve seen, in a class statement, more than one superclass can be listed in parentheses in the header line. When you do this, you leverage multiple inheritance—the class and its instances inherit names from all the listed superclasses.
                    classic classes =DFLR (depth-first, left-to-right)
                    new-style classes ='MRO/ARO' (=searches like diamondshape, =in breadth + deep  @
          -- p1009
            diamond patterns appear when multiple classes in a tree share a common superclass; the new-style search order is designed to visit such a shared superclass just once, and after all its subclasses.
                As we’ll see ahead, multiple inheritance also allows classes to function as general packages of mixable attributes.
            When this occurs, the conflict is resolved either automatically by the inheritance search order, or manually in your code:  @
                with superclass.method(self), for instance.
            Perhaps the most common way multiple inheritance is used is to “mix in” general-purpose methods from superclasses.  @
            In a sense, mix-in classes are similar to modules: they provide packages of methods for use in their client subclasses.
          -- p1010
                Unlike simple functions in modules, though, methods in mix-in classes also can participate in inheritance hierarchies, and have access to the self instance for using state information and other methods in their trees.
            For example, as we’ve seen, Python’s default way to print a class instance object isn’t incredibly useful:
                But, rather than coding one of these in each and every class you wish to print, why not code it once in a general-purpose tool class and inherit it in all your classes?  @
                That’s what mix-ins are for. Defining a display method in a mix-in superclass once enables us to reuse it anywhere we want to see a custom display format—even in classes that may already have another superclass.
                ((+ Here, we’re going to revisit these examples’ techniques and expand upon them to code a set of three mix-in classes that serve as generic display tools for listing instance attributes, inherited attributes, and attributes on all objects in a class tree.
                We’ll also use our tools in multiple-inheritance mode and deploy coding techniques that make classes better suited to use as generic tools.
          -- p1011
            """Mix-in class that provides a formatted print() or str() of instances via inheritance of __str__ coded here; displays instance attrs only; self is instance of lowest class; __X names avoid clashing with client's attrs
            (((All the code in this section runs in both Python 2.X and 3.X. A coding note: this code exhibits a classic comprehension pattern, and you could save some program real estate by implementing the __attrnames method here more concisely with a generator expression that is triggered by the string join method, but it’s arguably less clear—expressions that wrap lines like this should generally make you consider simpler coding alternatives:
            so the expression self.__class__.__name__ fetches the name of an instance’s class.  @
          -- p1012
            It displays the instance’s memory address by calling the id built-function, which returns any object’s address (
          -- p1013
            improved test script, testmixin
          -- p1014
          -- p1015
            Again, in a sense, mix-in classes are the class equivalent of modules—
            ((As it is, our ListerInstance mix-in displays instance attributes only (i.e., names at- tached to the instance object itself).))
                The trick is to use the dir built-in function instead of scanning the instance’s __dict__ dictionary;  @
          -- p1016
          -- p1017
            Display format is an open-ended problem (e.g., Python’s standard pprint “pretty printer” module may offer options here too),  @
          -- p1018
          -- p1019
          -- p1020
          -- p1021
          -- p1022
            This version avoids listing the same class object twice by keeping a table of classes visited so far (this is why an object’s id is included—to serve as a key for a previously
          -- p1023
            (( Technically, cycles are not generally possible in class inheritance trees—a class must already have been defined to be named as a superclass, and Python raises an exception as it should if you attempt to create a cycle later by __bases__ changes—but the visited mechanism here avoids relisting a class twice:
          -- p1024
          -- p1025
             sometimes puts your code in the awkward position of beta tester in the current 3.X line!
            [[tkinter example(!!)]]
          -- p1026
            (collector module)  = module to make it easier to import our tools  @
          -- p1027
            Like most software, there’s much more we could do here. The following gives some pointers on extensions you may wish to explore.
          -- p1028
            slots
          -- p1029
            In fact, displaying slots names as attributes of classes instead of instances is technically more accurate—as we’ll see in the next chapter their implementation is at classes, though their space is at instances.
          -- p1030
            “virtual” attributes
             --
            THE QUIZ SUMMARY OF WHAT DIFFERENT PATTERNS ARE (!!!!!!)(**(!!))  @
                (=Concrete examples of (first and foremost) Delegation and Composition


            Chapter 32 - Advanced Class Topics
          -- p1031
          -- p1032
            Extending Built-in Types
                Besides implementing new kinds of objects, classes are sometimes used to extend the functionality of Python’s built-in types to support more exotic data structures.
                (=x2)  For instance, to add queue insert and delete methods to lists, you can code classes that wrap (embed) a list object and export insert and delete methods that process the list specially, like the delegation technique we studied in Chapter 31. As of Python 2.2, you can also use inheritance to specialize built-in types.  @
          -- p1033
             although transparent to your script, a type-conversion call (e.g., list('spam') ) is now really an invocation of a type’s object constructor.
          -- p1034
          -- p1035
             For another type subclassing example, explore the implementation of the bool type in Python 2.3 and later.
             The “New Style” Class Model [[!!!!!]]  @
                Coding the object superclass is optional and implied.
          -- p1036
             The built-in name object is provided to serve as a superclass for new-style classes if no other built-in type is appropriate to use:  @
            Classes not derived from built-ins such as object are considered classic.
            New-style classes stem in part from an attempt to merge the notion of class with that of type around the time of Python 2.2, though they went unnoticed by many until they were escalated to required knowledge in 3.X.  @
            You’ll need to judge the success of that merging for yourself, but as we’ll see, there are still distinctions in the model—now between class and metaclass—and one of its side effects is to make normal classes more powerful but also substantially more complex.
          -- p1037
            For example, some subtle differences, such as diamond pattern inheritance search and the interaction of built-in operations and managed attribute methods such as __getattr__ can cause some existing code to fail if left unchanged.  @
            New-Style Class Changes  [[!!(!)]]
                Attribute fetch for built-ins: instance skipped
            1. As a data point, the book Programming Python, a 1,600-page applications programming follow-up to this book that uses 3.X exclusively, neither uses nor needs to accommodate any of the new-style class tools of this chapter, and still manages to build significant programs for GUIs, websites, systems programming, databases, and text.  *****(**)
          -- p1038
            Classes are now types, and types are now classes. In fact, the two are essentially  @
            synonyms, ....
            (Moreover, classes are instances of the type class, and type may be subclassed to customize class creation with metaclasses coded with class statements.  @
            .
                Automatic object root class: defaults
                Inheritance search order: MRO and diamonds    __mro__
                Inheritance algorithm: Chapter 40
                New advanced tools: code impacts (??)
          -- p1039
             the search for such names begins at classes, not instances.  @
                More formally, if a class defines a __getitem__ index overload method and X is an i stance of this class, then an index expression like X[I] is roughly equivalent to X.__getitem__(I) for classic classes, but type(X).__getitem__(X, I) for new-style classes—
                 a distinction that can matter in the metaclass model
                ((If every + , for example, requires extra steps at the instance, it can degrade program speed
          -- p1040
                ((+reason 2))    (+can negatively impact proxy classes(??)
            [Implications for attribute interception]
          -- p1041
          -- p1042
            The net effect: to code a proxy of an object whose interface may in part be invoked by built-in operations, new-style classes require both __getattr__ for normal names, as well as method redefinitions for all names accessed by built-in operations—whether coded manually, obtained from superclasses, or generated by tools.  @
          -- p1043
            it’s not an impossible task, and may need to be coded just once if done well.
          -- p1044
            ([[Type Model Changes]])
                This is why we can subclass built-in types, as shown earlier in this chapter—a subclass of a built-in type such as list qualifies as a new-style class and becomes a new user-defined type.
          -- p1045
            Classes have a __class__ attribute now, too, because they are instances of type :  @
          -- p1046
            Besides impacting code that does type testing, this turns out to be an important hook for tool developers. We’ll talk more about metaclasses later in this chapter, and again in more detail in Chapter 40.
            [=Implications for type testing]  Besides providing for built-in type customization and metaclass hooks, the merging of classes and types in the new-style class model can impact code that does type testing.  In Python 3.X, for example, the types of class instances compare directly and meaningfully, and in the same way as built-in type objects. This follows from the fact that classes are now types, and an instance’s type is the instance’s class:
            Of course, as I’ve pointed out numerous times in this book, type checking is usually the wrong thing to do in Python programs (we code to object interfaces, not object types), and the more general isinstance built-in is more likely what you’ll want to use in the rare cases where instance class types must be queried. However, knowledge of Python’s type model can help clarify the class model in general.  @
          -- p1047
          -- p1048
            In fact, type itself derives from object , and object derives from type , even though the two are different objects—a circular relationship that caps the object model and stems from the fact that types are classes that generate classes:
            The preceding may seem obscure, but this model has a number of practical implications. For one thing, it means that we sometimes must be aware of the method defaults that come with the explicit or implicit object root class in new-style classes only:  @
          -- p1049
            Diamond Inheritance Change
                For example, the new-style MRO allows lower superclasses to overload attributes of higher superclasses, regardless of the sort of multiple inheritance trees they are mixed into.  @
          -- p1050
                Moreover, the new-style search rule avoids visiting the same superclass more than once when it is accessible from multiple subclasses.
                [At the same time, the new MRO will locate attributes differently, creating a potential incompatibility for 2.X classic classes.]
                This change in the inheritance search procedure is based upon the assumption that if you mix in C lower in the tree, you probably intend to grab its attributes in preference to A ’s. It also assumes that C is always intended to override A ’s attributes in all contexts, which is probably true when it’s used standalone but may not be when it’s mixed into a diamond with classic classes—you might not even know that C may be mixed in like this when you code it.  @
          -- p1051
            If this search order deviation seems too subtle to remember, or if you want more control over the search process, you can always force the selection of an attribute from anywhere in the tree by assigning or otherwise naming the one you want at the place where the classes are mixed together.
            [[+ If you are willing to always resolve conflicts like this, you may be able to largely ignore the search order difference and not rely on assumptions about what you meant when you coded your classes.  Naturally, attributes picked this way can also be method functions—methods are normal, assignable attributes that happen to reference callable function objects:
            Here, we select methods by explicitly assigning to names lower in the tree. We might also simply call the desired class explicitly; in practice, this pattern might be more common, especially for things like constructors:  (???(**(*)))  @
                Such selections by assignment or call at mix-in points can effectively insulate your code from this difference in class flavors. This applies only to the attributes you handle this way, of course, but explicitly resolving the conflicts ensures that your code won’t vary per Python version, at least in terms of attribute conflict selection. In other words, this can serve as a portability technique for classes that may need to be run under both the new-style and classic class models.
           -- p1052
          -- p1053
             (=mainly affects diamond-patterns in multiple inheritance
             To trace how new-style inheritance works by default, we can also use the new class.__mro__ attribute mentioned in the preceding chapter’s class lister examples — technically a new-style extension, but useful here to explore a change.
          -- p1054
          -- p1055
            Technically, the implied object superclass always creates a diamond in multiple inheritance even if your classes do not—your classes are searched as before, but the new-style MRO ensures that object is visited last, so your classes can override its defaults:
          -- p1056
            The class.__mro__ attribute is available only on new-style classes; it’s not present in 2.X unless classes derive from object.  (++(+))
            Example: Mapping Attributes to Inheritance Sources
                As a prime MRO use case, we noted at the end of the prior chapter that class tree climbers—such as the class tree lister mix-in we wrote there—might benefit from the MRO.  @
            We won’t recode our tree lister here, but as a first major step, the following file, mapattrs.py, implements tools that can be used to associate attributes with their inheritance source;
          -- p1057
          -- p1058
          -- p1059
          -- p1060
          -- p1061
            tributes inherited by an instance will be correctly associated with the implementing class from which they are acquired, even though they are not physically stored in the instance’s __dict__ itself:  @
          -- p1062
            Beyond the changes described in the prior section (some of which, frankly, may seem too academic and obscure to matter to many readers of this book), new-style classes provide a handful of more advanced class tools that have more direct and practical application -- slots, properties, descriptors, and more.
             --
            By assigning a sequence of string attribute names to a special __slots__ class attribute, we can enable a new-style class to both limit the set of legal attributes that instances of the class will have, and optimize memory usage and possibly program speed.
          -- p1063
                This feature is envisioned as both a way to catch typo errors like this (assignments to illegal attribute names not in __slots__ are detected) as well as an optimization mechanism.
          -- p1064
            'We can still accommodate extra attributes, though, by including __dict__ explicitly in __slots__ , in order to create an attribute namespace dictionary too:  @
          -- p1065
          -- p1066
            If multiple classes in a class tree have their own __slots__ attributes, generic programs must develop other policies for listing attributes—as the next section explains.
                Handling slots and other “virtual” attributes generically
          -- p1067
            For example, some programs might classify slot names as attributes of classes instead of instances;
            Alternatively, as shown earlier, programs can be more inclusive by relying on dir to fetch all inherited attribute names and getattr to fetch their corresponding values for the instance—without regard to their physical location or implementation. If you must support slots as instance data, this is likely the most robust way to proceed:  @
                Under this dir / getattr model, you can still map attributes to their inheritance sources, and filter them more selectively by source or type if needed, by scanning the MRO— as we did earlier in both mapattrs.py and its application to slots in mapattrs-slots.py.
                As an added bonus, such tools and policies for handling slots will potentially apply automatically to properties and descriptors too, though these attributes are more explicitly computed values, and less obviously instance-related data than slots.
          -- p1068
            SLOT USAGE RULES (**!)  @
                Slots in subs are pointless when absent in supers:
                Slots in supers are pointless when absent in subs:
                Redefinition renders super slots pointless:
                Slots prevent class-level defaults:
                 Slots and __dict__:
              most crucially, a namespace dictionary is created when any class in a tree omits slots, thereby negating the memory optimization benefit:
          -- p1069
            (!!)  Such rules—among others regarding weak references omitted here for space—are part of the reason slots are not generally recommended, except in pathological cases where their space reduction is significant. Even then, their potential to complicate or break code should be ample cause to carefully consider the tradeoffs.
          -- p1070
            Either of the following works around the issue, and allows the tool to support slots— the first provides a default, and the second is more verbose but seems marginally more explicit in its intent:  @
                if attr in getattr(obj, '__dict__', {}):
                if hasattr(obj, '__dict__') and attr in obj.__dict__:
          -- p1071
          -- p1072
            Our next new-style extension is properties—a mechanism that provides another way for new-style classes to define methods called automatically for access or assignment to instance attributes. This feature is similar to properties (a.k.a. “getters” and “setters”) in languages like Java and C#, but in Python is generally best used sparingly, as a way to add accessors to attributes after the fact as needs evolve and warrant. Where needed, though, properties allow attribute values to be computed dynamically without requiring method calls at the point of access.  @
            Properties and slots are related too, but serve different goals.
                Both implement instance attributes that are not physically stored in instance namespace dictionaries—a sort of “virtual” attribute—and both are based on the notion of class-level attribute descriptors. In contrast, slots manage instance storage, while properties intercept access and compute values arbitrarily.
            As a brief introduction, though, a property is a type of object assigned to a class attribute name.  @
            The resulting property object is typically assigned to a name at the top level of a class statement (e.g., name=property() ), and a special @ syntax we’ll meet later is available to automate this step. [******]  @
            Here is the same example, coded with properties instead;
            For some coding tasks, properties can be less complex and quicker to run than the traditional techniques.
                For example, when we add attribute assignment support, properties become more attractive—there’s less code to type, and no extra method calls are incurred for assignments to attributes we don’t wish to compute dynamically:  @
          -- p1073
          -- p1074
            (For example, in many cases the set of attributes to be supported cannot be determined when the class is coded, and may not even exist in any tangible form (e.g., when delegating arbitrary attribute references to a wrapped/embedded object generically).
                In such contexts, a generic __getattr__ or a __setattr__ attribute handler with a passed- in attribute name is usually preferable.
            As we’ll see there, it’s also possible to code properties using the @ symbol function decorator syntax—a topic introduced later in this chapter, and an equivalent and automatic alternative to manual assignment in the class scope:  @!
          -- p1075
            Also in the class extensions department, the __getattribute__ operator overloading method, available for new-style classes only, allows a class to intercept all attribute references, not just undefined references.
                For more specialized attribute interception goals, in addition to properties and operator overloading methods, Python supports the notion of attribute descriptors—classes with __get__ and __set__ methods, assigned to class attributes and inherited by instances, that intercept read and write accesses to specific attributes.
            Descriptors have access to state in instances of themselves as well as their client class, and are in a sense a more general form of properties;
                in fact, properties are a simplified way to define a specific type of descriptor—one that runs functions on access. Descriptors are also used to implement the slots feature we met earlier, and other Python tools.
          -- p1076
            Along with these changes, Python also grew a more coherent and generalized protocol for coding metaclasses—classes that subclass the type object, intercept class creation calls, and may provide behavior acquired by classes.
                Accordingly, they provide a well-defined hook for management and augmentation of class objects.  @
            --
            Static and Class Methods
                static methods work roughly like simple instance-less functions inside a class, and class methods are passed a class instead of an instance.  Both are similar to tools in other languages (e.g., C++ static methods). Although this feature was added in conjunction with the new-style classes discussed in the prior sections, static and class methods work for classic classes too.
                To enable these method modes, you must call special built-in functions named staticmethod and classmethod within the class, or invoke them with the special @name-decoration syntax we’ll meet later in this chapter.  @
            Why the Special Methods?
                Sometimes, programs need to process data associated with classes instead of instances.  @
          -- p1077
            Although less commonly used, Python also supports the notion of class methods— methods of a class that are passed a class object in their first argument instead of an instance, regardless of whether they are called through an instance or a class.
          -- p1078
            • In Python 2.X, we must always declare a method as static in order to call it without an instance, whether it is called through a class or an instance.  @
          -- p1079
                The problem here is that unbound instance methods aren’t exactly the same as simple functions in 2.X. Even though there are no arguments in the def header, the method still expects an instance to be passed in when it’s called, because the function is associated with a class. In Python 3.X, calls to self -less methods made through classes work, but calls from instances fail:
            If you’re able to use 3.X and stick with calling self -less methods through classes only, you already have a static method feature. However, to allow self -less methods to be called through classes in 2.X and through instances in both 2.X and 3.X, you need to either adopt other designs or be able to somehow mark such methods as special.
            Static Method Alternatives  @
                (use normal functions outside the class, not class methods.)
          -- p1080
            , one could argue that there’s not typically any need to package functions in classes unless they implement object behavior.
                For one thing, it adds to this file’s scope an extra name that is used only for processing a single class. For another, the function is much less directly associated with the class by structure; in fact, its definition could be hundreds of lines away. Perhaps worse, simple functions like this cannot be customized by inheritance, since they live outside a class’s namespace: subclasses cannot directly replace or extend such a function by redefining it.  @
                Unfortunately, as mentioned earlier, such an approach is completely unworkable if we
                don’t have an instance available, ....  (+instead using static and class (methods)
                staticmethod  classmethod
          -- p1081
            .
                smeth = staticmethod(smeth) # Make smeth a static method (or @: ahead)  @
                cmeth = classmethod(cmeth) # Make cmeth a class method (or @: ahead)
                    the special @ syntax works here as an alternative to this just as it does for properties—but makes little sense unless you first understand the assignment form here that it automates.  @!
            Technically, Python now supports three kinds of class-related methods, with differing argument protocols:
                Moreover, Python 3.X extends this model by also allowing simple functions in a class to serve the role of static methods without extra protocol, when called through a class object only.  ((**))  @
          -- p1082
            Counting Instances with Static Methods  (*!)  @
          -- p1083
            and allows subclasses to customize the static method with inheritance—a more convenient and powerful approach than importing functions from the files in which superclasses are coded.
            Counting Instances with Class Methods
                Rather than hardcoding the class name, the class method uses the automatically passed class object generically:
            (When using class methods, though, keep in mind that they receive the most specific (i.e., lowest) class of the call’s subject. This has some subtle implications when trying to update class data through the passed-in class.
          -- p1084
          -- p1085
            In fact, because class methods always receive the lowest class in an instance’s tree:
                • Static methods and explicit class names may be a better solution for processing data local to a class.  @
                • Class methods may be better suited to processing data that may differ for each class in a hierarchy.
          -- p1086
            In recent Python versions, though, the static and class method designations have become even simpler with the advent of function decoration syntax—a way to apply one function to another that has roles well beyond the static method use case that was its initial motivation.  @
                This syntax also allows us to augment classes in Python 2.X and 3.X—to initialize data like the numInstances counter in the last example, for instance.
                --
                For a postscript on Python’s method types, be sure to watch for coverage of metaclass methods in Chapter 40—because these are designed to process a class that is an instance of a metaclass, they turn out to be very similar to the class methods defined here, but require no classmethod declaration, and apply only to the shadowy metaclass realm.  @
            Python decorators—similar to the notion and syntax of annotations in Java—both addressed this specific need and provided a general tool for adding logic that manages both functions and classes, or later calls to them.  @
            This is called a “decoration,” but in more concrete terms is really just a way to run extra processing steps at function and class definition time with explicit syntax.  @
                Function decorators—the initial entry in this set, added in Python 2.4—augment function definitions. (They specify special operation modes for both simple functions and classes’ methods by wrapping them in an extra layer of logic implemented as another function, usually called a metafunction.)  ="very general tools"
                    For instance, they may be used to augment functions with code that logs calls made to them, checks the types of passed arguments during debugging, and so on. Function decorators can be used to manage either functions themselves or later calls to them.  (******)   (= in the latter role, similar to the delegation design pattern)  @!
                Class decorators—a later extension, added in Python 2.6 and 3.0—augment class definitions.
          -- p1087
            +"now, some built-in function decorators" (***)  @
            This proved such a useful hook that it was extended in Python 2.6, 2.7, and 3.X—class decorators bring augmentation to classes too, and are more directly tied to the class model.
            A function decorator is coded on a line by itself just before the def state- ment that defines a function or method. It consists of the @ symbol, followed by what we call a metafunction—a function (or other callable object) that manages another function. Static methods since Python 2.4, for example, may be coded with decorator syntax like this:  ((****************)) !!!!!!  [SSSSSSssss]  @!  @!
                The net effect is that calling the method function’s name later actually triggers the result of its staticme thod decorator first. Because a decorator can return any sort of object, this allows the decorator to insert a layer of logic to be run on every call.  (+++++++)  @
            With this addition, here’s a better way to code our static method example from the prior section in either Python 2.X or 3.X:  (******)  @
          -- p1088
            +For the bothmethods.py (*** SSSSSS)
          -- p1089
            A First Look at User-Defined Function Decorators
                'Although Python provides a handful of built-in functions that can be used as decorators, ....
            (The net effect, again, is to add a layer of logic to the original spam function.)
          -- p1090
            As we’ll see in Part VIII, there are a variety of ways to code function decorators, including nested def statements; some of the alternatives are better suited to methods than the version shown here.  (=closures)  @
            A First Look at Class Decorators and Metaclasses
                In short, class decorators are similar to function decorators, but they are run at the end of a class statement to rebind a class name to a callable. As such, they can be used to either manage classes just after they are created, or insert a layer of wrapper logic to manage instances when they are later created.  @
            For example, in the code of the section “Counting instances per class with class methods” on page 1033, we could use this hook to automatically augment the classes with instance counters and any other data required:
          -- p1091
            ((Though this decorator manages a function or class itself, as we’ll see later in this book, class decorators can also manage an object’s entire interface by intercepting construc- tion calls, and wrapping the new instance object in a proxy that deploys attribute ac- cessor tools to intercept later requests—a multilevel coding technique we’ll use to im- plement class attribute privacy in Chapter 39.  (??)  @
            Metaclasses, mentioned briefly earlier, are a similarly advanced class-based tool whose roles often intersect with those of class decorators. They provide an alternate model, which routes the creation of a class object to a subclass of the top-level type class, at the conclusion of a class statement:  @
          -- p1092
                In Python 2.X, the effect is the same, but the coding differs—use a class attribute instead of a keyword argument in the class header:
                In fact, a metaclass need not be a class at all—a possibility we’ll explore later that blurs some of the distinction between this tool and decorators, and may even qualify the two as functionally equivalent in many roles.
                Both schemes, class decorators and metaclasses, are free to augment a class or return an arbitrary object to replace it—a protocol with almost limitless class-based custom- ization possibilities. As we’ll see later, metaclasses may also define methods that process their instance classes, rather than normal instances of them—a technique that’s similar to class methods, and might be emulated in spirit by methods and data in class deco- rator proxies, or even a class decorator that returns a metaclass instance.  (**(**))
          -- p1093
          -- p1094
            ((  In its defense, this call does have a valid use case too—cooperative same-named method dispatch in diamond multiple inheritance trees—but it seems to ask a lot of newcomers.  ))
            [super]  Traditional Superclass Call Form: Portable, General
          -- p1095
            'The role we’re interested in here is more commonly used, and more frequently reques- ted by people with Java backgrounds—to allow superclasses to be named generically in inheritance trees.  @
          -- p1096
             Python’s longstanding EIBTI design rule (run an “import this”
          -- p1097
            In other words, super usage may obscure a common source of errors in Python —one so common that it shows up again in this part’s “Gotchas.”
            This coding situation isn’t nearly as abstract as it may seem. Here’s a real-world example of such a case, taken from the PyMailGUI case study in Programming Python—the following very typical Python classes use multiple inheritance to mix in both application logic and window tools from independent, standalone classes, and hence must invoke both superclass constructors explicitly with direct calls by name.  [****]  @
          -- p1098
          -- p1099
            Because super adds an odd special case to the language—one with strange semantics, limited scope, rigid requirements, and questionable reward—most Python programmers may be better served by the more broadly applicable traditional call scheme
             Although you can use the 2.X call form in 3.X for backward compatibility, it’s too cumbersome to deploy in 3.X-only code, and the more reasonable 3.X form is not usable in 2.X:
          -- p1100
          -- p1101
            Having just shown you the downsides of super , I should also confess that I’ve been tempted to use this call in code that would only ever run on 3.X, and which used a very long superclass reference path through a module package (that is, mostly for laziness, but coding brevity can matter too).
                The super Upsides: Tree Changes and Dispatch  (+??)
          -- p1102
            ((( Since every class participates in a diamond under object in 3.X (and 2.X new-style classes), the applications are broader than you might expect. In fact, some of the earlier examples that demonstrated super shortcomings in multiple inheritance trees could use this call to achieve their dispatch goals. To do so, however,  ....
          -- p1103
          -- p1104
          -- p1105
          -- p1106
          -- p1107
            (Routing with super also assumes that you really mean to pass method calls throughout all your classes per the MRO, which may or may not match your call ordering requirements.
          -- p1108
            ((  Once again, the problem with assumptions is that they assume things! Although the assumption of universal routing might be reasonable for constructors, it would also seem to conflict with one of the core tenets of OOP—unrestricted subclass customization.
          -- p1109
            ( Subtly, when we say super selects the next class in the MRO, we really mean the next class in the MRO that implements the requested method
          -- p1110
          -- p1111
          -- p1112
            More to the point, by making mix-ins more self-contained, direct calls minimize com- ponent coupling that always skews program complexity higher—a fundamental software principle that seems neglected by super ’s variable and context-specific dispatch model.
             In realistic programs, this constraint may in fact be a true showstopper for many potential super applications, precluding its use entirely.
          -- p1113
            Watch what happens, though, when an employee is a member of both categories.
          -- p1114
            This example may warrant redesign in general—splitting off shareable parts of Chef and Server to mix-in classes without a constructor, for example.  @
            It’s also true that polymorphism in general assumes that the methods in an object’s external interface have the same argument signature, though this doesn’t quite apply to customization of superclass methods—an internal implementation technique that should by nature support variation, especially in constructors.
             In general, when superclass methods are called by explicit name, root classes of diamonds might check state in instances to avoid firing twice—a similarly complex coding pattern, but required rarely in most code, and which to some may seem no more difficult than using super itself.
          -- p1115
            should also consider this book’s preferred traditional technique of explicit-name superclass calls to be at least as valid a solution as Python’s super
            [ same-named method dispatch in multiple inheritance trees is relatively rare in real Python programs, and obscure enough to have generated both much controversy and much misunderstanding surrounding this role.
          -- p1116
        ]]Class Gotchas
            Changing Class Attributes Can Have Side Effects(!!)
                Because all instances generated from a class share the class’s namespace, any changes at the class level are reflected in all instances, unless they have their own versions of the changed class attributes.
          -- p1117
            This is a perfectly legal Python programming trick, but it’s less appropriate when applied to classes written by others; you can’t always be sure that class attributes you change aren’t critical to the class’s internal behavior.  [!!!!]  @
                If you’re out to simulate a C struct , you may be better off changing instances than classes, as that way only one object is affected:
            Changing Mutable Class Attributes Can Have Side Effects, Too
          -- p1118
                —and all are impacted if the shared object is changed in place from any reference. Here, this occurs in class attributes shared by all instances via inheritance, but it’s the same phenomenon at work.
                But again, this is not a problem, it’s just something to be aware of; shared mutable class attributes can have many valid uses in Python programs. [!!!***]
            Multiple Inheritance: Order Matters  (!!*)  @
          -- p1119
            Here, the assignment to other within the Sub class creates Sub.other —a reference back to the Super.other object. Because it is lower in the tree, Sub.other effectively hides ListTree.other , the attribute that the inheritance search would normally find.
            Multiple inheritance is an advanced tool. Even if you understood the last paragraph, it’s still a good idea to use it sparingly and carefully.
                Otherwise, the meaning of a name may come to depend on the order in which classes are mixed in an arbitrarily far removed subclass.
            As a rule of thumb, multiple inheritance works best when your mix-in classes are as self-contained as possible—because they may be used in a variety of contexts, they should not make assumptions about names related to other classes in a tree.
                (can use _|__x--names)
          -- p1120
            When working out the meaning of names in class-based code, it helps to remember that classes introduce local scopes, just as functions do, and methods are simply further nested functions.  @
            Even so, keep in mind that method def s cannot see the local scope of the enclosing class; they can see only the local scopes of enclosing def s.
                That’s why methods must go through the self instance or the class name to reference methods and other attributes defined in the enclosing class statement.  @
                To avoid nesting, we could restructure this code such that the class Spam is defined at the top level of the module: the nested method function and the top-level generate will then both find Spam in their global scopes; it’s not localized to a function’s scope, but is still local to a single module:  (***/????)
          -- p1121
            Choose per-instance or class storage wisely
                In a GUI program, for instance, if you want information to be shared by all of the window class objects your application will create (e.g., the last directory used for a Save operation, or an already entered password), it must be stored as class-level data; if stored in the instance as self attributes, it will vary per window or be missing entirely when looked up by inheritance.  @
            You usually want to call superclass constructors  (!!!)  @
            [Delegation-based classes in 3.X: __getattr__ and built-ins
                    ... unless operator overloading methods are redefined in the wrapper class.
          -- p1122
            KISS Revisited: “Overwrapping-itis”
            'This is a relatively lightweight topic, but I’ve saved it for last because new ex- ceptions are supposed to be coded as classes today.  @
          -- p1123
            +AGAIN: PICK GOOD SUMMATIONS|SUMMARIES OF THE FEATURES FROM HERE (!!!!!)
            1. You can embed a built-in object in a wrapper class, or subclass the built-in type directly. The latter approach tends to be simpler, as most original behavior is automatically inherited.
            Function decorators are generally used to manage a function or method, or add to it a layer of logic that is run each time the function or method is called. They can be used to log or count calls to a function, check its argument types, and so on.  They are also used to “declare” static methods (simple functions in a class that are not passed an instance when called), as well as class methods and properties.  @
            Static methods are simple functions nested in class objects.  To make a method static, it must either be run through a special built-in function or be decorated with decorator syntax.  @
          -- p1124
        ]]Exercises
          -- p1129
            (('Why You Will Care: OOP by the Masters'  @
            
                

          Exceptions (**!!)  1133 -- 1217



        -- -- -- -- -- --
        Unicode+ByteStrings  1217
          -- p1217
            Python 3.X provides an alternative string type for binary data, and supports Unicode text (including ASCII) in its normal string type.
            and XML parsing,  @
          -- p1218
            ((bytearray))
            If you deal with non-ASCII Unicode text—for instance, in the context of internationalized domains like the Web, or the results of some XML and JSON parsers and databases—you will find support for text encodings to be different in 3.X, but also probably more direct, accessible, and seamless than in 2.X.  Managed Attributes  1271
            If you deal with binary data—for example, in the form of image or audio files or packed data processed with the struct module—you will need to understand 3.X’s new bytes object and 3.X’s different and sharper distinction between text and binary data and files.  @
          -- p1219
            Though applications are beyond our scope here, if you work with the Internet, files, directories, network interfaces, databases, pipes, JSON, XML, and even GUIs, Unicode may no longer be an optional topic for you in Python 3.X.  @
            Character sets are standards that assign integer codes to individual characters so they can be represented in computer memory.
          -- p1220
            Unicode text is sometimes referred to as “wide-character” strings, because characters may be represented with multiple bytes if needed.
            To store such rich text in computer memory, we say that characters are translated to and from raw bytes using an encoding—the rules for translating a string of Unicode characters to a sequence of bytes, and extracting a string from a sequence of bytes.  (+encoding | decoding)  @
                That is, we encode from string to raw bytes, and decode from raw bytes to string.
            The widely used UTF-8 encoding, for example, allows a wide range of characters to be represented by employing a variable-sized number of bytes scheme.
          -- p1221
            Other encodings allow for richer character sets in different ways. UTF-16 and UTF-32, for example,
                ... and includes header bytes
                 >>> S = 'ni'
                 >>> S.encode('ascii'), S.encode('latin1'), S.encode('utf8')  @
            To Python programmers, encodings are specified as strings containing the encoding’s name. Python comes with roughly 100 different encodings; see the Python library reference for a complete list. Importing the module encodings and running help(encod ings) shows you many encoding names as well;  @
            For more on the underlying Unicode story, see the Python standard manual set. It includes a “Unicode HOWTO” in its “Python HOWTOs” section,  @
          -- p1222
            How Python Stores Strings in Memory  [[****]]  @
                , and in fact mutated substantially as of 3.3:
            Python 3.3’s new scheme is an optimization, .... (*****)
            Today, both string content and length really correspond to Unicode code points — identifying ordinal numbers for characters.  [**]  @
          -- p1223
            len returns the number of characters, not bytes; the string is probably larger in memory, and its characters may not fit in bytes anyhow.  @
            The key point here, though, is that encoding pertains mostly to files and transfers. Once loaded into a Python string, text in memory has no notion of an “encoding,” and is simply a sequence of Unicode characters (a.k.a. code points) stored generically. In your script, that string is accessed as a Python string object—the next section’s topic.
                str,  unicode  |  str  bytes  bytearray  (3.X  @
          -- p1224
            To achieve this, 3.X stores text in a redefined str type—an immutable sequence of characters (not necessarily bytes), which may contain either simple text such as ASCII whose character values fit in single bytes, or richer character set text such as UTF-8 whose character values may require multiple bytes. ...... This allows scripts to translate text to different encoding schemes, both in memory and when transferring to and from files.  @
            , many programs still need to process raw binary data that is not encoded per any text format.  Image and audio files, as well as packed data used to interface with devices or C programs you might process with Python’s struct module, fall into this category.  @
            3.X. bytearray is a variant of bytes that is mutable and so supports in-place changes.
          -- p1225
            In practice, though, this asymmetry is not as daunting as it might sound. It boils down to the following: in 2.X, you will use str for simple text and binary data and unicode for advanced forms of text whose character sets don’t map to 8-bit bytes; in 3.X, you’ll use str for any kind of text (ASCII, Latin-1, and all other kinds of Unicode) and bytes or bytearray for binary data. In practice, the choice is often made for you by the tools you use—especially in the case of file processing tools, the topic of the next section.  @
            When a file is opened in text mode, reading its data automatically decodes its content and returns it as a str ;  @
            If you are processing image files, data transferred over networks, packed binary data whose content you must extract, or some device data streams, chances are good that you will want to deal with it using bytes and binary-mode files.  @
                You might also opt for bytearray if you wish to update the data without making copies of it in memory.  @
                If instead you are processing something that is textual in nature, such as program output, HTML, email content, or CSV or XML files, you’ll probably want to use str and text-mode files.  @
            Text-mode files also handle the byte order marker (BOM) sequence that may appear at the start of files under some encoding schemes. In the UTF-16 and UTF-32 encodings, for example, the BOM specifies big- or little-endian format (essentially,  @
            [Coding Basic Strings]  @
          -- p1226
          -- p1227
                The bytes object is also immutable,
          -- p1228
            Python 2.X’s u'xxx' and U'xxx' Unicode string literal forms were removed in Python 3.0 because they were deemed redundant—
            However, in 3.3 and later, using the 2.X literal form can ease the task of porting 2.X code, and boost 2.X code compatibility (
          -- p1229
            Because of this, Python 3.X basically requires that you commit to one type or the other, or perform manual, explicit conversions when needed:
                • S.encode() and bytes(S, encoding) translate a string to its raw bytes form and create an encoded bytes from a decoded str in the process.  @
                • B.decode() and str(B, encoding) translate raw bytes into its string form and create a decoded str from an encoded bytes in the process.
            First of all, your platform’s default encoding is available in the sys module,  @
            Second, although calls to str do not require the encoding argument like bytes does, leaving it off in str calls does not mean that it defaults—
          -- p1230
            When in doubt, pass in an encoding name argument in 3.X, even if it may have a default.  @
            Coding Unicode Strings **
          -- p1231
            In any event, hex escapes are limited to coding a single byte’s value, but Unicode escapes can name characters with values 2 and 4 bytes wide.  @
            S = '\U000000c4\U000000e8'  @
            Encoding and Decoding Non-ASCII text  @
          -- p1232
          -- p1233
            However, as we’ll see later, the encoding mode you give to the open call causes this decoding to be done for you automatically on input (and avoids .....
            When needed, you can specify both 16- and 32-bit Unicode code point values for characters in your strings—as shown earlier, we can use "\u..." with four hex digits for the former, and "\U..." with eight hex digits for the latter, and can mix these in literals with simpler ASCII characters freely:
          -- p1234
            The same holds true for the UTF-16 and UTF-32 encodings, which use fixed 2- and 4- byte-per-character schemes with same-sized headers—non-ASCII encodes differently, and ASCII is not 1 byte per character:  @
          -- p1235
            Two cautions here too. First, Python 3.X allows special characters to be coded with both hex and Unicode escapes in str strings, but only with hex escapes in bytes strings —  @
            str strings, on the other hand, allow literals containing any character in the source character set—which, as discussed later, defaults to UTF-8
          -- p1236
            'Converting Encodings'  @
            Keep in mind that the special Unicode and hex character escapes are only necessary when you code non-ASCII Unicode strings manually. In practice, you’ll often load such text from files instead.  @
          -- p1237
            [Coding Unicode Strings in Python 2.X]
          -- p1238
            One of the primary differences between 2.X and 3.X, though, is that unicode and non-Unicode str objects can be freely mixed in 2.X expressions—as long as the str is compatible with the unicode object, Python will automatically convert it up to unicode: ???
          -- p1239
            unicode('spam')  @
            To read and write Unicode files and encode or decode their content automatically, use 2.X’s codecs.open call  @
            [Source File Character Set Encoding Declarations] (??)
          -- p1240
            The comment must be of this form and must appear as either the first or second line in your script in either Python 2.X or 3.X: ****(****)
                # -*- coding: latin-1 -*-  @
          -- p1241
            For an additional example of non-ASCII character coding and source file declarations, see the currency symbols used in the money formatting example of Chapter 25, as well as its associated file in this book’s examples package, formats_currency2.py.
                The latter requires a source-file declaration to be usable by Python, because it embeds non-ASCII currency symbol characters. This example also illustrates the portability gains possible when using 2.X’s Unicode literal in 3.X code in 3.3 and later.  *****
            Using 3.X bytes Objects
                Instead, let’s dig a bit deeper into the operation sets provided by the new bytes type in 3.X.  @
            As you can see, str and bytes have almost identical functionality.  (=inspecting w. dir)
          -- p1242
            One notable difference is that string formatting works only on str objects in 3.X, not on bytes objects
          -- p1243
          -- p1244
            Mixing String Types(??)
          -- p1247
            Python 3.X String Types Summary
                Finally, by way of summary, the following examples demonstrate how bytes and byte array objects are sequences of int s, and str objects are sequences of characters:
            Although all three Python 3.X string types can contain character values and support many of the same operations, again, you should always:  @
                • Use str for textual data.
                • Use bytes for binary data.
                • Use bytearray for binary data you wish to change in place.  @
            Related tools such as files, the next section’s topic, often make the choice for you.
            As mentioned earlier, the mode in which you open a file is crucial—it determines which object type you will use to represent the file’s content in your script.  @
          -- p1248
            The second argument to open determines whether you want text or binary processing, just as it does in 2.X Python—
                rt is default  @
            'Text File Basics'
            (note that file is no longer a built-in name in 3.X, so it’s perfectly OK to use it as a variable here):  (***(*))  @
          -- p1249
            and such translations should never occur for binary data (where end-of-line bytes are irrelevant).
          -- p1250
            [Type and Content Mismatches in 3.X]
                'This makes sense: text has no meaning in binary terms, before it is encoded.'
            [Using Unicode Files]
                It turns out to be easy to read and write Unicode text stored in files too, because the 3.X open call accepts an encoding for text files, and arranges to run the required encoding and decoding for us automatically as data is transferred.  (***(!!))  @
          -- p1251
          -- p1252
          -- p1253
            Finally, keep in mind that this behavior of files in 3.X limits the kind of content you can load as text.
            [Handling the BOM in 3.X] (**)  @
          -- p1254
            If this file is instead saved as UTF-8 in Notepad, it is prepended with a 3-byte UTF-8 BOM sequence, and we need to give a more specific encoding name (“utf-8-sig”) to force Python to skip the marker:  @
          -- p1255
            Notice that although “utf-8” does not drop the BOM, data without a BOM can be read with both “utf-8” and “utf-8-sig”—use the latter for input if you’re not sure whether a BOM is present in a file (
          -- p1256
            However, if you replace str with unicode and open with codecs.open , the result is essentially the same in 3.X:  @
          -- p1257
          -- p1258
            [PYTHONIOENCODING]
                A script that prints non-ASCII filenames, for example, may fail unless this setting is made.  @
            Many of the other popular string-processing tools in Python’s standard library have also been revamped for the new str / bytes type dichotomy.
                here’s a quick look at four of the major tools impacted: the re pattern-matching module, the struct binary data module, the pickle object serialization module, and the xml package for parsing XML text.  @
            [The re Pattern-Matching Module]   +EEe
          -- p1259
            But note that, like in other APIs, you can’t mix str and bytes types in its calls’ arguments in 3.X (although if you don’t plan to do pattern matching on binary data, you probably don’t need to care):
          -- p1260
             (open  + struct etc)  @
            Apart from the new syntax for bytes, creating and reading binary files works almost the same in 3.X as it does in 2.X. Still, code like this is one of the main places where programmers will notice the bytes object type:
          -- p1261
             However, if you must use or produce lower-level data used by C programs, networking libraries, or other interfaces, Python has tools to assist.
            [The pickle Object Serialization Module]
          -- p1262
                This implies that files used to store pickled objects must always be opened in binary mode in Python 3.X, since text files use str strings to represent data, not bytes —  @
            —correct usage in 3.X requires always both writing and reading pickle data in binary modes, whether unpickling or not:  @
          -- p1263
            If you care about version neutrality, though, or don’t want to care about protocols or their version-specific defaults, always use binary-mode files for pickled data—the following works the same in Python 3.X and 2.X:
            Because almost all programs let Python pickle and unpickle objects automatically and do not deal with the content of pickled data itself, the requirement to always use binary file modes is the only significant incompatibility in Python 3.X’s newer pickling model.
            [XML Parsing Tools]
                Because XML is such a pervasive format, Python itself comes with an entire package of XML parsing tools that support the SAX and DOM parsing models, as well as a package known as ElementTree—a Python-specific API for parsing and constructing XML  @
          -- p1264
            There are at least four basic ways to accomplish this (not counting more advanced tools like XPath). : (---->>)  (text matching, DOM parsing(**) EEe , SAX **  EEe, ElementTree (= stdlib: etree)  **(*),   @
            (Technically, though, in 2.X some of these scripts produce unicode string objects, while in 3.X all produce str strings, since that type includes Unicode text (whether ASCII or other):)
          -- p1265
          -- p1266
            if there is one, is likely in getting the encoding names right when transferring the parsed-out data to and from files, network connections, GUIs, and so on.  (**(**))  @
            Why You Will Care: Inspecting Files, and Much More
                To find the bad character, I simply started Python, decoded the file’s content from its UTF-8 format via a text mode file, and scanned character by character looking for the first byte that was not a valid ASCII character too: [****(!)]  @
                With the bad character’s index in hand, it’s easy to slice the Unicode string for more details: (++)
            [+ The Questions]
          -- p1267
            <+PERHAPS PULL UP THESE SUMMARIES>
          -- p1268
            'With binary-mode files, bytes are transferred to and from the file unchanged.'
            Text-mode files also handle the BOM for certain encoding types and automatically translate end-of-line sequences to and from the single \n character on input and output unless this is explicitly disabled; binary-mode files do not perform either of these steps.
          -- p1269
            You can also read in binary mode and manually decode the bytes to a string by giving an encoding name, but this involves extra work and is somewhat error-prone for multibyte characters (you may accidentally read a partial character sequence).  @
            This makes Unicode backward-compatible with the mass of ASCII text data in the world (though it also may have limited its options—self-identifying text, for instance, may have been difficult (though BOMs serve much the same role).
            Unicode data, the toolset you need has simply moved from 2.X’s unicode and codecs.open() to 3.X’s str and open.
            ((In general, Unicode will probably impact most 3.X users eventually.))


            Managed Attributes  1271
          -- p1271
            expands on the attribute interception techniques introduced earlier,  @
            —they can fetch and set attributes on objects without concern for attribute implementations.
            Especially for tools builders, though, managing attribute access can be an important part of flexible APIs. Moreover, an understanding of the descriptor model covered here can make related tools such as slots and properties more tangible, and may even be required reading if it appears in code you must use.
             --
            Object attributes are central to most Python programs—they are where we often store information about the entities our scripts process.
            —for example, you decide that names should be validated with logic when set or mutated in some way when fetched.  @
                However, this also requires changing all the places where names are used in the entire program—a possibly nontrivial task.
                Moreover, this approach requires the program to be aware of how values are exported: as simple names or called methods.
                This issue can crop up more often than you might expect. The value of a cell in a spreadsheet-like program, for instance, might begin its life as a simple discrete value, but later mutate into an arbitrary calculation.
          -- p1272
            A better solution would allow you to run code automatically on attribute access, if needed. That’s one of the main roles of managed attributes—they provide ways to add attribute accessor logic after the fact.  @
            Specifically, this chapter presents four accessor techniques:  [!!!!]
          -- p1273
                The tools in the first of these bullets are available in all Pythons. The last three bullets’ tools are available in Python 3.X and new-style classes in 2.X—
            BESIDES STUDYING THE SPECIFICS BEHIND THE FOUR ATTRIBUTE INTERCEPTION TECHNIQUES LISTED IN THIS SECTION, THIS CHAPTER ALSO PRESENTS AN OPPORTUNITY TO EXPLORE LARGER PROGRAMS THAN WE’VE SEEN ELSEWHERE IN THIS BOOK.  @
                The CardHolder case study at the end, for example, should serve as a self-study example of larger classes in action. [!!!!]  @
            The property protocol allows us to route a specific attribute’s get, set, and delete operations to functions or methods we provide, enabling us to insert code to be run automatically on attribute access, intercept attribute deletions, and provide documentation for the attributes if desired. (!!)  (+self)  @
                    As we’ll see, properties are strongly related to descriptors; in fact, they are essentially a restricted form of them.
          -- p1274
                fget  fset  fdel  @
            (To demonstrate how this translates to working code, the following class uses a property to trace access to an attribute named name ;
          -- p1275
            —it simply intercepts and traces an attribute —but it serves to demonstrate the protocol.
            In terms of inheritance, properties work the same as normal methods; because they have access to the self instance argument, ....  @
          -- p1276
            'Computed Attributes' (**)
            ''Coding Properties with Decorators'' (!!)  @
                @decorator
                def func(args): ...
                    ==>> [=expands into]
                def func(args): ...
                func = decorator(func)
          -- p1277
                Because of this mapping, it turns out that the property built-in can serve as a decorator, to define a function that will run automatically when an attribute is fetched:  @!
                    class Person:
                        @property
                        def name(self): ...
                    (+@name.setter  @name.deleter  (*****(!!!))   (SSSSS(SSSssss))
          -- p1278
            In fact, this code is equivalent to the first example in this section—decoration is just an alternative way to code properties in this case.
            [Descriptors]
                the property built-in is just a simplified way to create a specific type of descriptor that runs method functions on attribute accesses. In fact, descriptors are the underlying implementation mechanism for a variety of class tools, including both properties and slots.
                    'This allows us to insert code to be run automatically on attribute fetches and assignments, intercept attribute deletions, and provide documentation for the attributes if desired.' [!!!! (***)]   (SSSS (SS))  @
                Properties really are just a convenient way to create a specific kind of descriptor,  @
          -- p1279
            (Unlike properties, descriptors are broader in scope, and provide a more general tool.  For instance, because they are coded as normal classes, descriptors have their own state, may participate in descriptor inheritance hierarchies, can use composition to aggregate objects, and provide a natural structure for coding internal methods and attribute documentation strings.)  @
            Classes with any of these methods are considered descriptors, and their methods are special when one of their instances is assigned to another class’s attribute—when the attribute is accessed, they are automatically invoked.  @
                    —to make an attribute read-only, you must define __set__ to catch assignments and raise an exception.  @
            owner
          -- p1280
            The descriptor knows it is being accessed directly when its instance argument is None .
          -- p1281
            This is the way all instance attribute assignments work in Python, and it allows classes to selectively override class-level defaults in their instances. To make a descriptor-based attribute read-only, catch the assignment in the descriptor class and raise an exception to prevent attribute assignment—when assigning an attribute that is a descriptor, Python effectively bypasses the normal instance-level assignment behavior and routes the operation to the descriptor object:
            ''A First Example''   [EEEEeee]
                Like properties, descriptors work properly only for new-style classes, so be sure to derive both classes in the following from object if you’re using 2.X—it’s not enough to derive just the descriptor, or just its client:
          -- p1282
            Notice in this code how we assign an instance of our descriptor class to a class attribute in the client class; because of this, it is inherited by all instances of the class, just like a class’s methods. Really, we must assign the descriptor to a class attribute like this —it won’t work if assigned to a self instance attribute instead. When the descriptor’s __get__ method is run, it is passed three objects to define its context:
                self, instance, owner
          -- p1283
            Also like in the property example, our descriptor class instance is a class attribute and thus is inherited by all instances of the client class and any subclasses.
            When coded this way, Name becomes a local variable in the scope of the Person class statement, such that it won’t clash with any names outside the class. This version works the same as the original—we’ve simply moved the descriptor class definition into the client class’s scope—
            In practice, descriptors can also be used to compute attribute values each time they are fetched.
          -- p1284
            When run, the output of this example is the same as that of the original property-based version, but here a descriptor class object is intercepting the attribute accesses:
            [[Using State Information in Descriptors]] (??)  ('they get their information from different places - 
                Descriptor state
                Instance state
            For instance, you would not normally use descriptor state to record employee names, since each client instance requires its own value—
          -- p1285
            On the other hand, you would not usually use instance state to record data pertaining to descriptor implementation internals—
            ((For example, the following descriptor attaches information to its own instance, so it doesn’t clash with that on the client class’s instance—but also shares that information between two client instances:
          -- p1286
            It’s also feasible for a descriptor to store or use an attribute attached to the client class’s instance, instead of itself.
                Crucially, unlike data stored in the descriptor itself, this allows for data that can vary per client class instance.
            Both descriptor and instance state have roles. In fact, this is a general advantage that descriptors have over properties—because they have state of their own, they can easily retain data internally, without adding it to the namespace of the client instance object.  @
          -- p1287
          -- p1288
            As mentioned earlier, properties and descriptors are strongly related—the property built-in is just a convenient way to create a descriptor.  @
            'With descriptors, this “just works”:
          -- p1289
            [[You can also probably now at least in part imagine how descriptors are used to implement Python’s slots extension: instance attribute dictionaries are avoided by creating class-level descriptors that intercept slot name access, and map those names to sequential storage space in the instance.
             , though nested functions are usually a conceptually much simpler solution.
             (attribute interception)  Like properties and descriptors, they allow us to insert code to be run automatically when attributes are accessed. As we’ll see, though, these two methods can also be used in more general ways.  Because they intercept arbitrary names, they apply in broader roles such as delegation, but may also incur extra calls in some contexts, and are too dynamic to register in dir results.
          -- p1290
            ((Because of this, these two methods are well suited to general delegation-based coding patterns—they can be used to implement wrapper (a.k.a. proxy) objects that manage all attribute accesses for an embedded object.))   intercept fetches only, not assignment
          -- p1291
            The following class (borrowed from Chapter 31), for example, traces every attribute fetch made to another object passed to the wrapper (proxy) class:
                There is no such analog for properties and descriptors, short of coding accessors for every possible attribute in every possibly wrapped object.
          -- p1292
            This is normally desired behavior—intercepting every attribute fetch is this method’s purpose, after all—but you should be aware that this method catches all attribute fetches wherever they are coded.
                To avoid this loop, route the fetch through a higher superclass instead to skip this level’s version—because the object class is always a new-style superclass, it serves well in this role:
          -- p1293
            'A First Example'
          -- p1294
          -- p1295
            Because they are generic, __getattr__ and __getattribute__ are probably more commonly used in delegation-base code (as sketched earlier),
                Where just a single attribute must be managed, properties and descriptors might do as well or better.  @
          -- p1296
          -- p1297
            if you care about speed and want to avoid this, change __getattribute__ to use the superclass to fetch value as well:
            [__getattr__ and __getattribute__ Compared]
          -- p1298
            Management Techniques Compared
                (=A More Comprehensive Example (EEEEE)
          -- p1299
                'To do the same with descriptors(!)
          -- p1300
            For more on how these alternatives compare, and other coding options, stay tuned for a more realistic application of them in the attribute validation example in the section “Example: Attribute Validations” on page 1256.  (EEEEeeeeeee)
            First, though, we need to take a short side trip to study a new-style-class pitfall associated with two of these tools—the generic attribute interceptors presented in this section.
          -- p1301
            This means that operator overloading method calls cannot be delegated to wrapped objects unless wrapper classes somehow redefine these methods themselves.
            'In other words, in all Python 3.X classes (and 2.X new-style classes), there is no direct way to generically intercept built-in operations like printing and addition.'
            This does, however, make delegation-based coding patterns more complex in 3.X, because object interface proxies cannot generically intercept operator overloading method calls and route them to an embedded object.
          -- p1302
                This does, however, make object wrappers more work than they used to be when operator overloading methods are a part of a wrapped object’s interface.
          -- p1303
            Really, the __getattribute__ case is the same in 2.X as it is in 3.X, because in 2.X classes must be made new-style by deriving from object to use this method.
            Python 3.X (and new-style classes in general) skips the normal instance lookup mechanism when resolving such names, though normally named methods are still intercepted as before:
            Trace these outputs back to print s in the script to see how this works. Some highlights:
          -- p1304
          -- p1305
            Again, the net effect is that operator overloading methods implicitly run by built-in operations are never routed through either attribute interception method in 3.X: Python 3.X’s new-style classes search for such attributes in classes and skip instance lookup entirely.
                Of course, the addition of such methods can be partly automated by tools that augment classes with new methods (the class decorators and metaclasses of the next two chapters might help here).
            For a more realistic illustration of this phenomenon as well as its workaround, see the Private decorator example in the following chapter.  (***********************(!!!!))  @
            AS A MORE REALISTIC EXAMPLE OF THIS, THE NEXT SECTION RESURRECTS OUR CLASS TUTORIAL EXAMPLE. NOW THAT YOU UNDERSTAND HOW ATTRIBUTE INTERCEPTION WORKS, I’LL BE ABLE TO EXPLAIN ONE OF ITS STRANGER BITS.
          -- p1306
          -- p1307
          -- p1308
            , wrappers must accommodate them portably by redefining them locally.
            'Example: Attribute Validations'
                To close out this chapter, let’s turn to a more realistic example, coded in all four of our attribute management schemes. The example we will use defines a CardHolder object with four attributes, three of which are managed.  (!!! EEEEEEEEE)  @
          -- p1309
                , but properties help if we have been using attributes in existing code already. Properties run code automatically on attribute access, but are focused on a specific set of attributes; they cannot be used to intercept all attributes generically.  @
                This renaming (sometimes called name mangling) is necessary because properties use common instance state and have none of their own. Data is stored in an attribute called __name , and the attribute called name is always a property, not data.
          -- p1310
            try catch-blocks  =EEEEE(eeeeee)  @
          -- p1311
          -- p1312
          -- p1313
            'Importantly, the downside of this scheme is that state stored inside a descriptor itself is class-level data that is effectively shared by all client class instances, and so cannot vary between them.
          -- p1314
          -- p1315
            'Using __getattr__ to Validate'
          -- p1316
            Probably more important here are roles: generic tools like __getattr__ may be better suited to generic delegation, while properties and descriptors are more directly designed to manage specific attributes.  (!!!**)  @
            (Though this will likely result in negligible overhead for most programs, the more narrowly focused properties and descriptors incur an extra call only when managed attributes are accessed, and also appear in dir results when needed by generic tools.
          -- p1317
             Using __getattribute__ to Validate
                Also notice that this version incurs extra calls for both setting and fetching unmanaged attributes (e.g., addr ); if speed is paramount, this alternative may be the slowest of the bunch.
          -- p1318
            decorators—code run automatically at function and class creation time, rather than on attribute access.
            ++THE QUIZ ************ (SSSSSSSSSS)
          -- p1319
            (SSSSSSSSSSSSSSSSSSS)
                properties are really a simple way to create a specific kind of descriptor—one that runs functions on attribute accesses.  @
            

        Decorators  1321
          -- p1321
            As we’ll see, many of the concepts we studied earlier—especially state retention—show up regularly in decorators.
            Besides covering decorator construction details, this chapter serves as a more realistic case study of Python in action.  [EEEEE SSSSSS]
                As an extra perk, some of the code we’ll write here may be used as general-purpose tools in your day-to-day programs.  [EEEEE SSSSS ******  @
            Decoration is a way to specify management or augmentation code for functions and classes.
          -- p1322
            In short, decorators provide a way to insert automatically run code at the end of function and class definition statements—at the end of a def for function decorators, and at the end of a class for class decorators.  @
            (Call proxies  Interface proxies)
            <Managing Functions and Classes>
          -- p1323
            In other words, function decorators can be used to manage both function calls and function objects, and class decorators can be used to manage both class instances and classes themselves.
                Regardless of the role they play, decorators provide a convenient and explicit way to code tools useful both during program development and in live production systems.
            In addition, many popular Python toolkits include decorators to perform tasks such as managing database or user-interface logic.  (!!!!)  @
            For more general tasks, programmers can code arbitrary decorators of their own. For example, function decorators may be used to augment functions with code that adds call tracing or logging, performs argument validity testing during debugging, automatically acquires and releases thread locks, times calls made to functions for optimization, and so on. Any behavior you can imagine adding to—really, wrapping around—a function call is a candidate for custom function decorators.  (************ (SSSSS))  @!
                (=Class decorators)
            ((That said, decorators provide an explicit syntax for such tasks, which makes intent clearer, can minimize augmentation code redundancy, and may help ensure correct API usage:
          -- p1324
            • Decorators are applied once, when the subject function or class is defined; it’s not necessary to add extra code at every call to the class or function, which may have to be changed in the future.
                • Because of both of the prior points, decorators make it less likely that a user of an API will forget to augment a function or class according to API requirements.  @
            (But they should probably also keep in mind that decorators are about callable objects managing callable objects, not text expansion.)  (=vs macros)  @
          -- p1325
            The Basics
                (boils down to an automatic rebinding operation
            The decorator is coded on a line just before the def statement that defines a function or method, and it consists of the @ symbol followed by a reference to a metafunction—a function (or other callable object) that manages another function.  @
          -- p1326
            In both cases, the method name is rebound to the result of a built-in function decorator, at the end of the def statement.  (***(*))
                ((A decorator itself is a callable that returns a callable.))
            (('For example, to tap into the decoration protocol in order to manage a function just after it is created, we might code a decorator of this form:  @!
                Such a structure might be used to register a function to an API, assign function attributes, and so on.
          -- p1327
            In skeleton terms, here’s one common coding pattern that captures this idea—the decorator returns a wrapper that retains the original function in an enclosing scope:  [**!!!!]  @
                ((+'To do the same with classes, we can overload the call operation and use instance at- tributes instead of enclosing scopes:
          -- p1328
            (('To support both functions and methods, the nested function alternative works better:
          -- p1329
            'Class Decorators'
                ((They were initially resisted because of role overlap with metaclasses; in the end, though, they were adopted because they provide a simpler way to achieve many of the same goals.
                ((In the latter role, they may manage full object interfaces.
                [EE  SSS]
            'For example, to simply manage a class just after it is created, return the original class itself:  @
          -- p1330
            To instead insert a wrapper layer that intercepts later instance creation calls, return a different callable object:
            The callable returned by such a class decorator typically creates and returns a new instance of the original class, augmented in some way to manage its interface. For example, the following inserts an object that intercepts undefined attributes of a class instance:  (****)  @
             Like function decorators, class decorators are commonly coded as either “factory” functions that create and return callables, classes that use __init__ or __call__ methods to intercept call operations, or some combination thereof.
                Factory functions typically retain state in enclosing scope references, and classes in attributes.
          -- p1331
          -- p1332
            Decorator Nesting
                It’s irrelevant which is nested, as long as both steps run on later calls.
                To support multiple nested steps of augmentation this way, decorator syntax allows you to add multiple layers of wrapper logic to a decorated function or method. When this feature is used, each decorator must appear on a line of its own. **** (EE SS)  @
                'The last decorator listed is the first applied, and is the most deeply nested when the original function name is later called (insert joke about Python “interior decorators” here).
          -- p1333
            We use lambda functions to implement wrapper layers here (each retains the wrapped function in an enclosing scope); in practice, wrappers can take the form of functions, callable classes, and more. When designed well, decorator nesting allows us to combine augmentation steps in a wide variety of ways.  @
            Both function and class decorators can also seem to take arguments,
                By nature, this usually sets up multiple levels of state retention.
          -- p1334
            The outer function in this structure generally saves the decorator arguments away as state information, for use in the actual decorator, the callable it returns, or both.  (****)  (+the 'three levels')
                [Decorator arguments can be used to provide attribute initialization values, call trace message labels, attribute names to be validated, and much more—any sort of config- uration parameter for objects or their proxies is a candidate.  [tttt]
          -- p1335
                We’ll see more realistic examples later in this chapter that use this idea to register callable objects to an API with decoration and assign attributes to functions when they are created.  (********* ttttttt  @
            CODING FUNCTION DECORATORS
                Tracing Calls (!!! *  EE)
            For function calls, the @ decoration syntax can be more convenient than modifying each call to account for the extra logic level, and it avoids accidentally calling the original function directly. Consider a nondecorator equivalent such as the following: (!!*)  @
            -- p1336
          -- p1337
            'Decorator State Retention Options'
                (=better version of prior version   EE(EEE
                ; notice how the spam and eggs functions each have their own calls counter, because each decoration creates a new class instance:
          -- p1338
            Moving state variables out to the global scope with declarations is one candidate, and works in both 2.X and 3.X:  (but will be shared by every wrapped function)
          -- p1339
            (or using closures(??)
          -- p1340
            [or using Function attributes
            However, function attributes also have substantial advantages. For one, they allow access to the saved state from outside the decorator’s code; nonlocals can only be seen inside the nested function itself, but function attributes have wider visibility. For another, they are far more portable; this scheme also works in 2.X, making it version-neutral.
          -- p1341
            Because decorators often imply multiple levels of callables, you can combine functions with enclosing scopes, classes with attributes, and function attributes to achieve a variety of coding structures.  [!!(!*)]  @
             (Class Blunders I: Decorating Methods)  @
          -- p1342
            This isn’t a bug, but it’s wildly subtle. (!!)
          -- p1343
            Using nested functions to decorate methods
                If you want your function decorators to work on both simple functions and class-level methods, the most straightforward solution lies in using one of the other state retention solutions described earlier—code your function decorator as nested def s, so that you don’t depend on a single self instance argument to be both the wrapper class instance and the subject class instance.  @
          -- p1344
            Although the nested function solution illustrated in the prior section is the most straightforward way to support decorators that apply to both functions and class-level methods, other schemes are possible. The descriptor feature we explored in the prior chapter, for example, can help here as well.
          -- p1345
            ('Consider the following alternative tracing decorator, which also happens to be a descriptor when used for a class-level method:
          -- p1346
            Alternatively, we could use a nested function and enclosing scope references to achieve the same effect—the following version works the same as the preceding one, by swap- ping a class and object attributes for a nested function and scope references. It requires noticeably less code, but follows the same four-step process on each decorated method call:
            [[!! Add print statements to these alternatives’ methods to trace the multistep get/call process on your own, and run them with the same test code as in the nested function alternative shown earlier (see file calltracer-descr.py for their source).  (but may be costly in this instance
          -- p1347
            In the rest of this chapter we’re going to be fairly casual about using classes or functions to code our function decorators, as long as they are applied only to functions. Some decorators may not require the instance of the original class, and will still work on both functions and methods if coded as a class—
            THE MORAL OF THIS STORY, THOUGH, IS THAT IF YOU WANT YOUR DECORATORS TO WORK ON BOTH SIMPLE FUNCTIONS AND METHODS, YOU’RE PROBABLY BETTER OFF USING THE NESTED-FUNCTION-BASED CODING PATTERN OUTLINED HERE INSTEAD OF A CLASS WITH CALL INTERCEPTION.  @
          -- p1348
          -- p1349
            In this specific case, a nondecorator approach would allow the subject functions to be used with or without timing, but it would also complicate the call signature when timing is desired—we’d need to add code at every call instead of once at the def.
            In general, decorators may be preferred when functions are already deployed as part of a larger system, and may not be easily passed to analysis functions at calls. On the other hand, because decorators charge each call to a function with augmentation logic, a nondecorator approach may be better if you wish to augment calls more selectively.
          -- p1350
            The timer decorator of the prior section works, but it would be nice if it were more configurable—
          -- p1351
            We can put this structure to use in our timer to allow a label and a trace control flag to be passed in at decoration time. (?? (!! =*)
            Mostly all we’ve done here is embed the original Timer class in an enclosing function, in order to create a scope that retains the decorator arguments per deployment.  (++++ SSSSS EEEE  @
          -- p1352
          -- p1353
            As is, this timing function decorator can be used for any function, both in modules and interactively. In other words, it automatically qualifies as a general-purpose tool for timing code in our scripts.  [***** EEEE SS  @
            Coding Class Decorators  (--> EE
                Singleton Classes
                This code implements the classic singleton coding pattern, where at most one instance of a class ever exists.
          -- p1354
          -- p1355
            To make this decorator a fully general-purpose tool, [EEEEE *******
          -- p1356
            'we can use this hook to intercept method calls in a controller class and propagate them to an embedded object.'
                In this code, the Wrapper class intercepts access to any of the wrapped object’s named attributes, prints a trace message, and uses the getattr built-in to pass off the request to the wrapped object. Specifically, it traces attribute accesses made outside the wrapped object’s class; accesses inside the wrapped object’s methods are not caught and run normally by design.
            Class decorators provide an alternative and convenient way to code this __getattr__ technique to wrap an entire interface.
                As of both 2.6 and 3.0, for example, the prior class example can be coded as a class decorator that triggers wrapped instance creation, instead of passing a premade instance into the wrapper’s constructor (also augmented here to support keyword arguments with **kargs and to count the number of accesses made to illustrate changeable state):
          -- p1357
            It’s important to note that this is very different from the tracer decorator we met earlier (despite the name!). (!!)
          -- p1358
            (('As we’ll see ahead, orchestrating this is trickier than you may expect.
            ''Applying class decorators to built-in types''
                Also notice that the preceding decorates a user-defined class. Just like in the original example in Chapter 31, we can also use the decorator to wrap up a built-in type such as a list, as long as we either subclass to allow decoration syntax or perform the decoration manually—decorator syntax requires a class statement for the @ line.  @
            Attribute version skew note: (!!!!!!(ttttt))
                To work the same in 3.X, operator overloading methods generally must be redefined redundantly in the wrapper class, either by hand, by tools, or by definition in superclasses.
            -- p1359
          -- p1360
            (('Class Blunders II: Retaining Multiple Instances  @
                The net effect is that Tracer saves just one instance—the last one created.
          -- p1361
                The problem here is bad state retention—we make one decorator instance per class, but not per class instance, such that only the last instance is retained.
                The solution, as in our prior class blunder for decorating methods, lies in abandoning class-based decorators.
                  The moral here: decorators are not only arguably magical, they can also be incredibly subtle!
            [[Decorators Versus Manager Functions]]
             Essentially, class decorators shift special syntax requirements from the instance creation call to the class statement itself. This is also true for the singleton example earlier in this section—rather than decorating a class and using normal instance creation calls, we could simply pass the class and its construction arguments into a manager function:
             Alternatively, we could use Python’s introspection facilities to fetch the class from an already created instance (assuming creating an initial instance is acceptable):
          -- p1362
                For example, in the negatives column, decorators may suffer from three potential drawbacks, which can vary per decorator type:  (--> !!)
            That said, none of these is a very serious issue. For most programs, decorations’ uni- formity is an asset, the type difference is unlikely to matter, and the speed hit of the extra calls will be insignificant. Furthermore, the latter of these occurs only when wrappers are used, can often be negated if we simply remove the decorator when optimal performance is required, and is also incurred by nondecorator solutions that add wrapping logic (including metaclasses, as we’ll see in Chapter 40).
            Compared to the manager (a.k.a. “helper”) function solutions of the prior section, decorators offer:
                Explicit syntax
                Code maintenance
                Consistency
                Decorators also promote code encapsulation to reduce redundancy and minimize future maintenance effort; although other code structuring tools do too, decorators add explicit structure that makes this natural for augmentation tasks.  @
                    (especially as a tool for using libraries and APIs correctly
            -- p1363
          -- p1364
            Historic anecdote: I can recall similar arguments being made both for and against constructor functions in classes—prior to the introduction of __init__ methods, programmers achieved the same effect by running an instance through a method manually when creating it (e.g., X=Class().init() ).  @
            ''Managing Functions and Classes Directly''
                Because decorators work by running new functions and classes through decorator code, they can also be used to manage function and class objects themselves, not just later calls made to them.
                Imagine, for example, that you require methods or classes used by an application to be registered to an API for later processing (perhaps that API will call the objects later, in response to events).
          -- p1365
            When this code is run the decorated objects are added to the registry by name, but they still work as originally coded when they’re called later, without being routed through a wrapper layer. In fact, our objects can be run both manually and from inside the registry table:
            A user interface might use this technique, for example, to register callback handlers for user actions. Handlers might be registered by function or class name, as done here, or decorator arguments could be used to specify the subject event; an extra def statement enclosing our decorator could be used to retain such arguments for use on decoration.  ***********  @
          -- p1366
                This example is artificial, but its technique is very general. For example, function decorators might also be used to process function attributes, and class decorators might insert new class attributes, or even new methods, dynamically.
             --
            for the remainder of this chapter, let’s turn to two larger case studies of decorators at work.  [EEEEEEEEEEEEEEEEEEEEEEEEEE]  @
                Implementing Private Attributes
          -- p1367
            When a private attribute access is detected, this version uses the raise statement to raise an exception, along with an error message; the exception may be caught in a try or allowed to terminate the script.
                = the EEEEEEEEEEEE
          -- p1368
          -- p1369
                inheritance vs delegation
                decorator arguments
                state retention and enclosing scopes
                    (Speaking of enclosing scopes, there are actually three levels of state retention at work in this code:
          -- p1370
            (( (Using __dict__ and __slots__ (and other virtual names)
                Because of that, this code will work for most classes—including those with “virtual” class-level attributes based on slots, properties, descriptors, and even __getattr__ and its ilk.
            (( Now that we have a Private implementation, it’s straightforward to generalize the code to allow for Public declarations too—
            'Private and Public declarations are intended to be mutually exclusive:
          -- p1371
          -- p1372
          -- p1373
            , there are ways to remove decorations automatically if desired.
            As coded, the proxy class is a classic class when run under 2.X, but a new-style class when run by 3.X. As such, the code supports any client class in 2.X, but in 3.X fails to
          -- p1374
            We’ve met this issue a few times already in this book, but let’s take a quick look at its impact on the very realistic code we’ve written here, and explore a workaround to it.
                Caveat: Implicitly run operator overloading methods fail to delegate under 3.X  (SSSSSSSSSSS !!!!!)  @
            The most direct workaround in 3.X is to redefine redundantly in onInstance all the operator overloading methods that can possibly be used in wrapped objects. Such extra methods can be added by hand, by tools that partly automate the task (e.g., with class decorators or the metaclasses discussed in the next chapter), or by definition in reusable superclasses. Though tedious—and code-intensive enough to largely omit here—we’ll explore approaches to satisfying this 3.X-only requirement in a moment.  (*******)
          -- p1375
          -- p1376
            In other words, this is a matter of built-in operations versus explicit calls; it has little to do with the actual names of the methods involved. Just for built-in operations, Python skips a step for 3.X’s new-style classes.  [!!!]
                Approaches to redefining operator overloading methods for 3.X
                However, it isn’t an impossibly major coding effort; can be automated to some extent with tools or superclasses; suffices to make our decorator work in 3.X; and may allow operator overloading names to be declared Private or Public too, assuming overloading methods trigger the failIf test internally.
                 = Inline definition.
          -- p1377
                 = Mix-in superclasses. (**!)
                    The first catches built-ins and forcibly reroutes down to the subclass __get attr__ .
                    The second catches built-ins and reroutes to the wrapped object directly.
            Notice how these classes catch operation calls rather than operation attribute fetches, and thus must perform the actual operation by delegating a call or expression:
          -- p1378
            Either one of these superclass mix-ins will be extraneous code, but must be implemented only once, and seem much more straightforward than the various metaclass- or decorator-based tool approaches you’ll find online that populate each proxy class with the requisite methods redundantly (see the class augmentation examples in Chapter 40 for the principles behind such tools).  (*****)  @
                First, compare the following mutation of the first mix-in—which uses a simpler coding structure but will incur an extra call per built-in operation, making it slower (though perhaps not significantly so in a proxy context):
          -- p1379
            [[ This coding may be the most concise, but also the most implicit and complex, and is fairly tightly coupled with its subclasses by the shared name.
                If you care to experiment further, see files access2_builtins*.py in the book examples package for complete codings of these options;  [*** !!]
          -- p1380
            [[ Because all its classes are new-style, delegation-based code is more difficult—though not necessarily impossible—in Python 3.X.
                (( Implementation alternatives: __getattribute__ inserts, call stack inspection
             [[[[  One downside of the privacy example is that instance objects are not truly instances of the original class—they are instances of the wrapper instead. In some programs that rely on type testing, this might matter. To support such cases, we might try to achieve similar effects by inserting a __getattribute__ and a __setattr__ method into the original class, to catch every attribute reference and assignment made on its instances. These inserted methods would pass valid requests up to their superclass to avoid loops, using the techniques we studied in the prior chapter.
                    As we’ll see there, metaclasses are not strictly required for changing classes this way, because class decorators can often serve the same role.
                    In fact, most Python programmers will probably find this example to be largely or totally irrelevant, apart from serving as a demonstration of decorators in action. Most large Python programs get by successfully without any such controls at all.
           -- p1381
          -- p1382
            Example: Validating Function Arguments
                As a final example of the utility of decorators, this section develops a function decora- tor that automatically tests whether arguments passed to a function or method are within a valid numeric range. It’s designed to be used during either development or production, and it can be used as a template for similar tasks (e.g., argument type testing, if you must).
                ++ 'There, we noted that if we wanted the code to be robust it would be a good idea to check the percentage to make sure it’s not too large or too small. We could implement such a check with either if or assert statements in the method itself, using inline tests:
                A more useful and interesting alternative would be to develop a general tool that can perform range tests for us automatically, for the arguments of any function or method we might code now or in the future. A decorator approach makes this explicit and convenient:
          -- p1383
                Isolating validation logic in a decorator simplifies both clients and future maintenance.
            Here, we mean to validate the values of function arguments when passed, rather than attribute values when set.
            rangetest1.py
            New here, notice this code’s use of the __debug__ built-in variable—
                In other words, the decorator automatically removes its augmentation logic when –O is used, without requiring you to physically remove the decoration lines in your code.  (**************  !!!!! SS)  @!
          -- p1384
          -- p1385
            Assuming this is a debugging tool only, you can use this flag to optimize your program for production use:
          -- p1386
          -- p1387
          -- p1388
            (** On validation errors, we get an exception as before when one of the method test lines is uncommented, unless the -O command-line argument is passed to Python to disable the decorator’s logic:  @
            Function introspection  (*****)
                It turns out that the introspection API available on function objects and their associated code objects has exactly the tool we need.
          -- p1389
                func.__code__
          -- p1390
            (( Although our range-testing tool works as planned, three caveats remain—it doesn’t detect invalid calls, doesn’t handle some arbitrary-argument signatures, and doesn’t fully support nesting.
          -- p1391
          -- p1392
            Decorator Arguments Versus Function Annotations
                As we learned in Chapter 19, annotations allow us to associate expressions with arguments and return values, by coding them in the def header line itself; Python collects annotations in a dictionary and attaches it to the annotated function.  @
          -- p1393
          -- p1394
             ( In fact, using annotation instead of decorator arguments in this example actually limits its utility. (!!)
          -- p1395
            ; type checking may come in handy in isolated cases while debugging and when interfacing with code written in more restrictive languages, such as C++.  (!! (**))
          -- p1396
            ((QUIZ(!!)))
             Note that you will probably need to use function object attributes to keep track of total time, since you won’t have a nested class for state retention and can’t access nonlocals from outside the decorator code. As an added bonus, this makes your decorator usable on both Python 3.X and 2.X.
          -- p1397
          -- p1398
          -- p1399
          -- p1400
            Here too I split the self-test code off to a separate file, so the decorator could be imported elsewhere without triggering the tests, and without requiring a __name__ test and indenting:  @
          -- p1401
          -- p1402
            This handles ranges, type tests, value testers, and almost anything else you can dream up in an expressive language like Python.  [EEEEEEEEEEEEEEEEE]  @


            Metaclasses  1407
          -- p1407
            In a sense, metaclasses simply extend the code-insertion model of decorators.
                In a similar spirit, metaclasses allow us to intercept and augment class creation—they provide an API for inserting extra logic to be run at the conclusion of a class statement, albeit in different ways than decorators. (**)
            As in the prior chapter, part of our goal here is also to show more realistic code examples than we did earlier in this book. (**)  --> EE  @
          -- p1408
            Still, metaclasses have a wide variety of potential roles, and it’s important to know when they can be useful. For example, they can be used to enhance classes with features like tracing, object persistence, exception logging, and more. They can also be used to con- struct portions of a class at runtime based upon configuration files, apply function decorators to every method of a class generically, verify conformance to expected interfaces, and so on.  @
                In their more grandiose incarnations, metaclasses can even be used to implement alternative coding patterns such as aspect-oriented programming, object/relational mappers (ORMs) for databases, and more. Although there are often alternative ways to achieve such results—as we’ll see, the roles of class decorators and metaclasses often intersect—metaclasses provide a formal model tailored to those tasks.
            Probably the reason for studying metaclasses most relevant to this book is that this topic can help demystify Python’s class mechanics in general.  [!!!!]  @
                Although you may or may not code or reuse them in your work, a cursory understanding of metaclasses can impart a deeper understanding of Python at large. 1
                        1. And to quote a Python 3.3 error message I just came across: “TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases” (!). This reflects an erroneous use of a module as a superclass, but metaclasses may not be as optional as developers imply —a theme we’ll revisit in the next chapter’s conclusion to this book.
          -- p1409
            [ Special attributes like __class__ and __dict__ allow us to inspect internal implementation aspects of Python objects, in order to process them generically—to list all attributes of an object, display a class’s name, and so on.
          -- p1410
            As mentioned in this chapter’s introduction, metaclasses are a continuation of this story —they allow us to insert logic to be run automatically at the end of a class statement, when a class object is being created.  @
                Though strongly reminiscent of class decorators, the metaclass mechanism doesn’t rebind the class name to a decorator callable’s result, but rather routes creation of the class itself to specialized logic.  (= A Language of Hooks  @
            , attributes can often be managed with properties, descriptors, or attribute interception methods.
            .
                • Although class decorators are often used to manage instances, they can also be used to manage classes instead, much like metaclasses.
                • Similarly, while metaclasses are designed to augment class construction, they can also insert proxies to manage instances instead, much like class decorators.
                In fact, the main functional difference between these two tools is simply their place in the timing of class creation.  @
          -- p1411
            As we’ll see here, metaclasses, by contrast, run during class creation to make and return the new client class. Therefore, they are often used for managing or augmenting classes themselves, and can even provide methods to process the classes that are created from them, via a direct instance relationship.
                For example, metaclasses can be used to add decoration to all methods of classes automatically, register all classes in use to an API, add user-interface logic to classes automatically, create or extend classes from simplified specifications in text files, and so on. Because they can control how classes are made—and by proxy the behavior their instances acquire—metaclass applicability is potentially very wide.  @
            (+++   • Avoid code redundancy and its associated maintenance costs by factoring class customization logic into a single location, the metaclass  @
          -- p1412
            Sometimes, though, it’s impossible to predict such augmentation when classes are coded. Consider the case where classes are augmented in response to choices made in a user interface at runtime, or to specifications typed in a configuration file.
                Although we could code every class in our imaginary set to manually check these, too, it’s a lot to ask of clients ( required is abstract here—it’s something to be filled in):
          -- p1413
                It would be better if there was a simple way to enforce the augmentation in the subject classes, so that they don’t need to deal with the augmentation so explicitly, and would be less likely to forget to use it altogether. In other words, we’d like to be able to insert some code to run automatically at the end of a class statement, to augment the class.
                class Client1(metaclass=Extras): ...  (*****)  @
            .
            ([[Metaclasses Versus Class Decorators: Round 1]])
          -- p1414
          -- p1415
            Decorators can be used to manage both instances and classes, and intersect most strongly with metaclasses in the second of these roles, but this discrimination is not absolute. In fact, the roles of each are determined in part by their mechanics.
                As we’ll see ahead, decorators technically correspond to metaclass __init__ methods, used to initialize newly created classes. Metaclasses have additional customization hooks beyond class initialization, though, and may perform arbitrary class construction tasks that might be more difficult with decorators. This can make them more complex, but also better suited for augmenting classes as they are being formed.
                For example, metaclasses also have a __new__ method used to create a class, which has no analogy in decorators;  @
                Moreover, metaclasses may also provide behavior acquired by classes in the form of methods, which have no direct counterpart in decorators either;
          -- p1416
            To understand metaclasses, you first need to understand a bit more about Python’s type model and what happens at the end of a class statement. As we’ll see here, the two are intimately related.
          -- p1417
            ((ouroboros  =classes and types))
          -- p1418
            Metaclasses Are Subclasses of Type
                Because the notion of type is the same as class today, we can subclass type with normal object-oriented techniques and class syntax to customize it.  [!!!!!!  ******]  @
          -- p1419
            In other words, to control the way classes are created and augment their behavior, all we need to do is specify that a user-defined class be created from a user-defined meta- class instead of the normal type class.  [*****]  @
                [[+ 'Notice that this type instance relationship is not quite the same as normal inheritance.
            [[ Subclassing the type class to customize it is really only half of the magic behind meta-classes. We still need to somehow route a class’s creation to the metaclass, instead of the default type.
                'To fully understand how this is arranged, we also need to know how class statements do their business. (SSSS(!))   (+hooks for customizing subclasses =__new__ and __init__  @
          -- p1420
            In fact, you can call type this way yourself to create a class dynamically—
                x = type('Spam', (), {'data': 1, 'meth': (lambda x, y: x.data + y)})  @
            Because this type call is made automatically at the end of the class statement, though, it’s an ideal hook for augmenting or otherwise processing a class. The trick lies in replacing the default type with a custom subclass that will intercept this call. The next section shows how.
            Declaring Metaclasses
                SSSSSS (**********)
          -- p1421
            In Python 3.X, list the desired metaclass as a keyword argument in the class header:
                ++  class Spam(Eggs, metaclass=Meta):  ****
            We can get the same effect in Python 2.X, but we must specify the metaclass differently —using a class attribute instead of a keyword argument:  (!!)
            ((  Also in 2.X, a module level __metaclass__ global variable is available to link all classes in the module to a metaclass.
          -- p1422
            [[ When a specific metaclass is declared per the prior sections’ syntax, the call to create the class object run at the end of the class statement is modified to invoke the meta- class instead of the type default:
            ''The next section shows how we might go about coding this final piece of the metaclass puzzle.
            How, though, do we actually code a metaclass that customizes type?
                By definition, they are simply classes that inherit from type.
                Their only substantial distinctions are that Python calls them automatically at the end of a class statement, and that they must adhere to the interface expected by the type superclass.
          -- p1423
            [A Basic Metaclass]
                This metaclass doesn’t really do anything (we might as well let the default type class create the class), but it demonstrates the way a metaclass taps into the metaclass hook to customize—  @
          -- p1424
            Presentation note: I’m truncating addresses and omitting some irrelevant built-in __X__ names in namespace dictionaries in this chapter for brevity, and as noted earlier am forgoing 2.X portability due to differing declaration syntax. To run in 2.X, ....
            Metaclasses can also tap into the __init__ protocol invoked by the type object’s __call__ . In general, __new__ creates and returns the class object, and __init__ initial- izes the already created class passed in as an argument. Metaclasses can use either or both hooks to manage the class at creation time:  [[***(*)]]  @
          -- p1425
            'Other Metaclass Coding Techniques'
                Using simple factory functions (*)
                    , any callable object can in principle be used as a metaclass, provided it accepts the arguments passed and returns an object compatible with the intended class.
          -- p1426
                Overloading class creation calls with normal classes
                    Because normal class instances can respond to call operations with operator overloading, they can serve in some metaclass roles too, much like the preceding function.
          -- p1427
          -- p1428
            Although such alternative forms work, most metaclasses get their work done by redefining the type superclass’s __new__ and __init__ ; in practice, this is usually as much control as is required, and it’s often simpler than other schemes.  ****  @
                Moreover, metaclasses have access to additional tools, such as class methods we’ll explore ahead, which can influence class behavior more directly than some other schemes.
            [['Overloading class creation calls with metaclasses']]
          -- p1429
            Because of this, name lookup with metaclasses may be somewhat different than what we are accustomed to.  (!!!!)   (=metaclass of a metaclass)
                    SubMeta  SuperMeta  (????)
            [[(Here’s an illustration of the issue in simpler terms—a normal superclass is skipped for built-ins, but not for explicit fetches and calls, the latter relying on normal attribute name inheritance:)]]
          -- p1430
            Of course, this specific example is a special case: catching a built-in run on a metaclass, a likely rare usage related to __call__ here. But it underscores a core asymmetry and apparent inconsistency: normal attribute inheritance is not fully used for built-in dispatch —for both instances and classes.
                To truly understand this example’s subtleties, though, we need to get more formal about what metaclasses mean for Python name resolution in general.
            [[Inheritance and Instance
                Because metaclasses are specified in similar ways to inheritance superclasses, they can be a bit confusing at first glance. A few key points should help summarize and clarify the model:  @
          -- p1431
          -- p1432
          -- p1433
            [[ Metaclass Versus Superclass ]]
                —the acquisition of names by metaclass instances is distinct from the normal inheritance used for class instances:
                + 'This is why metaclasses often do their work by manipulating a new class’s namespace dictionary, if they wish to influence the behavior of later instance objects—instances will see names in a class, but not its metaclass.
          -- p1434
            In fact, classes acquire metaclass attributes through their __class__ link, in the same way that normal instances inherit from classes through their __class__ , which makes sense, given that classes are also instances of metaclasses.
                The chief distinction is that instance inheritance does not follow a class’s __class__ , but instead restricts its scope to the __dict__ of each class in a tree per the MRO—following __bases__ at each class only, and using only the instance’s __class__ link once:
            [[ Inheritance: The Full Story
                To illustrate the basics of this conceptual merger, in the following, the instance inherits from all its classes; the class inherits from both classes and metaclasses; and metaclasses inherit from higher metaclasses (supermetaclasses?):
          -- p1435
            Both inheritance paths—class and metaclass—employ the same links, though not recursively: instances do not inherit their class’s metaclass names, but may request them explicitly:
            If you care about metaclasses, or must use code that does, study these examples, and then study them again. In effect,  (....)
                In fact, understanding this example is important to Python name resolution in general, as the next section explains.  @
            Now that we know about metaclass acquisition, we’re finally able to formalize the inheritance rules that they augment.  [!!!!]  @
          -- p1436
            (Most programmers need only be aware of the first of these rules, and perhaps the first step of the second—which taken together correspond to 2.X classic class inheritance.)  @
                (( The descriptors special case
                    —those that define __set__ methods to intercept assignments—are given precedence, such that their names override other inheritance sources.
          -- p1437
            ......
            (( ( Python’s inheritance algorithm: The somewhat-more-complete version
          -- p1438
            ((( ????  Assignment inheritance
            ( Because descriptors are also the basis for other advanced attribute tools such as properties and slots, this inheritance pre-check on assignment is utilized in multiple contexts.
          -- p1439
            [[  The built-ins special case
          -- p1440
            [[ METACLASS METHODS
                Just as important as the inheritance of names, methods in metaclasses process their instance classes—not the normal instance objects we’ve known as “self,” but classes themselves.
          -- p1441
            Though they differ in inheritance visibility, much like class methods, metaclass meth- ods are designed to manage class-level data.
                (  In other words, metaclass methods can be thought of as implicit class methods, with limited visibility:  @!
          -- p1442
            ( Operator Overloading in Metaclass Methods
                Just like normal classes, metaclasses may also employ operator overloading to make built-in operations applicable to their instance classes.
          -- p1443
            Example: Adding Methods to Classes  [EEEEEEEEEEE]
                In this and the following section, we’re going to study examples of two common use cases for metaclasses: adding methods to a class, and decorating all methods automatically.  (+MORE  =DO SEARCHES ON INTERNET)
                    Moreover, both give us an opportunity to contrast class decorators and metaclasses— our first example compares metaclass- and decorator-based implementations of class augmentation and instance wrapping, and the second applies a decorator with a metaclass first and then with another decorator.
                —helper functions can usually suffice, but metaclasses provide an explicit structure and minimize the maintenance costs of changes in the future.  [****]
          -- p1444
            This works because methods can always be assigned to a class after it’s been created, as long as the methods assigned are functions with an extra first argument to receive the subject self instance—this argument can be used to access state information accessible from the class instance, even though the function is defined independently of the class.
          -- p1445
            Metaclass-Based Augmentation [***]  @
                Although manual augmentation works, in larger programs it would be better if we could apply such changes to an entire set of classes automatically. That way, we’d avoid the chance of the augmentation being botched for any given class. Moreover, coding the augmentation in a single location better supports future changes—all classes in the set will pick up changes automatically.
                One way to meet this goal is to use metaclasses. If we code the augmentation in a metaclass, every class that declares that metaclass will be augmented uniformly and correctly and will automatically pick up any changes made in the future. The following code demonstrates:
          -- p1446
            In fact, if all we need to do is always add the same two methods to a set of classes, we might as well code them in a normal superclass and inherit in subclasses. In practice, though, the metaclass structure supports much more dynamic behavior. For instance, the subject class might also be configured based upon arbitrary logic at runtime:
            ''Because of this, both tools in principle can be used to manage both instances of a class and the class itself. In practice, though, metaclasses incur extra steps to manage instances, and decorators incur extra steps to create new classes.  [****]
          -- p1447
            'In pure augmentation cases, decorators can often stand in for metaclasses. For example, the prior section’s metaclass example, which adds methods to a class on creation, can also be coded as a class decorator;  @
          -- p1448
          -- p1449
          -- p1450
            Again, decorators essentially serve the same role as metaclass __init__ methods.
          -- p1451
            .
                • Because decorators run after a class is created, they incur an extra runtime step in class creation roles.
                • Because metaclasses must create classes, they incur an extra coding step in instance management roles.
          -- p1452
            the next section concludes this chapter with one more common use case—applying operations to a class’s methods automatically at class creation time.  @
                [[Example: Applying Decorators to Methods
                It’s also possible to use them in combination, as complementary tools. In this section, we’ll explore an example of just such a combination—applying a function decorator to all the methods of a class.  [******   SSSSSSSSS  EEEEEEEEEEEEeeeeeeeee
          -- p1453
            <<Tracing with Metaclasses and Decorators>>  ****
                The manual decoration scheme of the prior section works, but it requires us to add decoration syntax before each method we wish to trace and to later remove that syntax when we no longer desire tracing. If we want to trace every method of a class, this can become tedious in larger programs. In more dynamic contexts where augmentations depend upon runtime parameters, it may not be possible at all. It would be better if we could somehow apply the tracer decorator to all of a class’s methods automatically.     With metaclasses, we can do exactly that—
           -- p1454
          -- p1455
            Applying Any Decorator to Methods
                The prior metaclass example works for just one specific function decorator—tracing.  However, it’s trivial to generalize this to apply any decorator to all the methods of a class. All we have to do is add an outer scope layer to retain the desired decorator, much like we did for decorators in the prior chapter.  [***** SSSSSSS  EEEEEEEEE
          -- p1456
            —Python’s decorators support arbitrary nesting and combinations:  @
          -- p1457
            Notice that the class decorator returns the original, augmented class, not a wrapper layer for it (as is common when wrapping instance objects instead). As for the metaclass version, we retain the type of the original class—an instance of Person is an instance of Person , not of some wrapper class.
                This distinction can matter in programs that require type testing for instances to yield the original class, not a wrapper. When augmenting a class instead of an instance, class decorators can retain the original class type.   [[ !!!!!!!  @
          -- p1458
             (( Finally, it’s possible to combine decorators such that each runs per method call, but it will likely require changes to those we’ve coded here.
          -- p1459
            [[  ; the last of these includes a sampling of typical application-level programs for self-study.  @
            +METACLASS QUESTIONS  ***(*)
          -- p1466
            —from GUIs, the Web, and databases to numeric programming, robotics, and system administration. See Chapter 1 and your favorite web browser for pointers to popular tools and topics.  @
            (( THE CERTIFICATION DIPLOMA SCRIPT ))



            
             All Good Things  1461
            -- -- -- --
            Installation  1473
            The Py 3 Win Launcher  1489
             Python Changes and this book  1503
             Solutions to exercises  1517

}}}
---- lpy08-exceptions.txt -- {{{
        Part VII - Exceptions and Tools
        Chapter 33 - Exception Basics

            ----
        exceptions (= defined as in the text) (*) @
            {{{
            events that can modify the flow of control through a program.
            --
            lpy3-p1133
            }}}
        In Python, exceptions are triggered automatically (on/by)
            {{{
            on errors
             + can be triggered and intercepted by your code.
            --
            lpy3-p1133
            }}}
        Catch and recover from exceptions (raised by Python, or by you.) @
            {{{
            try/except
              .
            --
            lpy3-p1133
            }}}
        Perform cleanup actions, whether exceptions occur or not. (@)
            {{{
            finally
            --
            lpy3-p1133
            }}}
        Trigger an exception manually in your code. @
            {{{
            raise
            --
            lpy3-p1133
            }}}
        Conditionally trigger an exception in your code. (**(*!)) (@)
            {{{
            assert
            --
            lpy3-p1133
            }}}
        Implement context managers in Python 2.6, 3.0, and later (optional in 2.5). (??) (@)
            {{{
            with/as
            --
            lpy3-p1133
            }}}
            ----

            ----
        code exceptions of your own. (= how they are built) @
            {{{
            are coded with classes
            --
            lpy3-p1133
            }}}
        In a nutshell, exceptions let us *(?) @
            {{{
            jump out of arbitrarily large chunks of a program.
                = 'As we have no hope of finishing the pizza task in such unusual cases,
            That’s exactly what exceptions let you do:
              you can jump to an exception handler in a single step, abandoning all function calls begun since the exception handler was entered.
              .
              .
            One way to think of an exception is as a sort of structured “super go to.”
            --
            lpy3-p1133
            }}}
        exception handler (= is and does what? @
            {{{
            'Code in the exception handler can then respond to the raised exception as appropriate (by calling the fire department, for instance!).'
              .
            more specifically, the try statement(!!) is the exception handler(!!)
            --
              (++no(!): the code in the except-block(=under the except-clause) is the handler (?(!!))  p1137
            --
            lpy3-p1134
            }}}
        An exception handler (try statement)  (= does what in two steps when it encounters an error? (**!) @
            {{{
            An exception handler (try statement)
              = leaves a marker and executes some code.
            Somewhere further ahead in the program, an exception is raised that makes Python jump back to that marker, abandoning any active functions that were called after the marker was left.
            --
            lpy3-p1134
            }}}
        This protocol provides a coherent way to respond to unusual events.  Moreover, because Python jumps to the handler statement immediately, your code is simpler - (=because) there is usually no need to
            {{{
            check status codes after every call to a function that could possibly fail.
            --
            lpy3-p1134
            }}}
        In Python programs, exceptions are typically used for a variety of purposes. (!!) @
            {{{
            1. Exception processing is useful for error handling, termination actions, and event notification.
            -- (p1142)
            Error handling
                (+catch and handle or ignore and let python handle)
              .
            Event notification
                can also be used to signal valid conditions without you having to pass result flags around a program or test them explicitly.
                = 'For instance, a search routine might raise an exception on failure, rather than returning an integer result code
              .
            Special-case handling
                = 'Sometimes a condition may occur so rarely that it’s hard to justify convoluting your code to handle it in multiple places.
                [+also common to use asserts to check that the conditions are right during the dev. process]
              .
             Termination actions
                (=w. finally (+ with is a newer alternative, when objects support it))
              .
            Unusual control flows
                For instance, although the language does not explicitly support backtracking, you can implement it in Python by using exceptions and a bit of support logic to unwind assignments.
                ((= 'a raise, for instance, can be used to jump out of multiple loops. (*)

                         (+footnote 1)
            --
            lpy3-p1134,1135
            }}}
        what happens (=with the execution of your program) when you catch and handle an exception? (*) (@)
            {{{
            If you don’t want this default(=Python stopping + writing an error message) behavior,
               code a try statement to catch and recover from the exception -
              .
            Python will jump to your try handler when the error is detected,
            and your program will resume execution after the try.
            --
            lpy3-p1134
            }}}
                ----

                ----
        '1. But true backtracking is not part of the Python language.
            {{{
            'Backtracking undoes all computations before it jumps,' (etc
              .
            = variables assigned between the time a try statement is entered and the time an exception is raised are not reset to their prior values.
            (+ 'Even the generator functions and expressions we met in Chapter 20 don’t do full backtracking - they
            --
            lpy3-p1135
            }}}
        Ex. 1:  Simple try exception handler for fetcher (***(!*))  eg. fetcher(x, 4)  (index out of bounds)  ****(*) @(@)
            {{{
            >>> try:
            ...     fetcher(x, 4)
                        # =Catch and recover
            ... except IndexError:
            ...     print('got exception')
            ...
            got exception
            >>>
              .
              .
              .
            >>> def catcher():
                    try:
                        fetcher(x, 4)
                    except IndexError:
                        print('got exception')
                    print('continuing')
              .
            >>> catcher()
            got exception
            continuing
            >>>
            --
            lpy3-p1135,p1136;p1137
            }}}
        te: stack trace (**(!!)) @
            {{{
            = a list of all the lines and functions that were active when the exception occurred. (!!)
            --
            lpy3-p1136
            }}}
        the except-clause(=line) does what? (!) (@)
            {{{
            = names the exception raised (*)
            --
            lpy3-p1137
            }}}
        when is the  default e.handling (= terminating the program immediately) acceptable? ()  (+ex. when it's not) (@)
            {{{
            for simple scripts; errors often should be fatal, and the best you can do when they occur is inspect the standard error message.
              .
            server programs (etc
            --
            lpy3-p1136
            }}}
        control continues after ____ when a try block is run and done (=after an exception is caught) (!!) @(@)
            {{{
            Once you’ve caught the exception, control continues after(!!) the entire try that caught the exception, not after the statement that kicked it off.
              (+ 'In fact, Python clears the memory of any functions that were exited as a result of the exception, like fetcher in our example; they’re not resumable.
            --
            lpy3-p1137
            }}}
        ((+note about cutting and pasting the try examples at the prompt))
            {{{
             (!!)
            --
            lpy3-p1137
            }}}
                ----

                ----
        trigger an exception  manually (= fr. w.in a script) *  (eg. the built-in IndexError exception) * @
            {{{
            >>> try:
                    # Trigger exception manually
            ...     raise IndexError
            ... except IndexError:
            ...     print('got exception')
            ...
            got exception
              .
              (+ as usual, terminates program if not caught)
            --
            lpy3-p1138
            }}}
        [[The raise statement introduced in the prior section raises a built-in exception defined in
            {{{
            Python’s built-in scope.
            --
            lpy3-p1138
            }}}
        +(!)you can also define new exceptions of your own that are specific to your programs. @(@)
            {{{
            User-defined exceptions are coded with classes, which inherit from a built-in exception class: usually the class named Exception:
              .
              .
                # User-defined exception
            >>> class AlreadyGotOne(Exception): pass
                  .
            >>> def grail():
                    # Raise an instance
                    raise AlreadyGotOne()
                  .
            >>> try:
            ...     grail()
                    # Catch class name
            ... except AlreadyGotOne:
            ...     print('got exception')
            ...
            got exception
            >>>
            --
            lpy3-p1138
            }}}
        an ____ clause on an except can gain access to the exception object itself. (@)
            {{{
            as
            --
            lpy3-p1138
            }}}
        Class-based exceptions allow scripts to build exception categories, which can @
            {{{
            inherit behavior, and have attached state information and methods.
            + They can also customize their error message text displayed if they’re not caught:
              .
              .
            >>> class Career(Exception):
                    def __str__(self): return 'So I became a waiter...'
              .
            >>> raise Career()
            Traceback (most recent call last):
              File "<stdin>", line 1, in <module>
            __main__.Career: So I became a waiter...
            >>>
            --
            lpy3-p1138,p1139
            }}}
        Finally, try statements can say “finally” - that is, they may include finally blocks. (= a concept called ____ in the book)
            {{{
            'Termination Actions
                = specifies termination actions that always execute “on the way out,” regardless of whether an exception occurs in the try block or not;
              .
            >>> try:
            ...     fetcher(x, 3)
                # Termination actions
            ... finally:
                    # = this line would never have been reached if an exception was raised by f1 (!!(**))
            ...     print('after fetch')
            ...
            'm'
            after fetch
            >>>
              .
            Here, if the try block finishes without an exception, the finally block will run, and the program will resume after the entire try.
              .
            + when an exception does occur in a try block, finally blocks are executed while the program is being unwound: (**(!))
            --
            lpy3-p1139
            }}}
        function that does a try finally and then prints 'after try' (= why the 'after try' will not be printed) (**!) (@)
            {{{
            try with an error + a finally
              = will execute the action and the finally clause and then go to Py.s error handling (!)
              ((= 'propagates the exception up to a prior handler (in this case, to the default handler at the top).
            --
            lpy3-(p1139,)p1140
            }}}
            ----

            ----
        In practice, try/except combinations are useful for (**!) (@)
            {{{
            catching and recovering from exceptions,
              .
            = For instance, you might use try/except to catch errors raised by code that you import from a third-party library,
            --
            lpy3-p1140
            }}}
        try/finally combinations come in handy to
            {{{
            guarantee that termination actions will fire regardless of any exceptions that may occur in the try block’s code.
              .
            and (you might use) try/finally to ensure that calls to close files or terminate server connections are always run.
            --
            lpy3-p1140
            }}}
        as of Python 2.5, we can mix except and finally clauses in the same try statement - (+ "how they interact")
            {{{
            - the finally is run on the way out regardless of whether an exception was raised,
              and regardless of whether the exception was caught by an except clause.
            --
            lpy3-p1140
            }}}
        2.X and 3.X  alternative to try/finally when using some types of objects. @(@)
            {{{
            The with/as statement
             'runs an object’s context management logic to guarantee that termination actions occur, irrespective of any exceptions in its nested block:
                 (=like finally)
              .
                # Always close file on exit
            >>> with open('lumberjack.txt', 'w') as file:
                    file.write('The larch!\n')
            --
            lpy3-p1140
            }}}
        try/finally vs with/as (*) (@)
            {{{
            try/finally is a more general termination structure, and is often simpler than coding a class in cases where with is not already supported.
              - -
            with/as may also run startup actions too, and supports user-defined context management code with access to Python’s full OOP toolset.
            --
            lpy3-p1140
            }}}
        One way to see how exceptions are useful is to compare coding styles in Python and languages without exceptions. (!) (@)
            {{{
            For instance, if you want to write robust programs in the C language, you generally have to test return values or status codes after every operation that could possibly go astray, and propagate the results of the tests as your programs run:
                In fact, realistic C programs often have as much code devoted to error detection as to doing actual work.
             --
            in Python,
               You can instead wrap arbitrarily vast pieces of a program in exception handlers and simply write the parts that do the actual work, assuming all is normally well:
               .
               .
        def doStuff():
            # Python code
            doFirstThing()
# We don't care about exceptions here,
            doNextThing()
# so we don't need to detect them
            ...
            doLastThing()
              .
        if __name__ == '__main__':
            try:
# This is where we care about results,
                doStuff()
# so it's the only place we must check
            except:
                badEnding()
            else:
                goodEnding()
            --
            lpy3-p1140,p1141
            }}}
            ----

            ----
        why  there’s no need to instrument all your code to guard for errors, ** (@)
            {{{
            Because control jumps immediately to a handler when an exception occurs, there’s no need to instrument all your code to guard for errors,
                and there’s no extra performance overhead to run all the tests.
            (+ because Python detects errors automatically, your code often doesn’t need to check for errors in the first place.
            --
            lpy3-p1141
            }}}
        To summarize, Python exceptions are
            {{{
            a high-level control flow device.
            --
            lpy3-p1141
            }}}
        exception error-handling: ='you may not need to test the outcome of every operation (like in C)  (=because  ** (??@)
            {{{
            In general, exception processing also cuts down on the amount of error-checking code your program may require
            - because all errors filter up to handlers,
            --
            lpy3-p1142
            }}}
        2. Any uncaught exception eventually filters up to the default exception handler Python provides  (where (=in the program? @
            {{{
            at the top of your program.
            --
            lpy3-p1142
            }}}
        3. If you don’t want the default message and shutdown, you can code try/except statements to **(*) (!) (??@)
            {{{
            catch and recover from exceptions that are raised within its nested code block.
            --
            lpy3-p1142
            }}}
        statements (that) can be used to trigger an exception, exactly as if it had been raised by Python itself. **
            {{{
            raise and assert
            --
            lpy3-p1142
            }}}
                ----


        Chapter 34 - Exception Coding Details

                ----
        [full version of the original try/except statement] **(!) @
            {{{
            = the try/except/else statement **
            --
            lpy3-p1145
            }}}
        the except-part of a try-statement (*(**)) @
            {{{
            = one or more except clauses that identify exceptions to be caught
                and blocks to process them; **
            --
            lpy3-p1146
            }}}
        the general and most complete try/except/else format in Python 3.X: (****(!!)) (@)
            {{{
           .
        try:
                # Run this main
                  action first
            statements
        except name1:
                # Run if name1 is
                  raised during try block
            statements
        except (name2, name3):
                # Run if any of
                  these exceptions occur
            statements
        except name4 as var:
                # Run if name4 is raised,
                  assign instance raised
                  to var
            statements
        except:
                # Run for all other
                  exceptions raised
            statements
        else:
                # Run if no exception
                  was raised during try block
            statements
            --
            lpy3-p1146
            }}}
        [[Semantically, the block under the try header in this statement represents ____ *  + The except clauses define ____ * (**(*))
            {{{
            1=  the main action of the statement - the code you’re trying to run and wrap in error processing logic.
             - -
            2=  handlers for exceptions raised during the try block,
            --
            lpy3-p1146
            }}}
        the else clause(=of a try/except) (+if coded) provides * @
            {{{
            a handler to be run if no exceptions occur.
            --
            lpy3-p1146
            }}}
        'as var' of an except-clause  has to do with (!)
            {{{
            a feature of raise statements and exception classes, (??)
             = assigns the raised exception object to the variable named after the as keyword
              --
            '• If an exception occurs while the try block’s statements are running, and the exception matches one that the statement names,
                Python jumps back to the try and runs the statements under the first except clause that matches the raised exception,
            after assigning the raised exception object to the variable named after the as keyword in the clause (if present).
            --
            lpy3-p1146
            }}}
        (How try Statements Work (=marking)) (@)
            {{{
            When a try statement is entered, Python marks the current program context  so it can return to it if an exception occurs.
            --
            lpy3-p1146
            }}}
        • If an exception occurs while the try block’s statements are running, but the exception does not match one that the statement names, @
            {{{
            the exception is propagated up to the next most recently entered try statement that matches the exception;
              .
              (or, Python terminates the program and prints out a default error message)
            --
            lpy3-p1146
            }}}
            ----

            ----
        Exceptions raised are matched to exceptions named in except clauses by **(*) (!) (@)
            {{{
            superclass relationships
            --
            lpy3-p1147
            }}}
        the empty except clause (with no exception name) *! (@@)
            {{{
            = matches all (or all other) exceptions. (= not matched by any of the specific exceptions named in the except clauses)
            --
            lpy3-p1147
            }}}
        ways for a try-statement to catch and handle exceptions that happen outside =in code not enclosed in its try-block (***(*)) (@)
            {{{
            as the try block’s statements can call functions coded elsewhere in a program, the source of an exception may be outside the try statement itself.
            In fact, a try block might invoke arbitrarily large amounts of program code - including code that may have try statements of its own, which will be searched first when exceptions occur.
              ( That is, try statements can nest at runtime,
            --
            lpy3-p1147
            }}}
        ((different clauses and their forms that can appear after the try-clause(!)))
            {{{
              (=formal listing|table)
            --
            lpy3-p1147
            }}}
        catch any of the listed exceptions. ** @
            {{{
            except (e1, e2, e3):
            --
            lpy3-p1148
            }}}
        an example try except clause with many different specific exceptions listed (*!!) @
            {{{
            try:
                action()
            except NameError:
                ...
            except IndexError:
                ...
            except KeyError:
                ...
            except (AttributeError, TypeError, SyntaxError):
                ...
            else:
                ...
            --
            lpy3-p1148
            }}}
        Note that the else runs only when no exception occurs in action - it does not run when
            {{{
            an exception without a matching except is raised.
            --
            lpy3-p1148
            }}}
            ----

            ----
        Empty excepts also raise some design issues, though. Although convenient, (!!) (= can be a gotcha)
            {{{
            = they may catch unexpected system exceptions unrelated to your code, and they may inadvertently intercept exceptions meant for another handler.
            For example, even system exit calls and Ctrl-C key combinations in Python trigger exceptions, and you usually want these to pass.
             --
            + 'Even worse, the empty except may also catch genuine programming mistakes for which you probably want to see an error message.
            --
            lpy3-p1149
            }}}
        same effect as an empty except, but ignores exceptions related to system exits: (***(*!)) (!@)
            {{{
            try:
                action()
            except Exception:
                # Catch all possible exceptions, except exits
                ...
               .
               .
            (+ 'works because exceptions match if they are a subclass of one named in an except clause, and Exception is a superclass of all the exceptions you should generally catch this way.
               .
            [+ Note(!): =better, but has  some of the same dangers - especially with regard to masking programming errors.
            --
            lpy3-p1149
            }}}
        3.X  E1, E2--form gotcha (!) @
            {{{
            = always interpret as a tuple of two exceptions (!!))
            --
            lpy3-p1149
            }}}
        (('and is in fact forcibly deleted.
            {{{
             (???)
            --
            lpy3-p1150
            }}}
        The purpose of the else clause (!!!(!)) @
            {{{
            [= like a flag to tell that the try-statement was passed
            without an exception being raised] **
              |
              |
            = Without it,  there is no direct way to tell (without setting and checking Boolean flags)
            # ='Did we get here because the try failed or not?
              |
            whether the flow of control has proceeded past a try statement
                because no exception was raised, or
                because an exception occurred and was handled.
            --
            lpy3-p1150
            }}}
        [[+ the subtle 'You can almost emulate an else clause by moving its code into the try block' error (*)
            {{{
            (= can lead to incorrect exception classifications,
            (SS)
            --
            lpy3-p1150
            }}}
                ----

        Some basic Exception-code

                ----
        a stack trace(=like w. the div. by 0-example) lists (**) (@)
            {{{
            all lines active when the exception occurred, from oldest to newest.
            --
            lpy3-p1151
            }}}
        module (in stdlib) to debug Python code (*) (@)
            {{{
            pdb
            --
            lpy3-p1152
            }}}
        Python standard error handling vs custom error handling try(etc)-code (*!) @
            {{{
            Python’s default exception handling is often exactly what you want - especially for code in a top-level script file, an error often should terminate your program immediately.
              .
            Sometimes, though, you’ll want to catch errors and recover from them instead.
            = 'If you don’t want your program terminated when Python raises an exception, simply catch it by wrapping the program logic in a try.
                = This is an important capability for programs such as network servers, which must keep running persistently.
            --
            lpy3-p1152
            }}}
        catch(ing) and recover(ing) from  TypeError  (= eg. trying to concatenate a list and a string) (**(*!)) @
            {{{
            def kaboom(x, y):
                # Trigger TypeError
                print(x + y)
              .
              .
            try:
                kaboom([0, 1, 2], 'spam')
# Catch and recover here
            except TypeError:
                print('Hello world!')
# Continue here if exception or not
            print('resuming here')
            --
            lpy3-p1152
            }}}
        ((('In a sense, this makes exceptions more like simple jumps than function calls - (@)
            {{{
            (=) - there is no way to return to the code that triggered the error.
            --
            lpy3-p1152
            }}}
        finalization (a.k.a. ____) actions.
            {{{
            termination
            --
            lpy3-p1152
            }}}
                ----

                ----
        If an exception does occur during the try block’s run, (= what happens then??) (**!!) (??@)
            {{{
            the program does not resume execution below the finally clause’s try statement.
            --
            =  the finally block is run even if an exception is raised,
            but ,  the finally does not terminate the exception
                => it continues being raised after the finally block runs.
            --
            lpy3-p1153
            }}}
        intended use for finally-clauses (**(!)) (@)
            {{{
            = allows you to specify cleanup actions that always must occur, such as file closes and server disconnects where required. **
                (= must always be run, regardless of any exceptions.
            --
            lpy3-p1153
            }}}
        [(+ the new with statement and its context managers provide (!) (@@)
            {{{
            = an object-based way to do similar work for exit actions.
              Unlike finally, this new statement also supports entry actions,
                  but it is limited in scope to objects that implement the context manager protocol it leverages.
            --
            lpy3-p1153
            }}}
        more realistic try/finally-example that illustrates a typical role for this statement: **
            {{{
            class MyError(Exception): pass
              .
            def stuff(file):
                raise MyError()
              .
              .
            # Open an output file (this can fail too)
            file = open('data', 'w')
              .
              .
            try:
                # Raises exception
                stuff(file)
            finally:
                # Always close file to flush output buffers
                file.close()
# Continue here only if no exception
            print('not reached')
              .
              .
              .
            +(=after the code in the finally block has closed the file:)  'The exception is then propagated on to either another try or the default top-level handler,
            = 'This way, later code can be sure that the file’s output buffer’s content has been flushed from memory to disk.
             + A similar code structure can guarantee that server connections are closed, and so on.
            --
            lpy3-p1153,p1154
            }}}
        use case for finalizing close|release of files [!] @
            {{{
            As we learned in Chapter 9, file objects are automatically closed on garbage collection in standard Python (CPython); this is especially useful for temporary files that we don’t assign to variables.
                However, it’s not always easy to predict when garbage collection will occur, especially in larger programs or alternative Python implementations with differing garbage collection policies (e.g., Jython, PyPy).
                The try statement makes file closes more explicit and predictable and pertains to a specific block of code.
            It ensures that the file will be closed on block exit, regardless of whether an exception occurs or not.
            --
            lpy3-p1154
            }}}
        Unified try/except/finally (+ its basic syntax(**)) @
            {{{
            (= partly inspired by Java syntax)
            # Merged form
            try:
                main-action
            except Exception1:
                handler1
                # Catch exceptions
            except Exception2:
                handler2
            ...
            # No-exception--handler
            else:
                else-block
            # The finally encloses all else
            finally:
                finally-block
              .
              .
            No matter what’s happened previously, the finally-block is executed once the main action block is complete and any raised exceptions have been handled.
            --
            lpy3-p1155
            }}}
        Unified try Statement Syntax (= order etc) (!) @
            {{{
            try -> except -> (else -> finally)
              (+ formal syntax summation)
            --
            lpy3-p1156
            }}}
        Prior to Python 2.5, it is actually possible to combine finally and except clauses (@)
            {{{
            = in a try by syntactically nesting a try/except in the try block of a try/finally statement.
              .
            # Nested equivalent to merged form
            try:
                try:
                    main-action
                except Exception1:
                    handler1
                except Exception2:
                    handler2
                ...
                else:
                    no-error
            finally:
                cleanup
            --
            lpy3-p1156
            }}}
        Here’s a demonstration of the merged try statement form at work.  The following file, mergedexc.py, codes four common scenarios, (!) ??????
            {{{
            tr
            except IndexError:
            fi
              .
            tr
            except IndexError:
            el
            fi
              .
            tr
            except IndexError:
            fi
            --
            lpy3-p1157,p1158
            }}}
            ----

            ----
        trigger exceptions explicitly, @
            {{{
            code raise statements.
              = consists of the word raise, optionally followed by the class to be raised or an instance of it:
              .
              .
# Raise instance of class
        raise instance  #=most common form
# Make and raise instance of class: makes an instance
        raise class
# Reraise the most recent exception
        raise
            --
            lpy3-p1158,p1159
            }}}
        The last form reraises the most recently raised exception; it’s commonly used in * @(@)
            {{{
            exception handlers to propagate exceptions that have been caught.
            --
            lpy3-p1159
            }}}
        [[Version skew note: Python 3.X no longer supports the raise Exc, Args form that is still available in Python 2.X. @(@)
            {{{
            In 3.X, use the raise Exc(Args) instance-creation call form described in this book instead.
                ((The equivalent comma form in 2.X is legacy syntax provided for compatibility with the now-defunct string-based exceptions model, and it’s deprecated in 2.X.
            --
            lpy3-p1159
            }}}
        raise indexerror (create instance implicitly) @
            {{{
            # Class (instance created)
            raise IndexError
            --
            lpy3-p1159
            }}}
        raise indexerror (create instance explicitly) @
            {{{
            # Instance (created in statement)
            raise IndexError()
            --
            lpy3-p1159
            }}}
        create the(=exception class) instance ahead of time **(!) @(@)
            {{{
            - because the raise statement accepts any kind of object reference, the following two examples raise IndexError just like the prior two:
              .
            # Create instance ahead of time
            exc = IndexError()
            raise exc
              .
            excs = [IndexError, TypeError]
            raise excs[0]
            --
            lpy3-p1159
            }}}
        If a try includes an except name as X: clause, **(**!) @@
            {{{
            the variable X will be assigned the instance provided in the raise:
                (= When an exception is raised, Python sends the raised instance along with the exception. *
               .
               .
            try:
                ...
            # X assigned the raised instance object
            except IndexError as X:
                ...
              .
              .
              .
            = the as X is optional but  including it allows the handler to access both data in the instance and methods in the exception class.
            --
            lpy3-p1159,p1160
            }}}
        [[= 'This model works the same for user-defined exceptions we code with classes -
            {{{
            (= the class MyExc( example(*))
            --
            lpy3-p1160
            }}}
                ----

                ----
        how  are exceptions identified? (=by name etc?) (@)
            {{{
            Regardless of how you name them, exceptions are always identified by class instance objects,
            --
            lpy3-p1160
            }}}
        how many exceptions are active at any given time?
            {{{
            at most one exception is active at any given time.
            --
            lpy3-p1160
            }}}
        Once caught by an except clause anywhere in the program, an exception dies (i.e., won’t propagate to another try), unless @
            {{{
            it’s reraised by another raise statement or error.
            --
            lpy3-p1160
            }}}
        In Python 2.X, the exception reference variable name in an except clause (=eg. localization) (*)[!!!!] @(@@)
            {{{
            is not localized to the clause itself, and is available after the associated block runs:
              (+Ee)
            By contrast, Python 3.X localizes the exception reference name to the except block - the variable is not available after the block exits, much like a temporary loop variable in 3.X comprehension expressions (
              (++SSss)
            Because of this, you should generally use unique variable names in your try statement’s except clauses, even if they are localized by scope.
                If you do need to reference the exception instance after the try statement, simply assign it to another name that won’t be automatically removed:
              .
            >>> try:
            ...     1 / 0
                # Python removes this reference
            ... except Exception as X:
            ...     print(X)
# Assign exc to retain exc if needed
            ...     Saveit = X
            ...
            division by zero
            >>> X
            NameError: name 'X' is not defined
            >>> Saveit
            ZeroDivisionError('division by zero',)
            --
            lpy3-p1160,p1161
            }}}
        ''This form is typically used if you need to catch and handle an exception but don’t want the exception to die in your code: (**) @
            {{{
            = a raise that does not include an exception name or extra data value simply reraises the current exception.
            (='Propagating Exceptions with raise
             .
             .
        >>> try:
            # Exceptions remember arguments
        ...     raise IndexError('spam')
        ... except IndexError:
        ...     print('propagating')
            # Reraise most recent exception
        ...     raise
        ...
        propagating
        Traceback (most recent call last):
        File "<stdin>", line 2, in <module>
        IndexError: spam
              .
              .
            Running a raise this way reraises the exception and propagates it to a higher handler (or the default handler at the top, which stops the program with a standard error message).
            --
            lpy3-p1162
            }}}
        'Exceptions can sometimes be triggered in response to other exceptions - both deliberately and by new program errors. @
            {{{
            ('Python 3.X Exception Chaining: raise from')
              .
            'To support full disclosure in such cases, Python 3.X (but not 2.X) also allows raise statements to have an optional from clause:
              .
            raise newexception from otherexception
              .
            When the from is used in an explicit raise request, the expression following from specifies another exception class or instance to attach to the __cause__ attribute of the new exception being raised.
            (++ If the raised exception is not caught, Python prints both exceptions as part of the standard error message:
            --
            lpy3-p1162
            }}}
        When ______, a similar procedure(=as 'raise from'-chaining) is followed automatically: (!) (@@)
            {{{
            When an exception is raised implicitly by a program error inside an exception handler, a similar procedure is followed automatically:
              the previous exception is attached to the new exception’s __context__ attribute and is again displayed in the standard error message if the exception goes uncaught:
               (+ see Ee)
              .
              .
              .
              .
            + 'The net effect in both explicit and implicit contexts is to allow programmers to know all exceptions involved, when one exception triggers another:
              .
            >>> try:
            ...     try:
            ...			raise IndexError()
            ...     except Exception as E:
            ...			raise TypeError() from E
            ... except Exception as E:
            ...		raise SyntaxError() from E
            ...
            Traceback (most recent call last):
              File "<stdin>", line 3, in <module>
            IndexError
              ((etc (?? =SSs) )
            --
            lpy3-p1163,p1164
            }}}
        ((ss: Code like the following would similarly display three exceptions, though implicitly triggered here: (?@)
            {{{
            try:
                try:
                    1 / 0
                except:
                    badname
            except:
                open('nonesuch')
            --
            lpy3-p1164
            }}}
        ((+ Python 3.3 adds a way to stop exceptions from chaining, per the following note. @
            {{{
            Python 3.3 chained exception suppression: raise from None.  Python 3.3 introduces a new syntax form - using None as the exception name in the raise from statement:
            raise newexception from None
              .
            This allows the display of the chained exception context described in the preceding section to be disabled.
            This makes for less cluttered error messages in applications that convert between exception types while processing exception chains.
            --
            lpy3-p1164
            }}}
                ----

                ----
        The assert Statement **(*) (!) @
            {{{
            = 'a somewhat special case for debugging purposes,
            It(=an assert) is mostly just syntactic shorthand for a common raise usage pattern, and an assert can be thought of as a conditional raise statement.
              (+ equivalence EE)
              .
            # The data part is optional
            assert test, data
              .
            works like the following code:
              .
            if __debug__:
                if not test:
                    raise AssertionError(data)
            --
            lpy3-p1164
            }}}
        In other words(= concerning asserts), if the test evaluates to false, Python raises an exception: the data item(=argument 2 + if it’s provided) is used as (@)
            {{{
            the exception’s constructor argument.
            --
            lpy3-p1164
            }}}
        + exception of a failed assertion is (@)
            {{{
            AssertionError exception
            --
            lpy3-p1164
            }}}
        + assert statements may be removed from a compiled program’s byte code (@)
            {{{
            = if the -O Python command-line flag is used, thereby optimizing the program.
            --
            lpy3-p1165
            }}}
        what the -O flag actually does (!)
            {{{
            sets the __debug__ flag (=a built-in name) to false
              (= which  is automatically set to True unless the -O flag is used.
            --
            lpy3-p1165
            }}}
        = run main.py in optimized mode (+= disable (and hence skip) asserts. * (@)
            {{{
            python –O main.py
            --
            lpy3-p1165
            }}}
        [another way to say] what assert does (!!**(*)) (@)
            {{{
            Trapping Constraints (but Not Errors!)
            = Assertions are typically used to verify program conditions during development.
            (= 'assert is mostly intended for trapping user-defined constraints, not for catching genuine programming errors.
            --
            lpy3-p1165
            }}}
                ----

                ----
        When displayed(=failed assertions), their error message text automatically includes (!) (@)
            {{{
            source code line information and the value listed in the assert statement.
              .
            def f(x):
                assert x < 0, 'x must be negative'
                    # +mess. 2 =the "err.message"(!!(**))
                return x ** 2
              .
            % python
            >>> import asserter
            >>> asserter.f(1)
            --
            lpy3-p1165
            }}}
        ((For another example of common assert usage, *
            {{{
            see the abstract superclass example in Chapter 29;
            there, we used assert to make calls to undefined methods fail with a message. It’s a rare but useful tool.
            --
            lpy3-p1165
            }}}
        with/as Context Managers (??) (!)
            {{{
            This statement is designed to work with context manager objects, which support a new method-based protocol, (??)
            = 'similar in spirit to the way that iteration tools work with methods of the iteration protocol.
              .
            (+ in 2.5+:
            from __future__ import with_statement
            --
            = 'designed to be an alternative to a common try/ finally usage idiom;
                (= specifying termination-time or “cleanup” activities that must run regardless of whether an exception occurs during a processing step.
              .
            Unlike try/finally, the with statement is based upon an object protocol for specifying actions to be run around a block of code.
              .
              .
            + 'On the other hand, with also handles entry actions, can reduce code size, and allows code contexts to be managed with full OOP.
             - - -
            = 'to wrap code blocks in context managers that specify entry and exit actions.
            --
            lpy3-p1166
            }}}
        (([[Python enhances some built-in tools with context managers, such as (@)
            {{{
            files that automatically close themselves and thread locks that automatically lock and unlock,
            --
            lpy3-p1166
            }}}
        ((+programmers can code context managers of their own with classes, too.
            {{{
            --
            lpy3-p1166
            }}}
                ----

                ----
        with/as (= basic usage)  (**)
            {{{
                             ((=optional))
            with expression [as variable]:
                with-block
              .
            Note that the variable is not necessarily assigned the result of the expression; the result of the expression is the object that supports the context protocol, and the variable may be assigned something else intended to be used inside the statement. (??)
            The object returned by the expression may then run startup code before the with-block is started, as well as termination code after the block is done, regardless of whether the block raised an exception or not. (??) (!!) *
            --
            lpy3-p1166,p1167
            }}}
        Python objects (that) have been augmented to support the context management protocol, (+Ex.) (!) (@)
            {{{
            For example, file objects (covered in Chapter 9)
              = have a context manager that automatically closes the file after the with block regardless of whether an exception is raised, and regardless of if or when the version of Python running the code may close automatically:
              .
            with open(r'C:\misc\data') as myfile:
                for line in myfile:
                    print(line)
                    ...more code here...
              .
              .
            ++ 'After this with statement has run, the context management machinery guarantees that the file object referenced by myfile is automatically closed, even if the for loop raised an exception while processing the file.
              .
              .
            Although file objects may be automatically closed on garbage collection, it’s not always straightforward to know when that will occur, especially when using alternative Python implementations.
            = 'The with statement in this role is an alternative that allows us to be sure that the close will occur after execution of a specific block of code.
            --
            (+ often shorter than equiv. try/finally)
              .
            myfile = open(r'C:\misc\data')
            try:
                for line in myfile:
                    print(line)
                    ...more code here...
            finally:
                myfile.close()
            --
            (+ lock and condition synchronization objects w. multithreading)
              .
            lock = threading.Lock()
            # After: import threading
            with lock:
                # critical section of code
                ...access shared resources...
              .
            'Here, the context management machinery guarantees that the lock is automatically acquired before the block is executed and released once the block is complete, regardless of exception outcomes.
            --
            lpy3-p1167
            }}}
        (more examples (= the decimal module))
            {{{
            As introduced in Chapter 5, the decimal module also uses context managers to simplify saving and restoring the current decimal context, which specifies the precision and rounding characteristics for calculations:
              +Ee
            + 'After this statement runs, the current thread’s context manager state is automatically restored to what it was before the statement began.
            = 'To do the same with a try/ finally, we would need to save the context before and restore it manually after the nested block. **(*)
            --
            lpy3-p1168
            }}}
        The Context Management Protocol ** (!)
            {{{
            Although some built-in types come with context managers, we can also write new ones of our own.
            note: 'The interface expected of objects used in with statements is somewhat complex, and most programmers only need to know how to use existing context managers.
              .
            For tool builders who might want to write new application-specific context managers, though, let’s take a quick look at what’s involved.
            = Here’s how the with statement actually works:
             ...
             ...
             ...
               (+ withas.py
            Context managers can also utilize OOP state information and inheritance, but are somewhat advanced devices for tool builders, so we’ll skip additional details here (see Python’s standard manuals for the full story - for example, there’s a new contextlib standard module that provides additional tools for coding context managers).
            --
            = For simpler purposes, the try/finally statement provides sufficient support for terminationtime activities without coding classes.
            --
            lpy3-p1168,p1169
            }}}
        Multiple Context Managers in 3.1, 2.7, and Later (??) (!!)
            {{{
            In these and later Pythons, the with statement may also specify multiple (sometimes referred to as “nested”) context managers with new comma syntax.
            In the following, for example, both files’ exit actions are automatically run when the statement block exits, regardless of exception outcomes:
              .
            with open('data') as fin, open('res', 'w') as fout:
                for line in fin:
                    if 'some key' in line:
                        fout.write(line)
               .
            Any number of context manager items may be listed, and multiple items work the same as nested with statements.
            with A() as a, B() as b:
                ...statements...
              .
                   //vs older//
              .
            with A() as a:
                with B() as b:
                    ...statements...
            --
            lpy3-p1170
            }}}
        (= multiple withs-Ex (*))
            {{{
            - to implement a parallel lines scan of two files, the following uses with to open two files at once and zip together their lines, without having to manually close when finished (assuming manual closes are required):
            (EEEE ****)
                 (= 'You might use this coding structure to do a line-by-line comparison of two text files, for example - replace the print with an if for a simple file comparison operation, and use enumerate for line numbers:
                ((+in CPython it is not required,, it might be good pattern in Jpython or PyPy
            --
            lpy3-p1170,p1171
            }}}
        ((+ Ee(????)  = 'the following automatically closes the output file on statement exit, to ensure that any buffered text is transferred to disk immediately: (=just Jpy/pypy  (+IF WE NEED PROG. TO CONTINUE PAST EXCEPTIONS
            {{{
            fin = open('script2.py')
            fout = open('upper.py', 'w')
            # Same effect as preceding code, auto close
            for line in fin:
                fout.write(line.upper())
              .
            However, in cases where programs must continue after exceptions, the with forms also implicitly catch exceptions, and thereby also avoid a try/finally in cases where close is required.
              (but, try finally can also always be used (!!))
            --
            lpy3-p1171
            }}}
                ----


        Chapter 35 - Exception Objects

                ----
        [As suggested in the prior chapter, as of Python 2.6 and 3.0 both built-in and user-defined exceptions are identified by
            {{{
            class instance objects.
              = 'This is what is raised and propagated along by exception processing, and the source of the class matched against exceptions named in try statements.
            --
            lpy3-p1175
            }}}
        basing exceptions on classes and OOP offers a number of benefits. (!) * @
            {{{
            = class-based exceptions:
            • Can be organized into categories.  Exceptions coded as classes support future changes by providing categories - adding new exceptions in the future won’t generally require changes in try statements.
            • Have state information and behavior. Exception classes provide a natural place for us to store context information and tools for use in the try handler - instances have access to both attached state information and callable methods.
            • Support inheritance.
            (= (can) obtain and customize common behavior - (eg.) inherited display methods,
            --
            lpy3-p1175
            }}}
        3.X requires exception classes to be derived from the (= which class? (@)
            {{{
            BaseException built-in exception superclass, either directly or indirectly.
                As we’ll see, most programs inherit from this class’s Exception subclass, to support catchall handlers for normal exception types - naming it in a handler will thus catch everything most programs should.
            --
            lpy3-p1176
            }}}
        +exc.classes and new style classes (?@)
            {{{
            Python 2.X allows standalone classic classes to serve as exceptions, too, but it requires new-style classes to be derived from built-in exception classes, the same as 3.X.
            --
            lpy3-p1176
            }}}
        'String exceptions were straightforward to use - any string would do, and they matched by (*)
            {{{
            object identity, not value (that is, using is, not ==)
              .
            C:\code> C:\Python25\python
                # Were we ever this young?...
            >>> myexc = "My exception string"
            >>> try:
            ...     raise myexc
            ... except myexc:
            ...     print('caught')
            ...
            caught
              .
            This form of exception was removed because it was not as good as classes for larger programs and code maintenance.
            --
            lpy3-p1176
            }}}
        chief difference betw. string and class exceptions  (=how)  exceptions raised are matched against except clauses in try statements:
            {{{
            • String exceptions were matched by simple object identity:
                (= The net result was that exception handlers were coupled with exception sets in a way that made changes difficult.
              .
              .
            • Class exceptions are matched by superclass relationships: the raised exception matches an except clause if that except clause names the exception instance’s class or any superclass of it.
              .
            That is, when a try statement’s except clause lists a superclass, it catches instances of that superclass, as well as instances of all its subclasses lower in the class tree.
            = naturally support the construction of exception hierarchies:
            (superclasses become category names, and subclasses become specific kinds of exceptions within a category.
                 By naming a general exception superclass, an except clause can catch an entire category of exceptions - any more specific subclass will match.
               .
               .
               .
            In addition to this category idea, class-based exceptions better support exception state information (attached to instances) and allow exceptions to participate in inheritance hierarchies (to obtain common behaviors).
            --
            lpy3-p1177
            }}}
                ----

                ----
        Coding Exceptions Classes (@@)
            {{{
            classexc.py,
              .
              .
            class General(Exception): pass
            class Specific1(General): pass
            class Specific2(General): pass
              .
            def raiser0():
                # Raise superclass instance
                X = General()
                raise X
              .
            def raiser1():
                # Raise subclass instance
                X = Specific1()
                raise X
              .
            def raiser2():
                # Raise different subclass instance
                X = Specific2()
                raise X
              .
            for func in (raiser0, raiser1, raiser2):
                try:
                    func()
                # Match General or any subclass of it
                except General:
                    import sys
                    print('caught: %s' % sys.exc_info()[0])
              .
            C:\code> python classexc.py
            caught: <class '__main__.General'>
            caught: <class '__main__.Specific1'>
            caught: <class '__main__.Specific2'>
            --
            lpy3-p1178
            }}}
        required in Python 3.X: =top level class must inherit from (@)
            {{{
            the built-in Exception class.
              (+ Exception provides some useful behavior we’ll meet later, (so) it’s a good idea to inherit from it  (= even if using Py 2.X
            --
            lpy3-p1178
            }}}
        classexc.py: =make instances for the raise statements.
            {{{
            X = General()
              (+General inherits fr. Exception)
              .
            In this code, we call classes to make instances for the raise statements.
            = 'In the class exception model, we always raise and catch a class instance object.
            If we list a class name without parentheses in a raise, Python calls the class with no constructor argument to make an instance for us.
              .
              .
            (+ 'Exception instances can be created before the raise, as done here, or within the raise statement itself.
            --
            lpy3-p1178(,p1179)
            }}}
        in exception handler(s): grab hold of the most recently raised exception in a generic fashion.  (=good if the handlers class is broad|general) ** @
            {{{
            calling sys.exc_info
             (= in the|a exc-handler)
              .
            the first item in its result is the class of the exception raised,
            and the second is the actual instance raised.
            --
            lpy3-p1179
            }}}
        alt. use for sys.exc_info (**) [SSSS(!!)] @@
            {{{
            commonly used with empty except clauses that catch everything.
                += 'the __class__ attribute of the instance also gives the exception type.
              .
            # X is the raised instance
            except General as X:
                # Same as sys.exc_info()[0]
              .
              .
            Because __class__ can be used like this to determine the specific type of exception raised, sys.exc_info is more useful for empty except clauses that do not otherwise have a way to access the instance or its class.
            Furthermore, more realistic programs usually should not have to care about which specific exception was raised at all - by calling methods of the exception class instance generically, we automatically dispatch to behavior tailored for the exception raised.
            --
            lpy3-p1179
            }}}
            ----

            ----
        Why Exception Hierarchies? (@)
            {{{
             (= vs listing and string-based)
            For large or high exception hierarchies, however, it may be easier to catch categories using class-based categories than to list every member of a category in a single except clause.
            + Perhaps more importantly, you can extend exception hierarchies as software needs evolve by adding new subclasses without breaking existing code.
             [=the num. progr.lib example +Divzero, Oflow
              .
              .
            Now, when people use your library, they typically wrap calls to your functions or classes in try statements that catch your two exceptions;
              .
            # client.py
              .
            import mathlib
              .
            try:
                mathlib.func(...)
            except (mathlib.Divzero, mathlib.Oflow):
                ...handle and recover...
              .
              .
            =simply listing exc.s is brittle (= cannot easily absorb changes)
              .
            +solut:
            mathlib.func(...)
            # Catch everything here (or catch Exception super)
              .
            But this workaround might catch more than they bargained for - things like running out of memory, keyboard interrupts (Ctrl-C), system exits, and even typos in their own try block’s code will all trigger exceptions, and such things should pass, not be caught and erroneously classified as library errors.
            Catching the Exception super class improves on this, but still intercepts - and thus may mask - program errors.
              (+some more rules of thumb (!!(*)) )
              .
              .
              .
            + 'As a rule of thumb, it’s usually better to be specific than general in exception handlers - an idea we’ll revisit as a “gotcha” in the next chapter.1
            --
            Class exception hierarchies fix this dilemma completely.
            Rather than defining your library’s exceptions as a set of autonomous classes, arrange them into a class tree with a common superclass to encompass the entire category:
              .
            class NumErr(Exception): pass
            class Divzero(NumErr): pass
            class Oflow(NumErr): pass
              (etc)
              ...
              ...
              .
            = This way, users of your library simply need to list the common superclass (i.e., category) to catch all of your library’s exceptions, both now and in the future:
            import mathlib
              .
            try:
                mathlib.func(...)
            except mathlib.NumErr:
                ...report and recover...
              .
              .
            + When you go back and hack (update) your code again, you can add new exceptions as new subclasses of the common superclass:
            --
            lpy3-p1180--p1182
            }}}
        +again an added benefit w. class-based exceptions for larger programs (!) (@)
            {{{
            Class-based exception hierarchies also support state retention and inheritance in ways that make them ideal in larger programs.
            --
            lpy3-p1182
            }}}
        In Python 3.X, all the familiar exceptions you’ve seen (e.g., SyntaxError) are really just   (+lives where?) [!!(***)]
            {{{
            predefined classes, available as built-in names in the module named builtins;
                + in Python 2.X, they instead live in __builtin__ and are also attributes of the standard library module exceptions.
            --
            lpy3-p1183
            }}}
        +Py's builtin exceptions are organized how? (***(*))
            {{{
            Python organizes the built-in exceptions into a hierarchy, to support a variety of catching modes.
            BaseException: topmost root, printing and constructor defaults
              (+ not supposed to be inherited from directly by user-defined classes, etc
            + 'It provides default printing and state retention behavior inherited by subclasses.
            --
            lpy3-p1183
            }}}
        root of user-defined exceptions
            {{{
            Exception (!!)
            = 'The top-level root superclass of application-related exceptions.
            = This is an immediate subclass of BaseException and is a superclass to every other built-in exception, except the system exit event classes (SystemExit, KeyboardInterrupt, and GeneratorExit).
            --
            lpy3-p1183
            }}}
        When this convention is followed, naming Exception in a try statement’s handler (= and not BaseException)  (**(!)) @
            {{{
            ensures that your program will catch everything but system exit events, which should normally be allowed to pass.
            In effect, Exception becomes a catchall in try statements and is more accurate than an empty except. (!!) *
            --
            lpy3-p1183
            }}}
            ----

            ----
        root of numeric errors
            {{{
            ArithmeticError
            Its subclasses identify specific numeric errors: OverflowError, ZeroDivisionError, and Floating PointError.
            --
            lpy3-p1183
            }}}
        root of indexing errors
            {{{
            LookupError
            = A subclass of Exception, and the superclass category for indexing errors for both sequences and mappings - IndexError and KeyError - as well as some Unicode lookup errors.
            --
            lpy3-p1183
            }}}
        see the built-in exceptions class tree in the help text of the exceptions module (=in Python 2.X only)
            {{{
            >>> import exceptions
            >>> help(exceptions)
            ...lots of text omitted...
              (+This module is removed in 3.X, =look in lib-ref and pocket-refs instead (!!)
            --
            lpy3-p1184
            }}}
        The built-in (exception) class tree allows you to choose how specific or general your handlers will be. (!!)(**(*)) (@)
            {{{
            For example, because the built-in exception ArithmeticError is a superclass for more specific exceptions such as OverflowError and ZeroDivisionError:
            • By listing ArithmeticError in a try, you will catch any kind of numeric error raised.
            • By listing ZeroDivisionError, you will intercept just that specific type of error, and no others.
            --
            lpy3-p1184
            }}}
        [+again: the general  catchall (**)  (+= allows system exit exceptions to pass and propagate as they usually should: (!)  ((+hitch in Py 2.X
            {{{
            try:
                action()
            # Exits not caught here
            except Exception:
                ...handle all application exceptions...
            else:
                ...handle no-exception case...
               .
               .
            (+ doesn’t quite work universally in Python 2.X, however, because standalone userdefined exceptions coded as classic classes are not required to be subclasses of the Exception root class.
            --
            lpy3-p1184(,p1185)
            }}}
        ((Python 3.3 reworks the built-in IO and OS exception hierarchies. (!!) * (@)
            {{{
            It adds new specific exception classes corresponding to common file and system error numbers,
            and groups these and others related to operating system calls under the OSError category superclass.
              .
              (+Former exception names are retained for backward compatibility.
             .
           + 'Prior to this(=3.3), programs inspect the data attached to the exception instance to see what specific error occurred, and possibly reraise others to be propagated (the errno module has names preset to the error codes for convenience, and the error number is available in both the generic tuple as V.args[0] and attribute V.errno):
              (+EE)
            =' This code still works in 3.3, but with the new classes, programs in 3.3 and later can be more specific about the exceptions they mean to process, and ignore others:
              .
            c:\temp> py -3.3
            >>> try:
            ...     f = open('nonesuch.txt')
            ... except FileNotFoundError:
            ...     print('No such file')
            ...
            No such file
            --
            lpy3-p1185
            }}}
        Default Printing and State(=retention) (**)  (+= preset for u-defined classes) (@)
            {{{
            Built-in exceptions also provide default print displays and state retention, which is often as much logic as user-defined classes require.
              (=Unless you redefine the constructors (of course)(!)
            --
            lpy3-p1185
            }}}
        (('This explains why arguments passed to built-in exception classes show up in error messages - any constructor arguments  (!) (@)
            {{{
            are attached to the instance and displayed when the instance is printed:
            --
            ((+ 'When intercepted in a try statement, the exception instance object gives access to both the original constructor arguments and the display method:
              (+Ee()  (+multip. args =gives tuple
            --
            lpy3-p1186
            }}}
        ((get|show  exception instance objects are as strings (!) (@)
            {{{
            use the __str__ operator overloading protocol we studied in Chapter 30 to provide display strings when printed; (+ 'to concatenate with real strings, ....
            --
            lpy3-p1186
            }}}
        + 'Custom Print Displays (!!) @
            {{{
            = redefine inherited methods such as __str__ and __init__ in Exception subclasses
              (+EE
             ...
              ...
            --
            lpy3-p1187
            }}}
                ----

                ----
        ([A subtle point here: you generally must redefine __str__ for exception display purposes, because .... (@)
            {{{
            --
            lpy3-p1188
            }}}
        state information options  (='Custom Data and Behavior (@)
            {{{
            Besides supporting flexible hierarchies, exception classes also provide storage for extra state information as instance attributes.
              (+providing our own constructor)
            --
            lpy3-p1188
            }}}
        'Providing Exception Details': When an exception is raised, it may cross arbitrary file boundaries -
            {{{
            = the raise statement that triggers an exception and the try statement that catches it may be in completely different module files.
                Passing extra state information along in the exception itself allows the try statement to access it more reliably. (= than trying to use global variables(!))
            (+= using and utilizing the fact that  when an exception is raised, Python passes the class instance object along with the exception.
               +using the as-keyword to access the raised instance))
              .
            = 'This provides a natural hook for supplying data and behavior to the handler.
              --
                  ((++ 'w. classes, this is nearly automatic  (=??(|!!))
            +For example, a program that parses data files might signal a formatting error by raising an exception instance that is filled out with extra details about the error: (EEEE ***(*))
            --
            + 'Although we could rely on the default state retention of built-in superclasses, it’s less relevant to our application (and doesn’t support the keyword arguments used in the prior example): (+Ee
            --
            lpy3-p1188,p1189
            }}}
        Providing Exception Methods (eg.  use(ing) exception state information to log errors to a file automatically: (EE(EE)) (@)
            {{{
            EEE(E)
            --
            lpy3-p1189
            }}}
        (customizing exception classes (**(*!))) @
            {{{
            class CustomFormatError(FormatError):
                def logerror(self):
                    ...something unique here...
              .
            raise CustomFormatError(...)
            --
            lpy3-p1190
            }}}
        the raised instance object assigned to exc in this code is also available generically as @
            {{{
            the second item in the result tuple of the sys.exc_info() call
                (= a tool that returns information about the most recently raised exception.
            --
            lpy3-p1190
            }}}
        generate Python’s standard error message with stack trace (for custom exceptions (=which module to use|import (@)
            {{{
            using tools in the traceback standard library module, which uses traceback objects.
            --
            lpy3-p1190
            }}}
        [[(*!) 'We saw that in a try statement, catching a superclass catches that class as well as all subclasses below it in the class tree - (+)superclasses and their subclasses become (***(*))
            {{{
            superclasses become exception category names, and subclasses become more specific exception types within those categories.
            --
            lpy3-p1191
            }}}
        2. How are raised class-based exceptions matched to handlers?
            {{{
            2. Class-based exceptions match by superclass relationships: naming a superclass in an exception handler will catch instances of that class, as well as instances of any of its subclasses lower in the class tree.
            --
            lpy3-p1191
            }}}
        3. Name two ways that you can attach context information to exception objects. @
            {{{
            3. You can attach context information to class-based exceptions by filling out instance attributes in the instance object raised, usually in a custom class constructor.
            For simpler needs, built-in exception superclasses provide a constructor that stores its arguments on the instance automatically (as a tuple in the attribute args).
                (+ 'In exception handlers, you list a variable to be assigned to the raised instance, ....
            --
            lpy3-p1191|p1192
            }}}
                ----


        Chapter 36 - Designing with Exceptions

                ----
        (what happens, +) For that matter, what does it mean if a try calls a function that runs another try? (!) (@)
            {{{
            Both of these cases can be understood if you realize that Python stacks try statements at runtime. (??)
            When an exception is raised, Python returns to the most recently entered try statement with a matching except clause. (+ 'Because each try statement leaves a marker, ....
            (++ 'This nesting of active handlers is what we mean when we talk about propagating exceptions up to “higher” handlers (- such handlers are simply try statements entered earlier in the program’s execution flow.
              .
              .
            When an exception is eventually raised, Python jumps back to the most recently entered try statement that names that exception, runs that statement’s except clause, and then resumes execution after that try.
                Once the exception is caught, its life is over - control does not jump back to all matching trys that name the exception; only the first (i.e., most recent) one is given the opportunity to handle it.
              (+FFs to show
            --
            lpy3-p1193
            }}}
        except clauses intercept and stop the exception - they are where you *(!)
            {{{
            process and recover from exceptions.
            --
            lpy3-p1194
            }}}
        finally clauses intercept(=exceptions,) (but * @
            {{{
            do not stop) an exception -  they are for actions to be performed “on the way out.”
            --
            lpy3-p1194
            }}}
        ((+ more examples with nesting when functions are calling back and forth (??(|!!)) (@)
            {{{
            (= 'func2 sends control back to the handler in func1, and then the program continues within func1. (!!!!)
            --
            lpy3-p1194
            }}}
        ([[By contrast, when try statements that contain only finally clauses are nested, ((!!))
            {{{
            --
            lpy3-p1194
            }}}
        If there are many try/finally clauses active when an exception occurs, they (!!!!(????
            {{{
             (!!)
            --
            lpy3-p1194
            }}}
        In other words, where the program goes when an exception is raised depends entirely upon **(*) (!) @
            {{{
            where it has been - it’s a function of the runtime flow of control through the script, not just its syntax.
                The propagation of an exception essentially proceeds backward through time to try statements that have been entered but not yet exited. ** (!)
            'This propagation stops as soon as control is unwound to a matching except clause, but not as it passes through finally clauses on the way. ((***(*)))
            --
            lpy3-p1194
            }}}
        Example: Control-Flow Nesting (!)(!!!!) (@)
            {{{
            nestexc.py  (EEEE(!)
              .
              .
              .
                (( 'Python picks and runs just the most recent try with a matching except - which in this case is the try inside action1.
                  + Again, the place where an exception winds up jumping to depends on the control flow through the program at runtime.
              + Because of this, to know where you will go, you need to know where you’ve been.
              --
              In this case, where exceptions are handled is more a function of control flow than of statement syntax.
              + 'However, we can also nest exception handlers syntactically - an equivalent case we turn to next.
            --
            lpy3-p1195
            }}}
        ((Example: Syntactic Nesting (()) )) (@)
            {{{
              .
                (+For a more useful example of syntactic nesting at work, consider the following file, except-finally.py:
                 ((((+ 'This code catches an exception if one is raised and performs a finally terminationtime action regardless of whether an exception occurs. (????)
              .
            'Moreover, syntactic nesting still works today, may still appear in code written prior to Python 2.5 that you may encounter, can make the disjoint roles of except and finally more explicit, and can be used as a technique for implementing alternative exception-handling behaviors in general.
            --
            lpy3-p1195|p1196,p1197
            }}}
                ----

        Exception Idioms

                ----
        Breaking Out of Multiple Nested Loops: “go to” (@)
            {{{
            As mentioned at the start of this part of the book, exceptions can often be used to serve the same roles as other languages’ “go to” statements to implement more arbitrary control transfers.
              + 'except clauses and exception names take the place of program labels.
            You can jump only out of code wrapped in a try this way, but that’s a crucial feature - truly arbitrary “go to” statements can make code extraordinarily difficult to understand and maintain.
            + raise Exitloop
              except Exitloop:
            + 'Variable assignments made in a try are not undone in general, though ....
            --
            lpy3-p1197,1198
            }}}
        'sometimes exceptions are not errors @
            {{{
            = Despite its name, though, the EOFError exception is just a signal in this context, not an error.
              .
        while True:
            try:
                # Read line from stdin (raw_input in 2.X)
                line = input()
            except EOFError:
                # Exit loop at end-of-file
                break
            else:
                ...process next line here...
            --
            lpy3-p1198
            }}}
        other ex. of signals (but not errors) (!) @
            {{{
            calling sys.exit() and pressing Ctrl-C on your keyboard raise SystemExit and KeyboardInterrupt, respectively.
                + some  built-in exceptions that represent warnings
                =signal use of deprecated (phased out) language features.
              (= the warnings module)
            --
            lpy3-p1198
            }}}
        Functions Can Signal Conditions with raise (= the try/except/else exception handler does the work of an if/else return-value tester) * (@)
            {{{
            ((+EE))
                More generally, such a coding structure may also be useful for any function that cannot return a sentinel value to designate success or failure.
            In a widely applicable function, for instance, if all objects are potentially valid return values, it’s impossible for any return value to signal a failure condition.
            Exceptions provide a way to signal results without a return value:
             ((+Ee(!)
            --
            lpy3-p1199
            }}}
        Closing Files and Server Connections
            {{{
              .
              .
            For example, some servers require connections to be closed in order to terminate a session.
              (+finally or with for closing files
            (+pos. w. with(!):) In fact, it can save a line of code when no exceptions are expected at all (albeit at the expense of further nesting and indenting file processing logic):
            --
            lpy3-p1199
            }}}
        Debugging with Outer try Statements @(@)
            {{{
            By wrapping an entire program (or a call to it) in an outer try in your top-level code, you can catch any exception that may occur while your program runs, thereby subverting the default program termination.
            In the following, the empty except clause catches any uncaught exception raised while the program runs.
              .
            try:
                ...run program...
# All uncaught exceptions come here
            except:
                import sys
                print('uncaught!', sys.exc_info()[0], sys.exc_info()[1])
              .
            This structure is commonly used during development, to keep programs active even after errors occur - within a loop, it allows you to run additional tests without having to restart.
            --
            lpy3-p1201
            }}}
        (handling program shutdowns without recovery from them, (@)
            {{{
            see also Python’s atexit standard library module.
            --
            lpy3-p1201
            }}}
        customize what the top-level exception handler does @
            {{{
            = sys.excepthook
            --
            lpy3-p1201
            }}}
        Running In-Process Tests (????) (@)
            {{{
            Some of the coding patterns we’ve just looked at can be combined in a test-driver application that tests other code within the same process.
              .
            import sys
            log = open('testlog', 'a')
            from testapi import moreTests, runNextTest, testName
            def testdriver():
                while moreTests():
                    try:
                        runNextTest()
                    except:
                        print('FAILED', testName(), sys.exc_info()[:2], file=log)
                    else:
                        print('PASSED', testName(), file=log)
            testdriver()
              .
              .
               [=partial code]
              .
            The testdriver function here cycles through a series of test calls (the module testapi is left abstract in this example).
            Because an uncaught exception in a test case would normally kill this test driver, you need to wrap test case calls in a try if you want to continue the testing process after a test fails.
            The empty except catches any uncaught exception generated by a test case as usual, and it uses sys.exc_info to log the exception to a file.
            + The else clause is run when no exception occurs - the test success case.
              ...
            --
            lpy3-p1201,p1202
            }}}
        In practice, however, testing can be much more sophisticated than this. (@)
            {{{
            For instance, to test external programs, you could instead check status codes or outputs generated by program-launching tools such as os.system and os.popen, used earlier in this book and covered in the standard library manual.
            Such tools do not generally raise exceptions for errors in the external programs - in fact, the test cases may run in parallel with the test driver.
                At the end of this chapter, we’ll also briefly meet more complete testing frameworks provided by Python, such as doctest and PyUnit, which provide tools for comparing expected outputs with actual results.
            --
            lpy3-p1202
            }}}
            ----

            ----
        More on sys.exc_info
            {{{
            try:
                ...
            except:
                # sys.exc_info()[0:2] are the exception class and instance
              .
            If no exception is being handled, this call returns a tuple containing three None values.
            Otherwise, the values returned are (type, value, traceback), where:
              exc.class
              exc.class instance
              traceback object that represents the call stack at the point where the exception originally occurred, and used by the traceback module to generate error messages.
            --
            lpy3-p1202
            }}}
        useful to determine the specific exception type when catching exception category superclasses. (@)
            {{{
            (=often)  you can also get the exception type by fetching the __class__ attribute of the instance obtained with the as clause,
                (=often don't have to use sys.exc_info
                  ((apart from the empty except:
              .
              .
            try:
                ...
            except General as instance:
# instance.__class__ is the exception class
            --
            lpy3-p1202
            }}}
        Even so, using the instance object’s interfaces and polymorphism is often a better approach than testing exception types - exception methods can be defined per class and run generically: (????) @
            {{{
            try:
                ...
            except General as instance:
                # instance.method() does the right thing for this instance
              .
            As usual, being too specific in Python can limit your code’s flexibility.
            A polymorphic approach like the last example here generally supports future evolution better than explicitly type-specific tests or actions.
            --
            lpy3-p1203
            }}}
        Displaying Errors and Tracebacks  (=manually?(* +printing it to files etc)) (@)
            {{{
            Finally, the exception traceback object available in the prior section’s sys.exc_info result is also used by the standard library’s traceback module to generate the standard error message and stack display manually.
            This file has a handful of interfaces that support wide customization, which we don’t have space to cover usefully here, but the basics are simple.
            (=EEEe  badly.py:
            This code uses the print_exc convenience function in the traceback module, which uses sys.exc_info data by default; when run, the script prints the error message to a file - handy in testing programs that need to catch errors but still record them in full:
            --
            lpy3-p1203
            }}}
        (((Version skew note: In Python 2.X, the older tools sys.exc_type and sys.exc_value still work to fetch the most recent exception type and value, but they can manage only a single, global exception for the entire process. (@)
            {{{
            ++The newer and preferred sys.exc_info() call available in both 2.X and 3.X instead keeps track of each thread’s exception information, and so is threadspecific.
            --
            lpy3-p1204
            }}}
                ----


        Exception Design Tips and Gotchas

                ----
        I’m lumping design tips and gotchas together in this chapter, because
            {{{
            it turns out that the most common gotchas largely stem from design issues.
            --
            lpy3-p1204
            }}}
        The real art behind (using exceptions) is in deciding ** @!
            {{{
            how specific or general your except clauses should be and
            how much code to wrap up in try statements.
            --
            lpy3-p1204
            }}}
        What Should Be Wrapped (!) @@
            {{{
            What to wrap is really a design issue that goes beyond the language itself, and it will become more apparent with use.
             • Operations that commonly fail should generally be wrapped in try statements. For example, operations that interface with system state (file opens, socket calls, and the like) are prime candidates for try.
             • (but)  in a simple script, you may want failures of such operations to kill your program instead of being caught and ignored. This is especially true if the failure is a showstopper.  Failures in Python typically result in useful error messages (not hard crashes), and this is the best outcome some programs could hope for.
             • You should implement termination actions in try/finally statements to guarantee their execution, unless a context manager is available as a with/as option. (..)
             • It is sometimes more convenient to wrap the call to a large function in a single try statement, rather than littering the function itself with many try statements.
             = That way, all exceptions in the function percolate up to the try around the call, and you reduce the amount of code within the function.
              .
            Servers, for instance, must generally keep running persistently and so will likely require try statements to catch and recover from exceptions.
            Inprocess testing programs of the kind we saw in this chapter will probably handle exceptions as well.
            --
            lpy3-p1204
            }}}
        Avoid Empty except and Exception
            {{{
            (= 'Catching Too Much
            As mentioned, exception handler generality is a key design choice.
              ((+Ee(??)
        Perhaps worse, such code might also
        catch unrelated system exceptions.
        Even things like memory errors,
        genuine programming mistakes,
        iteration stops, keyboard
        interrupts, and system exits raise
        exceptions in Python. Unless you’re
        writing a debugger or similar tool,
        such exceptions should not usually
        be intercepted in your code.
            +(!) can prevent sys.exit from running try/finallys on way out, because s.e relies on raising an exception
              .
            import sys
            def bye():
                # Crucial error: abort now!
                sys.exit(40)
            try:
                bye()
            except:
                # Oops--we ignored the exit
                print('got it')
            print('continuing...')
            --
            lpy3-p1205,p1206
            }}}
        ((((!!)For example, scripts normally exit when control falls off the end of the top-level file.  (+other normal way to allow early termination of a script((*)) @(!@)
            {{{
            Python also provides a built-in sys.exit(statuscode) call to allow early terminations.
            This actually works by raising a built-in SystemExit exception to end the program, so that try/finally handlers run on the way out and special types of programs can intercept the event.
              (+ os.exit ends a progr. by direct termination (=doesnt handle cleanup actions, +normally used for closing child processes)
            --
            lpy3-p1205
            }}}
        ((+ 'Using the built-in exception classes of the prior chapter can help in this particular case, because the Exception superclass is not a superclass of SystemExit: (@)
            {{{
            try:
                bye()
                # Won't catch exits, but _will_ catch many others
            except Exception:
                ...
            In other cases, though, this scheme is no better than an empty except clause - because Exception is a superclass above all built-in exceptions except system-exit events, it still has the potential to catch exceptions meant for elsewhere in the program.
            --
            lpy3-p1206
            }}}
        the 'mydictionary' case (= IndexError +(!) NameError (@)
            {{{
              .
              .
              .
            ((++ the 'If this happens in code that is far removed from the place where the fetched values are used, it might make for a very interesting debugging task!'-remark
                = 'In the last example, for instance, you would be better off saying except KeyError: to make your intentions explicit and avoid intercepting unrelated events.
            --
            lpy3-p1206,p1207
            }}}
        be as specific in your handlers as you can be (!!) ** (@)
            {{{
            - empty except clauses and Exception catchers are handy, but potentially error-prone.
              .
              .
            (= In simpler scripts, the potential for problems might not be significant enough to outweigh the convenience of a catchall, but in general, general handlers are generally trouble.
            --
            lpy3-p1207
            }}}
        Catching Too Little: Use Class-Based Categories @
            {{{
            When you list specific exceptions in a try, you catch only what you actually list. This isn’t necessarily a bad thing, but if a system evolves to raise other exceptions in the future, you may need to go back and add them to exception lists elsewhere in your code.
              ..
              ..
            Luckily, careful use of the class-based exceptions we discussed in Chapter 34 can make this code maintenance trap go away completely.
            As we saw, if you catch a general superclass, you can add and raise more specific subclasses in the future without having to extend except clause lists manually - the superclass becomes an extendible exceptions category:
            --
            lpy3-p1207
            }}}
        Especially in larger systems, exception policies (!) (@)
            {{{
            should be a part of the overall design.
            --
            lpy3-p1207
            }}}
                ----




        extras, tools, etc

                ----
        Speaking generally, Python provides a hierarchy of toolsets:
            {{{
            builtin, extensions, compiled extensions
            --
            lpy3-p1208
            }}}
        Development Tools for Larger Projects !@@(@)
            {{{
            PyDoc and docstrings
            PyChecker and PyLint
                Because Python is such a dynamic language, some programming errors are not reported until your program runs (even syntax errors are not caught until a file is run or imported).
                means that you have to test your Python code before shipping it.
                Some Python developers run their code through PyChecker prior to testing or delivery, to catch any lurking potential problems.
              In fact, it’s not a bad idea to try this when you’re first starting out - some of these tools’ warnings may help you learn to spot and avoid common Python mistakes.
              .
            PyUnit (called unittest in the library manual),
                provides an objectoriented class framework for specifying and customizing test cases and expected results.
            doctest(????)[stdlib] (= regression testing)
                Roughly, to use doctest, you cut and paste a log of an interactive testing session into the docstrings of your source files.
                doctest then extracts your docstrings, parses out the test cases and results, and reruns the tests to verify the expected results.
            IDEs
                IDLE provide a graphical environment for editing, running, debugging, and browsing your Python programs.
                Eclipse, Komodo, NetBeans, and others listed in Chapter 3 - may support additional development tasks, including source control integration, code refactoring, project management tools, and more.
            Profilers (eg. 'profile')
                Profiling is usually your first optimization step - code for clarity, then profile to isolate bottlenecks, and then time alternative codings of the slow parts of your program.
                The profile module can be run as a script or imported, and it may be customized in various ways;
                (eg. save run statistics to a file to be analyzed later with the pstats module.
                 +eg. the cProfile module,
                     = identical interfaces to profile but runs with less overhead, so it may be better suited to profiling long-running programs.
            pdb
                can be run either interactively or from a command line and can be imported and called from a Python program.
            --
            lpy3-p1209--p1211
            }}}
        To profile interactively, (eg. w. profile) * @
            {{{
            import the profile module and call profile.run('code'), passing in the code you wish to profile as a string (e.g., a call to a function, an import of a file, or code read from a file).
            --
            lpy3-p1210
            }}}
        To profile from a system shell command line (eg. w. profile), use a command of the form * (@)
            {{{
            python -m profile main.py args (see Appendix A for more on this format).
            --
            lpy3-p1210
            }}}
        use pdb interactively, * @
            {{{
            import the module, start running code by calling a pdb function (e.g., pdb.run('main()')), and then type debugging commands from pdb’s interactive prompt.
            --
            lpy3-p1211
            }}}
        launch pdb from a system shell command line, use a command of the form * (@)
            {{{
            python -m pdb main.py args.
            --
            lpy3-p1211
            }}}
        start the debugger after an exception has been encountered, possibly in conjunction with Python’s -i flag. (@)
            {{{
            = pdb also includes a useful postmortem analysis call, pdb.pm(),
            --
            lpy3-p1211
            }}}
        pdb vs IDEs such as IDLE (= since features point-and-click etc) *  (+the usual simple prints) @
            {{{
            pdb isn’t as critical a tool today, except when a GUI isn’t available or when more control is desired.
              .
                (+(!) most programmers either insert print statements or simply read Python’s error messages:
            --
            lpy3-p1211
            }}}
                ----

                ----
        Py progr.packaging @
            {{{
            package byte code and the Python Virtual Machine into “frozen binary” standalone executables,
                py2exe, PyInstaller, and others
            + 'Python programs may be shipped in their source (.py) or byte code (.pyc) forms, and that import hooks support special packaging techniques such as automatic extraction of .zip files and byte code encryption.
            We also briefly met the standard library’s distutils modules, which provide packaging options for Python modules and packages, and C-coded extensions; see the Python manuals for more details.
            + The emerging Python “eggs” third-party packaging system provides another alternative that also accounts for dependencies;
            --
            lpy3-p1211
            }}}
        Optimization options (@)
            {{{
            PyPy
            Shed Skin (=py to C++ translator)
               .pyo (although mostly used with -O to remove debugging code
           move parts of your program to a compiled language such as C to boost performance.
            --
            lpy3-p1211,p1212
            }}}
        Other hints for larger projects ** (@)
            {{{
            These include module packages (Chapter 24),
            class-based exceptions (Chapter 34),
            class pseudoprivate attributes (Chapter 31),
            documentation strings (Chapter 15),
            module path configuration files (Chapter 22),
            hiding names from from * with __all__ lists and _Xstyle names (Chapter 25),
            adding self-test code with the __name__ == '__main__' trick (Chapter 25),
            using common design rules for functions and modules (Chapter 17, Chapter 19, and Chapter 25),
            using object-oriented design patterns (Chapter 31 and others),
                and so on.
            --
            lpy3-p1212
            }}}
        Installing diff. third party tools (****) @
            {{{
            pypi
            --
            lpy3-p1212
            }}}
        1. try/except. Write a function called oops that explicitly raises an IndexError exception when called.
            {{{
            (+ Then write another function that calls oops inside a try/except statement to catch the error.
            --
            lpy3-p1214
            }}}
        2. Exception objects and lists.  Change the oops function you just wrote to raise an exception you define yourself, called MyError.
            {{{
            --
            lpy3-p1214
            }}}
        . Error handling. Write a function called safe(func, *pargs, **kargs) that runs any function with any number of positional and/or keyword arguments (....)
            {{{
              .
              .
            (+Finally, expand safe to also print a Python stack trace when an error occurs by calling the built-in print_exc function in the standard traceback module; see earlier in this chapter, and consult the Python library reference manual for usage details.
             +(!) We could probably code safe as a function decorator using Chapter 32 techniques, (****)
            --
            lpy3-p1214
            }}}
        At the end of Appendix D, I’ve included a handful of example scripts developed as group exercises in live Python classes for you to study and run on your own in conjunction with Python’s standard manual set. (****) @@
            {{{
            These are not described, and they use tools in the Python standard library that you’ll have to research on your own.
            Still, for many readers, it helps to see how the concepts we’ve discussed in this book come together in real programs.
            --
            lpy3-p1214
            }}}
            ----

}}}

---- lpy09-extras_unicodeetc.txt -- (=currently resides in '07-classes')


