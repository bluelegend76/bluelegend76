set foldmethod=indent foldlevel=2
vim: fdm=indent:fdl=2:

TODO: MAYBE INCLUDE INDEXES FROM THE PLUCKED IMAGICK-BOOKS[!!]

~/Empire/Doks/graf/pr/imagemagick.pdf

https://legacy.imagemagick.org/  (=man)
            ImageMagick

                Home
                Download
                Tools
                CLI
                Develop
                Community

            ImageMagick (legacy)

            And Now a Touch of Magick Use ImageMagick® to create, edit, compose, or convert digital images. It can read and write images in a variety of formats (over 200) including PNG, JPEG, GIF, WebP, HEIC, SVG, PDF, DPX, EXR and TIFF. ImageMagick can resize, flip, mirror, rotate, distort, shear and transform images, adjust image colors, apply various special effects, or draw text, lines, polygons, ellipses and Bézier curves.

            ImageMagick is free software delivered as a ready-to-run binary distribution or as source code that you may use, copy, modify, and distribute in both open and proprietary applications. It is distributed under a derived Apache 2.0 license.

            ImageMagick utilizes multiple computational threads to increase performance and can read, process, or write mega-, giga-, or tera-pixel image sizes.

            The current release is ImageMagick 6.9.12-31. It runs on Linux, Windows, Mac Os X, iOS, Android OS, and others.

            The authoritative ImageMagick version 6 web site is https://legacy.imagemagick.org. The authoritative source code repository is https://github.com/ImageMagick/ImageMagick6. Find the latest release of ImageMagick, version 7, at https://imagemagick.org.

            The design of ImageMagick is an evolutionary process, with the design and implementation efforts serving to influence and guide further progress in the other. With ImageMagick version 7, we aim to improve the design based on lessons learned from the version 6 implementation. As ImageMagick version 6 is near end of life, we recommend you switch to ImageMagick version 7. In the mean-time we continue to support and add security patches, but not enhance, ImageMagick version 6, until at least August 1, 2028.

            Features and Capabilities

            Here are just a few examples of what ImageMagick can do for you:
            Animation 	create a GIF animation sequence from a group of images.
            Color management 	accurate color management with color profiles or in lieu of-- built-in gamma compression or expansion as demanded by the colorspace.
            Command-line processing 	utilize ImageMagick from the command-line.
            Complex text layout 	bidirectional text support and shaping.
            Composite 	overlap one image over another.
            Connected component labeling 	uniquely label connected regions in an image.
            Decorate 	add a border or frame to an image.
            Delineate image features 	Canny edge detection, Hough lines.
            Discrete Fourier transform 	implements the forward and inverse DFT.
            Distributed pixel cache 	offload intermediate pixel storage to one or more remote servers.
            Draw 	add shapes or text to an image.
            Encipher or decipher an image 	convert ordinary images into unintelligible gibberish and back again.
            Format conversion 	convert an image from one format to another (e.g. PNG to JPEG).
            Generalized pixel distortion 	correct for, or induce image distortions including perspective.
            Heterogeneous distributed processing 	certain algorithms are OpenCL-enabled to take advantage of speed-ups offered by executing in concert across heterogeneous platforms consisting of CPUs, GPUs, and other processors.
            High dynamic-range images 	accurately represent the wide range of intensity levels found in real scenes ranging from the brightest direct sunlight to the deepest darkest shadows.
            Image calculator 	apply a mathematical expression to an image, image sequence, or image channels.
            Image gradients 	create a gradual blend of two colors whose shape is horizontal, vertical, circular, or elliptical.
            Image identification 	describe the format and attributes of an image.
            ImageMagick on the iPhone 	convert, edit, or compose images on your iOS device such as the iPhone or iPad.
            Large image support 	read, process, or write mega-, giga-, or tera-pixel image sizes.
            Montage 	juxtapose image thumbnails on an image canvas.
            Morphology of shapes 	extract features, describe shapes, and recognize patterns in images.
            Motion picture support 	read and write the common image formats used in digital film work.
            Noise and color reduction 	Kuwahara Filter, mean-shift.
            Perceptual hash 	map visually identical images to the same or similar hash-- useful in image retrieval, authentication, indexing, or copy detection as well as digital watermarking.
            Special effects 	blur, sharpen, threshold, or tint an image.
            Text & comments 	insert descriptive or artistic text in an image.
            Threads of execution support 	ImageMagick is thread safe and most internal algorithms execute in parallel to take advantage of speed-ups offered by multicore processor chips.
            Transform 	resize, rotate, deskew, crop, flip or trim an image.
            Transparency 	render portions of an image invisible.
            Virtual pixel support 	convenient access to pixels outside the image boundaries.

            Examples of ImageMagick Usage shows how to use ImageMagick from the command-line to accomplish any of these tasks and much more. Also, see Fred's ImageMagick Scripts: a plethora of command-line scripts that perform geometric transforms, blurs, sharpens, edging, noise removal, and color manipulations. With Magick.NET, use ImageMagick without having to install ImageMagick on your server or desktop. Finally, see Snibgo's ImageMagick Cookbook for Windows-based ImageMagick scripting.
            Security • News   And Now a Touch of Magick   Related • Sitemap
            Sponsor • Cite • Public Key • Contact Us
            •

            © 1999-2021 ImageMagick Studio LLC

https://legacy.imagemagick.org/Usage/       https://imagemagick.org/
                    =TODO(!!): Include text etc (+format for 'phone 35') fr. Use and Scripts(!!)

            Examples of ImageMagick Usage
            (Legacy Version 6)
            These web pages presents a set of examples using ImageMagick ("IM," for short), version 6, from the command line. However, they often have direct analogs in the current release of ImageMagick, version 7. They also illustrate what can be done using the ImageMagick Application Programming Interface (API). As such, these pages should be the first stop for IM users after reading the terse Command Line (CLI) Option manuals.

            Often, the same questions of "How do I..." gets asked, over and over again on the network. The examples in these web pages, I hope, will answer most of the common "how-to" questions that arise.

            [IM Logo]
            [IM Version]
            Download Page,  CentOS RPM,
            Linux SRPM,  Beta Release
            Legacy Discourse Server
            Other related sites...
                
            Fred's ImageMagick Scripts
            RubbleWebs, PHP using IM CLI
            Snibgo's ImageMagick pages
             
            Main ImageMagick Web Site
                -----   Practical Examples   -----
                 Basic Usage
            Basic command and image handling
                 Image File Handling
            Reading and writing images
                 Common Image Formats
            Handling GIF, JPEG, and PNG images
                 Text to Image Handling
            Converting text into images
                 Compound Font Effects
            Font drawing styles and techniques
                 Annotating Images
            Labeling and overlaying images
                 Thumbnails and Framing
            Small reference images of large photos
                 Photo Handling
            Modifying photographs
                 Lens Correction
            Correcting photo distortions
                 Montage, Arrays of Images
            Image indexes and arrays
                 Layers of Multiple Images
            Combining multiple images together
                 Animation Basics
            Creation and study of animations
                 Animation Optimization
            Making GIF animations smaller
                 Animation Modifications
            Changing and merging animations
                 Video Handling
            Handling real life video images
                 Image Comparing
            Comparing two or more images
                 Advanced Techniques
            Complex manipulations of images
                 Background Examples
            Examples of creating random backgrounds
             
                 Repositories Links
            Links to other IM scripts and info
                 Reference Index
            Quick index for specific options
                 Support Scripts
            Shell scripts used by examples
                
                -----   Basic Techniques   -----
                 Canvas Creation
            Creating canvas and background images
                 Color Basics and Channels
            Low level color handling
                 Color Modifications
            General color changes
                 Masking and Background Removal
            Alpha channel, and transparency handling
                 Color Quantization and Dithering
            Reducing the number of colors
                 Cutting and Bordering
            Slicing, dicing, framing, trimming
                 Resizing or Scaling
            Enlarging and shrinking images
                 Resampling Filters
            Controlling image resizing
                 Compositing Images
            Overlaying and merging two images
                 Drawing on Images
            Vector graphics, MVG and SVG images
                 Simple Image Warping
            Flipping, rotating, twisting
                 Distorting Images
            Carnival house of mirrors
                 Image Transformations
            Drastic changes to the look of an image
                 Image Mapping Effects
            Lens, glass and ripple effects
                 Blurring and Sharpening Images
            Blurring, sharpening and shadows
                 Morphology of Shapes
            Using pixel neighbourhoods
                 Convolution of Images
            Weighted averaged neighbourhoods
                 Fourier Transforms
            Modifying images in the frequency domain
                 Anti-Aliasing
            Anti-aliasing effects and problems
                 Miscellaneous
            Bits and pieces
                 APIs, Scripting, Building
            Usage in other environments
                 Usage under Windows
            IM on Windows PC
                 Development and Bugs
            Development proposals and bugs, new and old
            Legend for symbols used within example pages...
                Hint, tips or extra info 			For more advanced users 			Older version warnings
            Test Image Storage Directories...   Small Images (image display),     Photographs (fancy index).

            ImageMagick Examples - Introductory Notes
            What is ImageMagick? A No-Holds-Barred Summary
            ImageMagick is designed for batch processing of images. That is, it allow you to combine image processing operations in a script (shell, DOS, Perl, PHP, etc.) so the operations can be applied to many images, or as a sub-system of some other tool, such as a Web application, video processing tool, panorama generator, etc. It is not a GUI image editor.

            ImageMagick is, first of all, an image-to-image converter. That is what it was originally designed to do. That is, it will convert an image in just about any image format (tell us if it can't) to any other image format.

            But it is also a library of image processing algorithms. These can be access via the command line and shell/DOS scripts (which these example pages demonstrate), or via a large number of programming languages, such as C, C++, Perl, Ruby, PHP, etc. See: ImageMagick APIs.

            Speed was never a major feature of IM, which places more emphasis on the quality of the images it generates. That is not to say that it can't transform images in a reasonable amount of time. It's just not blindingly fast. Because of this, IM can be slow to perform certain processing operations, especially when attempting to compress images into image formats that have limited capabilities.

            ImageMagick concerns itself mainly with images in the form of a rectangular array of pixels, commonly called a "raster." It will handle "vector" image formats like Postscript or PDF, but at the cost of converting those images into a raster when loading them, and generating a vector image wrapper around the raster when saving it. As a result, vector images are often processed badly when using the default settings. However, specific options can be used to improve this situation. See: A word about vector image formats.

            About These Examples of ImageMagick Usage
            These pages were developed from, and are a continuation of, my Collection of ImageMagick Hints and Tips page I first started in 1993, and placed on the new fangled world-wide-web making its appearance around the same time. Information on many aspects of IM, and notes not included in these pages, are still present in that document. However, while the present pages were designed for you to look at, the hints and tips document was only for my own edification. So, it may be vague or chaotic in places. You are welcome to look at it, learn, and make comments on it.

            Other examples were grabbed or developed from answers to users' questions on he IM Forums, or contributed to me as solutions to various problems.

            I look forward to suggestions and e-mail from other IM users. Such e-mail generally results in improvements and expansions to these example pages.

            Command Line Environments
            All examples are written for use on UNIX, and specifically GNU/Linux systems, using BASH scripting. As a consequence, some examples use shell 'for-do' loops. Most examples use a backslash '\' at the end of a line to continue that command on the next line. The longer commands are broken into separate lines to try to further highlight the steps being applied.

            However, you can still use these examples from PC Windows batch scripts, with some changes to the handling of certain characters. With some slight adaptation, the examples can also be run directly from 'system' calls in PHP scripts.

            See Windows Usage and APIs and Scripting for more information on using the ImageMagick commands in these alternative environments. Contributions and test examples are welcome.

            PerlMagick, and Other APIs
            It should also be possible to adapt any of these examples to use the IM API from languages such as Perl, C, C++, Ruby, PHP, and so on. I recommend trying things out on the command line first, until you get them right, and then converting the operations to the specific API you are using.

            Although the situation has improved enormously with IM version 6, the command line really only deals with a single image sequence at any one time. However, APIs do not have this limitation, and allow you to manipulate multiple image sequences, separately or together, to perform more complex operations. This ability makes it simpler to implement these examples using the IM API, and removes the need to save images as temporary files, as many of the command line examples require. When using an API, only permanent and semi-permanent images need be saved to disk.

            Basically, let the example pages give you a start, to let you see what is possible with ImageMagick. Then, formulate what you want to do on the command line, before coding the operations in scripts and API code, where it is harder to make extensive changes.

            I also recommend that you comment your API code, heavily, adding the command line equivalents to what you are trying to do, if possible. That way, you can check and compare the results against those using the command line. This lets you debug problems that you may come across later, especially as improvements are made to image processing in the Core ImageMagick Library.

            Downloading Input Images and Results
            As much as possible, I try to use images built-into IM (such as "logo:" or "rose:") as input images for IM example commands, or to generate input images using IM commands. I also often re-use the output of previous commands in later examples. Because of this, you usually don't need to download any 'test' images in order to try out the examples yourself.

            However, such generated or built-in images are not always convenient. So, when I do use an external image, I tend to re-use that input image, or the results of previous examples, for later examples in that section.

            Sometimes the original source image will be displayed or for larger images a link to the source image is provided. More commonly only the final resulting image will be shown, as the input is well known or obvious.

            Almost all the IM example commands shown are executed in the same web directory in which they appear. That is, the command you see is the command that was actually used to generate the image. Because of this you can modify the page's URL to download or view the input image(s) used by an example. Extra copies of the external source images have also been placed in the "images" and "img_photos" sub-directories. See also the example of a Fancy Photo Index of those images.

            If text output or image information is produced by an example, it is saved to a text file, and an image of it is generated for display on the Web page. Selecting the text output image will link you to a copy of the actual text output by the command.

            In all these examples, selecting the output image should let you download the image which was actually created by the example command. But be warned, not all browsers understand all image formats used.

            External Image Sources
            By the way, most of the source images used in these examples come from Anthony's Icon Library, particularly the background tiles, large clip-art, and dragons sections of the library. (I like dragons!). ASIDE: these pages may be offline as the web site slowly moves to a new server.

            This library actually predates the WWW. I created it in 1991, due to the lack of good, clean iconic images for use on the X Window System. The advent of the WWW has of course changed this, but my original library still exists and remains available as a source of images, even though it is not actively growing.

            Some specific images, and larger images, are contributed by the authors of specific examples. The authors of such examples are listed in the contributed section, or at the bottom of the page.

            If you are looking for a specific image, I recommend using Google Image Search (or similar) to find something appropriate. You can, of course, convert or resize such images using IM for your own purposes. However, you should be careful about copyright if you plan to use such images commercially.

            PNG Images on Web Pages
            [IM Output] In many examples, I use an image in PNG format, such as that shown to the right of this text. The PNG image format supports images with semi-transparent pixels, a feature few other image formats provide. It is also a very well-understood image format and, as such, is usable by most of today's image programs and Web browsers.

            Some Web browsers, however, do NOT handle transparent PNG images correctly (most notably Microsoft Internet Explorer v6). Because of this, I generally use the JPEG and GIF formats for images on the Web, and only use the PNG format when generating images with semi-transparent pixels, or when exact colors are needed for later examples.

            To allow IE v6 browsers to display PNG images, I use a special 'style sheet' using complex JavaScript. For information on this, see PNG with transparency for IE. Technically, this is only problem with IE, not ImageMagick.

            Displaying Images on Your Screen
            Display problems can also occur when displaying images on-screen. Because of this, I recommend using a command like the following to tile a 'checkerboard' pattern underneath the image, to highlight any transparent or semi-transparent pixels in it.


                composite  -compose Dst_Over -tile pattern:checkerboard image.png x:

                [IM Output]

            The image displayed in the above example is a special PNG-format test image, which was generated using the shell script "generate_test". Normally, the command would output the results to your display, not onto a Web page like this.

            If you look carefully, you can see the checkerboard pattern though the semi-transparent colors. However, the image, as a whole, is fully opaque. So, this technique should work on all displays, Web browsers, and image viewers.

            As of IM v6.0.2, the "display" program performs something like this automatically. However, it does not seem to handle images using color tables (i.e., GIF) in this way. Using the "x:" output image format (as above) causes an image to be displayed directly to the screen, without having to save it. See Show Output Display for more information.

            Font Usage
            The fonts I use in these examples are from a small collection of TrueType fonts I have found over the years, and saved for my own use. Some of these are under copyright, so I cannot publish them online.

            You are, however, welcome to substitute other fonts that you have available. The examples should work (perhaps with some changes to image size) with any appropriate font you have available on your system. Microsoft "Arial" font, or even "Times-BoldItalic", should work on most systems.

            To see what fonts are currently available to your version of IM, run the following command...


                convert -list type       # for IM older than v6.3.5-7
                convert -list font       # for newer versions

            WARNING: If the font requested is not found, ImageMagick used to silently substitute a default font, typically Arial or Times. It still does this, but a warning is now given. So, test the font beforehand, to make sure that it is the one you want, and not the default font.

            On my Linux system, I use a special Perl script, "imagick_type_gen", to generate a file, "type.xml", saved in the ".magick" sub-directory of my home directory. ImageMagick uses that file, which contains a font list in XML format, to find fonts. The script "locate"s (run "updatedb" first, if you have just added new fonts), and describes all the fonts available on my system. With this setup, I only need to specify the name of the font I want to use, and not the full path to a specific font file.

            For example...


                # Instead of using the command...
                convert -font $HOME/lib/font/truetype/favorite/candice.ttf \
                        -pointsize 72 label:Anthony  anthony.gif

                # I can use the simpler font label...
                convert -font Candice -pointsize 72 label:Anthony  anthony.gif

                Before IM v6.1.2-3, the "type.xml" file was named "type.mgk". If you are using an earlier version of IM.

            The fonts used in these IM examples are listed in a Montage of Example Fonts Example. My personal favorite is Candice, so it gets used quite a bit.

                If you also like the 'Candice' font, or any of the other fonts I use, grab them from Free Fonts or 1001 Fonts .com.

            Example Page Updates
            These example pages are in an on-going cycle of improvement. Generally, I find I stop adding to these pages for long periods of time, when my interests become focused on other things.

            Often these examples are re-built using the latest beta release of IM, allowing me to see changes and bugs that may appear in each version of IM, before it is generally released. However, the example images shown are what the given IM command produces on my system. If you get something different, your IM is probably a much older version (with old bugs), or is not correctly installed.

            Note that e-mailing me, or discussing some aspect of ImageMagick on the IM Users Forum will generally result in new examples, or whole new sections, being added to these examples. The more discussion there is, the better the examples become.

            If you are doing anything interesting with IM, please share, and allow me to provide examples of your technique to the rest of the IM community. Some of the biggest advances in IM usage have come from users just like you.

            Special Thanks
            A special thank you goes to Cristy, who has tirelessly spent months, upgrading, bug-fixing, and putting up with my off-the-wall suggestions... especially with regards to my major suggestions for the command line processing, parenthesis, image sequence operators, and GIF animation processing.

            He has done a marvelous job making Version 6 the best and most advanced command line image processing program available. While most users will not show appreciation for that, I certainly do appreciate the effort he has put into IM.

            I also want to thank Gabe Schaffer, who has been most helpful in discussions involving the JPEG format and library, affine matrix operators, and Magick Vector Graphics in general.

            And to Glenn Randers-Pehrson, who looks after the PNG coder module and has a interest in Color Quantization and Dithering. He was the first to add 'halftone' dithering to IM, which I later revised and extended further, to added new dithers to the ordered dither configuration file.

            And finally, I want to thank the huge number of people with problems, suggestions, and solutions, who generally lurk on the IM User Forum. Many now have their names as contributors of ideas and suggestions throughout IM Examples.

            I also want to thank the people who regularly answer questions on the forums, such as 'Bonzo', and his web site RubbleWebs, detailing use of IM commands from PHP scripts. Also 'scri8e' and his Web site, Moons Stars, for glitter and star handling. Also a thank you goes to Pete 'el_supremo'

            A special thanks goes to Fred Weinhaus, a researcher from the early days of image processing, who was a major help in the initial implementation of the General Image Distortion Operator. You can see Fred's ImageMagick scripts on Fred's ImageMagick Site, often as a proof of concept for future IM additions.

            Also to Nicolas Robidoux, an expert in digital image processing, for reworking the Elliptical Weighted Average Resampling, which vastly improves the output of General Image Distortion.

            And finally to the many users of ImageMagick who, had allowed others to see the IM commands they use as part of some project, either on the forums, or on the web. You are all to be commended on your willingness and openness to share your findings.



            Well enough "Yadda, yadda, yadda."   Go look at some of the examples.

## ~/Dropbox/rsc/data/lists/ref/comp/pr/imagemagick_use-scripts.txt
===== Imagick Usage ** =====
https://legacy.imagemagick.org/Usage/basics/
            Here we explain in detail the command line processing that IM follows, some of the new image processing abilities, the ideas, philosophy, and methodology, and what is actually going on, internally.

            With this background knowledge the rest of the examples provided pages becomes much clearer. Even if you only use the Application Program Interface (API), this section is well worth knowing and understanding.

            ImageMagick Command Line Processing
            Why did the command line style change!  or...
            The problem with previous versions of IM
            In previous major version of ImageMagick (version 5.5.7 and earlier) the command line interface into the IM library has been prone to problems involving the order in which operations were performed. It was very haphazard, and confusing to anyone trying to make sense of what was actually going on. Also, what worked one time may not work in the same order another time, as the author of IM, constantly battled with the interface to get it to work as people expected.

            The cause of the problem was that ImageMagick followed a fairly standard UNIX command line style...

                command [options] input_image output_image 

            As time went on this started to produce problems, as images are complex objects with an enormous number of operations that can be performed on them often involving other images.

            As a consequence of this the above slowly expanded to become..

                command [options] image1 [options] image2 [options] output_image 

            This worked, and is the basic style that was used in version 5.5.7.

            The various image operations such as "-negate", "-resize", and "-crop", etc, could appear either before or after the image it was meant to apply to.

            For example under version 5.5.7 the following two commands were equally valid and did the same thing.


              convert  -negate  image.gif   output.gif

              convert   image.gif  -negate  output.gif

            The problem was what if you were dealing with two image processing operations! For example...


              convert -size 40x20 xc:red  xc:blue \
                      -append   -rotate 90    append_rotate.gif

            [IM Output]

            The result (in IM v5.5.7) was that the two input images were rotated first, then appended together, producing an image like...

            That is the "-rotate" operator would be applied BEFORE the "-append" which is probably not what the user intended.


            With ImageMagick version 6, the operators will always be applied in the command line order as given by the user.
            [IM Output]

            As such the previous example in IMv6 will result in: the two images being appended together first, then that result will be rotated; producing this...

            If the user actually intended to do the rotations before the append, he can explicitly ask IM v6 to do it in that order.


              convert -size 40x20 xc:red  xc:blue \
                      -rotate 90  -append    append_rotate_bad.gif

            This sort of fine control was just beyond previous versions of IM, and would probably have required a pipeline, or intermediate save images to achieve it.

            The solution to the problem, unfortunately required a drastic measure and some incompatibility. On the other hand just about every 'simple' command that worked in IM version 5 work as you would expect IM version 6.

            In essence command line usage in versions before version 6 was ill-defined and in my thinking broken, producing numerous odd and unexpected results.


            IMv6 command Syntax
            Note that no 'operation' should be given, before at least one image is either read in or created. In fact you may like to consider a 'image read/create' also as an operation as well. Afetr all it really is image processing operation, that of translate an image in a file to an image in memory.

            So the correct way to do this in IMv6 is to read the image, process and then use the final 'implicit write' argument to write out the result. That is..

                command "image" { -operation }... "output_image" 

            Of course there are some settings that may be need to control the image reading which need to be given before actually reading the image (see below for the meaning of a setting). As such IMv6 syntax basically follows the following...

                command { [settings] [operation] }... "implict_write" 

            With the part in '{...}' being repeated with as many 'reads' or 'operations' you want or need. And '[operation]' being either an image read or create, or image processing operation that actually 'does something'. And you would do them in the exact order you want to process the images.


            Types of Options - Operators and Settings...
            A summary of the following is now also available from the ImageMagick Website on The Anatomy of the Command Line.

            All command line options will now fall into two basic groups: 'settings' and 'image operators'. Settings set values, Operators actually preform some action.

            Setting Options
                are command line options that only save information, that will be used later by other 'image operators'. That is they do not do anything, except set some value, to be used later. Many of the options have both a '-' and a '+' style. The latter is generally used to turn off the setting, or reset it to its normal default state. This allow you remove the effect of a setting quickly and simply.

            For example "+gravity" will return the gravity setting to the initial 'gravity none' state. Settings can be further divided into a number of sub-categories...

            Operator Settings which control how later operators function. They set the colors, and fonts that may be used by an operator, control placement of images and text, the lookup of color from source images, control the method of processing by some of the more complex operators, etc., etc., etc..

                -dither  -gravity  -fill  -background  -bordercolor  -stroke  -font  -pointsize  -strokewidth  -box  -virtual-pixel  -interpolate  

            Most setting options belong to this category.

            Input Settings are specifically restricted to controlling the creation of images that are created or read in. Typically they are used to assign or override specific meta-data that is to be associated with the image(s) created after that setting was defined.

            they are created or read in from an external file.

                -label  -delay  -dispose  -page  -comment  -size  

            Remember, they are ONLY applied when an image is created or read in and are otherwise completely ignored.

            The special operator, "-set" has been provided to change the meta-data of images after they have been read into memory, or processed in some way. See Meta-Data below for more details.

            Output Settings which are only used during the writing or saving of images back to disk.

            While they can be given anywhere on the command line, they are only applied when the image is written, either as the default last image filename argument operation, or via a "-write", or "-identify" operation.

                -quality  -loop  -compression  -format  -path  -transparent-color  

            If not set, or turned off (using their plus '+' form), an appropriate default will be used. Generally this default is a saved value from the last image read in.

            A few 'operation settings' such as the current "-background" color, is also assigned to the image, if the file format requires.

            Control & Debugging Settings which control how IM, in general, performs its tasks. These includes...

                -verbose  -debug  -warnings  -quiet  -monitor  -regard-warnings 

            See IM Operation Controls below, for more information on these special settings.


             
            Image Operators
                Are command line arguments that will modify the image(s) in some way. They are performed immediately when seen, and may use other 'setting options' that have been given previously on the command line.

            These operators can be grouped into a few sub-categories...

            Image Creation Operators which will read images from a file or pipeline, or generate new images. These include...

                image.png  xc:  canvas:  logo:  rose:  gradient:  radial-gradient:  plasma:  tile:  pattern:  label:  caption:  text:  

            As 'operators' they are also performed immediately when seen on the command line. They only add new images to those already in memory, but do not touch those previously read.

            Of course being operators, any previously defined 'settings' will be applied to them. Especially Input Settings, used to control the input from the file or file stream. For example "-size", which hints at the size of the image you want to create, or setting that define or override image meta-data such as "-delay", and "-page".

            Simple Image Processing Operators will modify all images that have already been read into memory. Each image is modified separately to every other image. They include operations such as...

                -crop  -repage  -border  -frame  -trim  -chop  -draw  -annotate  -resize  -scale  -sample  -thumbnail  -magnify  -adaptive-resize  -liquid-resize  -distort  -morpohology  -sparse-color  -rotate  -swirl  -implode  -wave  -flip  -flop  -transpose  -transverse  -blur  -gaussian-blur  -convolve  -shadow  --radial-blur  -motion-blur  -sharpen  -unsharp  -adaptive-sharpen  -adaptive-blur  -noise  -despeckle  -median  -negate  -level  -level-color  -gamma  -auto-level  -auto-gamma  -sigmoidial-contrast  -normalize  -linear-stretch  -contrast-stretch  -colorize  -tint  -modulate  -contrast  -equalize  -sepia-tone  -solarize  -recolor  -opaque  -transparent  -colors  -map  -ordered-dither  -random-dither  -raise  -paint  -sketch  -charcoal  -edge  -vignette  -emboss  -shade  -poloroid  -encipher  -decipher  -stegano  -evaluate  -function  -alpha  -colorspace  -separate 

                And probably many other operators I missed! (or have been added) 

            Because all image operators are performed immediately when seen on the command line, they must be given after the images for which they are to operate, have been read into memory.

            If more than one image is present, all images are operated on, one at a time in sequence. As such you will have to be careful about what image(s) you have in the current image list.

            Note that it is possible that some of these operators can generate multiple images. For example "-crop" could generate multiple image 'tiles', or "-separate" which splits images into separate channel images. As such you may end up with more images in memory. But all of them only take one image at a time as input.

            Note that many API's only apply the equivalent operation to just the first image in the image list given. That is they may not loop over each image. The "convert" and other CLI (command line interface) commands, however apply the operator to each image in the current image list in turn.

            Multi-Image List Operators are special in that they modify the whole current list of images as a single entity. They could replace the whole list with a single combined image, or modify each image depending on the other images found before or after it. They are used for alpha composition, animation handling, color channel handling, etc...

                -append  -flatten  -mosaic  -layers  -composite  -combine  -fx  -coalesce  -clut  -average  -evaluate-sequence  

            Remember the whole list is treated as a single entity, and some images may be removed, or replaced. Most of the above operators merges all the given multiple images into a final single image.

            The Layers Composite method is currently the only operator that will spilt the current image list into two completely separate image lists, before merging them together to form completely new list of images. It makes the split by looking for the special 'null:' image somewhere in the current image list.

            None of these operators can be used in a "mogrify" command, as that command processes a list of input images (given at the end) as an individual images.

            Image Stack Operators affects the ordering of the list of images currently in memory. Specifically they provide special 'on the side' processing of images. They are in many way similar to the previous Image List Operator, but they don't actual modify the images themselves, only how they are arranged in memory.

                (  )  -delete  -insert  -swap  -reverse  -duplicate  -clone  

            Note that parenthesis '(' and ')' may require backslashing or quoting, to prevent any special meaning given to it by the Command Line shell Interface (CLI).

            None of these operators can be used in a "mogrify" command, as that command processes a list of input images (given at the end) as an individual images.

            Miscellaneous Special Operators are operators that do things in either an unusual or non-standard ways (compared to the above).

                -geometry  -version  -list  -bench  -concurrent  -preview  

            The "-geometry" operator is special as it is the only operator that only affects one image (the last) in the image list, rather than affecting all of the images in some way. It is only provided for backward compatibility and special alpha composition requirements. See Geometry, resize just the last image for more details.

            The other two "-version" and "-list" are information generating operators, and causes IM to explicitly quit, after returning the requested information. See IM Special Controls below, for more information on these options.

            Some options could even cause the whole command to be run multiple times. Basically they are specially handled in some strange and unusual way.

            Generally these as not used except in special situations or to recover specific global information.

            I hope the separation of options into settings and operators is clear as it is vital to the way IM now works.

            Remember under version 6 of ImageMagick...

            Settings are saved in some way for later use,
            while Operators are applied immediately to the images.

            This is what makes version 6 different from every previous version of IM. All options are defined to be a 'setting' or an 'operator' and the order will determine exactly when, and to what images, the option will be applied to.

            The IM Examples Options Reference can be used to identify what is an 'setting' and what is an 'operator'.

            Working Example of an IM Command
            Let's take a look at an example, and how it will be processed by IM version 6.


              convert  eye.gif news.gif -append    storm.gif tree.gif \
                       -background skyblue +append    result.gif

                [IM Output]

            Let's break this down and look at what IM v6 does...
            Argument 	    	Action Performed 	Images
            convert 	Initialize and Create an empty 'image list' 	empty seq
            eye.gif 	Read in image and add to end of current image list 	1 image
            news.gif 	Add a second image into list (now with two images) 	2 images
            -append 	Take all images in current list, and append vertically.
            All images are replaced by a single image. 	1 (merged)
            storm.gif 	Add another image to the image list 	2
            tree.gif 	And another 	3
            -background skyblue 	Set a 'background color' to be used later.
            No changes are made to any images. 	3
            +append 	Join all 3 images in the list horizontally
            Current background color is used to fill the empty space 	1 (merged)
            result.gif 	As this is last argument, an implicit -write operation is performed with this argument. The single image in the current list is written using the given filename which also sets image file format to use. 	written

            As you can see the processing of the command line in ImageMagick version 6 is very straight forward, and logical, making the result predictable. And that is the point...

            Legacy Command Line Style
            Due to the fact that a lot of very old IM scripts out there use a command with a single image operator of the form...

                command -operator input_image output_image 

            That is you specified an image operator before you actually read the image to which the operator will be applied.

            To handle this legacy situation, IM will save up all the image operators it sees, and apply them to the first image when it is finally seen on the command line. That is the above will work as if you wrote the operation in the IMv6 way...

                command input_image -operator output_image 

            For example, this IMv5 legacy (UNIX option handling) command....


              convert  -flip  storm.gif   cmd_flip_legacy.gif

                [IM Output]

            Will produce the same result as this IM version 6 command...


              convert  storm.gif -flip  cmd_flip_postfix.gif

                [IM Output]

            The legacy command line style works, but has the same problems that plagued IM version 5 (see Why did the command line style change above). All settings are applied before the first read, and all the operators are just saved away to be executed when the first image is read (and only on the first image). There is also no guarantee of the order of multiple operators will be the same as the order you give, though it is likely they will be applied in that order.

            Also as operators are being save up until the first image is actually read, you may find repeating a command multiple times before reading the image may result in some of the earlier commands 'disappearing'. This is not a bug, but a miss-use of the legacy abilities of IM.

            This style of command line is for legacy support only, and as such is depreciated, so should be avoided if at all possible. Any scripts containing this old style, should also be updated to do image reads before the operators you want to apply to them.

                Legacy support will continue into IM version 7, which includes a command that allows for single-pass processing of command lines. This allows it to actually read image processing options from script files and even a pipeline. However a single-pass processing technique will not allow for the saving of operators BEFORE reading an image to apply them to. In fact the "magick" command will produce 'no image' type errors, if you try to use an operator without an image in memory.

            Command Line vs API
            There is a couple of major differences between a command line IM, and using the Magick API's, such as PerlMagick, RMagick, PHP IMagick, and MagickWand.

            Only one Active Image List
                The command line only ever has one Image List which can be worked on at any one moment.

                You can 'push' or save an image list temporary (see Parenthesis and MPR: Named Memory Registers). You can even 'clone' (make an efficent copy) of images from the last 'pushed' list. But you can't really work on two such lists at the same time.

                Other language API's on the other hand allow you to have as many separate image lists or 'wands' as you like. In fact you typically save each image as a separate wand (image list and settings) for better processing and only merge the image into a list as needed or as part of the final step. You can also work on them in any order, and store them into databases or other data structures, for sorting or later comparison.

                On the command line however one single image list means you can not do operations in just any order, but generally try to do things in a more logical sequence, completely finishing each image processing step as you go. Basically it means is much harder to 'go back' or to change something later, using results from one set of operations to select or modify what set of processing operations should be performed next.

                It is especially more difficult to merge or interleave (shuffle) two completely separate lists of images into a logical whole. However some techniques have been worked out, to allow you to do this from the command line. For example see Multi-Layer Alpha Composition of Image Lists.

            Direct Access to Pixel Data
                Again you can do some math processing and merging of pixel data from the command line, but you can't easily look up attributes, or read and modify a specific pixel or area using the command line interface.

                You can merge and mathematically modify pixel data of images using the special FX Image Operator, but it is generally limited to transforming whole images, and is very very slow.

                To make it easier many common operations developed by users using the FX operator, have now been built into IM, creating things like Color Lookup Tables, Evaluate Math Functions, and Multi Argument Functions. As well as the General Image Distortion Operator, and some special Image Composition Methods.

                API's can manipulate images in a much more direct manner, alowing you to DIY an unique operation much more easilly, at the full speed provided by the API language.

            Conditional Processing
                The IM command line interface cannot easilly modify images based on some image derived attribute. For example it is very hard to process images differently depending on if the image uses a light background, or a dark background.

                Yes you can do some limited and specific conditional actions using the FX Image Operator, or ask IM to adjust (rotate) an image's Orientation based on certain conditions, or only shrink and never enlarge when Resizing Images. But these are only handling special well known and common processing conditions.

                The only truly practical way do conditional processing is to use separate commands and temporary files. For an example of this see the well commented Jigsaw Script.

                API's on the other hand can do this type of conditional processing, while holding all the images involved in memory, ready to continue processing based on the specific conditions, as and when you need it.

            Looped Processing
                You also cannot just simply loop over images in a controlled manner, or easily modify the process based on which image in the sequnece is being handled. that is you can not simply do something different to each image based on the image 'scene' number, or the results of previous images. For example draw text at different sizes, or gradually blur an image, or generate an animation list in the one single command.

                Yes you can modify specific images in an image list. For example see Frame by Frame Modification of an Animation. But you must know how many images are in the image list, and 'un-roll' the loop to process each image in the list separately.

                The only truly practical way to loop over images from the command line is to write out the individual images as separate image files (see Writing a Multiple Images) and process them one at a time in an external scripted loop. For example see the shell script that is designed to Divide an Image Vertically.

                Alternatively, you can generate the images using a shell script loop, and pipe the result into a final command to merge them into the final image or image sequnece. For example of this see Layered Images Examples, or the various Warped Image Animations shell script generators.

                API's however have no problem with looping over multiple images, either in a single image list, or even multiple image lists, or even with a whole array or data structure of image lists. It can also hold all the images in memory ready for the final combining step, without pipelining, or using temporary files.

            If your application needs to be able to do any of these things (though few applications actually need to go this far) then an API may be a better choice.

            The "conjure" program (see below) was originally designed to allow better scripted use of ImageMagick, allowing the use of multiple image lists. The improvements made to IM v6 "convert" has seen this experimental API fall into disuse, though it is still available and still being developed.


            Argument Handling
            Beyond the filenames and options on the command line there are only a few basic styles of option arguments that are used.

                Constant Names  (for specific settings and method types)
                List of Contant Names  (for example two colors, or Channels)
                Geometry Argument  (a special formated list of numbers with flags)
                Floating Point Lists  (sometimes with Percent Escapes)
                Free Form Text Strings  (with Percent Escapes) 

            Constant Names
            Constant Names are specific string constants that are used to look up an internal library of allowed settings that may be used by an option.

            For example, the "-gravity" setting can take any of nine different settings. Once set that setting is then be used by all the image processing operators that follow the setting on the command line. For example: settings such as 'North', 'East', or 'NorthEast'.

            You can get a list of all valid settings by using the List Operational Option (see below). For example using the command...


              convert -list gravity

            Only those specific settings are allowed and if you attempt to use some other setting you will get an error. For example...


              convert xc: -gravity Invalid   null:

            [IM Text]

            The setting can be specified in a number of different ways, all of which are perfectly valid. IM is very forgiving about this. For example a setting can be specified in uppercase, lowercase, or any combination of the two. The individual words (specified by uppercase letters in the "-list" output) can have extra spaces, hyphens, or underscores included, and which are then simply ignored (but only between words).

            Consequently all the follow arguments are valid to set "North East" "-gravity"...

                'NorthEast',  'northeast',  'NORTHEAST',  'NorTheAst',  'north east',  'north-EAST',  'NORTH_EAST',  ' North East ',  '___North___East___'. 

            But an argument of 'Nor The Ast' is not valid, even though the letters are all correct, as it uses spaces within the declared words of the setting.

            These constant names are not just for settings, but also to declare the operational method to use in some of the more complex image processing operators, such as "-layers", "-distort", and "-morphology".

            Some of the constant names are read from external configuration files. For example, color names such as for "-fill", "-stroke", "-background" and "-mattecolor". Or the special 'threshold' maps used for "-ordered-dither". Again "-list" can be used to look up what names your currently installed version of IM knows about.

            Constant Name List
            This is a little used argument and is most commonly used in settings that need one or two colors, such as Level Adjustment by Color. The "-level-colors" option can take any of the following argument styles.

                color   color1,color2   color1-color2 

            It is also used for Image Selection, for operations that make use of multiple image indexs, for example Duplicate and Clone. The indexes start with zero for the first image, while negative indexs can be used to denote image indexs starting from the end of the image list. For example '-2-1' means take the second last image (index '-2'), to the second image (index '1'). And yes this actually means take the images in the reverse order specified!

            Another option that makes heavy use of this is Channel Selection where you can specify a list of specifically named channels. For example: 'Red,Green,Blue,Black,Alpha'. However the Channel Setting can also use a shorthand using a string of single letters (Eg: 'RGBA')

            Geometry Arguments
            This is the most common form of option argument, and is typically used to specify sizes, rectangles, and offsets for various operations. But it is also used by any option that needs any list of 1 to 5 numbers, whether they are integers, or floating point.

            For example, options such as "-crop", and "-resize" will use the full syntax of a geometry argument, while others like "-border", "-level", and "-gamma", may only use a small part of the full geometry syntax.

            This type of argument is so common that a special (and complex) parser has been written to convert such string arguments to numbers and flags, for use by any operator that needs a geometry argument.

            A geometry argument basically allows an user to specify a single string argument containing up to 5 floating point values (though most operators only use integers). All the following string forms are understood the geometry argument parser...

                WxH+X+Y   WxH   +X+Y   A   A/B/C   A,B,C,D,E 

            Users could specify the small list of numbers in ANY of these forms, but typically which form is used depends on the operation the argument is being used for.

            The first few is typically used for the specification of a rectangle of specific size and location, or just an offset for some purpose. Offsets are always decoded to different numbers, those on either side of an 'x' in the string. That is a "+X+Y" is always decoded as a 3rd and 4th numbers while it flags that the 1st and 2rd are undefined (or zero).

            The last few forms will allow up to a maximum of 5 posible input values, and are typically used for specifying a value for each of the standard RGBKA image channels.

            On top of these numbers, the parser also reports if any special 'flag' characters are present (any of '%', '^', '!', '<', '>' ).

            The Parser however only reports if the characters is present. It does not report where they were found in the argument. IM for example does not remember that '% was attached to a specific number. It also does not report if it appears multiple times either.

            This means that a geometry argument of '%50' has exactly the same meaning as '50%' though the latter is preferred for readability. Also '50%x30' will probably actually mean '50%x30%' and NOT 50% of the images width, and 30 pixels high as you might think.

                As a geometry arguments can contain special '%' flags, you currently can not use Percent Escapes to set its values based on image attributes.

            There is a Future Proposal about exactly when a percent escape will be expanded that could fix this problem with geometry arguments. And hopefull will be part of IMv7.

            Floating Point Lists
            If more than 5 floating point numbers are needed, perhaps even an unknown number of values, then a Floating Point List argument, is used, though at the moment these are generally parsed by individual options, as they can vary slightly from option to option.

            Generally they consist of a string (typically quoted) of comma or space separated floating point numbers. The Distort Operator is probably the most well known operator to use a list of floating point numbers. Others include User Defined Morphology and Convolution Kernels, though it also has extra syntax specific to defining an array of numbers (kernels).

            One variant of floating point numbers is used by "-sparse-color", allowing you to substitute colors for some floating point values. Internally these are still converted to floating point values when the resulting array is passed into the core library function.

            Freeform Strings
            Other options just take a string as an argument. Either for generating labels, annotating text, or saving as image meta-data.

            These will typically include Percent Escapes in the string which are replaced (substituted) at some point before the string is used. It may be an immediate substitution, or the substitution may be performed later, just before the arguemnt is actually used. (See Delayed Percent Escapes below.

            Arguments with Percent Escapes
            Because of their nature, either of last two types of arguments are often pre-processed so as to expand Image Property Percent Escape within the string.

            That means that specific sequences of characters will be expanded (string replaced or substituted) into some other string, or value that is looked up or calculated from the image(s) being processed.

            This typically is done just before the argument is actually applied by the operator to a specific image, so that settings specific to that image can be used.

            If percent escapes are allowed in an argument, you can instead prefix the argument with a '@' so that the whole argument is instead read from the given external file (or standard input). For example '@filename' will be replaced with the contents of the file 'filename'. If this happens, no percent or other special escapes is applied. That is string read from the file will be taken as literal, and used without modification.

                WARNING: that file could be anything, including system and password files that may be readable by the program. As such web users should pre-check input strings for this special case, or better still feed that string to IM using the '@filename' clause, as a security measure.

            If the string is not read from a file or input stream, then any '\n' strings are replaced with a 'newline' character, and any '%' prefixed label is replaced with the appropriate value. See Image Property Percent Escapes for the complete list of replacements.

            The use of Percent Escapes in arguments, means that for growing list of operators that allow the use of such escapes, such as "-set","-sparse-color", "-distort", or "-morphology", you can generate arguments based in various image attributes and meta-data. ImageMagick version 7 allows the use of Percent Escapes in just about EVERY argument, (a key feature of IMv7!).

            Not only that but you can even calculate different arguments depending in the content or index of the image! You can even pre-calculate some complex settings using per-image or predefined global settings.

                Before IM v6.6.9-0 Percent Escapes and more specifically FX Percent Escapes involving image indexes, such as '%p', '%n', '%[fx:t]' and '%[fx:n]' were broken. Typically they would only return unhelpful values of either '0' or '1', and not the actual index and number of images in the current image list.

            Delayed Percent Escapes
            Note that for some setting options Percent Escapes are not be expanded immediately they are seen, but simply stored AS given. It is only later when the text is actually used, that any Percent Escapes found in the string should be expanded, when the image they will be used with are finally known.

            That is these arguments must delay the substitution of Percent Escapes until the argument is actually used.

            These options include the Input Settings such as: "-label", "-comment", as well as the "-format" setting, and global "-define" values.

            This means you can specify a "-label" containing image specific Percent Escapes long before the image it is to be applied to is actually read in. Only when the label is actually attached to the image (just after it is read in) is the Percent Escapes expanded, so that it can make use of the attributes of the image to which it is being applied.

                The major limitation to the more wide spread use of Percent Escapes is that it is currently only applied to a limited set of option arguments. For example we currently can not use them with Geometry Arguments, which also use 'percent' characters, but for a different purpose.

            This problem is one of the major problems that IMv7 will be fixing.

            ImageMagick Commands
            While the bulk of these ImageMagick example pages use the "convert" command to process images, there are a number of other ImageMagick commands, which I'll briefly introduce here.

            Some of these commands however can not be demonstrated properly on a web page. However I will try to give you hints and tips involving those commands here, even if I can't actually show their output directly, here.

            Convert -- Convert and Modify Images
            The "convert" command is the main workhorse of ImageMagick, and as such just about every set of examples in these pages uses this command. As such I will not cover the use of this command much here, but look at a little history instead.

            The commands original purpose when IM was first created was for the conversion of images in one image format into another. In fact it is still used for this purpose, and why it is called "convert".

            Because of this the command may not even read an image into memory, but may use secondary Delegate programs outside IM proper to do the conversion directly. This completely external aspect however has fallen into disuse over time, and lack of need, except as a means of reading in and writing out complex images file formats.

            Over a long period of time some extra image processing features was added to make minor changes to images as they were transferred between formats, or even the same format. These were generally simple options, but as of IM version 5 the use of these processing features had become extensive, and a far more important aspect to the "convert" command than just image conversion.

            As options multiplied, multiple options started to be used, the order of the options started producing weird and uncontrollable results. To users IM became known as unstable and uncontrollable when multiple image processing options was used, and it started to fall into disfavor.

            IM version 6 saw the switch from a simple 'options' style, to a 'do it as you see it' style for image processing, and as a result, image processing abilities become stable, predictable and IM's command line abilities became many orders of magnitude more useful.

            As a result of this, "convert", is no longer so much about 'converting' images from one format to another, but as a command line API for accessing image processing functions, to create, and modify images in very complex ways, without needing a degree in image processing, or programming in a computer language (such as Perl, PHP, or C). Of course some shell scripting knowledge is helpful, though not strictly required.


            identify -- Print the details of images, that IM sees
            The "identify" command is designed to return information about an image in a simple and useful way. By default it outputs a simple compact summary, detailing the images name, file format, image size, virtual canvas size and offset, color depth, internal format type, and if known the original size of the image on disk in human terms.

            For example...


              identify  tree.gif

            [IM Text]

            Note that the '8c' in the above result is not the number of colors within this image (which is actually 6), but the 'pseudo-color' palette size (see later example for actual number of colors). Also note that the image 'virtual canvas' is the same size as the actual image with a zero offset, meaning it is currently not being used.

            Adding a -verbose, Operational Control, will produce as much information about the image that IM knows about or can easily calculate. This includes color statistics, color counts, profile information, internal image save type of the image, etc. etc.. However be warned that the output really is... verbose!

            Specific information can be obtained and output in specific ways by using the "-format" setting, and IM special percent ('%') escapes to output Image Properties. However typically you need to specify an EOL (newline under UNIX or MacOSX) as part of that argument (changed in IM v6.8.5-8).

            For example you can just extract a count of the number of colors within an image.


              identify -format '%k\n' tree.gif

            [IM Text]

                Before IM v6.8.5-8 "-format" would automatically add an end-of-line character(s) to the output, so as to separate multiple image results. This is no longer done, so you may need to add your own appropriate EOL characters to the "-format" string.

            Identify, to Ping or not to Ping
            IM "identify" by default only reads minimal basic information about an image, using a technique know as "-ping". This means identify only reads enough of the image file to determine simple image information, such as size, without trying to read the whole image into memory. See Ping, Operational Control below.

            This is a big advantage of "identify" has over "convert".

            However, most image meta-data will not be available. For example, image labels from a PNG image file. For example, here I create an image with a 'label', and attempt to use a simple format setting to print out that label.


              convert rose: -set label "rose with a label" rose.png
              identify -format '"%l"\n' rose.png

                [IM Output]
            [IM Text]

            However this only happens for very specific cases. Any "-format" that has more complex escapes will automatically disable the use of a minimal 'ping' read.


              identify -format '"%[label]"\n' rose.png

            [IM Text]

            Or you can specifically disable this minimal 'ping' read, and force identify to read in the image 'in total' so it gets the desired information.


              identify +ping -format '"%l"\n' rose.png

            [IM Text]

            Generally you do not need to worry about it too much. Unless you are dealing with very large images such as photos.

            Identify as a floating point Calculator
            You can do some floating point mathematics using FX Escape Expressions...


              identify -ping -format 'double_width=%[fx:w*2] PI=%[fx:atan(1)*4]\n' tree.gif

            [IM Text]

            Note that the math does not even need to be related to the image itself, allowing you to use IM as a simple floating point calculator for use within your scripts.

            As we are only needing basic information we used the Ping control to prevent identify from reading in the whole image. It has no effect on the outcome in this case, but can speed up the command enormously.

            Extra Cavats about Identify

            Specific Format Details
                Normally IM reads in the image into memory (which is essentially into own internal data format), using various image library APIs and delegate programs, before outputting the results it sees using identify. That is "identify" analyzes the image/data content it has read in and stored. It does not analyze how the specific file format stores or handles the image data.

                This is important as there can be very specific aspects of specific file formats that "identify" will not report on. For example while it lists the contents of a GIF image color table for each image present (multiple images are possible), it will not tell you if all the images in the file share the same color table or not.

                If you need specific info about specific image file format, it may be better to use a tool designed specifically for that format. For example "giftrans" for the GIF file format, and "jpegtrans" for the JPEG file format.

            Color Histogram Output
                Note that if image has more that 1024 colors, no histogram or color tables will be included in the verbose output. To force the generation of this information you can use the special 'histogram:' file format which includes everything as a large image comment.

            Exit Status
                The identify program returns a non-zero exit status if a corrupted image is encountered and you add a Regard Warnings Control.


                  error=`identify -regard-warnings image 2>&1 >/dev/null;`
                  if [ $? -eq 0 ]; then
                    echo "The image is good"
                  else
                    echo "The image is corrupt or unknown format"
                    echo "$error"
                  fi

            Identify Output Alternatives
            As of IM v6.2.4 you can also produce identify output from the "convert" command using the special "info:" output file format.


              convert ../images/k* \
                      -format 'image \"%f\" is of size %G\n'  info:

            [IM Text]

            You can use a Write Operator to write to "info:" in the middle of a sequence of operations, say as a debugging tool. You can also have it write that output to a specific file (or file stream).

            A simplier method would be to use an "-identify" option to write to the normal 'standard output'.


              convert ../images/k* \
                      -format 'Image #%p named \"%f\" is a %m\n' -identify \
                      null:

            [IM Text]

            This can be also combined with another option, "-print" to output other information.


              convert null: -print ' (50 + 25)/5  ==>  %[fx: (50+25)/5 ]\n' null:

            [IM Text]

            The main difference between "-identify" and "-print", is that first will be run once for every image in memory, while the later will only run once.

            That means we can generate just about any text file we want about the images in memory, completely from within a single ImageMagick command.

            For example, here I generate a HTML file of same set of images I have used in the previous example...


              convert ../images/k* \
                 -print "<HTML><BODY><CENTER>\n" \
                 -print "<H1>  Display of %n Thumbnails  </H1>\n" \
                 -print "\n" \
                 -format "<IMG SRC=\"%i\" ALT=\"%f\" WIDTH=%w HEIGHT=%h>\n" -identify \
                 -print "\n" \
                 -print "<BR>That's all folks\!\n" \
                 -print "\n" \
                 -print "</CENTER></BODY></HTML>\n" \
                 null:

            [IM Text]

            You can see the result of the above output as a HTML Web Page showing the images.

            One final word about these options. All of them by default will print to the 'standard output' of the "convert" command. You can not specifically output to some other 'pipeline' or to a specific file, unless you previously re-directed 'standard output'.

            Writing the output using "info:" will let you direct the output to a specific file, just like you can to an image file. You can also direct the output to a previously prepared file descriptor, using the special "fd:" output file format. Of course that writes once per image, so some juggling of images may be needed to arrange for it to output once only.

            Mogrify -- in-place batch processing
            The "mogrify" command is in many ways like "convert" except it is designed to modify images in place. That is it's primary purpose is to read images (or animations), one file at a time, and modify them, before save the image back into the exact same filename the image was read from. Because of this...
            Mogrify is dangerous, as it can easily destroy the original image!

            As such, before you do anything final, test "mogrify" with a separate copy of your images. Do not do use it on an original image that has no backup.

            Now while "mogrify" normally saves a modified image into the same filename, it has two special options which allows it to save images into a different file.

            The "mogrify" specific setting "-format", defines a different format and suffix to use when saving files.

            As such a command like...


              mogrify    -format jpg   *.png

            Will allow you to convert, or batch modify images, without destroying the original image. In this case converting all PNG files into JPEG files with that same filename but a different suffix. However be warned that if there is an existing file with the same name, it will be over-written.

            So let me re-iterate...
            Think and check before you Mogrify
            or you may find you just overwrote something you wanted to keep. As of IM v6.2.0 you can also use a new "-path" option to specify a different directory in which to output the processed images. This makes it safer, however it will still overwrite any images of the same name that may already be in that directory. Also any old images that was left in that directory will not be removed.

            As such you can have IM save the results (say image thumbnails) into an existing sub-directory, using something like this...


              mogrify   -path thumbnail-directory   -thumbnail 100x100  *

                Before IM v6.3.4-3 the "-format" and "-path" settings were mutually exclusive. From that version you can change formats and output directory location.

            Due to the multi-image processing capability the "mogrify" command can not use any of the Multi-Image List Operators or Image Stack Operators.

            That means you can not use image processing operators like "-fx", "+swap", "-composite", "-append", "-flatten", and "-layers" in a "mogrify" command.

            As some setting options are needed to be set before the first image is read in (for example (for example "-size", "-label" and "-density"), these options are processed and set before the first image is read in. After this each image is read in and the operators applied to them in command line order before the image is saved and the next image read in.

            It is important to keep this in mind as if you change one of these settings later in the sequence you can make IM forget a previous setting.

            For example..


              mogrify -format gif  -size 200x200  -pointsize 18 \
                      -font Candice -gravity north  -annotate 0 "%f" \
                      -font Ravie   -gravity Center -annotate 0 "%f" \
                      -font Gecko   -gravity south  -annotate 0 "%f" \
                      -size 100x64   xc:gold  xc:orange   xc:tomato

            [IM Output] [IM Output] [IM Output]

            As you can see the size of the above images generated was determined by the second "-size" input setting with the first larger setting being ignored completely. On the other hand the operational setting "-font" is set correctly for each of the individul "-annotate" operations.

            This added complexity means that it is probably a good idea to...
            Mogrify images simply.

            Do not attempt to do very long and complex "convert"-like operations in a batch operation using "mogrify", it will probably have 'setting' issues. If you are really wanting to do complex processing, write a shell/dos/perl script to use "convert" to process each image one at a time, or go to an ImageMagick API interface.

            For examples of modifying lots of images using a script see Advanced ImageMagick Examples.

            Just remember, "mogrify" is a dangerous command, and should always be thoroughly tested on backup images, before putting into production.

            Actually I also recommend that scripts include a quick 'tests' on things like "mogrify" to make sure the command does not break anything (due to version changes or differences in computer installations) before processing a very large collection of images. That is do a small 'test case' and abort if it fails to produce a correct, before proceeding.

            This is actually a good idea for any large scale image processing project, so as to protect users from unforeseen consequences. I do this myself in IM Examples, and it has saved me a lot of trouble.

            Alpha Composition using "mogrify"
            Because "mogrify" can not use Multi-Image List Operators it can not easily overlay thing like logos, or mask images using Alpha Composition.

            There is one exception to this, using "-draw" to perform image alpha composition. This allows you to specify the second image, as part of the operators arguments, outside of the current image list.

            For example, here I first make a copy of the original images I want to process using a special "cp_perl" script. I then create temporary circle 'mask' image, which I then use to cut out a circle shape from all those images, using "mogrify" with a 'Dst_In' alpha composition method.


              cp_perl  's/^/mogrify_/'  eye.gif news.gif storm.gif tree.gif
              convert  -size 32x32 xc:none -draw 'circle 15.5,15.5 15.5,0'  circle.gif
              mogrify  -alpha Set -draw 'image Dst_In 0,0 0,0 "circle.gif"'  mogrify_*.gif

            [IM Output] [IM Output] [IM Output] [IM Output] + [IM Output] ==> [IM Output] [IM Output] [IM Output] [IM Output]

            Note that any Alpha Composition method can be used in this way, but only with a constant 'source' or 'overlay' image being applied to all the images.

            Also as "mogrify" will be reading the 'source' image multiple times, I suggest you use the special IM specific "MPC:" file format to reduce the overhead of decoding the image when reading it over and over. This image file format does not need to be parsed by IM as it will be mapped directly from disk into memory (for the same machine it was created on). This saves a lot of processing time, especially in dealing with a large number of images.

            Using Convert Instead of Morgify
            Using a special technique to modify the output filename using Percent Escapes, (see Filename Percent Escapes), you can replace "mogrify" with a more versatile "convert" command.

            Not only that but it will provide you with a more control of the final destination name of the image. and let you better handle multi-image processing such as compositions and animations.

            For example here I create thumbnails of images in the current directory, inserting a "_tn" string into the input filename, to create the appropraite output image filename.


              convert *.jpg   -thumbnail 120x90 \
                      -set filename:fname '%t_tn' +adjoin '%[filename:fname].gif'

            Warning, do not include a different file suffix in the filename setting itself. IM will not see it when deciding on the image file format to use. Note that IM can't decide from the filename it will fall back to the original file format that was read in, so a clear suffix, or a coder prefix can be important, when using this technique.

            To get the exact original filename the source image came from use "%i", "%d/%f" or "%d/%t.%e". Of course these all have the filename suffix, in the filename setting, whch IM does not use, but that should be okay as it is the same image file format.

            The real problem with using "convert" instead of "mogrify" is that ALL the images are read into memory first! Mogrify takes great pains to only read/modify/write one file (though that file could contain multiple images) at a time. But "convert" does not. As such you can very easily exceed memory limits if you are not careful. Though there are ways around this. See examples in Read Modifiers and Thumbnails.

            Also as all the images are in memory as a single image list, you will need to be careful on how you process those images. For example you can not directly use Alpha Composition as you normally would, but may need to use the specialised Multi-Image List Composition to do the job.

            Of course just as with "mogrify" this method of using "convert" can be dangerous, as it could easily overwrite and destroy the original image files.

            Batch Processing Alternatives
            If batch processing images using "mogrify" is not practical, especially if you are copying the images rather than modifying them in place, then it may be better to use some other non-IM looping solutions. These include...


              # Use a simple shell loop, to process each of the images.
              mkdir thumbnails
              for f in *.jpg
              do   convert $f -thumbnail 200x90 thumbnails/$f.gif
              done

              # Use find to substitute filenames into a 'convert' command.
              # This also provides the ability to recurse though directories by removing
              # the -prune option, as well as doing other file checks (like image type,
              # or the disk space used by an image).
              find * -prune -name '*.jpg' \
                     -exec  convert '{}' -thumbnail 200x90 thumbnails/'{}'.gif \;

              # Use xargs -- with a shell wrapper to put the argument into a variable
              # This can be combined with either "find" or "ls" to list filenames.
              ls *.jpg | xargs -n1 sh -c 'convert $0 -thumbnail 200x90 thumbnails/$0.gif'

              # An alternative method on linux (rather than plain unix)
              # This does not need a shell to handle the argument.
              ls *.jpg | xargs -r -I FILE   convert FILE -thumbnail 200x90 FILE_thumb.gif

            And so on.

            I recommend the use of both "find" and "xargs" for doing recursive or even non-recursive file processing. Read their man pages. For a quick introduction see this IM Discussion Post, as well as the guide Xargs - Wikipedia which includes information on the dangers involved.

            If your commands start to get more complicated than this, it may be time to go to a shell script, or API program, to read in multiple images, gather information, calculate appropriate arguments, and process the images.

            I also recommend a good look at the "parallel" command (typically a drop in replacement for "xargs"). This can not only let you run multiple commands simultaneously, but can with a little work run each command on different computers, allowing you to do network distributed processing of a very large number of tasks.

            For Windows Users I refer you to the Windows Usage section, and in particular Windows, Batch Processing Several Files.

                Remember "mogrify", and all other IM commands will also expand all filenames containing shell meta-characters such as '*' and '?'. This is done to allow the use of these meta-characters on the old DOS command line shell. However this could cause a bug, repeated mogrify execution, or possibly even a 'hack' from a some evil source that provided the filename to use. Caution and complete understanding of security issues is advised.


            Composite -- overlaying images in special ways
            The "composite" command is designed specifically for simple alpha compositing (overlaying) of two images together in various ways. This includes limiting the area in which images are combined together, though the use of a third masking image.

            Unlike "convert" the "composite" command is a very traditional command in that it will read all its options and settings, before it actually performs the single image processing operation it was designed to do.

            The "composite" command also provides simple access to some of the more complex alpha composition modes. For example "-dissolve", "-blend", and "-watermark" image composition. If any of these arguments are given, they will override any other "-compose" setting that was (or will be) given for that command.

            Note also that the "-tile" setting also works differently to that of either "convert" or "montage" and "display". In "composite" this will cause the overlaid image to be tiled across the whole of the background image. Something not yet available in other IM commands.

            While these special features makes "composite" an useful command, the alpha compositing is now also available for use in the "convert" command. (For details see Alpha Composition in IM).

            For a summary of multiple different ways of overlaying two or more images together see the examples in Compostion of Mutliple Pairs of Images.

            For more information on the method by which two images can be merged together see the Alpha Compositing examples page.

            The overlay limiting or 'Masking' abilities is also detailed in the above examples page in Using a Compose Mask to Limit the Composed Area.

            Montage -- generating arrays of thumbnails
            The special IM image indexing command "montage" also followed the same 'do it as you see it' style of command line structure, as "convert".

            The only difference is that when the end of the command is reached (other that the final output image filename argument), "montage" will start to process the image list into a thumbnail image index page(s), according to the settings that are currently set.

            This makes "montage" much more versatile than it was in IM version 5, as you can now process the images just as you would in "convert", then set all the "montage" settings you want, and let it finish the job.

            For more details about "montage" see Montage, Arrays of Thumbnails.


            display -- Slideshows of Images
            The "display" program is designed to display an image, or list of images in the form of a looped slideshow. It is not designed for a carefully orchestrated and timed animation of images, for that use the "animate" command.

            Each image will be displayed in a window sized appropriately for the image, unless other options (like window "-geometry", see below) override this behaviour. The image will also generally be displayed on a checkerboard background so as to show the effects of any transparency the image may have (see below).

            Remember this is NOT designed for the display of an animation, but as a slideshow of actual images. As such some caution may be needed when using display in a scripting program.

            Image Display Time, Loop, and other options

            By default a delay of approximately 2 seconds is used on top of whatever delay the user specifies using the "-delay" setting. However you can make it wait for user input (spacebar) by using the option "-delay 0". However defaults can be overridden by the images themselves, depending on there file format. As such animation formats like GIF and MIFF could result in either a pause, or a 2 second plus the images meta-data delay setting. It is thus recommended that you always set a "-delay" as appropriate (remember "-delay 5x1" will delay 5+2 or about 7 seconds) for your script and needs.

            The same goes for the "-loop" setting. By default "display" loops forever ("-loop 0") but image formats like MIFF or GIF can override this so as to cause it to exit after last image in the loop. See the "-loop" option appropriately for your situation.

            Note that "display" will not handle any GIF Animation Settings so frames are not disposed of, and virtual canvas sizes and offsets are ignored. In other words you will see the raw partial images in a GIF animation, not the correctly overlaid image. It does provide a "-coalesce" option to clean up such animations for display purposes.

            Transparency Handling
            Images containing a full alpha channel (EG PNG and MIFF formats) will be overlaid onto a 'checkerboard' background pattern, so as to let you see the effects of any semi-transparency, such as shadow effects.

            You can change that by selecting a different background with "-texture" such as...


              display -texture granite: test.png

              display -texture xc:black test.png

            Images with a palette (or boolean) transparency, such as GIF and PNG8 formats, is displayed with a the current 'transparent color' that was used to represent transparency in the color table. That is a generally random color may be used (typically black) rather than the default checkerboard pattern. This could be regarded as a bug, though technically it isn't.

            However if you like display to handle such images in the same way as other images containing transparency information, you can remove the palette meta-data before feeding the image to "display" using the following commands to change the internal style for the image output format.


              convert image.gif -type truecolormatte miff:- | display -

            Alternatively, just about any operation that modifies the image being displayed will also remove the existing palette meta-data. As such some "display" options can be used to remove the palette. For example using "-coalesce".


              display -coalesce image.gif

            This has the added bonus of cleaning up GIF animation optimizations that may be present. Though for multiple, unrelated images it could have other undesirable side effects.

            Yes these methods are clumsy, but they work.

            Display Using Convert
            An alternative display method (other than using "animate", see next) is to use the simpler "x:" output image format (See display output format).


              convert image.png x:

            This method does not provide a backdrop window, menu options, or other controls. It just simply displays the images one image at a time.

            If you do want to just simple 'display' the resulting image the special 'show:' or 'win:' output Spawning Delegate will do the same thing by runing the "display" command on the output image, and exiting without waiting for that window to be closed.


              convert image.png show:

            Display Output Size
            Display will not scale an image to fit it to the X window display. The window size will be adjusted to fit each image, unless set using the "-geometry" setting. That setting can also be used to fix the windows position on the X window display.

            Images which are larger that the screen, will also not be resized, but will overflow the screen, display will however also provide a 'scroll window' to let the user slide around the image.

            This can be painful when viewing a modern high resolution digital photo.

            To limit display to say a 800x600 pixel area (only resize smaller, never larger), use...


              display -resize 800x600\> photo.jpg

            For JPG images you can speed up the image read by using a special jpeg input size hint setting. See Reading JPEG Control Options.


              display -define jpeg:size=1600x1200 -thumbnail 800x600\> photo.jpg

            If the image is from a modern digital camera you can also use "-auto-orient" to correct the camera rotation of the displayed image, using the EXIF meta-data in the image file format.

            If you don't want menus, you can turn them off using the "-immutable" setting to "display", so it knows not to allow editing.

            Scripted use of Display
            With these options in mind, the following is my recommendation for using "display" to display results from a complex shell script...


              display -delay 0 -loop 1 -coalesce -resize 800x600\>   some_random_image

            Display with X Windows
            The option "-window root" can be used to display an image on the X window background (root) window. In this case the "display" program automatically exits.

            By default an image is tiled across the background. For example try this..


              display -window root pattern:checkerboard

            For many other examples of image tiles, and generating them see Tiled Canvases, and Background Image Examples.

            If you want to use a single image for your X Windows background, you may need to know the size of your X window display. The "xdpyinfo" program while not part of ImageMagick, can give you that information.


              xdpyinfo | grep dimensions:

            And here we use the output of "xdpyinfo", to resize an image to fill the X window background completely.


              screen_size=`xdpyinfo | sed '/dimensions:/!d;s/^[^0-9]*//;s/ pixels.*//'`
              display  -resize $screen_size! -window root photo.jpg

            Display Remote Control
            Display does provide a special "-remote" option. This will look for an already running "display" command and will then pass the given arguments to it.

            For example...


              display wizard: &
              sleep 5
              display -remote logo: &

            Will display the built in "wizard" image in a backgrounded command. The script will then wait 5 seconds before replace it with the built-in "logo" image.

            Note that if no "display" command is running, the current command will open a window and not exit. As such you should also background the "display -remote" commands as a precaution.

            At this time you can not request a remote "display" to exit. As such the best way to close the remote display is to either kill the running process, or 'delete' the display window using some X window command.

            For example (using the non-IM command "xdotool")...


              xdotool search -class "display" windowkill

            animate -- Show an animation of images
            In many ways "animate" and "display" are extremely similar.

            However "display" only shows the images in the given image file 'as-is' without change, adding an minimal 2 second pause between each frame for user input.

            "animate" on the other hand will apply any GIF Animation Settings that are saved with the image, and only display each image according to its 'time delay' settings, looping back to the start to repeat the animation. In other words "animate" 'animates' animation formats properly where "display" does not.

            However because of this, the virtual canvas of the first image will control the output image size, and other image will be overlaid into that image area.

            Of course as the images are animated, you do have a fine control of the image display timing, using options such as "-delay". The command also has an extra argument "-pause" to add an extra pause at the end of the animation loop, beyond whatever the final frames "-delay" setting specifies.

            For example you can use "animate" to generate a Flicker Comparison of two very similar images, using something like..


              convert image1.png image2.png -scale 400% miff:- |\
                 animate -delay 50 -loop 0 -

            I have written a script to take advantage of this method called "flicker_cmp", and find it extremely useful to pickup very subtle changes in pixel intensity that I would otherwise miss.


            compare -- Look for Differences
            All current information on this is on the Image Comparison Page section of IM Examples.

            stream -- pipeline processing of massive images
            "stream" is a special program that is designed to handle extracting a portion of a very large image file. It is the only such program within ImageMagick, all others read the images completely into memory before processing (the exception is JPEG images via the "-size", as this option is passed to the JPEG delegate library).

            You can select a portion of the image with the "-extract" setting. And you can specify the depth of the raw bytes with "-depth" setting. And finally, you can select which color channels to extract using the "-channel" option.

            However "stream" will only output the raw color bytes of the image (RAW format) as defined by the image depth, as such you may need to pipe the output of the extracted segment into convert.

            For example...


              stream -map rgb -storage-type char -extract 100x100+200+100 logo: - |\
                convert -depth 8 -size 100x100 rgb:-   stream_wand.gif

                [IM Output]

            For more information and examples see Really Massive Image Handling.

            import -- read images from the on screen display
            The "import" command is a special program that can be used to grab and extract images from an X windows display. For example lets get it to grab and print a window you select from your display...


              import -page A4 -gravity center ps:- | lpr

            It is actually rarely used as the special file format "X:" also provides exactly the same functionality from within the convert command.

            The only difference between the two is that "import" has more X window specific settings than the "X:" format, such as specifying the display, screen, and/or window ID, the image is to be grabbed from.

            Other options include controls display 'beeping' and repeated snapshots.

            If no specific window is specified, the mouse can be used to select what parts of the display the user wants to grab as an image.

                If a single mouse click is used the whole window clicked in is grabbed and returned as an image. Note that if any other windows on the display is obscuring part of the window selected, then you will grab an image of the obscuring other windows are obscuring the selected window being grabbed.

                A click in the root window, or selecting "-window root" will return the whole screen.

                If a mouse click and drag is used a Cropped section of the whole screen is returned, which of course also means the location (virtual canvas offset) on the whole display (virtual canvas, or page, size) is also returned.

            Other options allow you to avoid human interaction with the mouse by grabbing the whole screen ("-window root"), or a specific window, given a window title, or a X window ID, which you can find using the X window utility "xwininfo". You can also cut down the area of the selected window using "-extract".

            See also the special input format, "X:" as an alternative to using "import".

                Note to import from the Windows clipboard use
                  convert clipboard:myimage image.png
                and not "import"

            conjure -- IM experimental scripting language
            Was originally designed to allow scripted Imagemagick use, with the use of multiple image lists, but the improvements made to IM v6 "convert" has seen this experimental API fall into disuse.

            It is an XML based language. Though if you want XML, SVG may be better for your needs.

            In my opinion, using the "conjure" script is probably better and easier when dealing with multi-image list. And is being used, though not very widely, due to lack of examples and support by users.

            Image Lists...
            One of the most important points to remember with ImageMagick, and one that confuses both new users and experienced users, is that...

            ImageMagick works with Ordered Lists of Images, not single images

            That is IM deals not with just one image, but potentially an ordered list of images, be they separate individual images, a set of images that layer on top of each other, or the frames of an animation.

            Also in general all image operators will be applied to all the images in the current list.

            As such if you use a "-draw" operator, it will not only draw on the last image in the list, as many new users would assume, but it will draw onto all the other images in the current image list, and does so to each image in turn.

            Image Layering Operators, such as "-coalesce" and "-layers" will replace each image in the list with a new image modified according to the other images in the list. It may even add or remove extra images!

            Also Image List Operators, like "-append", "-mosaic", and "-fx", will replace ALL the images in the current image list with the resulting combined image. That is it will destroy all the images, unless they were previously saved using Parenthesis, and Cloned Images were used. See Image List Operators below for practical examples.

            Finally when a new image is read in or created, IM only adds that new image to the end of the current image list (which always exists). Some formats (like GIF) may actually add multiple images to the current image list, unless a special Indexing Read Modifier is added to the input filename, to limit what is read in.

            When saving images, IM will save the whole image list that is in memory at the time of writing. If image format allows it IM will write ALL the images into a single file. If the format does NOT allow multiple images (for example JPEG), it will write the images into separate files (See Writing a Multiple Images).

            Parenthesis -- processing images 'on-the-side'
            With the formalization of the command line options, the processing order is now exactly predictable, and it has also become possible to add parenthesis (or brackets) to the image processing. This has been a desired feature by IM users for a long time, and allows you to do things never before possible in a single command.

            The opening bracket '(' will in affect start a new image list, that all enclosed operators will work on. The matching close bracket ')' will then add the resulting image list (which may be more than one image, or none at all) to the end of the previous image list.

            In other words, using parenthesis means...
            "I need to do a bit of work in a separate image list
            before adding the results to the end of previous list."

            It allows you to work on a sub-set of images, like a scratch pad, than add the result back into the main image list without affecting the images you have already previously read in or have been working on.

            Let's look at some simple examples...


              convert   eye.gif  storm.gif  -negate  +append  cmd_negate.gif

                [IM Output]

            As you can see the "-negate" operator, color negated both images, as both were in the current image list in memory at that time.

            But by adding parenthesis we can limit the negation to just the second image...


              convert   eye.gif \(  storm.gif  -negate \) +append  cmd_bracket.gif

                [IM Output]

            Because the "storm.gif" image is read into a separate image list to that of the first image (generated by the "(" image list operator), it can be negated without affecting the first image. Then we can add the result to the main image list (that is the ")" operator), before appending the two images together as before.

                Parenthesis must be given as a separate argument. That is you must separate them from the other arguments by spaces. You can not add them hard up against neighbouring arguments. In other words in the IM command line argument " \(+clone " is wrong, while " \( +clone " is correct.

            Also in the last example I needed to put a backslash '\' before the parenthesis. That is because when using IM on an UNIX (linux) machine, parenthesis has special meaning to the command line shell. As such I need to escape, or quote the bracket symbols, when I use them.

            Windows DOS scripts do not require parenthesis to be escaped with backslash. See Windows DOS Scripts for this and other differences to linux scripting.

            Parenthesis also make it possible to do something not previously possible to do in a single "convert" command. Generating arrays of images!


              convert  eye.gif news.gif  +append \
                     \( storm.gif tree.gif +append \)   -append  cmd_array.gif

                [IM Output]

            Arrays like this were of course possible using "montage" (see Montage Concatenation Mode), But using a separate command makes image processing scripts more complex.

            Of course if you like to make the command look more array like itself, you are free to add some extra parenthesis.


              convert \( eye.gif    news.gif  +append \) \
                      \( storm.gif  tree.gif  +append \) \
                      -append  cmd_array2.gif

                [IM Output]

            The first set of parenthesis aren't strictly needed, and do add a tiny amount of extra work to IM's internal processing, but it does make it clear what the command is doing by separating the processing steps.

            It may also be easier for image processing scripts to perform each processing step as a separate parenthesis, as a means of separating the processing steps, it is applying.

            Parenthesis and Settings
            Option 'settings' are not affected by parenthesis, and will continue across the parenthesis image operators, until the setting is changed or turned off.

            For example...


              convert -pointsize 24 \
                      -font Candice label:Outside \
                      \(              label:Inside \
                         -font Gecko  label:Inside \) \
                      label:Outside       -append   cmd_settings.gif

                [IM Output]

            Note how the first "-font Candice" setting is NOT reset back to its default setting when the parenthesis is entered, while the second "-font Gecko" is not replaced by the original font setting when you leave parenthesis.

            In other words...
            Parenthesis only create a separate Image Sequence.
            They do not limit settings, only the images being worked on.

            As of IM v6.4.1-4 the new operational control option "-respect-parenthesis" can override this behaviour.

            When given at the start of an IM command, it will cause parenthesis to also save and retrieve the previous settings that have been given. That means any settings given within parenthesis, will only remain set, until the end of the parenthesis.

            For example...


              convert -respect-parenthesis   -pointsize 24 \
                      -font Candice label:Outside \
                      \(              label:Inside \
                         -font Gecko  label:Inside \) \
                      label:Outside       -append   cmd_settings2.gif

                [IM Output]

            As you can see, when the parenthesis ended, the font setting was restored to the previous 'Candice' font, instead of the 'Gecko' font that was set within the parenthesis.

            This can be most useful when you have to change a lot of setting, for just a short time...


              convert -respect-parenthesis \
                      -font Arial   label:"This is a line of plain text." \
                      \( -font Candice -pointsize 16 -fill red -undercolor lightblue \
                          label:"A line using a lot of different settings." \) \
                      label:"Text is back to normal -- like Magick\!" \
                      -append  cmd_settings_lots.gif

            [IM Output]

            Image List Operators
            With the stronger emphasis by IM on image sequences, especially within parenthesis, it is no surprise that a set of new image operators have been provided to manipulate the image lists.

            The arguments to these operators are numbers indexing the image list, starting with zero ('0') for the first image, and one ('1') for the second image, and so on. However if you give a negative index, the images are referenced from the end (last image added) of the image list. That is an index of '-1' is the last image in the current image list (generally the last image read or created), '-2' for the second last and so on.

            -delete {index_range_list}
            The "-delete" list operator is the simplest of the image list operators, it just deletes images from the current image list.


              convert font_[0-3].gif -delete 1 +append  seq_delete.gif

                [IM Output]

            The 'plus' form of the operator, "+delete" does not take an argument, and just deletes the last image in the current image list.

            The "-delete" operator will also accept a comma separated list of numbers, or a number range to be deleted.


              convert font_[0-7].gif -delete 1-4,6 +append  seq_delete2.gif

                [IM Output]

            Or delete everything (and add a new image)...


              convert font_[0-7].gif -delete 0--1  tree.gif seq_delete3.gif

                [IM Output]

            The '0--1' argument means delete images from first image (index 0) to the last image (index -1). In other words ALL images in the current image list. The tree image was then added to give IM an actual result, so as to avoid a 'no image' type error. A "NULL:" output image could also have been used, to produce no output.

            If an image index does not exist, or a number range is reversed, "-delete" will silently ignore that specific image deletion.

            For example, the argument '-25' will attempt to delete the last 25th image in the image list, but will silently do nothing if less than 25 images are present. As such you can generate a rolling animation of 24 images using a sequence like...


              convert animation.gif  new_frame.gif  -delete -25  animation_new.gif

            However no image will be deleted if the number of images was 24 or less. As a result the animation will grow by one frame, every time the command is run, until a maximim of 24 frames is reached. After that the oldest (first) frame will be delete while a new frame is added.

            As of IM v6.3.4 "-delete" will not delete images that result in the numbered range being reversed.

            That means that last example could be re-written like this...


              convert long_animation.gif  new_frame.gif  -delete 0--25  animation_new.gif

            This time the "-delete" will delete all images between the first, to the last 25th image, leaving at most 24 images in the list. If only 24 or less images are present, the given range of images to be deleted will be effectively reversed, and the "-delete" operator will not delete anything.

            -insert {index}
            The "-insert" operation is sort of the opposite of "-delete". It will take the last image in the current image list and insert so that it is positioned at the given index.


              convert font_[0-3].gif tree.gif -insert 1 +append seq_insert.gif

                [IM Output]

            You can think if the insert index as the number of images that should appear before the point where the image was inserted.

            Of course the image that was at that index (and all the images after it), will be bumped up into the next index position to make room for the new image.

            If a negative index position is used, the insert position is calculated after the image being inserted is removed from the end of the list. That is it will act as if the image being inserted was not part of the original image list. As such "-insert -2" will 'roll' the last three images, placing two images between the newly inserted image and the end of the image list.


              convert font_[0-3].gif tree.gif -insert -2 +append seq_insert2.gif

                [IM Output]

            The plus form "+insert" will move the last image to the front of the image list (index 0), effectively rolling the whole image list by one frame.


              convert font_[0-3].gif tree.gif +insert +append seq_insert3.gif

                [IM Output]

            To do the inverse of the above (move an image to the end of the image list), can be done by first using "-duplicate 1,0" to copy the first image, then use "-delete 0" to delete the first image.


            -swap {index}[,{index}]
            Simply put "-swap", will swap the positions of two images in the current image list. For example "-swap 0,2" will swap the first and the third images in the current image list.


              convert font_[0-3].gif  -swap 0,2  +append  seq_swap.gif

                [IM Output]

            The plus form of this option "+swap" will swap the last two images in the current image list. In other words, it is equivalent to "-swap -2,-1".


              convert font_[0-3].gif  +swap  +append  seq_swap2.gif

                [IM Output]

            Probably the most common use of this operator is to swap two images before being used by an image layering operator such as "-composite", "-flatten", "-append", or "-fx".


              convert tree.gif  frame.gif   +swap \
                      -gravity center  -composite   framed_tree.gif

                [IM Output]

            As of IM v6.4 a "-swap" with a single number will swap the last image with the number given. That is "-swap 1" is equivalent to a "-swap 1,-1".


              convert font_[0-3].gif  -swap 1  +append  seq_swap3.gif

                [IM Output]


            -reverse
            The "-reverse" operator (added to IM v6.3.4) will quite simply reverse the order of the whole image list.


              convert font_[0-3].gif -reverse  +append seq_reverse.gif

                [IM Output]

            It is basically an ultimate Swap Operator.


            -clone {index_range_list}
            This image list operator is a little different. Given an image list number "-clone" will make a copy of an image that has been saved by the 'open bracket' or 'parenthesis' operator. That is...

            Clone should only be used within parenthesis

            The reason for this is that it allows you to extract a copy of an image from the last saved (pushed) image list, so you can process it further. For example.


              convert font_[0-2].gif \( -clone 1 -rotate 90 \) +append  seq_clone.gif

                [IM Output]

            The 'plus' argument-less form "+clone" will just make a copy of the last image of the saved (pushed) image list so that you can process it further


              convert font_[0-2].gif \( +clone -flip \) +append  seq_clone2.gif

                [IM Output]

            As of the release of version 6.2.2 "-clone" operator will take a comma separated list of images, or a range of indexes of the form '{index}-{index}'.


              convert font_[0-2].gif \( -clone 1-2 \) +append  seq_clone_range.gif

                [IM Output]

            Of course negative indexes still behave just as you would expect. For example to duplicate the whole image list you can specify it using numbers '0' (first image) and '-1' (last image), that is by using the range '0--1'. It may look strange but it makes sense and works fine.


              convert font_[0-2].gif \( -clone 0--1 \) +append  seq_clone_all.gif

                [IM Output]

            When you use a comma separated list of indexes, the images are extracted in that order you specify.


              convert font_[0-2].gif \( -clone 2,0,1 \) +append  seq_clone_list.gif

                [IM Output]

            If the images in a range are reversed (after negative indexes are converted to an actual image index), the extracted images is also reversed, as part of the process.


              convert font_[0-2].gif \( -clone 2-0 \) +append  seq_clone_reversed.gif

                [IM Output]


            The Clone Image Operator can be used without parenthesis, and will just copy images from the current image list and directly append them. However this is not its intended use and is to be discouraged as it will produce a different result if you later surround that set of operations by parenthesis.

            Also in the examples above I am generating clones and appending them to the current image list, to demonstrate the operator. In reality I should be using the Duplicate Image Operator to duplicate images in the current image list. So should you, as it will make it clearer what you are trying to do.

            The MPR: Image Memory Register, can also be used to clone images and was available in IM v5. It is actually still an useful method for cloning and storing a whole image list (of unknown length) for later use, and not just a single individual images as the above image list operators do.


            -duplicate {count}[,{index_range}]
            You can use "-duplicate" to generate an extra copies (clones) of an image, from the current image list (added IM v6.6.8-7). The new images are added to the end of the list.

            Unlike the previous (and older) Clone Operator it does not require the use of parenthesis.

            For example to make N extra copies an image (to a total on N+1) you can do this...


              convert font_5.gif   -duplicate 4   +append seq_duplicate.gif

                [IM Output]

            Note that this operator can generate hundreds of images very quickly, however until the images are processed, the images are simply 'clones' of each other, sharing the actual image data between them. As such duplicated images are very memory efficent.

            If more than one image is present, the last image is duplicated N times...


              convert font_[0-1].gif   -duplicate 3   +append seq_dup_n.gif

                [IM Output]

            If you just want to duplicate the last image once, you can use the 'plus' form of the argument.


              convert font_[0-3].gif  +duplicate   +append seq_dup_last.gif

                [IM Output]

            If you want to select a particular image mutliple times duplication you can specify image index as a second argument.


              convert font_[0-2].gif  -duplicate 2,0  +append seq_dup_index.gif

                [IM Output]

            The index part of the argument can contain a list or range of image indexes to be duplicated N times. For example duplicate the whole list twice to create three times the original number of images...


              convert font_[0-4].gif  -duplicate 2,0--1  +append seq_dup_list.gif

            [IM Output]

            A Patrol Cycle type of animation list is also easy to create by using an image list that is reversed.


              convert font_[0-9].gif -duplicate 1,-2-1 \
                      -set delay 50 -set dispose previous -loop 0  seq_reverse_anim.gif

                [IM Output]

            Note that I did not copy the whole image list, but skipped copying the very first (0) and last (-1) image, making the image indexes -2 to 1.

            If your version of IM is older than v6.6.8-7, you can still generate duplicate images, Clone Image Operator, but only one set of images at a time.

            Or by using a technique that basically mis-uses the Color Morph Operator, generate multiple duplicate images. The trick is to first make one clone to generate two identical images, then use "-morph" to generate in the last N-2 images between them.


              convert font_7.gif \( +clone \) -morph 3  +append seq_dup_morph.gif

                [IM Output]

            Note however that by mis-using the Color Morph Operator the images are actually being processed, as such it takes time for morph to actually process the images (producing no change). Also the images created will contain actual copies of the original data, and are not simple, memory saving clones.


            Combining Image Sequence Operations
            Using these operators, you can extract a copy of a specific image, modify it, and return that image back where you got it from.

            For example, here I make a "-clone" of the 2rd image (image index '1'), rotate the images colors from blue to red, then replace the original image with the modified one by first "-delete" it and "-insert" the new one.


              convert font_[0-3].gif  \( -clone 1  -modulate 100,100,166 \) \
                      -delete 1  -insert 1    +append seq_update_1.gif

                [IM Output]

            Another way that seems to have become more common is use "-swap" to replace the original image, then "+delete" the old image that is now on the end. This only requires you to give the image position twice, instead of three times. Once to clone, and once to replace the modified image.


              convert font_[0-3].gif  \( -clone 2  -modulate 100,100,166 \) \
                      -swap 2  +delete     +append seq_update_2.gif

                [IM Output]

            These techniques are continued below in the next section on Complex Image Processing and Debugging.


            Complex Image Processing and Debugging
            Thanks to the addition of Image Sequence Operators (see above), you no longer need to process images one step at a time, saving the image and re-reading it again each time. Instead you can now simply hold the intermediate image in memory and continue processing it. This saves a lot of time, both in the converting of images to a file format, and in the actual IO to save the image to slow disk.

            This type of image processing commands can become very long and complex. As such it is better to write the command in scripts, and try to place each major operation on a line by itself for easier programming and editing. See Hints for Better ImageMagick Shell/PHP Scripts.

            For example, here I go though a whole complex processing sequence to generate a red button on a black background.


              convert -size 30x30 xc:black -fill white  -draw 'circle 15,15 5,15' \
                      \( +clone -shade 110x90 -normalize -negate -alpha Off \) \
                      \( +clone -clone -2 -compose Plus -composite \) \
                      \( -clone 0 -shade 110x50 -normalize -alpha Off \) \
                      \( +clone -gamma 1,0,0 \) \
                      \( -clone 2,-1  -compose Multiply -composite \) \
                      -append  seq_process_fx.gif

                [IM Output]

            Each line of the convert command generates a new image, except the last line where I just Appended all the working images together to output the results of all the processing steps, rather than just the final image.

            This technique lets you follow what each step (wrapped in parenthesis) the very complex command produced, and allows for easier debugging of each step in of a process.

            Note how it only uses the initial image's size and shape to generate the initial shape of the button, so you are free to use any shape or image you like! The rest of the command will process it just like before.

            Of course you would normally Delete all the temporary working images. That is I would replace the last line in the above with something like this...


                      -delete 0--2  seq_process_result.gif

            Other ways of checking the results is to pipe the result into the display command, so as to view the results on screen, instead of save it to an image file. That is, use something like this for the last line...


                      +append  miff:- | display -

            Alternatively instead of "display" you can use 'show:' which will display the resulting image on screen, and then allow the original command to continue or exit. See Show, Display Image Output for more information.


                      +append  show:

            You actually don't even need the "+append", in which case IM will show each image in sequence, by pressing 'spacebar'.

            You can even get fancier by using "montage" command to view the results in a nicer way...


                      miff:- | montage - -bordercolor blue -border 1 -geometry +2+2 show:

            This type of image processing also allows for easy viewing of intermediate images, immediately the image has been created. Basically you can insert lines this in between "\( ... \)" statements.


                      \( +clone -write show: +delete \)\

            IM will automatically continue processing once that intermediate image has been output for display purposes. See Show, Display Image Output.

            Alternatively, by inserting this line instead, you can display all the current images generated so far at that point in the processing...


                      \( -clone 0--1 -append -write show: +delete \)\

            After you have the image processing steps debugged and settled then you can optimize the code, so that you don't use as many parenthesis steps, as well as fewer Cloned Images, and resulting in less intermediate images to Delete at the end.

            Remember also that "Image Composition", and or "Layer Flattening" merges multiple images together, to leave just the one resulting image, which can reduce the overall number of intermediate images in memory.


              convert -font Ravie -pointsize 48 -background black -fill white \
                      label:'IM' -bordercolor black -border 5  seq_label.gif

              convert seq_label.gif -alpha Off \
                      \( +clone  -shade 110x90 -normalize -negate \
                         +clone  -compose Plus -composite \) \
                      \( -clone 0 -shade 110x50 -normalize -gamma 1,0,0 -alpha Set \) \
                      -delete 0 +swap  -compose Multiply -composite  seq_button.gif

                [IM Output] [IM Output]

            The ability of ImageMagick, to process any image, in a standard, programmed, and automated way, using multiple steps all in the one command is what makes IM such a powerful tool. You can script up a very complex operation, then apply it to many images. Image list operators, and parenthesis just made IM an order of magnitude more powerful, allowing you to write more complex image manipulation programs, with fewer commands.

            For another example of scripting a complex images process together see the example Scripted 3-D bullets from Shapes.

            Also see Hints for Better ImageMagick Shell/PHP Scripts, on ways of improving your image process scripting, both for easier editing, understanding, and for others to be able to follow what you have done.

            Image Meta-data: Attributes, Properties and Artifacts
            So far we have look at images and the actual content or data that makes up the image. But images are more than just 'image data'. There are many attributes or meta-data that is also part of an image, and affect its image processing and how other programs should handle the image.

            For example an image could have an 'offset' or be part of a larger 'virtual canvas' (page). That is a single image may only be a small part larger picture, made up of a series of other images, to form 'layers' or and 'animation'.

            IM also attaches has a lot of special 'settings' that is used by many image processing operators to modify how they work. For example, the 'background color' to use. Some of these are global setting, which are the same across a whole list of images, while others may be different for each image within the list.

            So what sort of things are also part of an images? Lots of things...

                Image meta-data that are typically (though not always) saved with the image in image file formats. For example: profiles, labels, captions, and comments, and virtual canvas information (page). These are all per-image settings, and can be different for each image in the current image list.

                Global settings used by many different image processing operators, but generally not save with the image: Colors such as background, bordercolor, fill, and mattecolor, also font, and pointsize, gravity, compose method, color channel handling, read/write bit depth of color values.

                Expert settings and defines, used to control the deeper lower level operation of specific image processing operators. For example: distortion viewport, special compose method arguments,

                How the image is actually to be stored in memory within ImageMagick: for example as RGB or CMYK. Whether an alpha channel is present, and enabled or not, also the palette an image might have had when read in. However some of these storage settings are hard coded at compile time (such as in memory color value Quality).

                Some general IM operational settings, such as debugging or verbose settings, typically controlling information output or error handling.

            That is a lot of information that can be saved, and/or affect how images are processed. And while they can fall into a number of groups, how well ImageMagick handles each of these things and if they are global, or image specific, depends a lot on the specific thing involved.

            Yes I am being vague, because until you get to specifics it is very hard not to be. It can also be very confusing.

            All these values are stored with the in memory images in three different ways...

            Attributes
                These are stored as special data structure items for each image, generally so as to allow fast and direct access by the various image processing operators. For example: image size, virtual canvas geometry, background, fill, stroke, matte colors, pointsize, density, font, compose, interpolate, virtual-pixel method, profile blocks, time delay and disposal settings; and many more things.

                Note that some of these are 'specific' to each image, while others are treated as a 'global' setting that is set to the same value across all images by the CLI interface, even though they are still stored as part of each individual image.

                Attributes are typically modified using the many options, as part of the normal image processing, or more generally using Set.

            Properties
                These are a freeform set of key-value strings that are attached to each image on an individual basis. Each image can have a completely different set of strings. Essentially they are meta-data items that do not need to be accessed or decoded regularly, or are used in some special way.

                Typical examples of this are: label, caption, and comment strings; creation and modified dates; user defined strings; results from some operators.

                Users can use Set to set or change these, as long as the 'key' does not correspond to some known 'attribute'.

            Artifacts
                This is a global set of freeform strings that is common across all images.

                It is used to hold freeform global settings that define or modify the reading and image processing of all the images. An example of which is the "verbose" setting that causes some operations to output general information about there actions, including more verbose identify output.

                Users can modify these global values using Define (see below), or with a special case of the Set, (see Using Set "Option:" to Define and Artifact).

            Understanding these three storage methods is the key to knowing how settings and meta-data handling works within ImageMagick. And allow you to do some very advanced and normally difficult to achieve image processing techniques.

            Setting/Changing Image Attributes/Properities
            Simple Meta-data are image attributes that are often have the greatest importance to image processing. So important they are decoded and made available in the image data structure to allow fast use by image processing operators.

            Such data is generally modified in two ways. A direct changing of the image meta-data as an image is read or created. Or as a modification of meta-data to an image that is already in memory.

            For example, "-label 'string'" will set the comment in every image that is read in or created after that setting has been set. However "-set label 'string'" will change the 'label' meta-data of all images the current image list, already in memory.

            The reason for the two methods is due to historical backward compatibility and convenience. Basically "-label" has traditionally been set BEFORE the image it is applied to has been read in. It only affects the images that are read in (or created) after it has been set, or changed.

            For example....


              convert -label one  image_one.png \
                      -label two  image_two.png     output_image_list

            On the other hand "-set" operator changes ALL the images that are in the current image list, including the ones previously read in. Thus you must generally use parenthesis to limit what image you are applying the option to, unless you want to apply it to ALL the images read in so far.


              convert \( image_one.png -set label one \) \
                      \( image_two.png -set label two \)  output_image_list

            You can un-define the setting using "+label", in which case the label meta-data will be left alone as the image is read in or created. If the image read in also doesn't have a label, IM will fall back to some logical default. For label that is just the empty string.

            You can see more detailed and specific examples of both methods Montage Labeling of Images which make heavy use of this for labeling purposes.

            This 'duality' of setting image meta-data, also exists for other options. This includes... "-comment", "-caption", "-page", "-dispose", and "-delay".

            The virtual canvas size and image offset setting (page) however also has a third method, using a special operator "-repage" (see Virtual Canvas below).


            For example here I use all the setting methods available to set the 'virtual canvas offset' or 'page' of the individual images, as I create a Animation from them...


              convert -delay 100 -dispose Background \
                        -page 100x100+5+10  eye.gif  \
                        -page +35+30        news.gif  \
                        \( storm.gif  -set page +62+50 \) \
                        \( tree.gif   -repage   +10+55 \) \
                      -loop 0  animation_page.gif

                [IM Output]

            As you can see the traditional (non-set) method is simpler when creating multi-image list from separate image files. But "-set" or the specialized "-repage" operators are better when you need to change an image that has already been read into memory, or was created by come complex image processing methods.

            For example to change the image offset of the third image (image index '2', or the 'tree') in the last example...


              convert animation_page.gif \
                      \( -clone 2 -set page +55+10 \) -swap 2  +delete \
                      animation_mod.gif

                [IM Output]

            For a more extreme example of extracting and modifying individual images in a image list see Frame by Frame Modification of an Animation.

            Here is another example using "-set" to specify a comment on all the images, and then modify one specific image.


              convert xc: -duplicate 9 \
                          -set comment 'T minus %[fx:n-t]' \
                          \( -clone 7 -set comment 'We have ignition!' \) -swap 7 +delete \
                          -format "image #%p : %c" info:

            [IM Text]


            You can use "mpr:", as an alternative way of setting attributes to in memory images. For example here we take an image with a 'Bad' comment, that is in memory, and replace the comment with a 'Good' one...


              convert -comment 'Bad Comment' rose: \
                      \
                      -write mpr:rose +delete \
                      -comment Good   mpr:rose  rose.jpg

              identify -format "image comment = %c" rose.jpg

            [IM Text]

            This works, but is extremely awkward and painful to use, especially when dealing with multiple images such as an animation. In fact this is the only way to change meta-data in images in IM version 5. (Yuck!)


            General Global Attributes
            Under Construction

            Most of these attributes are generally set globally either before or after
            reading images into memory (it makes no difference).  They are typically used
            as a general control of the later image processing operations.

             * Many settings are simpley globally saved for use as needed
                 -fill  -background  -bordercolor  -strokecolor  -mattecolor  -quantize
                 +dither  -channels  -size  -gravity  -units  -density  -font  -pointsize
                 -tile

             * Some settings affect the way an image is saved to disk, or the meta-data
               saved with the image.  This includes
                 -loop  -compression  -quality  -depth
                 -density  -background

             * -compose is awkward, as it can only be set globally. But if unset
               then individual images can have a different setting (for layering).

               Most of these however can be turned off, (using a + version) which
               causes the operator to retrieve the setting from image meta-data
               (eg: +background falls back to the original images meta-data if present)
               but more generally it falls back to some default value. (eg:
               +gravity falls back to 'None' to mean no gravity has been set).

               A few of these also get saved with images when written. Specifically
               the GIF format will save an the -background and -bordercolor as part of the
               images attributes, however these are normally ignored by programs which
               read these images.

            You may have noticed that some settings are used in multiple places.
            for example  -density

              * used in reading in many vector format images like
                Postscript, PDF, and WMF image formats.
              * also in special image generators such as label: caption: and text:
              * used as part of font drawing in -annotate -draw and -polaroid  operators.
              * And finally some formats save the density or resolution as part
                of the the image file format. For example postscript wrapped raster
                images, JPEG, and TIFF.

            Is it any wonder then why settings can be so confusing.

            Virtual Canvas, and the Page and Repage Operators
            The 'page' or 'virtual canvas' settings primary purpose within IM is to define how a the 'real' part of an image, (the part that actually contains color pixel data), fits in a larger context of a 'canvas'. This is especially important when multiple images are involved and need to be positioned relative to each other for Layers of Multiple Images and in GIF Animations.

            It is also used, (and hence its name of the term 'page') to define where an image fits on a larger physical piece of paper or 'page', in Postscript or in generating image of a 'page' of Text.

            While it is most often used for Layers of Multiple Images and in GIF Animations, it is also involved with remembering the original positions of images when Cropping, and Trimming Images, as well in Multi-Image List Composition, and in General Image Distortions.

            Now the 'page' defines two separate parts: a 'virtual canvas' or area, defining a larger space in which the image exists, and the 'offset' or location within that 'canvas' where the actual image is positioned.

                While negative 'offsets' are allowed, the 'canvas size' is limited to an area from 0,0 to the given width and height. That is only a positive canvas can be specified.

            These two aspects, 'size' and 'offset' are closely related, but usually you want to handle these aspects separately, or in a more controlled fashion. So in addition to the normal "-page" and "-set page" methods, a separate option "-repage" has also been provided to allow a finer control.

            Specifically...

            +repage
                Without and arguments, will reset the image virtual canvas to the actual image itself. That is just clear any virtual canvas information that the image may have.

                This often important after applying the image sub-diving operators such as Cropping, and Trimming.

                It is especially important in removing virtual canvas size and offsets before saving to the GIF or PNG image file formats, as many browsers use the canvas/offset information as part of the image display.

            -repage WxH
                Change the existing images virtual canvas size, but do not reset the image position on that canvas.

                Note supplying this argument to either "-page" or "-set page" will reset the images location to '+0+0' which is probably not wanted..

            -repage +X+Y
                Just move the image on the virtual canvas to this absolute location without changing the images canvas size.

            -repage +X+Y\!
                Do a relative move of the image on the virtual canvas by adding the given numbers (positive or negative) to the images existing offset position.

            -repage 0x0
                Attempt to find the best virtual canvas size that contains the whole image.

                This however will fail for images with a negative offset as there is no way to specify a virtual canvas with negative components. To avoid problems it will use the size of the actual image as the smallest canvas size possible. That is it will never assign a virtual canvas with a zero dimensions.

            -repage 0x0+X+Y
                Move the images offset, then resize the virtual canvas to best fit the images new location.

            -repage 0x0+0+0
                Equivalent to a "+repage" or "+set page" or a "-set page 0x0". All virtual canvas and offset information is removed.

            -repage WxH+X+Y
                Equivalent to a "-set page WxH+X+Y". That is just assign the given values directly.

            Note the use of a '!' flag will make the given offset a relative displacement to the images current offset. That is a '-repage +5+0\!" will move the images offset 5 pixels to the right, without modifying the virtual canvas size.

            It is currently not posible to directly specify a relative resize of the virtual canvas size. However it can be done by using FX Percent Escapes. But this is not commonly needed. One example is given in Trimming with a Specific Color.

            Caution is required in giving an image a final negative offset position as the GIF file format can not handle this, and resets it to zero if negative. Also some browsers go crazy when given PNG images with negative offsets.

            What virtual canvas information is saved with an image is format dependent.
            JPEG  	Like many image file formats, JPEG images do not save virtual canvas information at all. The information is just ignored and lost.
            GIF	The size of the virtual canvas and offsets will be saved as part of its GIF animation handling. However it will not handle negative offsets. Any negative offset will be reset to zero on save.
            PNG	Offsets and even negative offsets is saved, but the PNG file format does not normally save the virtual canvas information. However PNG images saved by IM will include the virtual canvas size information, but is only used by other IM commands.

            If IM does read a PNG image without this IM specific attribute, it will set the image virtual canvas to an appropriate size to ensure the image is visible on the virtual canvas (as per a "-repage 0x0"). For images without an offset that means the virtual canvas is the same size as the actual image.

            Some formats like GIF and PNG save virtual canvas information, others like JPEG do not. All of the above formats have there own limitations for virtual canvas information. Only the internal MIFF file format does not have any such limitations.

            Note that "-page" has special meaning for "text:" and "ps:" image generator operators (See Text: Multi-line Text Files and PS: Postscript formatted Text and Graphics). As such its normal canvas size and offset meaning are not used during the creation of these images.

            Set and Per-Image Properties
            However IM can not make an option for handling every possible setting that an image can have. That would be just impossible. Not only that users often like to add or define their own settings.

            Because of this the "-set" option can actually define ANY setting with ANY value.

            If the setting is not a specifically known attribute of an image (to be saved in a way to allow fast acceess by operators), it is saved into the image as a 'Property' (an array of strings), and will be listed near the bottom of a verbose "identify" output, or retrieved and expanded using Percent Escapes.

            The built in rose image for example automatically generates three 'properties': two date strings, and a 'signature hash'. To this I have also added my own user defined 'property' setting.


              convert rose:   -set my_property my_value   -verbose info: |\
                sed -n '/Artifacts/q; /Properties/,$ p'

            [IM Text]

            Some image processing operators even return values of special interest as image 'properties'. They are not needed by other operators, so are not stored as a 'attribute', but are saves as a 'property' string for posible use by the user. For example the final pointsize selected by a Best Fit Label, will be saved as a special image property.


              convert -size 100x label:Anthony  -verbose -identify  property_label.gif |\
                sed -n '/Artifacts/q; /Properties/,$ p'

                [IM Output]
            [IM Text]
                

                Note that the label: generator itself also sets a 'label' attribute, which happens to be saved as a property string.

                All 'properties' are saved as a free form string data type, and stored as image meta-data.

            Because of this, not all 'attributes' are saved as 'properties', as many attributes need to be saved and used directly as numerical data by image processing operators. An example of this is the virtual canvas 'page' attribute.

            Here I use an identify "-format" setting to get IM to output the pointsize of the label it created and discarded.


              convert -size 100x label:Anthony \
                      -format 'pointsize = %[label:pointsize]pts' info:

                [IM Output]

            Using this information to generate a new label image is trick and will be looked at below.

            One of the most useful user defined settings you can use is the "filename:" setting. For example...


              convert rose: -set filename:my_area '%wx%h' 'rose-%[filename:my_area].png'

            The above will generate an image named "rose-70x46.png".

            Only user defined settings prefixed with the "filename:" string can be used inside the output filename, as a security measure, though any name can be used. For more examples of this see Filename Percent Escapes.

            Define and Global Artifacts
            Defined values are known as 'Artifacts' and are defined globally across all images, and are set using the special "-define" operator.

            The primary purpose of such 'Artifacts' are as special settings that can be used as extra (or out of band) settings by Image File Format Coders, or Image Processing Operators. Basically it allows the addition of free-form settings for specific requirements without needing to create another 'attribute'.

            Also being globally set, they are not attached to specific images, but to all images in an Image Sequence, and are available when no images have been read in or created yet.

                Note that API's can have multiple image list, with different sets of 'artifacts' attached, but the command line interface (CLI), only has one active image list, as such 'artifacts' really are global.

            In other words 'defined artifacts' provide a way for expert users to modify the normal or standard operation of specific operators, beyond normal argument usage. For example, JPEG Coder Settings, for both Reading and Writing such images...


              -define jpeg:size=300x200
              -define jpeg:preserve-settings=1
              -define jpeg:optimize-coding=true

            Image Distortion Options, such as...


              -define distort:scale=2
              -define distort:viewport=44x44+15+0

            Resize Filter Controls, such as


              -define filter:blur=0.75
              -define filter:support=1.25

            Some artifact defines have shortcuts because they are used very regularly by users.

            For example the "-verbose" operational control (see below), is really equivalent to using "-define verbose", and thus creating a 'verbose' artifact. For example...


              convert xc: -verbose info: |\
                sed -n '/Tainted:/q; /Artifacts:/,$ p'

            [IM Text]

            It follows then the plus form "+verbose" just removes the 'verbose' artifact, and is thus equivalent to "+define verbose".

            Artifacts and Delayed Percent Escapes
            Artifacts are also often used to hold special attributes that should be assigned to images that are read in, after the define has been given.

            The "-label" setting also just sets an artifact with the argument provided by the user. This artifact is then converted into a 'label' Setting or Propriety after a new image has been read in or created.

            For example creating a "rose:" image with a label set


              convert -label "%wx%h"  rose:  -verbose info:  |\
                  sed -n '/Tainted:/q; /Properties:/,$ p'

            [IM Text]

            That is "-label" first defined the 'label' artifact shown. Later when the rose image was created (and its size attributes was known), IM converted that global artifact into an image specific 'property' and only then expanding any Percent Escapes at that time. This is known as a Delayed Percent Escapes.

            The same thing happens with a few other setting options, such as "-comment" and "-caption" as well.

            It is because of Delayed Percent Escapes that "-define" will only save the strings, while the "-set" operator will do the expansion.

            Using Set "option:" to Define an Artifact
            We showed above how you can "-set" special purpose personal Proprieties, on a per-image bases. For example...


              convert -size 80x40 xc:  -set myinfo 'I love IM!' \
                      -gravity center -annotate 0x0 '%[myinfo]' \
                      property_annotate.gif

                [IM Output]

            But as Proprieties are attached to specific images, you can't use them in the creation of new images. For example this will fail...


              convert rose:  -set myinfo 'I love IM!'  label:'== %[myinfo] ==' \
                      -gravity center  -append   property_append_fail.gif

                [IM Output]

            As you can see the 'myinfo' property was for found or included in the appended label.

            On the other hand globally defined Artifacts are available to the image generators. They have to be so that the image generators or image file coders can read them for various control settings. As such as using a "-define" will work as expected.


              convert rose:  -define myinfo='I love IM!'  label:'== %[myinfo] ==' \
                      -gravity center  -append   artifact_append.gif

                [IM Output]

            So how can use you create a label using an image property or attribute? The "-define" option does not currently allow the use of image properities!

            The trick is to use a special prefix "option:" when using the "-set" option. This addition causes "-set" to define a 'artifact' with the name that follows the prefix. For example, this is equivelent to the last example.


              convert rose:  -set option:myinfo 'I love IM!'  label:'== %[myinfo] ==' \
                      -gravity center  -append   property_option_append.gif

                [IM Output]

            More importantally the "-set" option will expand Percent Escapes. Which means if we have some per-image Propriety, we can convert it to a global Artifact. For example, here I create a label, then convert the 'label:pointsize' property the "label:" image generator created, into a global artifact 'my_pointsize'. As an artifact, this information is available when I create a second label image. I then append the two labels together (with a separating 'gray' line). A very tricky example.


              convert -size 100x -gravity center label:Anthony \
                      -set option:my_pointsize '%[label:pointsize]' \
                      -set option:my_height '%h' \
                      -size 100x1 xc:gray \
                      -size 100x label:'at %[my_pointsize]pt and %[my_height]px high' \
                      -append  property_append.gif

                [IM Output]

            Note the placement of the "-set option:..." in the above. If you were to place it AFTER the creation of the "xc:gray" it would be that image that would be used to set the global artifact. That is because only the properties of the last image define the value stored in the global artifact.

            The reason is that only the last image is used to define the artifact.

            Actually what realy happens is that "-set" is applied to every image in the current image list, even though it is generating a globel artifact. As such each image will assign its own properties into the global artifact, replacing the previously assigned values. When finished, only the last image will have 'defined' the artifact.

                At this time the 'FX escape' has no way of reading properties or artifacts. And as such you current can not do arithmetic on such values.

            Image Type when Reading and Writing
            The "-type" operator/setting defines the style or color space to use when an image is being read in or written out, to ensure the resulting image (in memory, or in the image file) is what you expect it to be. As part of this, it may do some Color Space modifications at the time of the file I/O, though only to ensure the image is in a form that was expected.

            For example "-type" has a special 'bilevel' setting that can be used convert and save images as a two color monochrome image for some image formats. Similarly 'TrueColor' and 'TrueColorMatte' can be used force a TIFF image to be saved as a full color RGB image even if the image is actually purely gray-scale.

            Other settings include 'GrayScale' and 'GrayScaleMatte' which will ensure the written image is gray-scale only (without or with transparency, respectively). Or 'Palette' to force the use of an indexed color map in formats that support this option.

            During reading of image file formats, a "-type" setting of 'TrueColorMatte' will force a JPEG image being read, to have a 'Matte' or 'Alpha' channel added to its in memory storage, even though the JPEG format itself can not handle transparency.

            When writing to a PNG file format setting a "-type" of 'Pallette' will force it to use a color indexed "PNG8' internal image format. Simularly using "BiLevel" will force IM to dither color images to black and white for most image file formats.

            Unfortunately the exact meaning and capabilities of "-type" depend on the specific image format you are reading or writing. See the various Image File Formats example areas. For specific PNG examples see PNG output formats.


            Controling the Quality of Images
            Depth - File Format Bit Depth
            Quality and Depth are two terms are often talked about in Mailing Lists and in these example pages, so I'd like to explain them a little. Quality is a compile time setting in ImageMagick, and is used to determine the size of the values use to store images in IM memory and during processing. Basically it means the Quality of Processing that a specific IM was compiled for.

            The Depth is the size of the values used when an image is either read or saved to/from an Image File Format. It is as such more highly variable. and controlled by the "-depth" setting, or by the original 'depth' of the image that was read in. More on this in a moment.

            Remember...
            Quality is 'in memory' value size, and is compiled into IM.
            Depth is file format value size, and is variable.

            Now most image formats are of depth 8. That is they use 8 bits (or a value from 0 to 28-1) to hold each color value used in the image. That is a value of 0 to 255 for red, 0 to 255 for green, and 0 to 255 for the blue channel.

            More usually this type of image is referred to as 24 bit images (that is "bits per pixel", NOT "bits per value" as used by the "-depth" setting). This includes such formats as such as JPEG).

            If the alpha channel is also involved than you get 4 x 8 bit values, or a 32 bit/pixel image. This is what a PNG image will typically use, though such images can also save using 16 bit per value too.

            What a lot of people refer to as 8 bit images (8 bit/pixel), are really images with an 8 bit palette or color map (giving a maximum 256 color limit over the whole image). The actual pixel data is a 8-bit index value (0-255) which is then used to look up the color for that pixel from the color table. That is the 'raster' (pixel array) is just an index used to lookup the actual pixel color from a separate table of colors.

            In other words while an 8-bit images also have a 8 bit depth, the 8-bit is an index into a color lookup table and not an actual color. GIF images are a good example of this.

            Transparency in such images are usually handled either by specifying a specific color as representing transparency (set using the "-transparent-color" meta-data setting) as in GIF format, or using a special profile for a specific number of colors in the color table, (as used by some PNG8 images (which is also a color imaged image like GIF).

            In general...

                24 bit images are : 3 x 8 bit values - 3 color channels only 
                32 bit images are : 4 x 8 bit values - 3 colors + Alpha channel 
                8 bit images are : 8 bit color indexed image, with a 256 color limit 

            Because most image formats only save color values at an 8 bit/value depth, a lot of people have installed IM using a 'Q' or Quality level of depth 8, which requires far less memory and processes images faster than a more normal Q16 version of IM. Often 3 or more times faster. These Q8 versions work well for general image processing (cropping etc) and converting between formats, and can also work well for generating simple images, annotating, or overlaying images.

            However while a low quality IM is faster and more memory efficient, it does not work work well when you start using complex sequences of operations involving multiple color changes, resizing, darkening, lightening, gamma or histogram color correction, etc..

            At Q8 the intermediate images in memory will remain stored as 8 bit quality, and thus multiple operations will each introduce small incremental color distortions. The result can be rounding effects, especially for extreme colors near white and black. (see below).


            Quality - In Memory Bit Quality
            Remember, Quality is a compile time setting in ImageMagick, and is used to determine the size of the values use to store images in IM memory and during processing. It can not be changed, except by re-compiling ImageMagick from sources.

            A 'Q16' ImageMagick (the IMv6 default) thus will use at least twice as much memory to hold the same amount of image data as a 'Q8' version of ImageMagick, and depending on your CPU, be a lot slower, though on today's processors that is not very likely. Similarly you can compile 'Q32' and 'Q64' versions, though these are not very common, and are typically only used in very high end image processing. Also see the new HDRI compilation quality option below.

            A 'Q16' ImageMagick also allows you to save more bit information for each pixel value. That is color values are saved as integers ranging in values from '0' to '2^quality-1'. That last value is known in IM programming as the current 'QuantumRange' (or the older obsolete name 'MaxRGB').

            The higher the Quality Setting, used when compiling IM, the more precise the color values are when storing the image in memory. That means that if in processing an image you generate a lot of very small, slight variations in color, then those variations will be preserved in the in-memory storage of ImageMagick, and can be used in later processing steps.

            Operations such as resizing, noise filters, blurring, sharpening, averaging, global color, gamma, and histogram modifications, or lots of complex image composition operations, can all produce unwanted color errors in a Q8 IM, creating very distinct color artifacts on the resulting image.

            Of course saving the final image to a 8 bit 'depth' image format will 'quantize' those color values back to 8 bit, but during the processing of the image in memory, the intermediate quality of the image is preserved.

            Some formats are available that preserve the higher quality level information used by IM. For example the MIFF IM format, the enumerated pixel TXT format, as well as the NetPBM image formats.

            However while a Q8 version of IM it will let you output a 16 bit depth images, such image will still only have information equivalent to 8 bit depth as the quality is just not present in memory, to be saved.

                If IM reads an image using 8 bit values (many image formats do), the images 'depth' will be set to 8 bit, and when saved IM will normally save the image at that same 8 bit value depth, even if you process the image using a Q16 version of IM. You can override this setting or clearing the "-depth" setting for that image, so IM will save it at the best depth posible for the image to match the IM in-memory quality.

            Also note that many operators that generate extra colors such as Image Resizing, will also reset the 'depth' of the image in memory to the compile time quality setting, so that IM will then try to save it at a higher depth, if possible.

            HDRI - floating point quality
            HDRI, or High Dynamic Range Imaging, was originally designed to more naturally represent our eyes ability to see both bright and dark areas of a scene simultaneously. In practical image processing terms it does a lot more than that.

            Basically a HDRI version of IM is specially compiled to use a floating point values for images stored in memory, to allow you to perform more exact HDRI handling of image operations, so as to prevent such operations 'clipping' the image colors at the extremes.

            The HDRI still uses same color range as the default compile-time Quality Setting for in memory storage. That is values still range from '0' to the 'Quantum Range' as meaning black to white. But the values are saved using floating point ('doubles' in C programming terms) rather than integers, so that the 'quantum' effects from rounding off values into integers will not be seen. The values are also not 'clipped' when the values go beyond the 'Quantum Range' or into negatives. Basically you loose far less information between processing steps.

            HDRI is thus vital when you plan to use extremely heavy mathematical processing of images, involving the temporary use of negative values, or strong scaling to very small or very large values. It is especially important for users that want to make full use of Fast Fourier Transforms (FFT) capabilities, and it is here that you will see the most examples of a HDRI version of IM, in these pages.

            For information of compiling a HDRI version of IM see Enabling HDRI in ImageMagick on the main IM website, also for Windows and Ubuntu Linux specific information see Fourier Transforms Announcement Discussion on the user forums.

            One important operator that should be kept in mind when using HDRI is "-clamp". This option will clip the values in an image that fall outsize the normal range for images. That is any negative value will be clipped to zero, and any value larger than 'QuantumRange' will be set to that value. It does NOT however 'round off' the floating-point values into integers.

            Quantum Effects, HDRI vs non-HDRI
            Quantum Rounding...

            For example here I use the Level and the Reverse Level operators to compress the color range of a gradient image down so they only use the values from 0 to 15, then un-compress it again. The resulting gradient is also displayed as an image profile (using the script "im_profile") to make it easier to follow.


              # Using a normal non-HDRI version of IM...
              convert -size 20x600 gradient:  -rotate 90 \
                      +level 0,15  -level 0,15  level_rounding.png
              im_profile -s level_rounding.png  level_rounding_pf.gif

                [IM Output]
            [IM Output]

            Notice the sever rounding (quantum effects) that is now visible, forming steps in the gradients profile. As only 16 gray-level values were used, you effectively converted the image to a color depth of only 4 bits!

            Note that this type of Quantum Rounding problem becomes very common in an IM Q8 version, just by doing multiple image processing tasks, beyond a basic resize, and cropping of images. Something that the more normal IM Q16 solves with its extra memory usage.

            Quantum Rounding only becomes a problem for IM Q16 when you use really heavy image processing such as, Fast Fourier Transforms (FFT) or merging of images containing different exposure times (light intensity) to generate High Dynamic Range Images. This is after all why HDRI was added to ImageMagick in the first place.

            Burning and Clipping...

            And here I 'stretch' the gradient so that the original black and white color values go well beyond the "Quantum Range", before being restored again.


              # Using a normal non-HDRI version of IM...
              convert -size 20x600 gradient:  -rotate 90 \
                      -level 20%  +level 20%    level_clipping.png
              im_profile -s level_clipping.png  level_clipping_pf.gif

                [IM Output]
            [IM Output]

            You can see that a normal IM looses the information at both ends. The lower end values gets 'burned' as values become negative, while the upper values become 'clipped' as they go beyond the maximum 'Quantum Range' limits of the integers used to store the values.

            HDRI version of ImageMagick result...

            Repeating these two operations using a HDRI version of ImageMagick will not produce any of the above rounding, burning, or clipping of the results, but will have an extra cost in terms of memory (doubles need more space than integers).

            Speed wise, it does not cost much, and may actually even be faster on many of today's modern computer hardware, due to floating point accelerators.


              # Using HDRI version of IM...
              convert -size 20x600 gradient:  -rotate 90 \
                      +level 0,15  -level 0,15  level_rounding_hdri.png
              convert -size 20x600 gradient:  -rotate 90 \
                      -level 20%  +level 20%    level_clipping_hdri.png
              im_profile -s level_rounding_hdri.png  level_rounding_hdri_pf.gif
              im_profile -s level_clipping_hdri.png  level_clipping_hdri_pf.gif

            [IM Output] [IM Output]

            As you can see the gradient remains perfectly intact, even after heavy compression or stretching of the image and back again.

            Clamp to Enforcing image bounds in HDRI
            You can force HDRI image to be 'clipped' by the normal image value range by using "-clamp" between the two level options. For example...


              # Using a HDRI version of IM...
              convert -size 20x600 gradient:  -rotate 90 \
                      -level 20%    -clamp   +level 20%   level_hdri_clamp.png
              im_profile -s level_hdri_clamp.png  level_hdri_clamp_pf.gif

                [IM Output]

            The use of "-clamp" in the above basically generated the same image as what I would have got with a normal non-HDRI version of ImageMagick.

            However this image would not be exactly the same as a non-HDRI result, as while "-clamp" will burn and clip the values in the image, it does not add quantum rounding effects. As such the values are only being rounded off to integers during the final save to a non-HDRI image file format.

            The "-clamp" option can be vitally important when using HDRI, to achieve the result you are wanting.

            HDRI File Formats
            Of course saving an image that contains very small, large or negative values into a normal image file format will also be clipped, quantized, and even color reduced, for the same reasons as above. As such if you need to save images that have not been 'normalized' back into a 0 to 'Quantum Range' scale, then you will need to use one of the rare floating point image file formats.

            Some image formats that can handle floating point values (without clipping or rounding) include, NetPBM PFM. This is the only image file format that does not require any extra special options.


            Other image file formats can also be used, but require a special switch to specify that the file is to save floating point values.

            Specifically you need to specify the coder option "-define quantum:format=floating-point" to request floating point values in these file formats.

            The "-depth" setting can also be used to define what type of floating point values are used. If "-depth 32" or less (the default in most versions of IM) is used then normal "floats" are used. But if "-depth 64" is set then "doubles" are used for the floating point data written to, or read from, the image file format.

            The image file formats that can use with this special flag to save floating point values include... TIFF, FITS, and MIFF. The raw data file format RGB will also save (and read) floating point, though that format does not save image size, and you need to specify the floating point settings for reading too.


            Another special coder option is is "-define quantum:scale=65535.0". This will be multiplied with value read from the image file, so as to scale the value from a normalized floating point value of 0.0 to 1.0, into the internal value range of 0.0 to 65535.0. So if you get a near pure black image when reading a floating point image, try adding this option to scale the values being read into the appropriate range.


            The direct memory-to-disk file format MPC, will also save floating point values used by a HDRI version of IM, and will not need any special flags. But as with any MPC image file, only the exact same version (specific compilation) of IM on the same machine will correctly read such a file. As such it is only good for temporary 'quick read' files for scripted image processing, and not for long term storage.

            What Q-level should I use
            In summery what type of ImageMagick should I use? Q8, Q16, HDRI?

            Q8 has a smaller memory foot print, as image values are saved in memory as 8 bit values, just like most image file formats. For basic composition, image format conversion, simple 'once off resize', or drawing on images, then Q8 is 'good enough'.

            Q16 doubles the memory foot print as color values are saved in 16 bit values (higher precision). But if you plan on doing heavy image processing involving many levels of operations, such as 'color space changed (even just sRGB to/from RGB), resize, distortions, blurring, shadows, etc etc all to the same image, in the same command (which is recommended for the same reason), then having 16bit is better as it will preserves the lower precision of the images between processing steps. You can also then save in 16bit file formats (PNG, MIFF, PbmPlus) between commands, even if the final save is back to a 8bit image file format like ICO and JPEG. (This is the default for this reason)

            The next level is Q16 HDRI, that takes precision to 32 bit floating point values which allows you to deal with image values that become very small or very large without the rounding and clipping effects of images. You can even deal with negative values, especially in some colorspaces. Essentially it is used to prevent image data loss when processing images in extremes such as when using HDRI images, Fourier Transforms, or just high levels of compression, expansion you may get in mathematical processing of raw data.

            That is it in a nut shell. Q16 is good middle ground for most operations involving distortions and multi-image compositions and image processing effects. Q8 if memory is tight but you are only doing simple operations, HDRI is you are doing extreme operations.

            Image Density or Resolution
            The Density of an image is the spatial (space) resolution of the image. That is the density (generally expressed as dpi, or dots per inch) of an image define how far apart (or how big) the individual pixels, and thus the overall size of the image in real world terms, and generally used for display or printing of the image on a real world device.

            It is just some number stored with the image to tell output devices such as printers and displays how many dots (or pixels) per inch the image should be displayed at, OR for vector formats like postscript, PDF, MWF, and SVG the pixel scale to draw using any real world coordinates that may be used within the image.

            It is completely irrelevant to the actual images pixel size, or the in-memory Quality and save file format Depth that defines the color 'resolution' of the image. You can set the resolution or density of an image as it is being read into IM by using the "-density" function, before reading or writing the image, or using "-set density" after reading the image.

            A "-units" setting can be used to define if the density number is expressed in the default (traditional printing) terms of 'PixelsPerInch' or in more modern metric units of 'PixelsPerCentimeter' (PNG uses the latter).

            For example, a 200x200 pixel image at 600 dpi will thus be displayed in 1/3 inch square in real world terms. On the other hand a much smaller 72x72 pixel image at 72 dpi will display in a 1 inch square, in the real world, though its spatial quality will not be very good in comparison. The former being 'photo quality' while the later being 'display resolution'.

            In practical terms, a 72dpi image will look 'digital' or 'dotty' on a printer. On the other hand a large modern digital photo taken at 1200dpi image would probably need to be resampled to show it on a display, or you may only see tiny part of the image.

            For more information on Resolution and Density of images see the notes on the Resample Resize Operator. For information of Resolution and Density for Text and Fonts see Pointsize and Actual Font Size.

            Photoshop and Density
            The "Photoshop" image editor saves an extra copy of the images resolution into a separate profile (named '8BIM') in the image, which IM will NOT touch. Thus if you change the resolution of an image with IM, you probably should also strip the profiles from the image before loading it back into "photoshop", or you may not see any density changes.

            You can remove just that profile from an image using "+profile 8bim".

            From a IM Forum Discussion, Jesper Nilsson (aka stroker), suggests that you use the program "exiftool' to directly modify the Photoshop Tags of the image.

            For example


              exiftool -g -Photoshop:XResolution=300 -Photoshop:YResolution=300 file.tif

            Speed Tests based on Quality
            Some speed tests were submitted to IM Forum, Q8 vs. Q16 speed (& HDRI).

            Rough results from the above article

                The amount of memory used per pixel per channel is as you would expect. Q8 - 1 byte, Q16 - 2 bytes, Q32 & any HDRI - 4 bytes, Q64 (HDRI) - 8 bytes.
                64bit has significant precision improvements for floating point operations, but so does any other HDRI version of ImageMagick.
                Speed wise Q8, Q16 and HDRI all about the same speed (presuming computer has floating point MPU), Q32 about 25% slower and Q64 (HDRI) is about 50% slower. 

                Note that Q64 automatically uses "double long floats", rather than 64 bit integers. It is sort of a double precision HDRI, but while very precise is the slowest of all in-memory quality settings, and most memory intensive.

                The actual speed will depend on your computer specifications, and if you have a Math Co-Processor or not. If it is not important using the default Q16, or standard HDRI, is probably best.

            If it is important then you should do simular tests for speed, on your equipment, but using the operations you typically expect to use in your image processing.

            ImageMagick Special Controls
            IM also has a few special options that it uses to control its operational working, information reporting, and for debugging purposes.
            -version 	Output what version of IM, the image quality it is using, and when was it built.

            IM will implicitly exit after outputting this information.

                In IMv7, "-version" will exit if it is the ONLY option on the command line. That is it will make the final 'implicit write' argument, optional. If any other arguments are present, OR it was read from a script (file or pipeline), the magick command will not exit, but continue.

             
            -list 	This is an informational option only and will list the requested items, then exit. That is you can not use this with any other option, or image processing. It is purely provides for informational purposes, especially in scripts to check input options and if IM has certain options implemented.

            The given argument defines what information you are wanting to list. For example a list of 'color' names that you can use, (such as using by ("-fill", "-background", "-mattecolor", "-bordercolor"). While 'font' lists the fonts that are specifically known to IM.

            Here are just some of the more interesting lists...
            list 	what lists can "-list" list!
            font 	Known fonts (IM also knows about X and PS fonts)
            type 	file image types ("-type" )(after IM v6.3.5-7)
            or the font list (before that IM version)
            color 	known color names for various color options.
            dispose 	all the GIF disposal settings ("-dispose")
            compose 	alpha compositions are available (includes internal methods)
            layers 	what multi-image "-layers" methods has been implemented
            distort 	The image distortion methods available.
            morphology 	The image morphological methods available.
            kernel 	The morphological/convolution kernels that are available.
            command 	what command line options (both settings and operators) are available
            configure 	what were the configuration parameters used to build ImageMagick

            That last 'list' setting 'Configure' is very important, as it will tell you what libraries, and delegates were available when IM was built. It also includes the 'point' release number, which was missing from the normal "-version" output of older versions. (See Script Version Handling for one example of using this information.

            IM will implicitly exit after outputting this information.

                In IMv7, "-list" will exit if it is the ONLY option on the command line. That is it will make the final 'implicit write' argument, optional. If any other arguments are present, OR it was read from a script (file or pipeline), the magick command will not exit, but continue.

             
            -verbose 	Report extra info on some of the more complex operations.
            For example "-segment", which outputs a lot of color quantization details.
            And "-distort", outputting extra information and 'FX' equivalents to the requested image distortion. Also monitoring the number of changes when iterating a "-morphology" operation.

            This is especially useful for generating for more detailed image information from the "info:" and "-identify" outputs.

            You can turn off the setting using the 'plus' form of the option, "+verbose".

             
            -regard
              -warnings    	The '-regard-warnings', will make some informative warnings about some image file formats fatal. It also causes IM to return a proper exit status according to such error conditions.

            It can be used in scripts to 'sanitize' image file being provided from uncontrolled sources. That is this option will make IM fail and exit, if when the JPEG or TIFF image was not correct, complete or contained 'unknown' profiles.

             
            -precision {number} 	Control the number of significant digits.
            When IM outputs floating point values in response to various debugging, verbose, or formatting requests, this setting sets how precise you want that output.

            By default it will limit such numbers to 6 significant digits, but this operator will increase or decrease this default. The default setting of 6 can also be modified using the 'MAGICK_PRECISION' environment variable.

            It affects output from...

                The verbose "identify" command or the "-identify", "-print" and "-format" settings.
                The 'debug()' output from a "-fx" operator and the '%[fx:...]' string escape. (See FX, DIY Image processing Operator
                The floating point values of a "-morphology" kernel when "-set option:showkernel 1" has been enabled. See Displaying the Kernel. 

             
            -quiet 	Don't report informational warning messages. Only proper errors such as I/O errors, or bad options, etc.

            This is especially useful for "-crop" or "-trim" and "-layers optimize" which normally report 'missed images' warnings, when the operator would produce no 'real' image as a result.

            This will also quieten the coders of some complex image file formats that can contain 'unknown chunks' which IM would normally ignore. For example when IM is reading TIFF images, or strange MPEG (AVI) video formats.

             
            -respect
              -parenthesis    	Causes parenthesis to not only to save and restore the current image list but also all the current operational settings are saved and restored. Than means that when given, any settings set within parenthesis, will be reset when the parenthesis ends. See the examples in Parenthesis and Settings above.

             
            -ping 	For the "identify" command. IM will try to avoid completely reading and decoding the full image file format for basic information such as the images size.

             
            -monitor 	Report a percentage of processing during each stage of image processing, especially for very large or long image processing tasks.

            In a lower level API, you would use SetImageInfoProgressMonitor() or SetImageProgressMonitor()

             
            -debug 	Report verbosely exactly what IM is doing, in various areas.

            The argument is a comma separated list of options, such as...
            exception 	What is IM not understanding about the command
            cache 	See how much disk space IM is caching
            configure 	Show IM search attempts to find its configuration files.
            trace 	Report the trace points at the start of each library function
            annotate 	Report on font metrics when a font is used with "-annotate".
            command 	IMv7 -- show the command line options (or script) as they are being processed. EG: option processing.
            all 	Show every trace point during processing
            This is very very VERY verbose and not recommended

            If "-debug" is used the location of the logging output is controlled by the "log.xml" file. This is by default set to "console". To have it save to a file change <log output="console"/> to <log output="file"/>

            For command line and API usage you can also define an environment variable to set the debug level using actions by IM.


              export MAGICK_DEBUG=all

            Limiting image size (quick note)
            To prevent excess memory usage, set your memory limit to say 16GB. Now set
            the disk limit to 4GB. ImageMagick will exit if the disk limit is exceeded,
            with a "cache resource exhausted" exception.
https://legacy.imagemagick.org/Usage/files/
            To process an image, you not only need operators to work on the images, but you also need ways to read in and write out the image in as many different file formats as possible. In this section we look at IM file formats in general.

            Image Formats Summary
            One of the most common uses of ImageMagick is not to modify images at all, but only to convert an image from one image format to another. In fact this was the original reason for IM's creation was this sort of image format conversion. This is why the primary IM command is call "convert".

            To this end, ImageMagick can handle a bewildering array of image and file formats. Added to this array are a large number of special input and output formats for built-in test images, simple image creation, and image formats specific for programming shell scripts, and programs. For a complete list, see IM Image Formats Page on the IM web site.

            All this can be daunting for a new user of ImageMagick. My best advise is to ignore most of the file formats, as you will probably never need them. Instead concentrate on what you want to do, and try to do it. If you don't know how, try to look for an example in these pages and across the web.

            For image formats demonstrated in IM Examples, see Reference Index, File Formats.

            Reading Images
            IM by default will attempt to determine the image format type by the 'magic' file identification codes within the file itself. If this fails however you will need to specify the images file format using with the files suffix, or by adding a prefix format.

            Some formats will not read any files and ignore any given filename. These are some of the common built-in images...


              logo:      granite:     rose:

            Some of them will generate images based on arguments given as a filename and perhaps an extra "-size" controlling the final image size...


              -size 30x30  canvas:red
              -size 30x30  gradient:yellow-lime
              -size 30x30  pattern:fishscales
              import:

            In some cases you can even use multiple formats...


              -size 30x30  tile:pattern:gray95

            This is however overkill in this case as the 'pattern:' format coder has the 'tile:' coder built into it. But it does make it clear what you were intending to do.

            IM can also download an image that is published on the 'world wide web' by specifying that images URL. This basically provides a 'http:' image coder, which is why it works.


              convert http://www.ict.griffith.edu.au/anthony/images/anthony_castle.gif \
                      -resize 100x100 castle_logo.png

                [IM Output]

            As you can see this command reads the image from the WWW and resizes it before finally saving the result to disk.

                When a prefix file format is given, any suffix given as part of the filename does not have any bearing on the way the file is read. This is in fact vital when reading some file formats such as the "text:" verses the "txt:" file format handling. Of course if an image generator actually reads in an image file to process it in a special way (for example "tile:") then the suffix (or prefix) file formats will again become important, as it was in the last example

            A special coder prefix "implicit::" can be used to 'turn-off' any use of coders, allowing use of ':' in the filename.

            Filename can have the special 'file meta-characters', such as '*' and '?' embedded in them. IM will expand these characters to generate a list of filenames to be read in, avoiding the need for an external shell to do this, or problems with command line length limits. For example...


              montage  '*.jpg' -geometry 50x50+2+2  image_index.gif

            This will produce a single montage index image of all the JPEG files in the current directory. Note however that I needed to quote the argument to prevent my UNIX shell from expanding the file names rather than ImageMagick. See below for a more complete "montage" specification.

            Of course the linux shells can also expand '*' and '?' characters passed to them unquoted. However in some cases you may find yourself hitting 'command line limits' if the file list expands to a very large number of filenames.

            Here are other examples of using a linux shell to expand the filename...


              convert image_[0-9].gif  image_[1-9][0-9].gif  animation.gif
              convert image_?.gif  image_??.gif  image_???.gif  animation.gif
              convert image_(?|??|???|????).gif  animation.gif

            Also see the Read Frames, Read Modifier below, for an formated incrementing number in the filename.

            If the filename is simply the single character string '-' IM reads the image from standard input.


              cat tree.gif | convert - -frame 5x5+2+2 read_stdin.gif

                [IM Output]

            Note that some image file formats allow you to simple append multiple image files together in one long multi-image stream. These formats include the simple PbmPlus/NetPBM image formats, as well as IM's own special file format MIFF:


              for image in eye.gif news.gif storm.gif
              do
                convert $image  miff:-
              done |
                convert - -frame 5x5+2+2 +append read_multiple_stdin.gif

                [IM Output]

            The special character '@' at the start of a filename, means replace the filename, with contents of the given file. That is you can read a file containing a list of files!


              echo "eye.gif news.gif storm.gif" > filelist.txt
              convert @filelist.txt  -frame 5x5+2+2 +append filelist.gif

                [IM Output]

            You can also use '@' with the special filename '-' to read the filenames from standard input.


              echo "eye.gif news.gif storm.gif" |\
                convert @- -frame 5x5+2+2 +append filelist_stdin.gif

                [IM Output]

                Reading a list of filenames from a file using the '@' syntax was added in IM v6.5.2-1.

                As a security precaution this only works with actual image files. It does not work with image generators such as "rose:" or "label:string". It also can not be used to 'include' command line options from a file.

            Read Modifiers or Extract Setting
            Image can be modified immediatally they have been read into memory, but before the image(s) are actually added to the current image sequence. You can specify a "-extract" setting. For example, here I crop the rose image...


              convert -extract 32x32+20+5 rose: +repage rose_extract.gif

                [IM Output]

            Or you can append a read modifier to the end of the filename using square brackets '[...]'. For example...


              convert 'rose:[32x32+20+5]' +repage  rose_read_modifier.gif

                [IM Output]

            Note however that '[]' characters are usually also special shell meta-characters, so if you use them it is a good idea to quote the additional modifier, to stop UNIX shells interpreting it.

            Both the "-extract" setting and the read modifer does the same job, though the latter will override the former.

            Also when you use a modifier, you must let IM handle any special file expansion meta-characters, such as '*' and '?', as an UNIX shell will not 'find' the requested files due to the modifier. What it actually does in that case is shell dependant. As such the whole filename should be quoted when using read modifiers.

            The real purpose of these read modifiers is to limit the amount of memory needed, by removing unwanted images or making images smaller, while images are still being read into memory. For example when readin a whole directory of large JPEG images.

            Here is the list of all the special read modifiers (and "-extract" settings ) and their effects. A '#' represent some number.

                '[#]' '[#-#]' '[#,#,#]' [#,#-#,#]'. Read Frames
                    Will select specific sub-frames from a multi-image file format from the image that has been read in. The given number '#' index specifies the frame number to read. Multiple indexes can be specified in either comma order or as an index range.

                    The image index start at zero for the first image, 1 for the second and so on. If you specify a negative index then the count is from the end of the image sequence, in reverse order, -1 for the last image, -2 for the second last image.

                    This is exactly the same convention as used for the Image Lists Operators.

                    For example


                      convert document.pdf'[0]'     first_page_of_pdf.gif
                      convert animation.gif'[1-3]'  second_to_fourth_frames.gif
                      convert animation.gif'[-1,2]' last_then_the_third_frame.gif

                    You can also get IM to read images based on a list of numbers. For example..


                      convert 'image_%03d.png[5-7]' ...

                    will read in the files "image_005.png", "image_006.png", and "image_007.png". With this method you can not use a negative index.

                '[#x#]' Read Resize
                    From IM version 6.2.6-2 a new modifier was added to help IM users to handle very very large images.

                    This modifier will resize the image that was just read in, immediately before that image is added to the other images already in memory.

                    This can both shrink images, or enlarge images. For example...


                      convert pattern:gray95'[60x60]' enlarged_dots.gif

                        [IM Output]

                    Warning, the read modifier does not currently use any of the resize flags, such as '!' (no aspect preserve) or '>' (only shrink larger images. (perhaps if you put in a request?)

                    You can also use it as an alternative way of specifying the size of a solid color canvas. Actually what is happening is that it is resizing the default single pixel image. For example...


                          convert 'canvas:DodgerBlue[50x50]'  canvas_size.gif
                        

                        [IM Output]

                    The modifier is most important when you are attempting to read in lots of very very large images, as each image will be resized before the next image is read, producing a substantial saving in total memory needed to handle those images.

                    For example instead of...


                      montage '*.tiff'  -geometry 100x100+5+5 -frame 4  index.jpg

                    which reads all the tiff files in first, then resizes them. You can instead do...


                      montage '*.tiff[100x100]'  -geometry 100x100+5+5 -frame 4  index.jpg

                    This will read each image in, and resize them, before proceeding to the next image. Resulting in far less memory usage, and possibly prevent disk swapping (thrashing), when memory limits are reached.

                    For JPEG images I also recommend you use the special "-define" setting instead, producing something like...


                      montage -define jpeg:size=200x200 '*.jpg[100x100]' -strip \
                              -geometry 100x100+5+5 -frame 4  index.png

                    The special setting is passed to the JPEG library and is used to limit the size the JPEG image during the reading process. However it is not exact, with the resulting image being somewhere between that size or double that size with the aspect ratio preserved. See Reading JPEG Images for more details.

                    The result of the combination is a much faster reading and even lower memory usage for JPEG images. Especially when generating lots of small thumbnails. See General Thumbnail Creation.

                '[#x#+#+#]' Read Crop
                    From IM v6.3.1 if you also add an offset the above becomes a crop of the image being read in.

                    For example, To get a smaller 600x400 pixel sub-section from a much larger image.


                      convert 'image.png[600x400+1900+2900]' tileimage.png

                    This however will read in the entire image into memory then crop it before it is finally added to the current image sequence.

                    If you want to handle really large images I suggest you look at the "stream" command and pipe you image into the "convert" command for further processing. See Massive Image Handling below.

            If the image is "gzip"ed, IM will automatically uncompress it, into a temporary file before attempting to figure out the image format and decode the image file format. As such you can not only save images in gzip compressed format, but use them directly in later IM processing. For large text based images this can result in enormous disk space savings.

                The PNG format includes "gzip" compression as part of its format specification. In this case the first digit of the two digit PNG "-quality" setting defines the level of compression. For more detail see PNG Image File Format examples.

            The above is only a short summary of the special input options available when reading images into ImageMagick. A full summary is given on the The Anatomy of the Command Line page on the ImageMagick Website.


            As shown previously the image input can be modified by some IM settings such as "-size" for image creation and "-define jpeg:size=??" for JPEG reading. Other options also effect image input creation, including, "-page", "-type", "-dispose", "-delay". See Setting/Changing Image Meta-Data.

                Be very careful when passing an user provided argument to IM in a script, insuring that the argument is what you expect. You do not want to let a web image processing script return an image of the system password file for example.


            Input Filename Meta-Character Handling
            Under Construction

            Not only does the shell handle meta-characters (unless that argument is
            quoted) but IM also does its own form of meta-character handling in filenames.

            For example
              convert  *.jpg ....

            is expanded by the shell BEFORE passing the filenames to IM, while

              convert  '*.jpg' ....

            will have the shell pass "*.jpg" to ImageMagick, which then expands into
            an internal list of filenames!  This was provided for Windows Dos support, and
            as a method to preventing command line limit overflows in command such as
            "mogrify" and "montage", which typically process long lists of images.

            As such to actually get IM to read a file names literially named on disk as
            '*.jpg'  you need to use any of the following forms...

              convert  '\*.jpg' ....
              convert "\*.jpg" ....
              convert "\\*.jpg" ....
              convert \\\*.jpg ....

            NOTE; the second line is NOT recommended as some shells (not bash) and some
            APIs (C programs, possibly PHP) may actually remove the single backslash, and
            pass '*.jpg' to IM which it will again expand!

            On top of '?' and '*',  IM also adds the meta-character handling of  ':', '%'
            and '[...]' for read modifier handling.  These however have a different
            meaning  (codec specification, scene number inclusion, and read modifiers) to
            normal shell syntax of those meta-characters.

            For example DOS uses will need to escape a 'drive-letter' in filename paths
            being passed to ImageMagick.  For example...

              convert  C\:\path\to\image.jpg ....

            Another example is when loading an image containg a time code.  For example..

              convert "time_10\:30.jpg" ....

            will read the filename "time_10:30.jpg" from disk.  Without the backslash, IM
            may think that the image should be read with a non-existant image file format
            (or delegate) "time_10:", and fail in an unexpected way.

            An alternative is to use a question mark...

              convert "time_10?30.jpg" ...

            However that may also match another file such as "time_10_30.jpg" as well!

            Compressing Images
            Under Construction

            IM will also read files that have been compressed, and given the appropriate
            suffix, or image format specification.

            That is an image saved as "image.gif.gz"  will first be uncomressed, before
            being decoded from its GIF image format.

            Gzipped XPixmap (xpm) and NetPbm/PbmPlus (ppm) images is also automatically
            handled, both by Imagemagick, and the formats normal delegate library.  As
            such you can use the compressed forms directly either in IM, or in other
            programs that understand these file formats.

            See  Saving Compressed Images below.

            Saving Images
            Processing images is well and good but it can be just as important to save the results in the right way.

            The last argument of the "convert", "montage" and "composite" defines a filename, and image format for a final write of the image (defailt image output). Though you can also save an image in the middle of an image sequence using "-write" (see below).

            To specify what file format you want to save your image, or images, you can either use a filename suffix, such as I use in just about all these examples, or prefix the filename with the string "{format}:". For example...


              convert tree.gif    GIF:tree_image

                [IM Output]

            If you check the resulting image you will find that a GIF image file was actually created, even though the filename itself does not have a ".gif" filename suffix. The case of the format is not sensitive, so you can use either lowercase or uppercase.

            This image format specification becomes particularly important when you want to save the image to the standard output of the command (using a "-" filename). This special filename does not have a suffix, so you must tell ImageMagick what format to use. If you don't, the image will default to the original image format that the image came from (if known).

            For example, here we write an IM pixel enumeration to the screen using a "-" to output the result to the standard output.


              convert tree.gif  -resize 1x3\!  txt:-

            [IM Text]

            It is also used to pass the image, on to another command such as "identify" though a shell 'pipeline', without saving it to a temporary file.


              convert tree.gif -resize 200% miff:- | identify -

            [IM Text]

            In this case you can also see that the special "-" filename is also used to denote reading an image from standard input by the "identify" command.

            For more information see the offical guide at The Anatomy of the Command Line, Output Filenames.

            Filename Percent Escapes
            The save filename can contain a few special percent escape (%) sequences. Specifically, '%d', '%x', and '%o'. These inserts the images 'scene number' into the file name using the C 'printf()' formats. For more information see Writing a Multi-Image Sequence below.

            Of course this means that if you want to insert a percent character into the filename you will need to double it ('%%').

            As of IM v6.4.8-4 you can now also insert special pre-prepared setting (must start with 'filename:' into the final filename. For example...


              convert rose: -set filename:mysize "%wx%h" 'rose_%[filename:mysize].png'

                [IM Output]
            This saves the built-in rose image into a file containing that images size in pixels. Specifically, the filename "rose_70x46.gif". This will let you (with a little indirection) use any Image Property Percent Escape as part of your output filename.

            Note that only a '%[filename:label]' image Property can be used within the output filename (along with the normal '%d' escape. This restriction is for security reasons and the fact that legitimate image filenames could include '% and '[]'.

            Warning, do not include the file suffix in the filename setting! IM will not see it, and save the image using the original file format, rather than the one that was included in filename setting. That is the filename will have the suffix you specify, but the image format may different!

            The 'filename:' setting does not need to be the same for every image. You can generate or even calculate or set a different setting for each image being used. Here is another example where I modify an image, and write it to a new filename, that was built using each individual images original filename.


              convert eye.gif news.gif storm.gif    -scale 200% \
                      -set filename:f '%t_magnify.%e' +adjoin '%[filename:f]'

            [IM Output] [IM Output] [IM Output]

            This magnifies each image such as "eye.gif" and saves it in the file "eye_magnify.gif" in the current directory. However all three images are read into memory, and then modified by the one command. This is not a recommended solution for a number of large images, or very large numbers of images, due to the posibilty of reaching memory limits and thus going to disk swapping (thrashing).

            Note that the "+adjoin" in this case is vital to prevent IM saving all the images into a mutli-image GIF animation, using just the filename of the first image.

            I also ensured I preserved the original suffix of the filename using the "%e" escape sequence. Normally including the suffix in the filename setting is a bad idea, as IM does not see it when it comes from an escape sequence, for determining the output file format. In this case however the format is not changing so there is no problem. Caution is needed.

            To get the exact original filename of the image use '%d/%f' or '%d/%t.%e'. You can also use '%m' instead of '%e' which is the actual format (in capitals) that IM found in the original images file (which may not match the original images filename suffix). Note that for built-in images, many of these escape sequence strings are blank. Also if there is no directory the '%d will be blank. This is a known problem for IMv6

            Another example of using 'Filename Escape Sequence' is in Tile Cropping Images, where the technique it is used to generate a filename basied on a calculated tile position for each of the resulting images. Also see the example in Using Convert Instead of Morgify.

            Automatic GZip Suffix
            IM will also automatically "gzip" images if a ".gz" suffix is given.

            For example here I save the built-in "rose:" image as a "gzip"ed, uncompressed GIF file. I turn off the normal LZW compression of GIF, as it would prevent "gzip" compression from achieving its best compression.


              convert rose: -compress none  rose.gif.gz

                [IM Output]
            How browsers handle a gzipped image depends on the file type returned by the web server and how your browser handled compressed images. Because of this I did not directly display the above image. Click on the 'art' icon to see what your browser does, with such an image from this web server.

            Compare the size of this to a normal saved LZW compressed GIF image...


              convert rose: rose.gif

                [IM Output]

            The "gzip"ed rose is [IM Text] bytes in size, while a normal LZW compressed rose is [IM Text] bytes. As you can see GZIP compression is actually slightly better than the LZW compression that the GIF format uses, so may be better for archiving purposes.

            GZipped image files are more commonly used for longer term storage of image file formats that do not have any compression by default. This includes the IM File format "MIFF:" and the simpler NetPBM image file formats.

            Saved Attributes
            Under Construction

            Other Settings specific to image writing....
                -depth  -quality  -compress -type  -loop
                -set label   -set comment
            Also see Image Depth,
            Image Type,
            JPEG Quality,
            PNG Quality.
            GIF loop.

            Talk about file compressions, which are part of various image formats.

            Different compressions are used for different image formats.

            Especially the JPEG to TIFF compression change needed.

            Using or "-compress
            None" and "-compress" NetPBM text/binary format selection.

            The GIF compression and the copyright patent.

            Other than using IM to reduce -quality or changing the format to something
            else the -compression option is rarely used.  Often it is only used internally
            by IM to save images using the same compression the image was read with.

            Encrypted Images
            IM also allows you save sensitive images with encrypted with a pass phrase using the options "-encipher" and "-decipher". See Encrypting Images

            Writing a Multiple Images - Adjoin Techniques
            A major problem with saving images, is that ImageMagick works with an ordered sequence (list) of images, not just one image at a time. Because of this IM will attempt to write ALL the images in the current image sequence into the filename given.

            If the file format allows multiple images IM will by default save all the images in the current image sequence into that image file. For example if you look at the GIF Animation Basics examples page you will see that it will save multiple image frames into a single image file format to produce an animation.

            If the output format does not allow you to save multiple images into the one file, IM will instead generate multiple files. For example, when saving to image formats like JPEG and PNG and so on.

            You can also force this behavior on image formats that do allow multiple images per file, such as GIF and PS by using the "+adjoin" output file handling setting.


              convert eye.gif news.gif storm.gif  +adjoin  image.gif

            [IM Output] [IM Output] [IM Output]

            If you look closely at the filenames of the three images generated above, you will see that IM generated images named "image-0.gif" to "image-2.gif".

                Previous to ImageMagick version 6.2.0 the output filename of the above would have been "image.gif.0" to "image.gif.2". This resulted in many problems due to the loss of the filename suffix, so was changed to add the image number, before the filename suffix.

            An alternative is to add a 'C language printf()' construct "%d" to the output filename. This special string will be replaced by the current image number of each image in sequence.


              convert eye.gif news.gif storm.gif  +adjoin  image_%d.gif

            [IM Output] [IM Output] [IM Output]

            Here we generated the images "image_0.gif" to "image_2.gif", using an underscore rather that the IM default of a dash.

                Not only can you use '%d' for a decimal number, but you can use '%x' for a hexadecimal number (lowercase), '%X' for a hexadecimal number (uppercase), or '%o' for an octal number.

                If you really want a percent character which is followed by one of these letters, then you will need to double the percent character to escape its meaning. That is you will need to use '%%' to ensure you actually generate a percent symbol.

                The '%d' in the output filename actually enables the "+adjoin" setting of ImageMagick, automatically.
            However while I don't actually need the "+adjoin" in the above, it is probably a good idea to provide it anyway, just so it is clear that you are generating separate images.

            This works well for a small number of images, but if you have more than ten images you will get a mix of image with one digit and two digit numbers. And if you have more than a hundred, you get three digit numbers too. When that happens, directory listings will no longer list the saved images in sequence, since "image_15.gif" would alphabetically appear before "image_5.gif".

            Of course there are ways to fix this. For example using a command line shell expressions like..


              convert image_[0-9].gif  image_[1-9][0-9].gif  animation.gif
              convert image_?.gif  image_??.gif  image_???.gif  animation.gif
              convert image_(?|??|???|????).gif  animation.gif
              convert 'image_%d.gif[0-123]'  animation.gif

            The last method is the proper IM way of handling a sequence of files, though you need to know the range of number you want to use. The '%d' formats each number to match the filename (see next)

            In any case, this is awkward and prone to mistakes, can produce errors if files are missing, and can be dependant on what type of computer system you are using. Better to avoid this problem altogether.

            If you are familiar with the 'C' language (look up the UNIX system man page for 'printf') then you will probably know that if you use something like "%03d" you will always get 3 digit numbers (with leading zeros) for the image sequence frame number. The image names would in that case be "images_000.gif", "images_001.gif" and so on.


              convert  eye.gif news.gif storm.gif  +adjoin  image_%03d.gif

            [IM Output] [IM Output] [IM Output]

            Using this method, the images will not only be numbered, but will also list alphabetically correctly, making image file handling a whole lot easier.

            I thus recommended you add a '%03d' or whatever is appropriate, to the output filename whenever you plan on writing multiple images, as separate image files.

            Written Scene Numbers
            If you want the image sequence to start at '1', instead of '0', and don't want to rename all the resultant image files, the simplest solution is to prepend a 'junk' image on the front of the sequence to be written.


              convert  null:  eye.gif news.gif storm.gif  +adjoin  image_%01d_of_3.gif
              rm image_0_of_3.gif

            [IM Output] [IM Output] [IM Output]

            You can, of course, use "+insert" to do this after your image processing. This is not a particularly nice solution, but works, and is simple, and backward compatible with the older major versions of IM.

            As of IM version 6.2 you can use the "-scene" setting to set the starting number for the current image sequence.


              convert  eye.gif news.gif storm.gif  +adjoin -scene 101 image_%03d.gif

            [IM Output] [IM Output] [IM Output]

            Which produced the image files "image_101.gif" to "image_103.gif".

            Writing an Image, Multiple Times
            While on the subject of writing images, it is possible to write an image from the middle of a sequence of image operations, using the special "-write" image operator.

            This is very useful when you like to output an image multiple times at various points during image processing. For example, see Complex Image Processing with Debugging.

            Here is an example where I have a Photo of some Parrots, curtisy of the Kodak Lossless True Color Image Suite (image 23), but I want to save them in a range of different sizes, using one command...


              convert parrots_orig.png \
                      \( +clone -resize x128  -write  parrots_lrg.jpg +delete \) \
                      \( +clone -resize x96   -write  parrots_big.jpg +delete \) \
                      \( +clone -resize x64   -write  parrots_med.jpg +delete \) \
                                -resize x32           parrots_sml.jpg

            [IM Output] [IM Output] [IM Output] [IM Output]

            As you can see we can use the Image List Operators to process a 'clone' of an image, write out the result, then delete and backtrack back to the original source image, repeating the process as many times as you need.

            In this particular case it means I did not end up resizing the same image over and over, and thus accumulating resize errors. It also meant I could have just as easily generate the smaller images first, then the larger images after that, without problems, or modify the image in many different ways for each image file generated.

            That is the order and modification of each image is irrelevent!

            Note that "+clone" does not actually duplicate the image data! IM uses a reference-counted cloning process which only copies the image pixels when they are updated. As such only enough memory to hold the original image and the new image that is generated is actually used, in the above process. It also makes "+clone" very fast, and memory efficient.


            Here is another technique of doing the same thing, but saving the original image in a named image register using "MPR:" (see below), instead of "-clone".


              convert scroll.gif  -background lightsteelblue -flatten  -alpha off \
                      -write mpr:scroll  -resize x128  -write scroll_lrg.jpg +delete \
                             mpr:scroll  -resize x96   -write scroll_big.jpg +delete \
                             mpr:scroll  -resize x64   -write scroll_med.jpg +delete \
                             mpr:scroll  -resize x32          scroll_sml.jpg

            [IM Output] [IM Output] [IM Output] [IM Output]

            Here we save one copy of the original image into the "mpr:scroll" image register, before modifying the image still in memory after the write. Note that a MPR register can actually hold a whole sequence of images.

            Once the results of that operation is written and deleted from memory, the original image (or image sequence) is recovered, and the process repeated as many times as needed.

            Of course as previously there is no need to use "-write" on the final image, as we can just output it as normal. If you did use a "-write", you can instead just junk the final image using another special file format "NULL:" (see below).

            A word of warning about "-write": Because some file formats require images to be in a special format for writing, the "-write" operator could modify images. GIF images for example may be color reduced (see Quantization and Dithering). However other formats will leave the source image as is (see MIFF and MPC below).

            If you need protect yourself from these changes (as you are not simply deleting the image afterward), you can use "+write" which will make an internal clone of the image for writing, then delete it afterwards. However remember that this can result in a doubling of memory use to hold the write modified copy of the image. At least for a moment.

            Special File Formats (specific to IM)
            As you saw above (and will explore in the next section Common Image File Formats), ImageMagick understands a huge number of well known image file formats. It also includes a good number of special image generators (as exampled in Canvas Creation). On top of these there are also some very special file formats, which allow some very special handling of images.

            miff:
                Is the ImageMagick File Format. The whole image sequence and all the attributes associated with the images are saved in this file format. Of course only ImageMagick commands will read this format, so it is not suitable for transferring between different image processing packages.

                The "miff:" file formats primary purpose is as an intermediate save format, when processing images in long an complex ways. It is also suitable for 'pipelining' an image from one IM command to another, while passing image meta-data and other attributes assocated with the image.

                I recommend when writing "miff:" that you include a "+depth" option. This will reset the 'input depth' of the image to the IM memory quality so as to use the best posible quality for the intermediate image save. Of course you can 'clip' the save image depth using "-depth 8" so as to reduce the image size on disk, however that will also force Quantum Rounding effects as well (unless HDRI floating-point save is also enabled).

                For those interested in parsing this format, it starts with a plain text header of all the image attributes. The header end in a line containing a single formfeed character.

                This header is itself an useful way of extracting basic image information in various image processing processing scripts. For example here are I use a GNU-sed command to list the "miff:" header up to the formfeed separator, showing all the attributes of the built-in "rose:" image.


                  convert rose:   miff:-  | sed -n '/^\f$/q; p'

                [IM Text]

                This is actually quite useful as it reveals all the current settings flags and meta data that IM knows about the image. However there is also statistics, as these are generated by either the "identify" command, the "-identify" operator or the special "info:" format; if requested with a "-verbose" option. (see next)

                The image file format has very low parsing requirements, and while not compressed, can handle ANY type image IM knows about. It is almost the most ideal format to use for temporary images, and pipelined image commands you can use, though ImageMagick programs is the only one that can read it.

                See also the "MPR" image memory register, and "MPC" memory disk mapping formats below.

                    The raw image data (binary) is actually prefixed by the four character sequence "\n\f\n:", (formfeed on a line by itself, and a colon). How this data should be read is encoded in the header data, but tyically consists of binary integers in RGB turples. But can have more channels, and could even consist of floats or even double data values.

                In may ways it is practically identical to a binery PbmPlus Image file format,with a greatly expanded header to hold image meta-data, and more variations in number of channels and data types.

            MIFF Image Streaming
                The "miff:" format is a 'streaming' image file format. That is to say multiple images are handled simply by appending or concatenating the images together, one after the other.

                This means you can generate a 'stream' of multiple images, simply by writing the images to the same destination, such as a pipeline. Even if the individual images were generated by different commands.

                For example you can have a loop of image processing commands, each command simply outputs a 'streaming' MIFF image. After the loop you can pipe the 'stream' of images into an into a single command to generate montages, collages, animations, or something else.

                For example the following generates a list of colors starting with the letter 'b', then uses a loop of "convert" commands to generate a labeled color patch, one color at a time. These are then 'piped' into a "montage" to generate a simple color table.


                  convert -list color | egrep '^b' | \
                    while read color junk; do \
                       convert -label $color -size 70x20 xc:$color +depth miff:-; \
                    done |\
                      montage - -frame 5 -tile 6x -geometry +2+2 \
                              -background none color_table.png

                [IM Text]

                The above specific example was programmed into a script "show_colors" which you can use to search for, find and display colors, for use in your image processing.

                The above is an example of a 'Pipeline of Streaming Images that is very useful for generating multi-image sequences. Other examples of this technique include Programmed Positioning of Layered Images, Pins in a Map, the 'Named Colors Image' in Colors by Name, and the animations such as shown in Random Ripples.

                This technique can also be used with operations like "-write miff:-", so as to output a miff format image from multiple places in a single command. Each image will be automatically append together in the final output stream. This can be especially useful for debugging complex image processing commands.

                The alternative method (commonly using in PHP scripts) is to use a 'generated command' technique, that uses a shell script to generate a long "convert" comamnd to be run. The scripts in Image Warping Animations use this technique.

            info:
                The "info:" file format (added in IM v6.2.4) does NOT output an actual image! This format basically outputs the same information that the ImageMagick "identify" command will output.

                Like "identify" this output format is controlled by the "-format" and "-verbose" options allowing you to output just the specific information you are interested in, as defined by the Image Property Escapes page.

                For example instead of piping a MIFF image to "identify" as we did above (see Saving Images), we could have used the following, to retrieve the single line identification of the resulting image format.


                  convert  granite:  info:-

                [IM Text]

                Of course you can use a "-format" setting to output the desired information in a specific and more parsable way.

                What is so useful about "info:" is that you can now produce your image, while extracting extra information about it, at the same time. This is done by using the "-write" operator to save this special image format to a file (or the commands normal standard output).
                    


                  convert rose: -shave 12x0 -repage 64x64+9+9 \
                          -format '%wx%h %g'  -write info:info_paged.txt    paged.gif

                    [IM Output]
                    
                [IM Text]
                    

                There is also a "-identify" operator that is equivalent using "-write info:" to output image identification information to standard output. This make it even easier to monitor what is happening to your images when debugging your IM commands.

                For example...
                    


                  convert logo:           -identify \
                          -trim           -identify \
                          +repage         -identify \
                          -resize 80x80\! -identify \
                          logo_thumbnail.gif

                    [IM Output]
                    
                [IM Text]
                    

                Here you can see how "-trim" reduced the size of the image but preserves the 'crop' information of what part of the image was trimmed, then the "+repage" removing that extra 'canvas' or 'page' information. And so on.

                Also like the "identify" command, both "info:" and "-identify", will become much more verbose if the "-verbose" setting is turned on. Here I limit the long output to just the first few lines, just so you can get a bit of an idea about it.


                  convert  rose:  -verbose  info:  | head

                [IM Text]

                    The "-verbose" setting will also cause extra information about images being read in or out, to be printed to the standard error (with the exception of the "info:" format). It also causes some operators like "-colors" to output additional information. As such you may like to turn it off again after using it with either "-identify" or the "info:" format.

                For example    "-verbose -write info:image_info.txt +verbose"    or    "-verbose -identify +verbose" .

                    Scripted reading of the output from any form of "identify", should do so in a case in-sensitive way. This insures better backward compatibility between different versions of ImageMagick.

                NOTE: "info:" (and "-identify") is only an output format, producing the same output as the "identify" command. You can not read, or create an image using the "info:" file format.

                You can also use "-print" to print information, but that is applied only once against the whole image sequence. That means you can use this operator to calculate much more complex '%[fx:...]' expressions involving multiple images. But remember unlike the other methods above, it is only applied once accross all images.

            null:
                As an output format, this will just 'junk' the image results. As such if used as the final argument in a "convert", "montage", or "composite" command the final result will not be saved!

                Why? Well it may be that you are more interested in specific images, generated during image processing rather than the overall result, especially when debugging.

                For example, here we extract and save one image, from an image sequence, then junk all the other images using "null:".


                  convert  eye.gif news.gif storm.gif tree.gif rose: logo: \
                            \( -clone 2 -write write_storm.gif \)   null:

                    [IM Output]

                This is a lot simpler than attempting to delete all the other images one at a time.

                As an input image format however, "null:" will generate a special placeholder image of a single transparent pixel, with with a special 'null source' flag, in the current image sequence.

                This special image is especially important to Leave Gaps in a Montage, and as a list separator for multi-image Layer Composition. It is closely related to another special image format known as a 'missed image', that can be generated for operations like "-crop". This image format is produced when an operation produces an empty or non-sensible result. Both images are a single transparent pixel, and as such "null:" images will also be treated as if it is a 'missed image'.

                At this time there is no method to remove any "null:" or even 'missed image', from the current image sequence. However such a method has been proposed. Mail me if you find you need such a method.

            txt:
                This is a simple ASCII text file, which basically lists each pixel in the image, one per line. It is not a general text to image converter, for that see Multi-line Text Files Examples. If the 'pixel enumeration' is not reconised, the image will be passed to the "text:" format coder, for rendering as a plain text file.

                For example here is a "netscape:" image scale to a 2x2 pixel image, then listed using a "txt:" image format.


                  convert  netscape: -scale 2x2\! txt_netscape.txt

                [IM Text]

                The first line (header) of the image is packed with the basic information about the image. The information consists of...

                File Magic: The image header defines this file as a the special IM text image format (EG a "ImageMagick pixel enumeration" file), this is known in computing circles as the files 'magic' or the code string which identifies this file as being this specific file format.

                Image Size: The next two numbers define the size of the image contained in this file. Multiplying these numbers together will also tell you how many lines should follow the header to fully define the image. IM will always output this many lines, though as you will see later when reading you do NOT need to define ALL the pixels.

                MaxValue: The last number in the header defines the 'maximum value' of the image data that is possible. In the above examples this was '255' which is a result of using a 8 bit depth.

                The reason it output the built-in "netscape:" image at this depth is because it was defined internally using 8-bit values, and as such IM preserved this depth level for the image. See the section on the Depth Setting for more information.

                But you can override the depth setting (up to the limit of your IM's Q or Compile-time Quality setting, by changing the images "-depth". For example here I output the color values as 16 bit values (from 0 to 65535)...


                  convert netscape: -scale 2x2\! -depth 16 txt_netscape_16.txt

                [IM Text]

                    At this time you can not set a specific 'Maximum Value' to use in the output file format. You can only define a different value in terms of the current "-depth" setting, making the maximum value equal to 2^depth-1.

                Colorspace: The last item in the header defines the colorspace of the data that follows. If the image contained any transparency, a final letter 'a' (for alpha) is also appended to the colorspace name, and an extra column of numbers added between parenthesis. Grayscale images will output an image as 'grey', but will define at least three numbers, which will be the same value for each pixel.

                For example here is the same image using a colorspace of 'LAB' with an alpha channel added!


                  convert  netscape: -scale 2x2\! -colorspace LAB -matte txt_cspace_lab.txt

                [IM Text]

                After the initial header are the Pixel Data lines, one per pixel in the image.

                Coordinates: The first two numbers up to the colon ':' is the pixel position, starting from 0.

                Color Values: After this the color values for the pixel (from 0 to the MaxValue given in the header) is given in parenthesis, with anywhere from 3 to 5 numbers depending on the current colorspace for the image. Spaces are optional so caution is advised when parsing the numbers in parenthesis.

                    The values are normally intergers. However as of IM v6.9.2-1, if the special define "-define txt:compliance=css" is given with "-depth 16" the values will be represented as percentage values with '%' signs. This is part of SVG, CSS compliance.

                Color Comments: Anything that follows the numbers in parenthesis, is regarded as comment. IM will fill in extra information on the pixel color using formats that it can parse as a color argument (See "-fill" manual entry for details of these color specifications).

                The color comments are however variable, though typically it will start with a hash ('#') hexidecimal color value, after which it may output RGB() values, or color names depending of the pixel data given. These colornames should be understood by ImageMagick, but are meant as a referance only, as it is purely a comment. Exactly what colors is provided is highly dependant on the IM version you are using, especially in early IM v6 versions and before. There is no guarantee that this comment area will not change again in the future, so it is best not to rely on it. IM doesn't when reading a Pixel Enumeration Image.

                Here is an example of correctly reading a Pixel Enumeration in a shell script. The exact format of the TXT image is defined by the convert command, then 'tail' is used to junk the header, 'tr' to character replace every non-number character with a single space, so that the later 'while' can read the numbers easily, junking any later comment numbers that may have been left over.


                  convert  rose: -resize 3x2\! -depth 8 -colorspace RGB +matte txt:- |
                    tail -n +2 | tr -cs '0-9.\n'  ' ' |
                      while read x y r g b junk; do
                        echo "$x,$y = rgb($r,$g,$b)"
                      done

                [IM Text]


                Reading TXT images is also valid. You do not need to define ALL the pixels in the image. In fact you do not even need to have the pixels in the correct order! ImageMagick will just read each pixel defining line in turn, and 'draw' it onto a blank image canvas. Only the numbers in the parenthesis on each line is used for this, not the color names.

                The initial blank canvas, is cleared and set to the current background color. As such any pixel not provided by a "txt:" image, will be left as this color.

                For interesting use of "txt:" images, look at Forward Pixel Mapping where I output an Enumerated Pixel Image, then change each of the pixel locations so as to rotate (distort) the image, before reading the Enumerated Pixel Image, back into IM again. In the resulting image some pixel locations were not defined, while other locations had multiple pixels added. IM handled this without problems.


                The "txt:" format is especially useful with the "-unique-colors" operator, which replaces each image in the current image sequence with a new image containing one pixel for each unique color found. When this is output to a "txt:" format file, you get a basic summary of the colors contained in an image (though not their counts, or histogram).

                For example here are the colors used by the tree image. As GIF can only use 8 bit numbers, the colors is also output at the same Depth.
                    


                  convert tree.gif -unique-colors txt:-

                    [IM Output]
                [IM Text]

                There is another alternative to using the IM "txt:" format using the various NetPBM image file formats. IM by default outputs this format as binary, but you can turn off "-compress" to output an ASCII text version of the NetPBM format. For example.


                    convert tree.gif -unique-colors -compress None -depth 8 tree_netpbm.ppm

                [IM Text]

                You may notice that the numbers in the above matches the number in the IM's Enumerated Pixel ("txt:") format. See Resized Gradient for some examples of generating a NetPBM format image for IM to read.

                If you just want the color of a specific pixel you can crop the image down to one pixel, and output it as a "txt:" image.


                  convert rose: -crop 1x1+12+26 txt:

                [IM Text]

                Or you can use a special FX Escape Format to output the color in a form directly usable by IM.


                  convert rose: -format '%[pixel:u.p{12,26}]' info:

                [IM Text]

                See also Extracting Image Colors.

            sparse-color:
                This is a special output image format that will return a simple comma separated list of coordinates and colors for each pixel that is not transparent. The output string is suitable for direct input into the Sparse Color Operator.

                For example this finds the few pixels 'closest' to a pure red color in the "rose:" image.


                  convert rose: -alpha set -fuzz 13% +transparent red sparse-color:

                [IM Text]

                In many ways this is more useful that the "txt:" format shown above, but only if a couple of pixels are involved.

                Be warned however that at the time of writing, the output is all one line. Shell scripts may like to convert the spaces in the output to newlines.

            histogram:
                This is actually the "miff:" image format, but with a very large image comment that contains a complete count of all the colors within the image. That is in the "miff:" text header 'Comment={...}' attribute.

                For example, here we again list the colors present in the "tree" image, but this time including the pixel count for each color. The text histogram comment is extracted from the "histogram:" image using a secondary "info:" formatted identify.
                    


                  convert  tree.gif  -define histogram:unique-colors=true \
                           -format %c histogram:info:-

                    [IM Output]
                [IM Text]

                    The "info:" output format was added to IM v6.2.4. For IM versions before this use..


                  convert  tree.gif histogram:- | identify -format %c -

                You will note that the format is almost exactly the same as that of the previous TXT, or IM Pixel Enumeration Image format, including the comments on the color values. The only difference is that the X,Y location has been replaced by a count of the number of pixels.

                    This comment can take a very long time to create. As of IM v6.6.1-5, you can add the special setting "-define histogram:unique-colors=false" which will turn off this comment generation if you do not need it.

                The image itself is a histogram graph, 256x200 pixels in size. The x-axis is color value (0-255) and the y-axis is pixel count (normalized to the number of pixels). The histogram for each channel is displayed in the color it represents, and added together. Thus, red and blue overlap to make magenta. In other words with color channel has its own separate histogram.

                If you want the image converted to some other format, just save it into that format. "histogram:" is a special image processing format. It will convert the image, then output in the format specified by the filename suffix or further "format:" codes.


                  convert rose: \
                          -define histogram:unique-colors=false \
                          histogram:histogram.gif

                    [IM Output]

                An image that is very dark will be heavily weighted to the left, while a light image will be heavily weighted to the right. Mid-tones, likewise, are represented in the middle.

                To see this better here I separate the histograms for each of the color channels. I also strip the histogram text comment (if still present), and resize the image for display.


                  convert histogram.gif -strip -resize 50% -separate  histogram-%d.gif

                [IM Output]
                Red 	[IM Output]
                Green 	[IM Output]
                Blue

                For the "rose:" image above you will see that red is spread more showing its vital importance in the image. On the other hand green and blue spikes on the left, showing that is has very little influence on the image at all.

                If you are more interesting in the brightness of an image rather than its colors, convert the image to a gray-scale before generating a "histogram:" image.


                  convert rose: -colorspace Gray \
                          -define histogram:unique-colors=false \
                          histogram:histogram_gray.gif

                    [IM Output]

                As you can see the histogram of a gray-scale image is a little different. As the predominate red color become more of a mid-tone grey color, producing a spike in the center of the histogram. Also the small area of off-white in the image now produces a distinct spike at the extreme right of the graph.

                The completely empty space at the extreme left also shows that there are no dark patches in the image at all.

                On the other hand a better 'global' histogram can be generated by simply separating all the color channels in the original image and appending. The resulting histogram is a representation of all the color values regardless of which channel that value is from.


                  convert rose: -separate -append \
                          -define histogram:unique-colors=false \
                          histogram:histogram_values.gif

                    [IM Output]

                Unfortunately as "histogram:" is an output format, you will either need to 'pipe' the image into another command, save it to disk, or use the special "mpr:" save/read, if you want to process the image further. See example in "mpr:" below.

                It would good if some method of generating histograms (and other graphs) became available as operators rather than a special output format.

            mpr:{label}
                (Memory Program Register) will save the whole image sequence into a named memory register, from which you can later read the image data. As such if you want to save an image for use latter, in a complex image operation you can do so.

                Writing to a "mpr:" at the end of processing is useless, as the program memory is returned back to the system when the program finishes. As such you will want to use a Write operation to save the images to a file in the middle of your processing steps, if you need it in a different process.

                The 'label' given to "mpr:" can be anything you like, it is only a label on where the image was saved in memory. It can even be just a simple number for people who do scripting and don't want to deal with names, though names could make your script easier to follow.

                After you have saved an image see below), you can then read in the image again, from the same 'labelled' memory location, as many times as you like. For example...


                  convert tree.gif -write mpr:tree  +delete \
                          \
                          mpr:tree  mpr:tree  mpr:tree   +append  mpr.gif

                    [IM Output]

                Note the use of "+delete" in the above image processing. In the above it is not necessary (just re-read the "mpr:tree" two times instead of three), but it is very common to Delete all images from the current image sequence after saving the images in a "mpr:" register.

                Basically the two lines in the above can be thought of as two completely separate "convert" commands, but using a named memory register for the intermediate image rather than disk space.

                In many ways using "mpr:" is like using Clone or Duplicate (which we could have used in the above example), but using "mpr:" allows use to completely remove all the images, to clear the current image list for other work.

                The best feature of this method is that it also allows you to use settings and operations that only work on image input. For example, using it with the input image "tile:" operator to tile an image over a larger area.


                  convert tree.gif -flip   -write mpr:tree  +delete \
                          -size 64x64 tile:mpr:tree   mpr_tile.gif

                    [IM Output]

                You can also use "mpr:" to grab the output of some of the special output image format filters for further processing. For example here we save the output image from "histogram:" and then read it back in continue to processing it in the same command,


                  convert rose: -define histogram:unique-colors=false \
                          -write histogram:mpr:hgram  +delete \
                          mpr:hgram  -strip  -resize 50%  histogram_resized.gif

                    [IM Output]

                The "mpr:" in-memory save is actually the only way you can re-use images already in-memory through special I/O filters such as an output file format like "histogram:" or an input file format like "tile:".

                The same is true for the special options that take an actual input image, such as "-tile" or for "Color Mapping" images using another image as a source. See Multi-image Color Maps. NOTE that such options are being replaced in IMv7 with versions that do not need the image to be read from a file.

                It is also the only way to use the -draw 'image' method to overlay images using a generated in-memory image, though there are lots of other techniques to do this.

                The "mpr:" image actually saves the whole image sequence and not just one image. It is a bit like taking a snapshot of the current image sequence so you can reload it later on for further processing. This for example allow you to take copies of a whole animation sequence, for duplicating or cloning, without needing to know how many images are actually involved. See Layers Composition for an example of doing this.

                When you do have multiple images in "mpr:" you can actually still extract individual images from that sequence! Using "mpr:image'[2]'" will pull the third image from a multi-image sequence saved using "-write mpr:image".

                For example here I extract the 'storm' image from a set of four images.


                  convert eye.gif news.gif storm.gif tree.gif \
                          -write mpr:images  -delete 0--1 \
                          \
                          mpr:images'[2]'   mpr_extract.gif

                    [IM Output]

                The Image Cloning operator cannot generally handle an unknown variable number of images, and in fact before the Clone operator was added "mpr:" was the only method available for duplicating in-memory images, without using intermediate disk files.

                    As of IM v6.8.2 you can also store images in a remote IM caching daemon process. This allows images (and there meta-data) to be passed between separately running IM commands, without needed disk space. See Distributed Pixel Cache Daemon

            mpc:
                Is a special IM specific disk save format that was originally designed with really large images in mind. Basically is is a memory-mapped disk file of program memory, saved to disk as two binary files, a ".mpc" holding the meta-data of the image, and a ".cache" holding the images pixel-cache.

                The "MPC:" format creates two files to save one image

                Such files will not work after IM is recompiled or upgraded, and only for the IM compiled for a specific machine. As such it is only good for temporary 'quick read' files, such as in holding temporary images used by scripted image processing, and not long term storage.

                For example...


                  convert very_big_image.tif  very_big_image.mpc

                will create two files on disk. A small "very_big_image.mpc" file and a special memory dump file called "very_big_image.cache". The second file size will likely be very much larger that any other image file format as it is just a raw, uncompressed memory dump.

                However the file does not need to be 'read in' or 'decoded' but can be directly 'paged' into computer memory, and used exactly as-is, without any processing overhead. Only lots of disk space and disk IO. In other words it only needs disk access time to read, without any file format processing. That is no decoding of the data needed.

                Because the image is 'memory-ready' it is especially useful for temporary images of all sizes as it will be usable immediately by the next IM command you issue. But remember, two files are generated and they will be larger than a normal image filesize, so be careful of your disk usage, and script cleanup.

                My own IM scripts make good use of this feature. For example see the scripts "de-pixelate", and "divide_vert", which make use of quite a large number temporary image files for image processing operations.

                This can be extremely useful for scripts or Mogrify Alpha Compositing that needs to be able to read the same image, over and over and over again, as IM does not have to decode the image, or use up lots of memory just to store it.

                This is also very useful for processing a very large image, where you must extract or Crop a smaller section of the image for the for actual processing. However as most image operations actually make clone copies of images during processing, a new in-memory copy, could still be made. As such some care is still needed. A Crop or Resize to much smaller image sizes are the safest operations for MPC large image handling.

                For more information see Really Massive Image Handling below.

            fd:{file_descriptor}
                This special file name which allows you to specify a specific 'file descriptor' the image is to read from or written to.

                The name 'fd:0' is the 'standard input' and 'fd:1' is the 'standard output' of the program. These are equivalent to using a '-' as a file name.

                However you can specify any 'file descriptor' to with to read/write the image. Including 'fd:2' for 'standard error', or whatever other previously opened file handle the parent program may have arranged.

                The most common use for this is in very advanced shell scripting, where you may have multiple file streams of images. Or for network daemons that may have multiple file streams open simultaneously.

            inline:{base64_file|data:base64_data}
                Inline images let you read an image defined in a special base64 encoding.

                For example to read a base64 encoded image use...
                inline:base64_image.txt

                This encoding could be from a file, but it is more typically given directly as the read argument instead of as a file name from some external image source. This is more typically used an alternative to 'blobs' on the command line, or in API image processing.

                Or put the image data directly on the command line...
                inline:data:mime-type;base64,/9j/4AAQSk...knrn//2Q==

                For example lets base64 encode a very small image (there are many programs that will let you do this conversion)...


                  openssl enc -base64 -in noseguy.gif

                [IM Text]

                Note base64 data can contain any amount of white space such as returns and newlines. It is simply ignored by the format. It also only uses normal ASCII characters, which is why it is used to encode binary data for email and web pages. It also allows binary data to be stored in programs and scripts without problems.

                For example I could have the following command in a shell script so the script itself has the image built into it, and thus does not need a separate external image source.


                  convert 'inline:data:image/gif;base64,
                      R0lGODlhIAAgAPIEAAAAAB6Q/76+vvXes////wAAAAAAAAAAACH5BAEAAAUALAAA
                      AAAgACAAAAOBWLrc/jDKCYG1NBcwegeaxHkeGD4j+Z1OWl4Yu6mAYAu1ebpwL/OE
                      YCDA0YWAQuJqRwsSeEyaRTUwTlxUqjUymmZpmeI3u62Mv+XWmUzBrpeit7YtB1/r
                      pTAefv942UcXVX9+MjNVfheGCl18i4ddjwwpPjEslFKDUWeRGj2fnw0JADs=
                    '  b64_noseguy.gif

                    [IM Output]

                Remember with this the image could be used in your script (shell or API). You do not needing to have a separate external image file, making installation of an otherwise simple script more complicated.

                So why does "inline:" have this rather complicated form?

                Basically because this is the format used for inline images in HTML web pages. For example in the following the image on the right was included directly inline on the web page, and not as a separate external file, using HTML tag of the form...


                  <IMG SRC="data:image/gif;base64,
                        R0lGODlhIAAgAPIEAAAAAB6Q/76+vvXes////wAAAAAAAAAAACH5BAEAAAUALAAA
                        AAAgACAAAAOBWLrc/jDKCYG1NBcwegeaxHkeGD4j+Z1OWl4Yu6mAYAu1ebpwL/OE
                        YCDA0YWAQuJqRwsSeEyaRTUwTlxUqjUymmZpmeI3u62Mv+XWmUzBrpeit7YtB1/r
                        pTAefv942UcXVX9+MjNVfheGCl18i4ddjwwpPjEslFKDUWeRGj2fnw0JADs="
                      ALT="Nose Guy" WIDTH=32  HEIGHT=32  VSPACE=5 HSPACE=5 BORDER=0 >

                    Nose Guy
                This will not work with all web browsers, for example it will not work with IE7 and earlier, but will work with IE8. Basically the most modern web browsers understand it.

                The same type inline data format is also used for 'face' images in EMail headers, and probably many other file types.

                ASIDE: Thanks to the 'magic' part of ImageMagick, most image file formats do not need to have the mime-type (the 'image/gif' part of the long string) included. And in actual fact it is completely ignored by IM in any case). However the comma ',' is still required to mark the end of that part of the inline image data string.


                  convert 'inline:data:,R0lGODlhEAAOALMAAOazToeHh0tLS/7LZv/0jvb29t/f3//U
                       b//ge8WSLf/rhf/3kdbW1mxsbP//mf///yH5BAAAAAAALAAAAAAQAA4AAARe8L1Ek
                       yky67QZ1hLnjM5UUde0ECwLJoExKcppV0aCcGCmTIHEIUEqjgaORCMxIC6e0CcguW
                       w6aFjsVMkkIr7g77ZKPJjPZqIyd7sJAgVGoEGv2xsBxqNgYPj/gAwXEQA7
                    '  b64_folder.gif

                    [IM Output]

                WARNING: Command line option input is restricted to 5000 characters. Also many shells (and particularly PC-DOS input) has total command line length limits. As such this is not suitable for very large base64 images.

            clipboard:
                Read or Write the image to or from the Windows Clipboard. (Windows only).

            ephemeral:{image_file}
                Read and then Delete this image file.

                This is a special image reading file format which will cause IM to delete the given image file after that file has been read into memory.

                Note that the image in memory will not have been processed or even saved when the read file has been removed.

                This is very dangerous and should be used with extreme caution.

                It is mostly used in Delegate Spawning. Here the background delegate will read the input image, then deletes it when it has the data. This in turn notifies the foreground 'parent' process, that the 'child' is ready to proceed on its own, as it has finished reading the image provided. The main program can then clean-up and continue its image processing separately, or simply exit, as the case may be.

                The "show:" image output delegate uses this with the "display" command, to automatically background an image display before the main command continues or exits. (see below)

                For example I used this in a shell script that calls "flicker_cmp" to display some intermediate results, but then automatically continues (or exit) when the IM has signaled that the program has finished reading its input image by deleting the second image given. If you need that feedback but also need to preserve the image being read, then make a copy, hard link, or symbolic link to the original image, and pass that file as "ephemeral:". that way when it is deleted the orignal image is preserved.

                NOTE: There is currently no way to get "animate" or "display" to signal when it has finished an animation, or has actually put the image up for display. :-(

                However you can have "convert" read a separate "ephemeral:" image, to notify a controling script that it has reached a specific point in its image processing.


                  # Blur an image, and show an on screen comparision before
                  # auto-deleting and exiting.
                  convert rose:  input_image.png
                  convert input_image.png -blur 0x5  blurred.png
                  flicker_cmp input_image.png ephemeral:blurred.png &

                  # wait for the second image to have been read and deleted!
                  while [ -f blurred.png ]; do usleep 100; done

                  # At this point we can continue (or exit) without problems.
                  # while the on screen display continues in background.
                  rm -f input_image.png

                I have also used this in other background programs, as a signal that that background program is ready to continue.

            show:, win: and x: -- Display images directly on screen
                These are special output formats that will which will directly display the image result to your screen. Instead of saving the image into a file, it just displays the result.

                This is very useful for quick testing IM commands to see what the results will be, and is highly recommended for this purpose. However they are only very simple versions of the "display" and "animate" command.

                For example, get a fast summary of images in a directory...


                  montage *.jpg show:

                See the areas that are different between two images...


                  compare image1.png image2.png show:

                All the formats listed here, actually call on the "display" program to perform their task. However they each handled the job in different ways.

                For example 'show:' will use a Spawning Delegate to run a separate "display" program. This means that once the image has been displayed, the original command will continue its processing (typically exiting, unless you use "-write show:" ).

                On the other hand, using 'x:' or 'win:' will wait for you to quit the display window before allowing the original command to continue (and exit).

                Unfortunately none of these methods will display animations very well. For that you are better off piping the animation (in MIFF format) into the "animate" command.

            x: (as input) - Reading an X Window Display
                You can also read the current X window display using the "x:" operator, in much the same way as you can with the "import command. In fact without options it acts exactly like the "import" command. Use the left button to select the window to grab a copy of, or mark out an area using the middle button.

                For example, to select a window using your mouse, then display the window just grabbed in another window (exit when grabbed window is displayed)...


                  convert x:  show:

                WARNING. if you grab a window that is unmapped (iconized), or has another window over it, the image contents will contain either a blank area, or the contents of the overlapping window!!! So make sure when grabbing a window that window fully visible on screen.

                To grab the whole display use 'root' for the window name.


                  convert x:'root'  full_screen_dump.jpg

                Or use the Read Modifiers to grab a specific area of the display.


                  convert x:'root[300x400+879+122]'  part_screen_dump.jpg

                Providing a window name you can grab a specific window. For example this will grab the window titled 'MailEd'...


                  convert x:'MailEd'  window.jpg

                However that does really not work well, as often you have multiple windows with the same name, or the name of the window just can't be determined.

                The better way is to tell IM the exact window wanted using a "X Window ID" which is the number that the X display uses to uniquely identify a specific window (or child window).

                The X Window ID is typicaly looked up using the "xwininfo" command, but other programs such as "xdotool", and "xwit" as well as other tools like "xprop" can be used to find information about the windows. For example things like, window class, name, title, its size and placement, child windows, and window manager decoration.

                For example, find all windows with "Mozilla Firefox" in the title or name...


                  xwininfo -root -all | grep "Mozilla Firefox"

                I can then extract the X Window ID of the window I want from the output of the above.

                Here is a little more complex bash script I have in my window manager. When I press a button, it looks up the ID of the window with the current 'focus', captures it, then names the file as a PNG in my current directory using the next capture number, according to any previous captures made.


                  bash -c "
                    id=$(xprop -root _NET_ACTIVE_WINDOW | sed 's/.* //')
                    convert x:$id capture-tmp-$$.png
                    num=$( ls capture-[0-9]*.png 2>/dev/null | sed -n '$ s/[^0-9]//gp' )
                    num=$( printf %03d $(expr $num + 1) )
                    mv capture-tmp-$$.png capture-$num.png
                  "

                Most terminal programs will tell you the X Window ID they are using to display text in the environment variable "WINDOWID". As such if you run this from a command line of a XTerm, or Gnome Terminal, you will grab a copy of the current terminal window.


                  convert x:$WINDOWID  this_terminal.png

                Now for some fun... Here I grab the contents of my current terminal, draw some stuff into it, and then use the "display" to draw it back into the same terminal window!


                  window=`xwininfo -children -id $WINDOWID |\
                                  sed -n 's/^ *\(0x[^ ]*\).*/\1/p'`; \
                  window="${window:-$WINDOWID}"; \
                  convert x:$window -background black \
                          -draw 'fill black         rectangle 40,40 160,160' \
                          -draw 'stroke red         line 50,50 50,150 line 50,150 150,150' \
                          -draw 'fill lime          circle 110,100 80,100' \
                          -draw 'stroke dodgerblue  line 50,150 150,50' \
                          rose: -geometry +180+60 -composite \
                          png:- |\
                    display -window $window -

                The first command in the above is designed for an "XTerm" window, which requires that the window you "display" into, be the child window of the provided "WINDOWID". The second line falls back to original value of "WINDOWID" if no 'child' window is found, as is the case for a "Gnome-Terminal" window.

                Once the window to use is worked out, it is grabbed, drawn on, and restored into the terminal window! And presto you have instant graphical output directly into the current terminal window.

                Here is a simpler example, this darkens the window contents each time you run it. Try running this a few times in an actual "xterm" window, and you find the older the command in the terminal window the darker it gets!


                  window=`xwininfo -children -id $WINDOWID |\
                                  sed -n 's/^ *\(0x[^ ]*\).*/\1/p'`; \
                  window="${window:-$WINDOWID}"; \
                  convert x:$window -background black -colorize 20% png:- |\
                    display -window $window -

                And here is a 'screen capture' showing what happened as I repeated the above in my own "xterm" window...
                [snapshot]

                Be warned that while the contents of the terminal are modified, it is only temporary. If you iconify, obscure, or change desktop screens, then go back to the terminal, the modifications will be lost as the terminal program re-draws the window, and wipe out your own 'drawing'.

                The above does not work nearly as well for a "Gnome-Terminal" as for "XTerm"s because the former likes to 're-draw' its window every time it scrolls, where a "XTerm" does not.

                Imagine IM scripts that display the results of graphs and other things directly in various windows as part of a larger client program. This is in fact how many postscript viewers, and even many web browsers display output from special sub-programs. That is they have that sub-program take over and directly draw into a provided sub-window.

                Experiment, and please let me (and others) know what you come up with, either via email or the IM Users Forum.

            Coders and Delegates for Image Formats
            Coders are dynamic library modules (usually written in the C programming language) that handle the "format:" aspect of image input and output. They can also be used by users to create special purpose filters. They may require the installation of extra external libraries to be installed, which are often called 'delegate libraries'.

            They are loaded as dynamic modules only as needed, which means the associated libraries used by a coder does not need to be installed, unless you want to actually make use of that coder.

            These examples will not go into the C programing required for writing coders, but there is an example coder in the source that can be used to create your own coder modules.


            A Delegate is simply a command that IM knows that will allow it to convert between different formats. This allows IM to use that 'simpler' and pre-written command, rather than requiring a more complex binary coder to handle some image file format.

            To get a list of what delegates are available use the special command...


              convert -list delegate

            The most well known 'delegate' program Im makes use of is "ghostscript" which will allow IM to read, and convert the very complex Postscript and PDF format vector images into some other raster image file format that IM can read.

            However 'Delegate Commands' are very useful for users too, as it allows you to expand IM so that it can handle special types of images, or to provide alternative methods to read and write those images.

            The 'commands' themselves are listed in a file named "delegates.xml", and which is located in IM's system configuration directory. But it will also read a "delegates.xml" located in the users personal ".magick" sub-directory of there Linux/UNIX home directory. And it is in this second file that users should place their 'command delegates'.

            Input Delegate Command Example
            For example I can create a personal "delegates.xml" file in the ".magick" sub-directory of my Linux/UNIX home directory, of the form...


            <?xml version="1.0" encoding="UTF-8"?>
            <delegatemap>
              <delegate decode="flip" command="convert '%i' -flip 'miff:%o'"/>
            </delegatemap>

            This is a complete 'delegate' configuration file, but only the middle line is an actual delegate. A very simple one that tells IM that if it sees an image with either a '.flip' suffix or a 'flip:' format prefix, it should call the above command, to read the 'flip' format image.

            For example..


              convert flip:tree.gif   delegate_tree_flip.gif

                [IM Output]

            In this case all the delegate command does is use a separate IM "convert" command to 'flip' the image upside down, before the original IM command even reads and processes the image!

            The delegate assumes the command will understand the image file format given and that it will return ANY image file format that IM itself can understand and process (a MIFF image file format in this case).

            The '%i' and the '%o' parts of the delegate represent temporary filenames the command is the provided input and outptu filenames the delegate should use. These filename are generated by IM, and will be located in a temporary directory. These temporary filenames also do NOT have any image suffixes, so it is important that you prefix the image format type desired, if necessary.

            It is done this way for security reasons, and because IM itself may only be reading a stream of data, and not an actual file. It also means the delegate command does not have to deal with things like clean up of those files when finished.

            There are other '%' substitutions for things like a second temporary filename for intermediate temporary files, image density, size, and so on. More detail about these escapes and other delegate options are provided in the comments at the top of the IM installed 'system' "delegate.xml" file.

            Now this may seem like a rather silly and trivial example, but it basically means you can now use a secondary command to convert ANY data file into ANY image IM understands. IM will then know how to handle that data type automatically given the image suffix, or a format prefix, without you needing to remember all the details.

            Lots of delegates of this type has already been added to the system file, so it is worth a look.

                For security reasons delegates in a personal "delegates.xml" file will not override the delegates defined in the system installed "delegates.xml" file. You can only add new unique delegate formats in ".magick/delegates.xml" in your home directory, later duplicate delegates will be ignored.

            Of course if the input format is already known internally then of course system delegates are not looked at.

            Also as always, sanitise any user (especially web user) input, as you don't want the user to make use of a delegate without you knowing about it.

            For example as of IM v6.4.2-6, a "autotrace:' delegate was added to the system delegates file, which will run the "AutoTrace" command while reading ANY input image. IM converts the input image to the required PNG image format needed by the delegate program, filters it though the delegate, then reads the resulting SVG (typically via an external RSVG library), to generate a smooth edged version of the original input bitmap image. See Raster to Vector Converter Example.

            If a converter generates multiple image files (such a PNG), you will need to merge all those separate images into a single multi-image format such as MIFF, so that IM can read the multiple images from the one output file.

            Sometimes IM will string together multiple delegate programs to read in an image. For example to read a 'HTML' page as an image, it first calls the delegate "html2ps" to convert it to postscript. Then it converts the generated postscript file into a set of multiple images using the special "ghostscript" program delegate.

            Of course using two, or more delegates like this can produce other problems due to the complex interactions, miss-installations, and bugs that may be present in the delegate programs. But in general it works, and is a key aspect of what make ImageMagick, magical.

            Output Delegate Example
            Similar things are done when saving to specific image file formats that IM does not directly understand.

            For example by adding this delegate to your personal ".magick/delegates.xml" file, you can tell IM how to create a '.xyzzy' image file.


              <delegate decode="gif" encode="xyzzy" command='mv "%i" "%o"'/>

            Of course this just quickly copies a GIF file format image as a TMP file format, but the command can be any type of image converter, script or shell command sequence you like.

            With that personal delegate, IM can now create your '.xyzzy' images, having been provided at least one method of going so.


              convert rose:  -negate   rose.xyzzy
              identify rose.xyzzy

            [IM Output]

            Note that the identify in the above does not understand the '.xyzzy' suffix (no input delegate has been provided). However as no specific delegate is provided, the file 'magic' (an identification string inside the file itself) tells IM that it is in reality a GIF image format, so IM handles it correctly anyway, without needing a special input delegate or coder.

            This is actually the the 'MAGIC' part of 'ImageMagick'.


            Delegate Listings
            A full list of external delegates that IM can use for converting image formats is read from a special system file called "delegates.xml" as well as a personal "delegates.xml" file (see below). If you can find this file it makes interesting reading.

            The format of this file however is too complex to do into here, though it is explained in both the system file and the manuals provided both online and with your ImageMagick installation (docs area).

            A simplified summary of the delegates and conversions that IM is reading from these files can be printed using the "-list delegate" option...


              convert -list delegate

            However please note that delegated declared with 'stealth="True"' will not be listed, by the "-list delegate" option.

            All delegates are optional, and more than one can be created for a specific conversion. If one delegate is not available (or it errors and image is not created), then IM will try the next delegate, until one is found that does work, or it runs out of delegates to try, at which point an error will be produced indicating it can not read that image.

            Printing Delegate
            One of the most useful delegates I have ever created was to let me easily print images to a postscript printer. The printer was already set up using the linux "lpr" command and it could accept either a PNG format image, or a postscript file.

            Here is the simple "PRT: delegate I decided to create.


              <delegate decode="ps" encode="prt" command='lpr "%i"'/>

            Notice I decided to use postscript format ("decode="ps"") for the image being passed to the "lpr" command on my system. I chose that as I can then use options such as "-density" to adjust the size of the output image.

            For example I can create a command to grab a window form my screen, modify the image, so as to fit on printed page (as I want it) then print it.


              convert x:Loopy -shave 6 -chop 0x24 -modulate 220,0 \
                      -bordercolor white -border 50x150 -density 130   prt:

            I could have also used "decode="png"", however my system would then enlarge or shrink the image to always completely fill the A4 page. You however may like this.


              <delegate decode="png" encode="prt" command='lpr "%i"'/>

            Spawning External Commands
            External command delegates does not have to just be for converting images to/from files, but can be used as a quick way to run (or 'spawn') complex commands in the background. Such a delegate will have the attribute 'spawn="True"' added to it, and will launch the command, wait for it to delete its input image, then IM will continue as normal, leaving the command running in the background.

            For example two output delegates "show" and "win" both provide simple ways to display the result of a command in the IM "display" program.

            For example..


              convert rose: label:rose -append   show:

            This will append a label to the built-in 'rose' image and just display it on the screen. When the spawning delegate has read its input image and deleted it (typically using the special "ephemeral:" input format, see above), the launching IM will continue (and exit), leaving the 'display' program running in the background to show the results.

            Here is the "show" spawning delegate, showing the use of "ephemeral:" in the "display" command.


              convert -list delegate | grep show

            [IM Output]

            Unfortunatally the "list" option does not show the 'spawn="True"' flag of the delegate, but it is defined for this delegate.

            This is a lot more convenient that trying to remember all the special options that a scripted "display" command needs.

            Perhaps you have some complex command that you run all the time.

            Postscript and PDF Delegate
            By using delegates ImageMagick can make use of external programs to do some of the more complex and specialised image format conversions.

            For example, while Postscript (PS:), and Encapsulated Postscript (EPS:) can be written directly by ImageMagick. These file formats can not be read by IM. Postscript is a full computer language and requires a very complex interpreter to create images from it. As such it is far beyond the scope of IM to handle the reading of this file format.

            To solve this IM looks for an external delegate program called "ghostscript" to do the work of converting an PS or EPS format file to some other image format that IM can read easily.

            Of course that means that if you get an error like...
            convert: no decode delegate for this image format `...'
            Basically means that IM was unable to find the appropriate external program to convert your given image format into an image format that IM itself can handle. For Postscript images, that usually means "ghostscript" is not installed, mis-configured, or in an unknown location on your system.

                The PDF/PS "ghostscript" delegates are in a special format used internally. IM internally examines postscript format images to attempt to determine exactly how to rasterize the file via the given delegates.

            In fact, multiple PS delegates are present and selected by IM depending on the situation. For example the ghostscript device used ('bmpsep8' verses 'pngalpha') is selected depending on if "-colorspace RGB" had previously been set or not.

            For PDF we use the 'ps:color' delegate rather than 'ps:alpha' because the 'pngalpha' ghostscript device only supports an one-to-one page-to-image conversion and PDF's generally are multi-page.

            Direct Delegate Format Conversion (Taint)
            The delegate system also allows IM to call an external program to convert an image from one format to another format, without any processing of the image by ImageMagick itself. But only if the destination image is readable by IM as an image and the final result of the "convert" was an 'untainted' copy of the image.

            For example if you try this comamnd to convert a 'Adobe Illustrator' file (".ai") (which is a type of Postscript), to EPS (encapsulated postscript)...


              convert -density 300   map.ai  map.eps

            Then IM will convert the "map.ai" to an EPS file (in "/tmp"), a format it understands. Then after reading into memory (after using the 'eps' delegate), it will then find that it does not actually need to modify it (it remains 'untainted').

            Because no change was made to the image, and the image was already converted to a 'eps' file file format, IM will short-circuit itself and directly copy the 'eps' file it generated to "map.eps".

            That is the EPS file will be just a copy of the original unchanged Adobe Illustrator file!

            In otherwords IM only used its internal delegates to convert the file (actually just rename it). It never actually processes the image itself, and as such the image remains a pure vector image.

            This is actually the original purpose of "convert" as a program back in version 1 of ImageMagick. All the other operations and settings were added later over a very long period of time.

            You can however force IM to actually read-in and write-out the image, as a raster, by using the special "-taint" operator to mark it as being modified, without actually modifying it.


              convert -density 300 map.ai  -taint  map.eps

            Here the image IM reads does become 'modified' or 'tainted' so it will write out the version of the image in memory to the final EPS file, rather than simply copy the input file.


            Other Delegate Examples
            Modifying Postscript Delegate for CMYK postscript
            See Blog of John,
            DCRaw 8-bit processed camera image Delegate
            An alternative delegate for reading 8-bit fully processed 'raw' digital camera images (CRW, CR2, NEF, etc) is...


              <delegate decode="dcraw8" command='dcraw -v -w -O "%o" "%i"'/>

            This will read the 'raw' camera image, and convert it to a PNG file format (though you can also just as easily add a '-T' flag and use a TIFF image format). That output image turn is readable by ImageMagick.

            By adding this delegate can then use it simply, for any ImageMagick image read operation (any API, not just command line), and IM will handle all the file IO and cleanup. For example...


              convert dcraw8:image.crw  image.png

            If you do not define the filepath of the "dcraw" executable, IM will search the for the program along the users current PATH environment variable, however allowing this could represent a security problem. System installed delegates generally define the command path fully.

            See comments in this IM Users Forum Discussion.

            Video decoder delegate using 'ffmpeg'
            For example here is a delegate published by Mikko Koppanen, on his Mikko’s blog site. Add this to your personal "delegates.xml" file in ".magick" directory of your home...


              <delegate decode="ffmpeg" command="'ffmpeg' -i '%i' -y -vcodec png -ss %s -vframes 1 -an -f rawvideo '%o'" />

            IM can now use the "ffmpeg" program to decode the frames from an MPEG video image. For example.


              convert  "ffmpeg:test1.mpg[40]"  frame_40.png

            Really Massive Image Handling
            For handling any sort of large image it would probably be better for you to use a Q8 version of ImageMagick, which has half the memory requirements of the higher quality Q16 version. Check your IM's compiled Q level using "identify -version".

            For medium sized images you can attempt to use "-limit" to increase the processing limits (for example processing "-limit area 8192 -limit memory 8192"), so as to try to avoid IM caching the image data to disk. However your system may reject large memory requests and still force IM to cache the image to disk (about 1000 times slower).

            To see if IM is using disk cache for the image processing, you can use "-debug cache" to monitor that action.

            Also see IM Forum Discussion.
            Memory/Disk Management
            If you are planing to process really large images you may want to make sure IM does not use up all the computers memory, and slowing down the processing of other programs (by spending all its to shuffling between memory and disk swap) simply by asking it to immediately use temporary swap disk files.

            For example this is a nice way of processing a very large image over a long period of time without stopping you from using your computer for other things. Basically it forces IM to cache everything to disk.


              env MAGICK_TMPDIR=/data nice -5 \
                convert -limit memory 32 -limit map 32 \
                        huge_9Gb_file.psd  -scene 1 +adjoin layer_%d.png

            Of course this assumes that "/data" has enough file and disk space to handle the images memory requirements.

            Memory Mapped Disk Files
            If you have many operations to perform on the same source image and you have plenty of disk space you can use the MPC image format which is expensive to create but has near zero overhead when loading...


              convert mybigassimage.jpg mybigassimage.mpc
              convert mybigassimage.mpc   -resize 50%  resized.jpg
              convert mybigassimage.mpc   -rotate 90   rotated.jpg
              ...etc...
              rm -f mybigassimage.mpc mybigassimage.cache

            This will let you read a very large image multiple times with a minimal cost, and memory usage.

            An example of a scripted for of tiling using this method was presented in an IM Forum Discussion Cut large image on tiles and revisited in Cropping very very large images.

            Basically the MPC image format file consists of two actual files, an informational ".mpc" file, and a direct memory paged copy of the image in a ".cache". Of course you need to clean up both files when you are finished.

            This method is designed so that IM does not have to re-parse the image format and cache it to disk, every time you run a new "convert" command. Also if you are accessing only sections of the input image, each command does not need to process the whole image, but can now read just that smaller section from the cahced disk file as needed.

            If you plan to process a very large MPC copy of the image, it is a good idea to extract or crop a smaller section of the image for actual processing. This is because just about any operation performed on an image, will generally result in a new in-memory copy being made of the result, so an initial crop is a very good idea.

            If you have the memory you can also try to use a 'memory disk' such as a 'TMPFS' or RamDisk type filesystem. Be warned however that filling that type of disk also directly fills your computers memory. So really you are just swapping one use of memory for another.

            Processing Images in small sections
            While you can use the MPC method above to crop out various sections from a source image for further processing, you still need to read in and write out the the whole image, and for a massive image that can still take a lot of time.

            IM has also evolved a simpler pipeline processor for images called "stream". This program has a limited set of image operations that are designed to only process images one scan line (row of pixels) at a time. As such only enough memory to hold a single line of pixels is used when processing images in this way.

            For example this allows you to extract a smaller area of a very large image for further processing, without needing to read in the whole image into memory first. However the output of "stream" is raw RGB image values, so some post-processing is recommended.


              stream -map rgb -storage-type char -extract 600x400+1900+2900 image.png - |\
                convert -depth 8 -size 600x400 rgb:- tileimage.png

            You don't have the save the output to a file but can continue processing the smaller image directly. For example...


              stream -map rgb -storage-type char -extract 600x400+1900+2900 image.png - |\
                convert -depth 8 -size 600x400 rgb:-  ...more_processing_here...  tile.png

            This will only process the 600x400 pixel image extracted without reading in the whole larger image first.

            Speed concerns...

            Peter V <peter.v@pv2c.com> noted... In my experience is the approach of using "stream" for cutting 800MB PNM files the fastest compared to use of MPC files, or using "convert -crop".

            What formats work...

            Paul Heckbert (of image distortion fame) noted that the "stream" command works well for certain file formats (in particular, JPEG), but does not work well for other types like PSB, which may be interleaved.

            I believe it would depend on if the 'coder' for a particular file format provides support for line by line streams of pixels. This may be because the programmer that generated the file format 'coder' just did not get round to, or need 'streaming'. In this case some more work by a programmer familiar with that image file format maybe needed to complete the 'coder' module.

            Also a vector image file format like SVG or WMV, or an image that is pre-processed by some 'delegate', like digital camera image file formats, could not possibly be 'streamed' because, there are no actual rows of pixels in the image, only drawn objects (lines, polygons and gradient shades).

            JPEG images sections

            As per the IM forum discussion Extract a region of an huge jpeg you can use specialized JPEG programs such as the special "jpegtran" and "jpegcrop" developed by JPEG Club, can extract a regions from a JPEG image without actually decoding the data. That is a lossless crop of a JPEG to another JPEG image. For example..


              jpegtran -crop 100x100+0+0 -copy none huge.jpeg  crop.jpg

            However there an few cavats. The top-left starting point will be moved to the smaller 8 or 16 multiple, with an appropriate increase in the final image size. That is because JPEG images uses 'frequency encoded blocks' which are typically either 8x8 pixel or 16x16 pixels in size (determined by the JPEG sampling factor, 1 = 8 pixels, 2 = 16 pixels). These blocks need to be preserved if lossless copies are to be made.

            For a '+0+0' offset, it is already at an appropriate boundary, so the above should produce an exact 100x100 pixel crop. But for other offsets you will need to so some final cleanup of the extracted region. For example...


              jpegtran -crop 100x100+123+425 -copy none huge.jpeg  crop.jpg
              convert crop.jpg -gravity SouthEast -crop 100x100+0+0 +repage crop_fixed.png

            Processing Images in Tiles (PbmPlus)
            To process an massive image in tiles, without ever holding the whole image in memory is a much harder problem.

            Basically while you are breaking up an image you will need to either hold a whole row of images, or have multiple streams (one for each column of images) open, while the massive image is being broken up, or later being put back together.

            Most common technique is simply save the each image tile as separate image files on disk. In fact this is often the better way of storing ultra large images as programs can then just read the 'tiles' needed at any given moment for processing, producing a sort of 'disk based' random access image.

            This type of massive image storage, combined with a pyramid type multiple-resolution structure is actually how "google image maps" work.

            While IM does not have anything to break breakup (tile crop) massive images using a small amount of memory, the PbmPlus/NetPBM can do this.

            Pbmpus processing of a small section For example here I use PbmPlus tools to cut (crop) out a small section of the large image, process it, then compose that piece back into the original image.


              tifftopnm INPUT.tif input.pam

              pamcut     input.pam  part.pam
              # process smaller "part.pam" image here
              pamcomp -xoff= -yoff= - input.pam output.pam

              pamtotiff output.pam OUTPUT.tif

            The "tifftopnm" does a conversion to an image data stream, and performs a similar job to ImageMagick "stream" command.

            The "pamcut" is the equivalent of a Crop Operation, and will extract a smaller area from the input image. Instead of width or height. You can also specify right or bottom bounds of the crop. You could substitute a "stream" command with "convert

            The central part, can be processed using normal ImageMagick, or if you like pain, a chain PbmPlus equivalent tools.

            The "pamcomp" should overlay the modified part of the image back into the PbmPlus version of the original image.

            Other possible alternative to "pamcomp", is "pnmpaste", but this has not transparency handling, for pixel bleading.

            Note that by using composition with pieces it should be posible to distort small tiles and re-join them into a larger image afterwards.

            Pbmpus diced (tile crop) processing We may be able to use "pamdice" and "pamundice", or other alternatives to generate and merge smaller image tiles that can be processed individually, however this must save files into separate disk files (or named pipes) due to the 'multiple images per row tile problem'.

            An example script, "pam_diced_flip.pl" of doing this has been provided by bugbear, to 'flip' or 'rotate' (90 degree only) very large PbmPlus images using smaller tiles. Something that normally requires you to read the whole image into memory.

            Note that it does use a lot of temporary files, but it has a very small memory footprint.

            VIPS and NIP, a Massive Image TIFF handler
            Jenny Drake < jennydrake @ lineone.net > reports... You may also like to look at the non-IM alternative of "Vips" and "nip", developed by the National Portrait Gallery in London, which is designed to work on very large image files (generally TIFF) with low specification computers. "Vips" is the underlying engine and "nip" is the gui. Works on Linux, Windows and sometimes on Mac.

            Long Streams of Lots of Images, Video sequences
            Streams of images is another problem area. Here it isn't the size of the image that is of concern, but the shear number of images involved. So many you generally do not want to load them all into memory, or even save them individually to disk, as normal images.

            The biggest cultript of such images is of course, video handling, and animations

            The key to handling such images are the streaming image file formats where images can be simply concatanated together, one after another, into the one file stream. We touched on this briefly above in MIFF Image Streaming. Like ImageMagick's own MIFF format, the PbmPlus/NetPBM is also a streaming format (almost the same just simpler) but is much more well know and commonly used in video image stream processing.

            In a forum discussion, Reading Multiple Images, an user wanted to process a 'stream' of multiple PPM images, generated by a "ffmpeg" video processing program. Pbmplus images (like MIFF images, can be simply concatenated together to generate a multi-image stream.

            At this time IM does not allow you to just read one image from such a stream, process it, and then read another single image. All IM commands will always read the whole stream, and then close it. This is being fixed as part of IMv7 scripted processing.

            One solution is a small perl script, "process_ppm_pipeline", that will accept a stream of PPM images, and run a separate "convert" command on each image, as it arrives. The output is also a series of PPM images that produces a new stream of images.

            For example read a video, and 'flip' every frame, one by one...


              ffmpeg input.mpg -f image2pipe -vcodec ppm | pnmtopnm -plain |
                process_ppm_pipeline -flip |
                  ffmpeg -f image2pipe -vcodec jpeg output.mpg

            The "pnmtopnm -plain" is vital, as the script currently only handles a stream of ascii-PPM images, though with some more smarts it could also be made to handle any binary (raw) Pbmplus image stream, or even a MIFF image stream.

            Such a tool might be even used for processing a multiple streams (columns) of massively large images too. Though this may require a lot more in-depth knownlege in internal processing of the commands incolved. if a way can be found to sub-divide such images into a stream of tiles, and then re-construct the large image again at the end.

            Eventually I hope to include some mechanism by which you can ask a coder to read and return just one image from a multi-image file stream without closing that stream, so that another image can be read in again later. In this way Im can then process a stream of images, one image at a time.

            UPDATE: IMv7 can read one image at a time from a stream. With a loop, or using the pipelined commands, it should be posible to generate streaming image filters. More experimentation needed.
https://legacy.imagemagick.org/Usage/formats/
            Many of the image file formats have particularities which you need to keep in mind when using that format. This page deals with these special needs, and ways to improve results in those formats.

            A Brief Summary of Common Image File Formats
            For an introduction to reading and writing image formats see Image File Formats. While a list of all the ImageMagick file formats are given on the IM Image Formats Page.

            Here is a very quick summary of the most common 'normal' image file formats, as well as their general advantages and disadvantages...

            GIF
                This format is extremely common, and has been around for so long that all image handling programs understand it. But only uses a limited number of colors (a 256 color table) and only saves using 8 bit quality. However its built-in run-length encoding allows it to save images with only a few colors very efficiently.

                While the format has transparency, it only understands Boolean (on/off) transparency and so consequently suffers from 'aliasing' or 'jaggies'. Plain text with thin lines suffers badly when saved as a transparent GIF image. The only solution to this problem is to tie the GIF image to a specific background of the web page in which it is used.

                The GIF format can save multiple images to form an animation sequence, and for this purpose also saves the image canvas size and offset (page) information. Note however that negative offsets are not supported, and attempts to do so resets that offset to zero.

                Its best used for small images of cartoons, line drawings, and small icons, all of which have limited colors, and will allow it to compress well. Its use however should be avoided when a newer format like PNG is available.

            JPEG
                Does not handle transparency at all. The image is equivalent to using "+matte" operation to remove the alpha channel, so any background transparency commonly becomes black depending on the image processing used to generate the image.

                This format is also 'lossy', producing edge effects on sharp lines and borders and thus should not be used for any intermediate image processing, or storage of image originals (unless they were already in this format).

                It is well suited to long term storage of real life photographs, but avoid it if you plan to further process the image, or the image contains large areas of solid colors.

            PNG
                This format is intended to eventually replace older formats like GIF and TIFF. It is a modern format capable of handling 16 bit quality with four color channels allowing the full use of semi-transparent colors. It also includes a huge number of lossless image compression options.

                Its biggest disadvantage is that it is still relatively new, such that the Microsoft IE (v6) web browser does not automatically handle it correctly. However a fix is available for this problem.

                The format does not save canvas size information (where GIF does), but it does save the canvas offsets and even negative offsets (which GIF does not), though some web browsers have problems when a negative offset is used, so this is not recommended for a final image to be displayed in a browser.

                For saving intermediate 'layered' images, the ability to save negative offsets can be very important and is often much more important than its not saving canvas size information.

            MNG
                This is the multi-image format for PNG, and allows animations to movie quality levels and speed.

                A simple example of using MNG is wanted, so if you have one mail me.

                The MNG animation format appears to becomeing obsolete and has been abandoned by some web broswers such as FireFox.

            TIFF
                This is the Image interchange format that was developed to transfer high quality images between programs before any serious image formats were available. Unfortunately, because of this beginning, the format has been modified with a haphazard array of features and compression styles and no programs understands them all.

                The format is now pretty well only use by "Photoshop" on windows platforms, and this is the only source that provides any sort of standard reference for the TIFF image format.

                TIFF files can handle multiple images, though few applications other than IM handle multiple image TIFFs.

                Generally, unless the internal format of the TIFF image is kept relatively basic, there is no guarantee that a TIFF file generated by one program will be usable by another program, including IM or even "Photoshop" itself. As such I do not recommend this format period! I suggest you use some other format than TIFF (or JPEG), especially for long term storing of images.

                The few notes I have on this format and its problems are provided below in the Miscellaneous Formats, TIFF section. These usage notes were found in the IM mailing lists and forums, as I myself don't use or need to use TIFF.

            Video Formats
                Other movie quality animation formats generally based on using lossy compression to reduce the size (and quality) of the movie. Both formats are in a constant state of flux, improvements and security limiting features, making any form of processing difficult.

                At last count there was more than 200 video format 'codecs' that are in general use for one purpose or another.

                Because of this IM does not directly handle this format, instead it relies on other software packages, to handling the processing of the individual frames into and out of the animations. These 'delegate' programs include "mpeg2decode", "mpeg2encode", and "mplayer".

                See MPEG, M2V, and AVI below).

                Some system (like ubuntu) disable the use specific image file formats using a security policy. Type convert -list policy to see what policies and where they are set from are present on your system.

            GIF Image File Format
            The GIF format is a very widely known image file format, as it has been around for a very very very long time (from the late 1980's). It is often picked for images which are to be displayed on web pages that involve transparency or image animation. It is also about the only format absolutely universally understood by all web browsers.

            Unfortunately it is not a very good format for anything but line drawings, figures, diagrams, and cartoons. That is because it is limited to a maximum of 256 colors, one of which is usually flagged as being transparent.

            Flagging one specific color in the image as transparent has some drawbacks. If the color to use as transparent is badly chosen, it can result in other parts of the image being transparent when that was not intended. Care must be taken to ensure that does not happen.

            Further more, the transparency ability is 'Boolean', which basically means it is either fully on, or fully off. Semi-transparent colors are just not possible, and if present need to be made either transparent or opaque. That means the format can not provide any form of anti-aliasing of edges of an image, usually resulting in a bad case of the 'jaggies'. (See Anti-Aliasing)

            Because the "GIF" image formats color limitations causes so many problems, especially from a high quality image processing package like ImageMagick, I would like to say up front...

            Avoid GIF format, if at all possible.
            If you must use it, do so only as the final step.

            Finally for a long time the compression algorithm used by GIF was patented. Consequently it was not available for use by many image processing programs, such as ImageMagick. Thus very old IM programs will output GIF format images un-compressed, and thus using more disk space than it should. You can fix this using a GIF batch compression program such as "Gifsicle" or "InterGIF". However as the patent expired completely in mid-2004, the current release of IM has the GIF image compression re-enabled again.

            The image compression is also rather simple, and works best on images with large areas of solid, unchanging colors. Or on simple repeated patterns of the same set of colors, such as you get using Ordered Dithering (not the default dither in IM).

            Finally GIF images can save multiple images in the one file. And this is used to generate GIF Animations as understood by pretty well all web browsers, since the technique was first introduction by the very old "Netscape" browser.

            In Summary The GIF image file format with its limited color table, Boolean transparency, and simplistic compression (if enabled), makes it ideal for small images, such as thumbnails, and especially "cartoon-like" icons, logos, and symbols images with large areas of solid colors. Its animation abilities also make it an ideal method of generating flashy attention grabbing logos and advertisements you see all over the World Wide Web.

            For anything else its limitations make it a poor image file format and you may be better moving to JPEG, PNG, or a video image format for your needs.

            GIF Limited Color Table

            FUTURE: color reduction examples -- reference basic color dithering
            Ensuring that a specific color is present in the final GIF image
            Map color tables to color reduce.
            See Color Quantization.

            See Advanced 3-D Bullet Scripting for an example of generating multiple images over a range of colors. This technique can also be used to auto-convert your image into multiple images for many different backgrounds colors and patterns.

            GIF Transparency Color
            For example here we use identify to extract the transparent color, and the color table a particular GIF image file used to represent transparency. The perl script extracts just the specific fields of interest (which can be multi-line).
                


              identify -verbose hand_point.gif |\
                  perl -0777 -ne 's/^  //gm; \
                        print $& while /^(Colors|Alpha|Colormap):.*?(?=^\S)/gms'

                [IM Output]
            [IM Output]

            As you can see, a transparent grey color ('#CCCCCC00') was used for this image and this color has its own separate entry in the color table.

            You can also see that even though this image only uses 5 colors (one transparent), the color table used is for 8 colors. that is because the GIF file format can only use a color table that is a power of 2 in size. That is the color table is always 2, 4, 8, 16, 32, 64, 128 or 256 color entries in size.

            As such the last 3 color table entries are not used. Actually they are just not refered to. In some cases these unused entries may not be the last three entries in the color table, and could actually contain any color value. You can also actually have duplicate color values, though IM typically removes any such duplicate color entries if it processes the image in some way.

            As of IM version 6.2.9-2 (and in some older versions), IM will preserve the color table, and more specifically the transparent color value, whenever it reads, processes and writes a GIF image.
                


              convert hand_point.gif    -fill white -opaque wheat   hand_white.gif
              identify -verbose hand_white.gif |\
                  perl -0777 -ne 's/^  //gm; \
                        print $& while /^(Colors|Alpha|Colormap):.*?(?=^\S)/gms'

                [IM Output]
            [IM Output]

            As you can see even though the image was modified (all 'wheat' color pixels were replaced with a 'white' color) the transparent color used was preserved

            However if the final image has no transparency, the transparency color entry ('Alpha:') in the color table is completely removed.
                


              convert hand_point.gif   -background white -flatten    hand_flatten.gif
              identify -verbose hand_flatten.gif |\
                  perl -0777 -ne 's/^  //gm; \
                        print $& while /^(Colors|Alpha|Colormap):.*?(?=^\S)/gms'

                [IM Output]
            [IM Output]

            If you like to change the transparent color that the GIF file format is using, you can use the "-transparent-color" output setting (added IM v6.2.9-2). For example...
                


              convert hand_point.gif -transparent-color wheat  hand_wheat.gif
              identify -verbose hand_wheat.gif |\
                  perl -0777 -ne 's/^  //gm; \
                        print $& while /^(Colors|Alpha|Colormap):.*?(?=^\S)/gms'

                [IM Output]
            [IM Output]

            As you can see even though the result is not visibly different from the original, the transparent color was changed to a fully-transparent version of the 'wheat' color.

            If you look closely you will also see that the image now has two 'wheat' or '#F5DEB3' colors in its color table. That is, one transparent wheat and one opaque wheat. As of IM version 6.2.9-2, this presents no problem. Though only one transparent color can be defined by the GIF image file format.

            Why would you do that? Because some very old web browsers and graphic programs do not understand GIF transparency. So this option lets you set what color the transparent areas should be in that situation.

            Typical choices for the transparent color are 'white' for modern browsers, OR more typically 'grey75' ('#BFBFBF'), which was the original "mosaic" web browser page color. Other popular transparent color choices are 'grey' ('#BEBEBE'), and 'silver' ('#C0C0C0') which is what the 'hand' image above used. This shows just how popular that specific area of the gray-scale color range is for the transparent color.

            FUTURE: add link to color selection.

                Before IM v6.2.9-2, and the creation of the "-transparent-color" output setting, IM would typically save the transparency of an image as the special color 'none' (fully-transparent black), which is not particularly nice when transparency fails.

            Note that setting "-transparent-color" does NOT add any transparency to a GIF image, nor does it convert the specified color to become transparent. All the option does is specify what color should placed in the color table for the color index that is used representing the transparent colors in a GIF image.

            If you want to change a specific (exact) color to become transparent, then use the "-transparent" Color Replacement Operator.

            GIF Boolean Transparency
            Because the GIF format does NOT understand semi-transparent colors, and as ImageMagick by default generates semi-transparent color as part of its normal Anti-Aliasing Methods, when you save a image to this format it will often come out horrible looking.

            For example, here I draw a simple black circle on a transparent background. Also I will generate an enlarged view of the edge of the images, to make it clear what is happening.

            First I will output using the PNG format...


              convert -size 60x60 xc:none -fill white -stroke black \
                      -draw 'circle 30,30 5,20' circle.png
              convert circle.png -crop 10x10+40+3 +repage  -scale 600%  circle_mag.png

                [IM Output] [IM Output]

            As you can see the edge of the circle on the left drawn (in PNG format) as a very clean looking (though slightly fuzzy) edge to the image. You can see the semi-transparent pixels in its enlargement.

            Now lets output the same image using the "GIF" image format...


              convert -size 60x60 xc:none -fill white -stroke black \
                      -draw 'circle 30,30 5,20' circle.gif
              convert circle.gif -crop 10x10+40+3 +repage  -scale 600%  circle_mag.gif

                [IM Output] [IM Output]

            The result is that the circle has a very sharp stair case effects along the outside edge of the circle, while the inside remains properly anti-aliased.

            Basically while PNG format can save semi-transparency pixel information, GIF cannot. The GIF image format can only save a single pure transparent color. In other words...

            GIF format has an on/off or Boolean transparency

            If you look more closely at the resulting GIF, you will find that the semi-transparent pixels could have either become fully-transparent or full-opaque.

                What ImageMagick actually does with semi-transparent pixels depends on just what version of IM you are using. It was for a long time not properly defined and what a version did, often depended on the last 'bug fix' that was applied due to bug reports from users.

            As of v6.2.9-6 ImageMagick should by default threshold the image at a 50% level for both GIF and XPM image formats. This has become the accepted standard as used by image handlers, while still allowing you to set your own methods of dealing with the transparency problems of the GIF file format.

                Because of the GIF limitations, IM performs the following set of operations before saving to the GIF file format...

                -channel A -threshold 50%
                if (fully-)transparent pixels are present it then...
                  -quantize transparent -colors 255
                otherwise if no transparent pixels present...
                  -colors 256

            The -colors quantization process automatically does nothing if less that that many colors are present in the image. Nor will it do anything if the image has a valid colormap (as assigned by "+/-map").

            It also does not attempt to use a common color map for multi-image GIF files. As such if the colors are very different from one frame to the next, a local color table may be added to each individual image saved into the GIF file format.

            Also the settings used in the above are not permanent just temporary for the image being saved. That is if you used "-write image.gif" the settings used during the process do not effect later operations.

            You may like to do the thresholding yourself, and this is recommended if you are not certain of what version of IM (especially older versions) you are using.


              convert -size 60x60 xc:none -fill white -stroke black \
                      -draw 'circle 30,30 5,20' \
                      -channel A -threshold 50%  circle_threshold.gif
              convert circle_threshold.gif -crop 10x10+40+3 +repage \
                      -scale 600%   circle_threshold_mag.gif

                [IM Output] [IM Output]

            The above example performs the same "-threshold 50%" on the alpha channel that IM now does automatically, that is if a pixel is more than 50% transparent, it will be made fully-transparent (using the color given by the "-transparent-color" setting if defined.

            However you now have control of the threshold level as you like.

            Thresholding the alpha channel at 50% works well for most types of images. Especially those with a simple edge, but the technique breaks down rather badly, when you need to deal with large areas of semi-transparent pixels. This is what the most of the following examples for GIF handling will look at.

            For example suppose we want to save an image with a large fuzzy semi-transparent shadow such as this image (in PNG format)...


              convert -size 70x60 xc:none -font Candice -pointsize 50 \
                      -fill black -annotate +10+45 'A' -channel RGBA  -blur 0x5 \
                      -fill white -stroke black -draw "text 5,40 'A'"   a.png

                [IM Output]

            If you just convert this letter directly to GIF format or even use a "-threshold" operation to control the Boolean transparency, you will be sorely disappointed.


              convert a.png  a.gif
              convert a.png -channel A -threshold 75%   a_threshold.gif

                [IM Output] [IM Output]

            The first image is a normal save to GIF format, which as you can see thresholded the semi-transparent pixels at '50%', the second image was thresholded at '75%' allowing more semi-transparent pixels to become fully-opaque (or visible).

            If you just want to remove all the semi-transparent pixels (EG the shadow) you could try something like a "-threshold 15%", to remove just about all semi-transparent pixels.


              convert a.png -channel A -threshold 15%   a_no_shadow.gif

                [IM Output]

            Most other solutions to the GIF Boolean transparency problem is to inextricably tie the image to the background color of the web page on which it lives. Methods for doing this are complex and tricky, and this is what we will now look at.

            GIFs on a solid color background
            What we would really like to to somehow preserve the shading of the semi-transparent and anti-aliased pixels, and still display it nicely on the WWW. To do this we have to be a little tricky.

            The typical solution is to match the image to the background on which you are going to display the image on. This is simple to do, just overlay the image onto a background of the appropriate color, before you save it to the GIF format. This removes the need for any form of transparency and the whole thing becomes a non-issue. Of course the limited number of colors is still an issue, but often not a big problem.


              convert a.png -background LightSteelBlue -flatten  a_overlay.gif

                [IM Output]

            See just about perfect!

            Of course for this method to work correctly you need to know what exactly the background color the image will be used on. Also after we are finished the image will not be much good on any other background. A big sacrifice to make.

            GIFs on a background pattern
            But what if you are using some pattern for a background, instead of a simple solid color?

            You could try positioning the overlay onto a copy of the background pattern so that the pattern in the resulting image matches the pattern of the web page. However that would require a lot of trial and error to get the background in the image to match up with the web page. Also you could only guarantee it to work for a particular browser, and then only that specific version of the browser. Not a good idea for a web page, so don't even bother to try. I certainly won't.

            Instead of trying to do a perfect match-up with the background pattern, lets just overlay it onto a color that at least matches the background we intend to use.

            For example lets overlay our image onto a 'typical' bubble like background pattern. But first we need to know the average color of this background. A simple way to find this color is to just scale the image down to a single pixel, then read the resulting color.


              convert bg.gif -scale 1x1\! -depth 8 txt:-

               [IM Text]

            See IM Pixel Enumeration Text Format for more information on the special "txt:" output format used.

            Now lets set the background transparency of the image using "-flatten".


              convert a.png  -background '#BABBD7' -flatten  a_bg.gif

                    
            [IM Output]
            I have setup the web page to overlay our image on that background, even though that background is NOT part of the image itself.

            Though the background color used matched the general color of the background pattern, it still has a very obvious rectangle of solid color, devoid of the the background pattern, around it.

            One practical solution is to declare the color we overlay, as the "-transparent" color in the GIF output. By doing this we remove the 'squareness' of the image. Also adding a small fuzz factor improves the result and adjusts the amount of space the transparent color uses, in the same way threshold did above.


              convert a.png  -background '#B9BBD6' -flatten \
                      -fuzz 5%   -transparent '#B9BBD6'   a_bg_trans.gif

                    
            [IM Output]

            This is typically good enough to handle transparency in most GIF images, though it does tie the image to a specific background color.

            In essence we are using the transparency to set a basic outline shape to the image, rather than a true transparency. By using a color for the overlay and GIF transparency so that it matches the background pattern means it is no longer clear exactly where the image stops, and the background pattern starts.


            Be cautious however with the "-fuzz" setting, as too much and you can end up with more than just the outside of your image becoming transparent!


              convert a.png  -background '#B9BBD6' -flatten \
                      -fuzz 25%  -transparent '#B9BBD6'   a_bg_overfuzz.gif

                    
            [IM Output]

            It will also fail if you used a color close to the background colour within the image itself. As such this technique is not recommended for general images, but only in specific cases.

            To solve this problem we use a 'matte floodfill' to set the areas we want transparent.


              convert a.png  -background '#B9BBD6' -flatten \
                      -fuzz 25%  -draw 'fill none  matte 0,0 floodfill' a_bg_none.gif

                    
            [IM Output]

            Now as long as the borders of our image do not 'leak' we can use similar colors inside the image as our background, and not have them turn transparent on us, due to 'over fuzzing'.

            Of course if our image has 'holes' in it, then those holes will also have to be taken care of too. In which case the previous 'fuzzed transparency' may work better.

            Did say handling a GIF transparency color is easy! NOT!


            An alternative technique especially for images with a sharp anti-aliased edge is to simply add a minimum outline of the background color. See Outline or Halo Transparency.


            Remove the Background Color...

            Trying an remove a specific background color from an existing GIF image is not easy. It is especially difficult if the overlaid image also contains the background color, as you then don't really know what is background and what isn't.

            The best solution is to get a copy of the same GIF overlay on two different and well known background colors. With two such images, you can recover the original overlay and all its semi-transparent pixels perfectly. See Background Removal using Two Backgrounds.

            If you don't have two such images, then you can not perfectly recover the images semi-transparency, but there are techniques that can do a reasonable though imperfect job. For this see the other sections of Background Removal.


            GIFs for non-specific backgrounds (or Dithering the Transparency)

            FUTURE: This will move into a more generalise (non-GIF specific), alpha
            dithering section.

            The biggest problem with the above is that it would only work if you happened to know exactly what color the background, or background pattern your image will be used on. If you don't know all is not lost.

            As you saw above, threshold does not work well for an image with a very large area of transparency, such as a fuzzy shadow. But another technique known as dithering can, and does NOT require knowledge of the background it will be used on.

            Basically dithering limits the transparency to on/off values, creating an effect of semi-transparency over a larger area using a pattern if pixels. In other words it fakes semi-transparency.

            This method was exampled in what is now known as the "Opossum Examples". Unfortunately these examples did not actually give the commands that were used to generate the example. For completeness I will attempt to demo them again here.

            The "-monochrome" operator converts all colors in an image into a pure black and white "Floyd-Steinberg error correction dither". However as it converts a grey scale image into just pure back and white colors we will need to extract an alpha channel mask from the image, dither that, and return it back into the image.


              convert a.png \( +clone -fx a +matte -monochrome \) \
                      -compose CopyOpacity -composite   a_dither.gif

                [IM Output]

            In a similar way, there are a couple of other dither operators which can be limited to just the alpha channel using the "-channel" setting (unlike "-monochrome").


              convert a.png -channel A -ordered-dither   o2x2   a_ordered_2x2.gif
              convert a.png -channel A -ordered-dither   o3x3   a_ordered_3x3.gif
              convert a.png -channel A -ordered-dither   o4x4   a_ordered_4x4.gif

              convert a.png -channel A -ordered-dither  checks  a_halftone_2.gif
              convert a.png -channel A -ordered-dither  h4x4a   a_halftone_4.gif
              convert a.png -channel A -ordered-dither  h6x6a   a_halftone_6.gif
              convert a.png -channel A -ordered-dither  h8x8a   a_halftone_8.gif

              convert a.png -channel A -random-threshold  5x95% a_random_5x95.gif
              convert a.png -channel A -random-threshold  5x70% a_random_5x60.gif
              convert a.png -channel A -random-threshold 50x95% a_random_50x95.gif
              convert a.png -channel A -random-threshold 45x55% a_random_45x55.gif
              convert a.png -channel A -random-threshold 50x50% a_random_50x50.gif

            [IM Output] [IM Output] [IM Output]
            [IM Output] [IM Output] [IM Output] [IM Output]
            [IM Output] [IM Output] [IM Output] [IM Output] [IM Output]

            As you can see "-ordered-dither" produces a pattern of transparent and opaque colors to represent the overall transparency. This however produces a very noticeable regular pattern. However if you use a shadow color that is similar too but darker than the normal background then you can make this pattern almost completely invisible.

            The 'checks' pattern (first image on second line) is of particular interest as it is a very simple 3 level pattern that is very clean, and neat.

                The "-ordered-dither" was extended in IM v6.2.8-6 with 'half-tone' dither patterns. The operator was then completely revised for IM v6.3.0 with named dither patterns (use "-list threshold" to see the full list). You can even generate your own dithering pattern to generate other special effects. See Ordered Dithering Examples and the Ordered Dither Upgrade notes for more details.

            Before this redevelopment, arguments could only consist of the geometry strings '2x2', '3x3' and '4x4' (which will still work). However, anything else was then treated as being a "-random-threshold" argument, usually with disastrous results. Caution is required when using this option on very old versions of IM.

            The "-random-threshold" on the other hand produces a highly variable randomized dither that is different each time it is run. The purely random nature of the this dither algorithm however tends to produce large 'clumps' of pixels, rather than the smoother, algorithmic placed dithering generated by the "Floyd-Steinberg" "-monochrome" operator.

            The big advantage of "-random-threshold" however is the limit controls it provides. By making the parameters very restrictive (for example as '50x50%') you would convert -random-threshold" into a simple "-threshold" operator. By being only a little less restrictive you can randomize just the very edge of the threshold limit, (for example using '45x55%').

                The "-random-threshold" argument 'PxQ', where P is the min threshold and Q is the max (the '%' symbol is required). So "5x95%" says anything below is 5% of MaxRGB is set to 0, anything above 95% is set to MaxRGB otherwise we choose a random value between 5% and 95% of MaxRGB, as the threshold level to use for that pixel. an argument of "5x95%" value is probably the best value to use in most situations.

            You can improve the final look by using a darker mid-tone color (like a dark grey) instead of black for the shadow color. By doing this the color will tend to blur into the background more making the dither less pronounced that what is shown above.

            If you do know approximately what the background color is, you can even use a darker color of that shade to make the shadow bend in better without restricting yourself to the specific background shade. Sort of mix the two methods a little to improve the overall result.

            Basically The more work you put into what you want to do, the better the result will be.

            FUTURE: dither example with a dither color matching the light blue background
            of this web page.

            Non-ImageMagick GIF Processing
            giftrans 	Lists all the attributes and color table of GIF image. It can also set a specific color index as the transparent color without modifying the images color table ordering, or merging color indexes holding the same color (not a recommended situation).

            The IM "identify" command I have found to do a better job of listing image attributes, including the 'loop repeat limit' in the "Mosaic Application Extension" used in image animations.

            See also the "gif2anim" script (below), which previously used this program to extract the GIF image meta-data needed to re-create the GIF from the individual 'frames' extracted. It now only uses "identify", to extract this meta-data.

            GIFsicle 	This is a general-purpose image optimizer program, whose original purpose was to re-add compression to GIF images at a time when that algorithm was still under copyright.

            The program can also be used to add comments, create GIF animations and also optimise such animations in the same way that the IM "-deconstruct" operator does, though with further transparency optimizations such as LZW Compression Optimization.

            InterGIF 	A similar program to GIFsicle, designed for processing animated GIFs. However it only provides Transparency Compression Optimization. Other features however may be useful however. Mail me your views.

            gif2anim 	A shell script which takes a GIF animation file, and extracts all the individual frame images, as well as a ".anim" file containing all the IM "convert settings needed to rebuild the animation from the extracted frame images.

            anim2gif 	The reverse of the above script, which takes a ".anim" file containing all the IM "convert settings and rebuilding a GIF animation image.

            This script is very useful for studying, editing, adjusting and merging GIF animation files. For basic usage see Animation List Information. Also see Appending Animations (time synced) for a practical example of its use.

            GIF Image Offset handling
            While the GIF format saves images with offsets as part of its image animation handling, it will not save a negative offset. Any attempt to save a negative offset to a GIF image will result in the offset being reset to zero. This can be a real pain when designing GIF image animations.

            If Internet Explorer web browser is given an GIF image whose 'page offset' places the image somewhere outside the 'page canvas size', it will ignore the page size and offset and display it as if it has no such offset.

            The ancient Mozilla web browser on the other hand will just display the image canvas, and apply the offsets to the image. This can result in an empty canvas being display with no image data present, which while correct, can be unexpected.

            Both will display the image using the page canvas size, with the appropriate page offset if the image is wholly contained on that page canvas.

            Related GIF Output formats

            GIF87: Output the image in the older GIF 87a format.

                If the "Mozilla" web browser sees this older format it will completely ignore the page geometry of the image, and will not use a larger 'page' frame, or use image offsets with the image.

                IM version 6.0.4 and earlier would normally produce a GIF89a format. But if the image was a GIF animation, and was split up into separate images using +adjoin, Im would use the GIF87a, resulting in inconsistent results when displayed in web browsers.

                IM after v6.0.4 will always produce a GIF 89a image format file, unless the user specifically asks for the older "GIF87:" output format.

            JPEG Image File Format
            This format is about as common as the GIF format above. But where GIF is designed with small simple "cartoon-like" images in mind, JPEG is designed for large real life images with lots of different colors, and shades of colors, such as photographs.

            A key feature of the JPEG file format is its compression, which reduces image size while keeping the image acceptable to the human eye. This is a very complex process and beyond the scope of this discussion. For more information about this process and its effects see Jpeg Compression Introduction. And a great nitty-gritty explaination in the You Tube Video JPEG DCT, Discrete Cosine Transform (JPEG Pt2)- Computerphile

            Unfortunately, to compress images well, the algorithm intentionally loses information. What is saved is NOT the same image as what is in memory; the color of a particular pixel or area of an image will generally will NOT be exactly the same color that was saved. This is particularly true near the edges of objects within the image.

            So as a quick word of warning...
            IM is a general raster image processor, for modifying images.
            It will not do lossless JPEG modifications.
            If you are interesting in lossless handling, see Non-IM JPEG Handling.


            This lossy behaviour becomes even more noticable if a JPEG image is changed so that the amount of change to the top or left boundary is not a multiple of 8. When this happens the JPEG compression 'blocks' or 'cells' will be completely different, and that can produce a large increase in the final image save size.

            That is operations such as chop, trim, shave, border, frame, extent, etc.. (See Cutting and Bordering Operations that can shift the image data by a pixel offset that is not a 8.

            See the IM Forum discussion Cropping an image result in an unexpected increased file for more details.


            Normally this lossy nature of JPEG data is not very noticeable. However it can become noticeable when you either load and save a JPEG image multiple times or use a very low quality with a diagram showing sharp color changes.

            However as long as you don't load or re-use JPEG images over and over (preserve and apply operations from the original source), it is still a good file format even image types it is not particularly good at handling.

            As an example of this lossy JPEG nature, here I generate a simple image of two gradients appended together. While the gradients provide a smooth color change that JPEG handles very well, the sharp color change between the two gradients are not handled well.


              convert -size 5x10  gradient: gradient:blue-navy  +append jpg_lossy.gif
              convert jpg_lossy.gif                  jpg_lossy.jpg

            [IM Output] ==> [IM Output]

            The first image is a magnified view of the undistorted GIF format version of the image (click the image to see or downlaod the un-magnified view). It only contains 20 colors, so in this case the GIF format can handle the image perfectly and actually generate a very small file size (see table below). On the other hand the JPEG version of the image shows clear color distortions that the JPEG compression added to the saved image, to allow it to compress it better.

            The distortions are greatest in the blue color channel, which is not surprising as blue is not resolved well by the human eye. That is the human eye tends to 'spread out' blue colors naturally, so the JPEG algorithm takes advantage of this (by internally using a YCbCr colorspace). In fact without the magnification used above, you would be hard pressed to see the effect.

            Lets have a look at the effect of quality on the image.


              convert jpg_lossy.gif   -quality 100%  jpg_lossy_100.jpg
              convert jpg_lossy.gif   -quality  80%  jpg_lossy_80.jpg
              convert jpg_lossy.gif   -quality  50%  jpg_lossy_50.jpg
              convert jpg_lossy.gif   -quality  20%  jpg_lossy_20.jpg
              convert jpg_lossy.gif   -quality   5%  jpg_lossy_5.jpg

            [IM Output] ==> [IM Output] [IM Output] [IM Output] [IM Output] [IM Output]

            If you look closely at first image result in the above, which we saved the test image at '100%' or maximum quality, there is still some slight color distortion. It is very hard to see, but it is present.

            On the other hand using a progressively lower "-quality" setting for the JPEG image makes this color distortion even larger and more noticable. Not only that it sets up a sort of 'shadowing' of the edges producing 'waves' of color changes spreading out from the sharp edges. An effect commonly known as Ringing Artefacts.

            However the reason for using compression is that the size of the resulting image is very dramatically smaller, at least initially. Here is a file list of the results and their size in bytes.

            [IM Text]

            Note that the GIF image in this case is very small, as large 'blocks' of color compresses extremely well in GIF. As the JPEG quality gets lower, the size of the image also gets smaller. The default quality setting, when no JPEG quality is set, either by the user, or from the source image format file, is about 92%, which is a very high quality.

            However using a lower quality setting than '50%', image sizes do not get much smaller in terms of file size savings, only a much more progressively degraded image. It is a process of diminishing returns.

            In summary...
            JPEG losses information, degrading images when saved.
            Use some other format for intermediate images during processing.
            Only use JPEG format, for the final image, not for further processing.

            JPEG is also not good for artificial images with sharp color changes, such as line drawings, diagrams, or cartoon-like icons, text, and symbols. Such images with a low number of colors are better saved using a palette image format, such as GIF, or PNG8.

            A new JPEG image format, Jpeg2000, is becoming available which does allow lossless JPEG compression. However this requires the 'JasPer' library to also be installed. To use this special format, you also need to use a "-compress jpeg2000" option or save to a JP2 file format, so IM will call the right library.

            JPEG transparency - NOT
            Other than compression, the other major problem that JPEG users faces is that
            JPEG does not save transparency

            Thus while you can overlay images onto a background color or pattern and save to JPEG, you cannot give a JPEG image a free-form border or with see-through holes.

            As JPEG was designed to save real world images, and not parts of images, as such transparency was not an issue it was concerned about, when the format was created. Consequently the designers never worried about including an alpha channel, or other transparency information in the file format.

            For example let take the PNG with transparency we used above and convert it directly to JPEG.


              convert  a.png  a.jpg

            [IM Output] ==> [IM Output]

            As you can see all transparent parts just became black. But depending on the image source (especially GIF images) the transparent areas could have just as easily become some other random, or other inappropriate color.

            If this could be a problem the best idea is to have IM Remove Alpha Transparency, before saving the image to the JPEG image file format.

            JPEG Color Distortion (testing)
            As mentioned above, the compression algorithm JPEG used is lossy. That image will be modified to allow it to compress better, reducing file space, hopefully.

            Exactly how much color distortion occurs depends on the quality settings use. For example let us look at how many colors are in the IM built-in "netscape:" image...
                


              identify -format "Colors: %k" netscape:

                
            [IM Text]
            As you can see this image by default has 216 colors in a large rectangular array. This type of image is NOT a very good image for saving to JPEG format, which makes it ideal for our purposes.

            So lets look at the number of colors a JPEG image save of this image produces...
                


              convert netscape: JPG:- |\
                 identify -format "Colors: %k\nFile Size: %b" -

                
            [IM Text]
            That is, by default, the saved JPEG file has almost 9 times as many colors! Though the result would still look like the original image, the edges of the rectangular area will have had colors added to nearby.

            Saving at the highest quality setting will not save the image without any color distortion...
                


              convert netscape: -quality 100 JPG:- |\
                 identify -format "Colors: %k\nFile Size: %b" -

                
            [IM Text]

            As you can see a very high quality setting will only add a few extra colors but the image will still have a slight (minimal) color distorted. You can also see that the filesize is larger, as very little compression can be achieved.

            Now let us try "Lossless"...
                


              convert netscape: -quality 100 -compress Lossless JPG:- |\
                 identify -format "Colors: %k\nFile Size: %b" -

                
            [IM Text]

            Still a color distortion! Obviously my JPEG library is NOT patched for lossless encoding. However remember only another patched library can read such a lossless JPG image.

            Alternatively I recommend compiling your IM to use the JasPer library and the newer JP2 image file format.
                


              convert netscape: JP2:- |\
                 identify -format "Colors: %k\nFile Size: %b" -

                
            [IM Text]

            As you can see the Jpeg2000 format switched to other non-lossy methods of image compression, but does not color distort the image, by default. It also performs some very high compression methods on the image.

            However using a lower quality with the new JP2 format will again introduce the color distortions, so as to generate a smaller image, just like the normal JPEG image file format...
                


              convert netscape: -quality 50% JP2:- |\
                 identify -format "Colors: %k\nFile Size: %b" -

                
            [IM Text]

            For more information of using the JPEG2000 coder, see JPEG2000 encoding parameter documentation.

            Reading JPEG Control Options

                -define jpeg:size={width}x{height}
                    This setting is a hint to the JPEG image library to read just enough of the input (JPEG) image file to create an image that is at least the given size (width × height) or larger.

                    If the input image is huge, this can greatly reduce the amount of memory IM needs for the image read, since IM will then be handling a smaller image. This, in turn, can dramatically increase the speed of the complete operation.

                    Remember this is only a hint as the size of the image wanted, you are not guaranteed to get this size, just something close-to but larger than that size. Typically you will get something that is between this size and one twice that big, while preserving the images aspect ratio.

                    Usually after reading a JPEG image with a size hint, the image is then immediately resized to its final 'exact' size. Typically using "-thumbnail" to strip any image profiles, as well.

                    For example...


                        convert -define jpeg:size=64x64   jpeg_large.jpg jpeg_size_hint.jpg
                        convert -define jpeg:size=128x128 jpeg_large.jpg \
                                                       -thumbnail 64x64  jpeg_thumbnail.jpg

                        Before IM v6.5.6-0 this coder setting was extracted from the "-size" setting. This caused problems when users used "-size" for image creation but then had JPEG reading produce unexpected results. As such this was changed to be a special coder setting instead.

                    On older versions you may need to reset the "-size" setting using "+size before reading JPEG images, or IM may not real a JPEG image in full.

                    Note that this modifier causes the JPEG library to skip the reading of whole columns and rows of pixels. As such it will produce effects much like the Sampling Resize Operator, including its strong Aliasing Artefacts.

                    Because of this is it recommended that you specify at least double the final 'resize' of the image, to avoid this problem, just as shown in the above example.

                        Note that the Thumbnail Resize Operator also uses the same sampling technique for extrememly large-scale resizing operations to quickly reduce the size of the image before using a normal resize operation, though to 5 times rather than double the final image size. The difference in size is a matter of final image quality.

                +profile '*'
                -strip
                    JPEG images as saved by digital cameras, scanning software and other image processing software like "photoshop" will often add large profiles of "program comments" to JPEG images. Either of these options will remove those profiles from an image, after that image read in.

                    The "+profile" operator will remove all color profiles from an image, while "-strip" will remove all profiles and meta-data that the image may have.

                    Also note that "-thumbnail" is a "-resize" option that will also so a "-strip" at the same time. See also Creating Thumbnails.

                -type TrueColorMatte
                    As JPEG does not save any form of transparency, when it is read in it will always be fully-opaque, and have not 'alpha' or 'matte' channel in memory. This setting will force any JPEG image read in after the option to have a fully-opaque 'matte' channel to be added to the image in memory.

                    The better way to do this however is to use a "-matte" or "-alpha set", after reading the image, as it will have less impact on the reading and writing of other image formats.

                    See Image Type when Reading and Writing and Alpha Set for more information.

            Writing JPEG Control Options
            By default the "-quality" and "-sampling-factor" that was found when reading the JPEG image is used when writing back to a JPEG image. This however may not produce the same file size on the disk, and you will still always have a further loss of image quality due to reading and re-saving an JPEG image.

            The JPEG quantization tables are not however preserved.

                -quality {percent}
                    Probably the more important option when saving JPEG images, as this controls just how much the image is compressed when save it to disk. The value is not a size percentage, just a quality value. The lower the value the smaller the image and the more image information is lost, producing more artifacts, and degrading the image.

                        FUTURE: VERY low quality example of a photo

                    NOTE: a quality setting of '100%' is not guaranteed to save an image without any loss of quality, just a minimal amount of loss. (See the next option)

                    NOTE: You cannot determine a quality to get a specific file size, except through trial-and-error. Start with a "-quality" of 75% and check the resulting file size. If it is too large, reduce the quality by 10%; if too small, increase. After you have a lower and upper bound on quality, do a binary search to find a quality that best matches your desired file size. A total of five or six trials should be sufficient.

                -define jpeg:extent={size}
                    As of IM v6.5.8-2 you can specify a maximum output filesize for the JPEG image. The size is specified with a suffix. For example "400kb".

                    It works by generating many versions of the JPEG image, doing a binary search, of the output quality "-quality" setting, until it gets as close as possible to the file size given without exceeding it. It does this by writing the image repeatably into a temporary file and once it has the appropriate quality size, it then outputs the final image to the given output filename, once.

                    The output will thus still work fine when outputting the final image to a pipeline, or direct to network, and not just to a real file. However do not expect this process to be very fast due to I/O requirements. Perhaps 4 to 8 times slower.

                    Mail me your results if you actually do a timing comparison.

                -compress LossLess
                    While a "-quality" setting of '100%' can still produce slightly different colors (it is still 'lossy'), the "-compress LossLess" option will ask the JPEG library to save the image without any loss of data. As such re-reading the image will restore should be exactly as it was saved.

                    WARNING: This will only work if your JPEG library has been patched for 'LossLess JPEG' encoding, but the use of the JP2 file format has replaced this so this option rarely has any real effect anymore.

                    Also you MUST also set "-quality 100%" for this to work.

                    While intuitively you would think that saving with 'LossLess' will automatically mean using a 100% quality, this is not the case. This is the result of tacking on an unusual patch for the JPEG image writing, which is a lossy format by definition.

                    Of course the file generated will probably much be larger than a normal JPEG image. Also you will end up with a lossless compressed JPEG which you won't be able to read anywhere except with a similarly 'patched' JPEG library.

                    As such 'lossless JPEG' is NOT recommended and some other format (like PNG or JP2) should be used instead.

                -interlace Line
                    Use a 'Progressive JPEG' style that allows you to see large jpeg images while it is still being loaded. Also see the non-IM solution for re-encoding an existing JPEG without further loss, below.

                -sampling-factor {horizontal}x{vertical}
                    Adjust the sampling factor used by JPEG library for chroma down sampling. This can be set to '2x1' for creating MPEG-2 animation files.

                    "2x2, 1x1, 1x1" is IM's standard sub-sampling method and corresponds to 4:2:0, see Wikipedia, Chroma Sub-Sampling. However when "quality" is 90 or higher, the channels are not sub-sampled. Basically it will define whether the processing 'block' or 'cell' size is 8 pixels or 16 pixels.

                -density {Xdpi}x{Ydpi}
                    While density has no effect on the output pixel size of the the resulting image. The above setting however is stored in the JFIF header of the JPEG image file format. Unfortunately some programs like Photoshop will ignore this setting if a density is also present in a special photoshop specific profile ('8BIM') stored in the image.

                    Density is really only important when an output device is being used, such as printers or monitors, allowing these devices to display the image scaled to real world sizes. For example ensuring the photo or page you scanned is printed at the right size. For more information about density see and Image Density Meta-data and Resample Resizing.

                -type TrueColor
                    IM will automatically use a gray-scale internal format for images that only contain gray-scale values. This setting will override this behaviour and force IM to always produce a color JPEG image rather than gray-scale.

                    See Image Type when Reading and Writing for more information.

                -define jpeg:optimize-coding=false
                    Turn off the calculation of optimal Huffman coding tables for this image. This is on by default. It does require an extra pass over the image, to do the calculations needed, but this is minimal.

                -define jpeg:q-table={path}
                    Defines a file containing custom JPEG quantization tables, in XML. An example table is typically installed in "/etc/ImageMagick/quantization-table.xml" but is built-in to ImageMagick and thus not normally used.

                    A number of discussions about generating tables are to be found in the Digital Image Processing Forum, with specific discussions (at time or writing) at JPEG Quantization Tables, Better JPEG quantization tables?, Stupid PET Trick qtable of one, JPEG luma quantization table.

                    This option was added to IM v6.5.7-8.

            JPEG Quality vs File Size
            The final file size of a JPEG file for a given quality is indeterminate. The whole process of compression is so complex with small changes producing wildly different changes to the compression. Its a 'butterfly-effect'.

            Even the same source picture with the same quality, but with different versions of IM, JPEG library, or other image processing programs, you will get very wide differences in file size, and observed quality. You may as well treat the quality setting as simple 'guess' as to how much compression or visual quality should be applied to a specific image.

            In essence it is a practical impossibility to pre-determine the final file size for a given image and quality setting... Except by actually doing it.

            IM however can do 'test runs' to discover the best quality to use for a specific file size by using the special 'jpeg:extent' define. See JPEG Write Controls above. It is extremely slow, but faster than a similar DIY solution.

            Doing this is not recommended, and not just because it is slow.

            By your fixed file size method, a simple image might come out at quality 90%, but contain 50k of unnecessary data, where as a complicated image would have to drop to quality 30% and be exhibiting JPEG artifacts (or to put it less technically, it would look rubbish) due to a shortage of data for the detail present.

            The better idea is to find a single quality setting that produces an average file size of 100KB for a reasonable selection of your images. Even then images with not much detail in may come out at only 50k. While images with lots of intricate detail may come out at 150k, both will look acceptable.

            For a practical guide to the JPEG compression and quality, see Optimization of JPEG compression settings.

            Also see JPEG Compression, Quality and File Size for a look at the JPEG internal details.

            Photoshop Tip: Photoshop will add about 4 Kbytes of extra information to JPEG images to hold previews and color management info (profile '8BIM'). If you do not want that information, use the 'Save for Web' function. This tip was found in a paper on JPEG compression by Gernot Hoffmann.


            Related JPEG Output Formats

            PJEG: Write a Progressive load JPEG Image.
                This is not often used in these days of fast network downloads, but was very common when dial-up modems were the norm. Basically write every N lines first, then a line between them, and so on, so you can see an image even after only down downloading a small percentage of the complete image.

            JPEG2000: The latest JPEG format with new additions.
                This format requires the 'JasPer jp2' library to be installed or you get a error..
                "no encode delegate for this image format"

                This format uses wavelet compression to compress images instead of the standard JPEG DCT method. This gives you much better compression ratios for the same image quality. Thus reducing disk space even more.

                Unfortunately it hasn't been widely adopted yet, so you can't use it for external purposes, at least until web browsers and other image viewers and editors also start making use of the format.

                Any images saved with this format are only readable by users with this library, and it will probably be a long time before a good percentage of uses use this library. Particularly windows users as Microsoft will probably not include it unless enough people demand it.

                Quicktime Tip: Quicktime uses jp2 format but it must be output at "-depth 8". 

            Non-ImageMagick JPEG Processing (A quick summary)
            jpegtran 	Standard tool that is installed with the JPEG library. This allows you to apply various transforms to JPEG format images without decoding and re-encoding the image data, thus avoiding the JPEG data to become degraded. (see below)

            jpegtrans 	A newer version of the previous "jpegtran" program, though many of the added features (such as lossless cropping) has now been built into the distributed library version (above).

            jhead 	A more user-friendly lossless JPEG handler, especially with regards to the EXIF digital camera profile. That the handling of comments, date adjustments, thumbnail extraction, deletion or replacement, profile stripping, etc. It also attempts to ensure that other profiles are not trashed, which is something that "jpegtran" tends to do.

            There are also other similar programs such as "ExifTool", and "Exifer". Many JPEG to web photo-album programs also does this.

                The JPEG lossless rotation (which all the above provide) will only work correctly for images that have a size that is divisible by 8 or 16. This is true with most (but not all) digital camera photos. If you try this with an image that is an odd size the right or bottom edge blocks (containing the partial size) will not be positioned correctly in the final image, as these block can only exist on the right or bottom edge.

            For an example of this see this specific discussion

            As you can see most of these programs are designed to process JPEG image meta-data without re-processing the JPEG compressed image. (see next)

            Lossless JPEG Processing
            As decoding and re-encoding a JPEG image results in a degrading of image quality (unless lossless compression is used) the JPEG image library provides a number of special programs that can manipulate the image, without loss of quality.

            These commands will also be generally a lot faster than IM equivalents, as they do not have to do as much processing of the image.

            When modifying comments in JPEG images You can use the lower level JPEG library programs "rdjpgcom", "wrjpgcom" and "jpegtran". However I recommend you use "jhead" program, as it preserves any profile or other information that is also present in the image.

            The "jpegtran" allows you to go further and actually losslessly manipulate image data, including 90 degree rotation, cropping, and drop-in. It Even allows the creation of mixed quality JPEG images. For a demonstartion of this see JPEGhack page by Nemo Thorx. (See the notes below)

            However these commands are NOT recommended for general use, as they are limited to the block boundaries (8 or 16 bit) of the JPEG image. That is to say That is you can only crop, rotate, or drop-in at a JPEG compression cell level, not at the actual pixel level.

            Comments...

            If you are creating Montage Thumbnail Web Index Pages of your JPEG photos, and like to use the comments you add to the JPEG files, using the above programs, use a "-label '%c'" to tell montage to use the 'comment' field, before reading filename on the "montage" command line.

            You can also use that comment in a Complex Polaroid Transformation, or a Polaroid Montage or some type of image Annotation.

            The "jhead" program be used to add or modify comments in JPEG image files. However I found using the "edit comments" ("-ce") option to not a good way to do that as it adds an extra newline to the end of the comment. This extra newline stuffs up the use of commands ('%c' label formatting escape) in IM.

            The better way is to use "comment input" ("-ci") to feeding in a comment (without newlines at the end), or the "comment literal" ("-cl") options to be a much better way...


              jhead -cl 'Photo of some stuff, by Joe Citizen'  image_of_stuff.jpg

            Thumbnails...

            Brian Jackson <brian@brianjacksonphoto.com> also reports that most digital cameras (such as his is a Cannon 1D) embed a thumbnail somewhere between 12kb-25kb in size (160x120 pixels), in the JPEG image they produce.

            IM can extract these thumbnails using...


               convert  image.jpg   thumbnail:thumb.jpg

            However the program "jhead" can also extract these thumbnails too...


              mkdir thumbs
              jhead -st "thumbs/&i" *jpg

            This is super fast compared to IM as it does not edit the image, just transfer existing data. However the quality of the thumbnail is not nearly as good, as thumbnails IM can generate from the real image, and they also may not be rotated right, and they definitely will not be the size you want.

            Using ExifTool...

            From Rob, If you want more detailed editing of the profiles stored in JPEG image files, than what "jhead" provides, have a look at more EXIF-centric applications of the perl based, "ExifTool", an alternative compiled version "ExifTool", and a Windows GUI "Exifer", just to name a few.

            With the Image::ExifTool Perl module installed, this will strip out all JPEG metadata loslessly. I found the following to be equivalent to the command line method for stripping EXIF data. In case anyone is interested in the future:


              use Image::ExifTool;
              $exifTool = new  Image::ExifTool;
              $exifTool->SetNewValue('*');  # delete  all...
              $exifTool->WriteInfo('original_image.jpg','modified_image.jpg');
              $errorMessage = $exifTool->GetValue('Error');
              print  $errorMessage;  # (if has value an error occurred)

            Took some figuring because it turns out you needed to assign the setting first using SetNewValue then load and save simultaneously using WriteInfo.

            Mixed JPEG Quality Images, using JpegTrans...

            Wolfgang Hugemann wanted the edges of a JPEG image to not be compressed at all, as it stuffs up photo handling. See this site. The solution provided by Yuval Levy <imagemagick07_AT_sfina.com> solution was to use "jpegtran" to insert a low quality JPG, into a high quality JPEG...

                The solution:
                produce two versions of the same image with ImageMagick, one at the high quality 100 and the other at low quality 60 (for size reduction).
                use jpegtran to crop the q60, shaving off 8 pixels on each side
                use jpegtran to merge the q60 on top of the q100
                use jpegtran to merge to a stripe 

            Nemo Thorx <jpeghack@nemo.house.cx>, read the above and tried to implement Mixed JPEG quality. He succeeded and demonstrates the results on his Wiki pages at JPEGhack. Basically it is very posible to do lossless JPEG, processing such as 'cropping' and 'dropping' new sections of JPEG blocks into an existing image.

            PNG Image File Format
            This is one of the newest and most modern image formats, supporting 32 bit colors including alpha channel transparency, but can also be optimised to a GIF like 8 bit index color scheme (256 color limit).

            As such it makes an excellent intermediate format for image processing without loss of image information.

            PNG compression
            When used with PNG output, quality is regarded as two decimal figures. The first digit (tens) is the zlib compression level, 1-9. However if a setting of '0' is used you will get Huffman compression rather than 'zlib' compression, which is often better! Weird but true!

            The second digit is the PNG data encoding filtering (before it is comressed) type: 0 is none, 1 is "sub", 2 is "up", 3 is "average", 4 is "Paeth", and 5 is "adaptive". So for images with solid sequences of color a "none" filter (-quality 00) is typically better. For images of natural landscapes an "adaptive" filtering (-quality 05) is generally better.

                The PNG coder has been undergoing lots of work, and better methods of controlling the exact encoding and compression settings is typically set using the Define Operator.

            See Writing PNG Image Controls below for more details of the defines, or loot at the comments in the PNG coder file, "coder/png.c source code.

            If you have an ImageMagick image with binary (on/off) transparency, the PNG encoder will write it in an efficient manner, using the tRNS chunk instead of a full alpha channel. But if any opacity value other than 0 or MaxRGB is present, it'll write a PNG with an alpha channel. You can force this behavior by using the "-type TruecolorMatte" image reading setting, or you can save the image using the "PNG32:" format file.

            An external program "pngcrush" or the newer version "OptiPNG" will attempt to re-compress a specific PNG for the best possible compression available, and is recommended for images that you plan to place on a web site. Another program "pngnq" will color quantize it to a 256 color, 8bit PNG, though it is not known if this support semi-transparent colors in that format.

            Better PNG Compression
            One point about PNG images is that PNG image will preserve the color of fully-transparent pixels. That is even though you can not see it transparency has color, and PNG preserves that data.

            This means that in many cases PNG can be made to compress better by replacing that 'invisible color' with a static solid color, rather than garbage color that may be left over from previous image processing.

            There are two major methods you can use for this, using Alpha Background Operator to just handle fully-transparent pixels only, or using a Fuzz Factor with Transparency type operation to also map near-semi-transparent colors to fully-transparent-black.

            For example here I take the fuzzy shadowed "a.png" image we generated above and replace all pixels that are within 20% of full transparency.


              convert a.png  -fuzz 10% -transparent none  a_compress.png

            [IM Output]
            [IM Output] [IM Output]

            As you can see you get a substantial improvement in image size (around 50%). But with a sharp cut-off for the shadow of the image.

            Another alternative is to just make the shadow effect smaller, by adjusting transparency channel Levels.


              convert a.png  -channel A -level 20,100%,0.85 +channel \
                      -background black -alpha background a_compress2.png

            [IM Output]
            [IM Output] [IM Output]

            You can also improve the compression algorithm results, and thus the final size of your PNG image by using a smaller number of colors.


              convert image.jpg -thumbnail 200x90 -colors 256 \
                      -quality 90 -depth 8  thumbnail.png

            This however is only recommended for small thumbnail images that do not involve transparency, and only as a final step as it is a very 'lossy' technique.

            PNG, Web Browsers and Transparency
            The Microsoft Internet Explorer (IE version 6 and earlier) does not correctly display PNG when any sort of transparency is involved. Now while this is the most well known browser not to fully support PNG, it isn't the only one. The PNG transparency test and Another PNG test pages will let you test your browser. They also list the browsers and versions that produce the results displayed.

            However as IE (at least at time of writing) is probably the most common browser, you can add to your web page a number of work-arounds to the problem. For information on this look at my WWW Laboratory Page PNG with Transparency and IE, where I test and demonstrate the the "PNG in IE" solution I am using.

            Other solutions are to convert the PNG to either JPEG (with the right colored background), or GIF formats. These methods are discussed thoroughly for GIF Images on Backgrounds.

            Another solution is to set the color of all fully-transparent colors in a image before saving it to PNG. PNG will save that fully-transparent color, but be warned that just about any other IM operation will reset fully-transparent back to fully-transparent black (as transparent color is not suppose to matter at that is the way image mathematics work).

            For example the standard IM examples test image uses full transparent black for any pixel that is fully-transparent. We can verify this by either turning off the alpha channel, or saving it a JPEG...


              convert test.png test.jpg

                [IM Text]

            Now lets save this so that all the fully transparent colors was replace with fully-transparent 'silver' color (see the Alpha Background operator)...


              convert test.png   -background silver -alpha Background   test_silver.png

                [IM Text]

            Note that the image should still look correct if transparency (or the special JAVA script on the page) is working on your browser.

            But if we turn off the alpha channel (by saving to JPEG that does not allow alpha) we can see that the PNG image really does use a 'silver' color for the fully-transparent pixels.


              convert test_silver.png test_silver.jpg

                [IM Text]

            Note however that this does NOT modify semi-transparent pixels, and these will still have their normal (non-transparent) colors without mixing that color with either the page background, or the color used for fully-transparency.

            As semi-transparency is no longer involved, borders can look jagged (aliased), as well as 'halo' effects, along lighter colored edges. For example look at the edges of the black and white circles which show the 'jaggies' aliasing effects. However using a gray replacement color should make this not as bad as as the original 'black' color used for full transparency.

            The other advantage of setting the color of fully-transparent pixels, is an improvment in compression of data. Sometimes, the underlying colors in transparent areas used during processing were preserved. These in turn do not compress as well as a solid color. As such setting the fully-transparent color as we did above, can produce a good saving in the final file size.

            However this should be done as a final step as many IM image processing operations will replace any fully-transparent color that is present in an image back into fully-transparent black. See the Alpha Background operator for a list of operators known to do this.

            My preference is for PNG display problems, is for Microsoft to fix IE, and it seems that IE version 7 will finally have a fully working PNG transparency handling, in all situations.

            PNG and the Virtual Canvas
            While normally PNG will NOT save virtual canvas size information, it does save virtual canvas offset information, and if present, IM will try to generate a 'canvas size' that is appropriate for that offset and image size. This can be important to remember for some image operators such as "-crop", "-trim" and "-flatten", etc., which make use of the images canvas or page size as part of its operation or results.

            Of course you can use the "-page" setting and "-repage" operator, to set or remove the virtual canvas size and offset. (See Page Image Attribute). For example, the second IM "convert" sees the offset that is present in this PNG image, and defines a canvas that is large enough to ensure the image is visible within the virtual canvas bounds (Added to IM v6.1.7)...


              convert rose: -repage 0x0+40+30 png:- |\
                  convert - -background LightBlue -flatten  png_offset_flattened.jpg

                [IM Output]

            However, even though the PNG format will not normally save canvas size information, IM does add some virtual canvas size meta-data to PNG images. This data however will only be usable by IM commands, and is generally ignored by other PNG image format readers.

            For example the second "convert" command does see some virtual canvas size information...


              convert rose: -repage 100x100+10+10 png:- |\
                  convert - -background LightBlue -flatten  png_size_flattened.jpg

                [IM Output]

            If the PNG is processed by some non-IM program this canvas size meta-data will probably be lost. Remember canvas size information is not normally part of the PNG image file format.

            The other thing to note is that the 'offset' information can have a negative offset (unlike the GIF format), and IM will handle these appropriately, making the format good for storing intermediate Layer Images.

                Some web browsers do not handle negative offsets very well, producing odd results (one version of firefox had this problem). Best to avoid a negative offset in images that may be used by other programs like web browsers.

            PNG Resolution, Density and Units
            After some testing it seems the PNG image file format does not support a "-units" setting of 'PixelsPerInch', only 'undefined' and 'PixelsPerCentimeter'.

            Because of this IM converts a given density/unit setting into the appropriate values for 'PixelsPerCentimeter'.

            More to come on this subject.

            PNG Sub-Formats
            PNG: 	Default. Save image using economical format.
            PNG8: 	The PNG equivalent to GIF, including Boolean transparency and a 256 color table.
            PNG24: 	8 bit RGB channels without an alpha channel. Special case can include boolean transparency (see below)
            PNG32: 	Force a full RGBA image format with full semi-transparency.
            PNG48: 	16 bit RGB channels without alpha channel
            PNG64: 	16 bit RGBA image (including semi-transparency)
            PNG00: 	Inherit PNG color and bit depth from input image.

            For more information see Image Type I/O Setting.

                PNG8 was defined by PhotoShop, not the PNG group. And while it can handle multiple semi-transparent colors, as well as a fully-transparent color, IM assumes that it doesn't. This provides a way to force images to work properly with default be readable by Internet Explorer v6. The "Photoshop CS" program can read it.

                The PNG48, PNG64 and PNG00 styles were added as of IM v6.8.2-0

            You can force IM to create an image color index table (or palette) then IM will save that image using a "PNG8:" format...


              convert {input_image}  -type Palette  indexed.png

            To force the use of an single 8 bit greyscale channel, but not a palette indexed image use...


              convert {input_image}  -type GrayScale -depth 8  gray.png

            You can (added IM v6.3.5-9) also output greyscale with a transparency channel.


              convert {input_image}  -type GrayscaleMatte  gray_with_transparency.png

            And for a simple two color image...


              convert {input_image}  -type BiLevel  bitmap.png

            A special case exists for PNG24 images. If the image only contains boolean transparency, and all thge transparent colors are the same and that color is only used for transpareny, then the PNG coder will specify that specific color as being transparent. For example...


              convert a.png -channel A -threshold 75% +channel \
                      -background hotpink  -alpha background png24:a_png24_alpha.png

                [IM Output]

            This image does not have a pallette, but does have some on/off alpha.

            The -threshold of the alpha channel ensures only boolean (on/off) transparency is present, while the Alpha Background option ensures all fully transparent pixels is a specific color. The above does NOT ensure there is no opaque pixel with that color, so the above can still fail.

            Writing PNG Image Controls
            To better control the writing of PNG images, Glenn Randers-Pehrson revised a number of coder "Define Global Setting" controls, for IM v6.5.2. These include...

            -quality '{level}{filter}'
                The basic compression level and filter when saving a PNG image.

            -define png:compression-strategy=zs
            -define png:compression-level=zl
            -define png:compression-filter=fm
                Completely define the compression system to be used for the PNG image being written. The -quality setting will normally set the zl and fm values, but not the zs setting.

            -depth {depth}
                The general depth of the image to be generated, typically set to 8 or 16 bit.

            -define png:bit-depth={depth}
                Precisely specify the depth of the resulting PNG image file format. This overrides the normal IM "-depth" control, but only for writing PNG images, and only when the change can be made without loss. In the case of color-mapped images, this is the depth of the color-map indices, not of the color samples.

            -define png:color-type={type}
                Precisely specify the type of the PNG file being written. Values can be either
                '0' 	for Greyscale, which allows for 'bit-depths' of 2, 3, 4, 8 or 16.
                '2' 	for RGB, which allows for 'bit-depths' of 8 or 16.
                '3' 	for Indexed, which allows for 'bit-depths' of 1, 2, 4 or 8.
                '4' 	for Gray-Matte
                '6' 	for RGB-Matte

                Note that "-define png:color-type='2'" is specifically useful to force the image data to be stored as RGB values rather than sRGB values. However a similar effect can be achieved using "-set colorspace sRGB" on a linear RGB image. Howvever, do not expact that programs will honor this linear colorspace when reading. This includes ImageMagick.

            -profile PNG-chunk-{x}:{file}
                Add a raw PNG profile at location {x} from {file}. The first 4 bytes of {file} contains the chunk name, followed by a colon ':' character, and then the chunk data.

                The {x} can be 'b' to place profile before the PLTE, 'm' between the PLTE and IDAT, or a 'e' for after the IDAT. If you want to write multiple chunks of the same type, then add a short unique string after the {x} to prevent subsequent profiles from overwriting the preceding ones .

                For example..


                  -profile PNG-chunk-b01:file01 -profile PNG-chunk-b02:file02

            +set date:create
            +set date:modify
                These are image 'properities' which are created by ImageMagick whenever it reads a file. They contain (respectively) the image files create time (actually permission/owner/move change time) and last file modification time.

                Unfortunatally PNG image file formats like to write such image data with the PNG image file format, and if this data is different, then the file generated will also be different, even if nothing else has changed.

                 convert logo: logo.jpg convert logo.jpg
                    logo1.png

                  sleep 2; touch logo.jpg      # change the JPG file timestamp
                  convert logo.jpg logo2.png

                  diff -s logo1.png logo2.png
                  compare -metric RMSE logo1.png logo2.png null:

                The "diff' in the above will return the message
                "Binary files logo1.png and logo2.png differ"
                Even though the "compare" returned "0 (0)" which says the images have exactly the same image data.

                Note that as IM overwrites these properities with the times of the PNG file it just read, you can't see the actual values of these properities recorded in the PNG using "identify".

                The solution is to save PNG images without any 'time stamps'.


                  convert logo: logo.jpg
                  convert logo.jpg +set date:create +set date:modify logo1.png

                  sleep 2; touch logo.jpg
                  convert logo.jpg +set date:create +set date:modify logo2.png

                  diff -s logo1.png logo2.png

                This time "diff" reported...
                "Files logo1.png and logo2.png are identical"

                ASIDE: you can also use other UNIX programs such as "cmp", "md5sum", or "sha1sum" to compare binary image files. The latter two programs is not guranteed, but they are practically impossible to fool, and are faster for comparing more than two files (using the checksum)

                Thanks to some additions by GlennRP, the PNG developer you can now also use "-define png:exclude-chunk=date" to tell the PNG coder not to write date-related text chunks. 

            Non-ImageMagick PNG Processing
            There are quite a number of helper applications for PNG, that could be useful adjuncts for generating a final PNG image file.

            pngtrans 	PNG information stored with an image

            pngcrush 	Tries to find the best compression of a PNG by attempting to compress the image using all logical PNG compression available, before making a final choice, for each individual image. This of course can take some time on each image.

            OptiPNG 	A newer PNG compression optimizer.

            pngquant 	Lossy PNG optimizer, reducing a PNG image down to an 8 bit color palette with dithering. It will build indexed-color PNG's with alpha transparency colors conveyed in the tRNS chunk.

            pngnq 	A newer lossy PNG quantizer, to generate 8 bit color table PNG images. Also forces the use of a color palette.

            pngout 	A Windows platform PNG optimizer (with optional GUI) that uses a ZIP compressor that is optimized for space rather than speed (also on the page linked above).

            Most of these are to improve the final size of the image file, either using a lossy OR non-lossy techniques.

            Image Profiles
            Handling profiles photo quality images is important, However from what I can tell this is a very magical art, and not simple matter.

            Not all formats use profiles, but most modern formats do. This includes JPEG, PNG, TIFF, and (as of IM v6.3.4-1) GIF.

            If fact the problem is exacerbated by the fact that many programs do not even understand or look for color profiles in images. Alan Gibson, aka Snibgo, put together a summary of how various web browsers handle various Color Profiles, on his own Snibgo, ImageMagick Profiles page. This is worth a look.

            To list what profiles are present in an image use...


              identify -verbose image.tif | grep 'Profile-.*bytes'

            Common Profiles (and pointer to info I have on them) include...

                EXIF	Digital Camera Meta-Data
                ICC	Image Color Space Profile
                ICM	Microsoft Color Management (like ICC)
                IPTC	Image and Author Info
                8BIM	Photoshop Meta-data profile. Including data on: Clip Paths... What else?
                XMP	Adobe's Extensible Metadata Platform (XMP) (See adobe page)

            You can extract these common profiles using some special output formats that IM provides for this purpose. For example...


              convert -define jpeg:size=64x64  image.jpg  iptc:profile.iptc
              convert -define jpeg:size=64x64  image.jpg  xmp:profile.xmp

            The "-define" option in the above is used as a 'hint' to the JPEG library to reduce the amount of actual image data it reads into memory and then save a lot of processing of the data you don't actually intend to use.

            You can also insert or re-insert an arbitrary profile as a 'blob' or binary string containing whatever information you like.


              -profile 'profile_name:data_file'

            That is the file "data_file" is added 'as is' to the image as the profile profile_name. IM or any other application will ignore such profiles, unless it specifically knows about it.

            Color Profile Basics
            First a quick word...
            Color Management is for Wimps -- Don't Play with them
            Messing with profiles generally makes things worse
            So if the colors look good... Leave it alone.

            An user fhoech in the IM Forums, (who has since disappeared) has quite a number of times posted the following basic introduction in using color profiles to change the color space used by images...

            The RGB, sRGB and CMYK are not colorspaces, they are color systems (which IM controls using the "-colorspace" operator). There is no single RGB or CMYK colorspace, but a literally infinite amount of different colorspaces are possible in each color system.

            You need ICC (or ICM) profiles which accurately characterize the colors in your images. Normally, the ICC profile that describes an image should be embedded in the image itself, otherwise, you have to use a 'best guess' attempt which is only a workaround: Open the image in an ICC-capable image editor and assign different ICC profiles (do not convert!) until you find one that looks OK with your image (your monitor must be calibrated so you actually get a good preview of the colors). Then, save the image with the profile embedded.

            As to why you need two profiles: The source profile describes the colors in your image as they are now. The destination profile describes the colors in the output image after conversion.

            Also, you should take great care when converting to a given destination profile: If, for example, you use a profile that describes offset printing on uncoated stock but intend to use the images for printing on coated paper, you will of course not get any good results. The output profile needs to be an accurate representation of your intended output condition.

            When converting from a subtractive into an additive color-space (or visa-versa) without using the correct profile (for both steps of conversion) you won't get 'correct' colors or brightness in most cases, although you may be lucky and hit the mark 'by accident'.

            You can download color profiles from International Color Consortium.

            Changing Colorspace via Profiles
            While you can just simple convert color spaces directly like this...


              convert cmyk_image.jpg -colorspace rgb rgb_image.jpg

            The best solution for converting CMYK to RGB JPEG is to use color profiles with the "-profile" operator.

            Raf Lenaerts pointed out the following rules in using the "-profile" operator within ImageMagick...

                If there is no embedded profile then the first "-profile" is the input profile. A second "-profile" then defines the output profile.

                If there is an embedded profile then a single of "-profile" operator will immediately define the output profile.

            In summary...

                The "-profile" must be placed between the input and output file.
                This is actually standard IM Command Line Processing Practice.
                Use "+profile" with 'icm' to remove any icc-profile present.
                The first "-profile" then given, is the input profile.
                The second "-profile" given, is the output profile. 

            As such to use profiles for ALL images, you will need three "-profile" operations: remove, input, and output profile options.

            For Example, If the input image already has a color profile then only one is needed.


              convert rgb_image.jpg -profile USCoat.icm cmyk_image.jpg

            But if the image doesn't (or you know it is a RGB image, without an existing profile), you can use...


                convert rgb_image.jpg +profile icm \
                        -profile sRGB.icc  -profile USCoat.icm cmyk_image.jpg

            This sets the resulting image to a CMYK USCoat.icm profile. Another CMYK profile is the SWOP.icm profile.

            For the reverse (image already has a profile) use...


                convert cmyk_image.jpg -profile sRGB.icc rgb_image.jpg

            WARNING:

            If the original image already contains a profile, for example a CMYK profile, then given two profile conversions is a bad idea.

            For example


                convert cmyk_image.jpg -profile "CMYK.icc" -profile "RGB.icc" \
                              output_image.jpg

            Will result in a CMYK -> CMYK -> RGB conversion. But as CMYK is not symmetric, the the extra conversion step can result in a disastrous color conversion. (See the IM Forum discussion Question on ICC profile conversion behaviour)


            Color Profile Modification
            The images you want to convert should all have ICC profiles embedded. As such to convert your images with same a CMYK ICC profile...


              convert rgb_image.jpg -profile CMYK_PROFILE cmyk_image.jpg

            This will convert using perceptive intent, the default (see Color Space Conversion for an detailed explanation on rendering intents). Because the results via perceptive intent can differ greatly depending on the software that was used to create the ICC profiles, you can use "-black-point-compensation" along with "-intent relative" to get a result that is somewhat nearer to what one might expect.


              convert rgb_image.jpg  -intent relative -black-point-compensation \
                      -profile CMYK_PROFILE     cmyk_image.jpg

                Both "-black-point-compensation" and "-intent" settings need to be specified before the "-profile" operation for it to be effective.

                The "-black-point-compensation" option was added to IM v6.2.7-0.

            You can download color profiles from International Color Consortium.

            EXIF InterColorProfile
            On top of the above Color Profile handling, many Digital Cameras, save color profile information in the EXIF profile attribute 'InterColorProfile'. This attribute is meant to be "assumed in the event of no colour profile being embedded", according to the document, "Colour Management and Adobe PhotoShop 7".

            IPTC Profiles
            The IPTC profile is used in images to store identification attributes of the image, such as caption, credit, author, keywords, etc.

            If you want to add an IPTC profile to an image, you need a single -profile:


              convert image.jpg -profile iptc iptc_image.jpg

            If an image contains a profile you can save it with this, so you can add that profile to other similar images:


              convert iptc_image.jpg iptcData.iptc

            Or you can extract a text version of the profile that you can edit


                convert iptc_image.jpg IPTCTEXT:iptcData.pro

            Here for example is a profile contributed by fcaserio in the IM Forums.
            [IM Text]

            You can add this profile to an image using


              convert image.jpg +profile 8BIM -profile 8BIMTEXT:iptcData.pro \
                      iptc_image.jpg

            That image can be converted into an EPS (Encapsulated Postscript) with a TIFF preview (EPT), that also contains the IPTC profile. (Thanks Tee Tanne).


              convert itpc_image.jpg  EPT:image.eps

            XMP Profiles
            Extract a XMP profile from a TIF image...


              convert picture.tif metadata.xmp

            A word about Vector Image formats
            Their is more than one style of image storage in the world...
            Raster 	Images which are stored and processed using arrays of colored pixels. Raster image formats include GIF, PNG, JPEG, TIFF, and so on. Images can consist of multiple arrays (channels) representing different colors, and can have multiple images, layers, or frames (depending on usage) in the one image file format file.

            Vector 	Images are defined in terms of lines, thicknesses, tiles, gradients, and larger compound objects. Formats include SVG, Postscript, PDF, FIG, DXF, WMF, and even TTF fonts. It allows images to be resized, and even greatly enlarged without loss of quality. Also while editing such formats, you can generally move whole objects around without destroying what is underneath (object layering).

            Fractal 	Images are a special rare case, used to achieve extreme compression of complex images, such as old paintings. However the only usage I know about is in a very expensive commercial product. Outside that usage it is also used for complex mathematical objects such as Mandelbrot and Julia sets, and in generating randomized splashes of color in screen savers (IFS). It is very rarely seen.

            Why is this important? Because IM is a 'raster image processor', and while it can read or write images stored in one of the vector formats it does so by converting the image to and from an internal raster image.

            Consequently if you are trying to convert an image from a vector format, to another vector format, IM will essentially rasterize this image at the currently defined resolution or density which will hopefully (but unlikely) be suitable for the output device you intend to use it on.

            In other words, any output from IM will never be a true vector format. While it can convert its internal raster format into a vector format file, the result is only a superficial vector image wrapper around an image in raster format. And unless the raster image is defined properly (at the right resolution) for the output device, the result will not be particularly good.

            Unfortunately new uses to IM do not know anything about this. They see IM as a converter that can convert say PDF to Postscript, producing images with 'blocky' aliasing effects, 'washed out' colors, or blurry images that just do not look good at all, on the intended output device.

            Which brings use to what I am trying to say...

            Avoid using ImageMagick for 'Vector Image' to 'Vector Image' conversions
            EG: converting between formats like: PDF, PS, SVG

            In other words, use the right tool for the right job. And for this situation, ImageMagick is not the right tool.
            That is not to say IM can't be used to do such a conversion. After all most printers and monitors actually rasterize the image themselves for the actual printing onto a sheet of paper. The difference is that the printer knows what resolution it needs for the hardware it is using. ImageMagick does not.

            For examples of converting vector images to rasters (and improving such conversions), see the example Postscript/PDF pre-formatted Text and Graphics Input, and for SVG and user generated vector images see SVG Image Handling.

            You may also find the information on Font Size, Resolution and Pointsize useful, particularly with regard to the effect of "-density" on drawn text fonts.

            Non-IM Alternatives
            If you really do need to do general conversion between vector formats, the program UniConvertor, Sk1 Project (usually available as a standard linux package) and the VectorSection can be used to convert vector-to-vector without actually rasterizing the images.

            For general conversion of Postscript to other vector formats, look at "pstoedit", which is typically available in your systems extra package repositories. Also look at "epstopdf" which is part of the Comprehensive TeX Network (CTAN). TeX and LaTeX are UNIX documentation (book and scientific article) text processing system. It has lots of tools to do with Postscript and PDF formats.

            For SVG to PDF conversion, Wolfgang Hugemann <Auto@hugemann.de> suggests that the easiest vector to vector conversion was to display the SVG in a browser (Firefox) and the print it using a PDF printer driver. Though the "Uniconvertor" could be used too.

            Other Image File Formats
            There are of course a huge number of other image file formats that IM can use and understand, however using many of these less 'common' formats are specialized for some specific purpose, and often require some tweaking or other options to get them to perform the way you want them to perform.

            I do not recommend these file formats, and generally I myself don't used them. However I do try to log various notes, techniques, and options that have been reported on the IM mail list, or IM forum, so others may also use the information gleaned.

            Many of the notes are in a raw, unprocessed form, and I am willing to accept further contributions, ore re-writes to the notes below.

            Postscript (PS, EPS) and Adobe PDF
            For basic handling see Postscript Text Handling and the warning about Vector Image formats.

            The major problem with Postscript and its related formats (like PDF) is that it is a complex page formatting language. That is the format is a program and not really an image format! That means IM is forced to rely on another external program (or delegate) to 'run' the program and return the generated image.

            Encapsulated Postscript (EPS)
            Encapsulated Postscript is actually exactly the same as normal postscript (a vector image format) except it is a single page image, and a "Bounding Box' entry is present to define the exact area the image covers.

            The format was designed to to allow other programs to move and scale the image when inserting the postscript it defines into other postscript documents.

            IM handles it in basically the same way as postscript. (See above).

              convert image.jpg -compress none eps2:image.eps

            Use "EPS2:" or "EPS3:" to create JPEG compressed EPS files: Note: Adding profiles to EPS images are on the 'to do' list but is currently not supported.

            Postscript/PDF Input
            As this format is a vector image format it is effected by settings such as "-page", and "-density".

            Examples of reading Postscript (which is the same for EPS and PDF format) are provided in Postscript Formatted Text, and you should read this first.

            However the reading of these formats is very complicated, as they are full computer languages designed specifically to generate a printed page on high quality laser printers. This is well beyond the scope of ImageMagick, and so it relies on a specialized delegate program known as "ghostscript" to read, and convert Postscript and PDF pages to a raster image.

            One point. As IM uses Ghostscript to rasterize a postscript file at a specific resolution, any raster images that are in the postscript file will often be blurred, or distorted, unless the exact density for that raster image is known. This also assumes that the postscript program itself does not rotate or otherwise manipulate the raster image.

            In fact, multiple delegates are present and selected by IM depending on the situation. For example the 'ps:color' (using the 'bmpsep8' ghostscript device) verses 'ps:alpha' (using 'pngalpha') is selected depending on if "-channel RGBA" had been set or not.

            The 'ps:color' delegate is used rather than 'ps:alpha' by default because the 'pngalpha' ghostscript device only supports an one page/one image and PDF's generally are multi-page. Use "-channel RGBA" before reading the image to select the 'pngalpha' delegate method.

            If all you want is the number of pages, using ghostscript can be a lot faster.


              gs -q -sPDFname=document.pdf   pdfpagecount.ps
              %%Pages: 96

            Windows and Ghostscript is a little more complex, as it requires the use of the windows registery.

            Special ImageMagick PDF Reading options
            Special options for PDF handling...

            -units PixelsPerInch
                Should be set when handling PDF documents (reading or creation of). I am not sure what this does but reports indicate it should be set for correct working.

            -define pdf:use-cropbox=true
                Use a 'cropbox rather than the default 'mediabox' as per Adobe generated PDF files. (Basically adds a "-dUseCropBox" to the ghostscript conversion from PDF images.

                NOTE: This works if your PDF only has one page, but if it is a multiple paged PDF, it won't crop correctly.

            -define pdf:use-trimbox=true
                Use a 'trimbox rather than the default 'mediabox' as per Adobe generated PDF files.

            Modifying the Input Delegate
            Modifying the system delegate is dangerous and a mistake could render IM unable to read postscript/PDF files. You also may need administration privileges, as you cannot replace a system defined delegate with a personal delegate, due to security ('hacker') measures.

            See Delegates and Coders for Image Formats for more info on the delegate XML syntax and meaning, and creating personal input/output delegates.

            On the forum topic Convert EPS to JPG Unreliable, it was suggested that you edit your system "delegates.xml" and replace "-sDEVICE=bmpsep8" to "-sDEVICE=bmp16". Other users have found that changing this to "-sDEVICE=pnmraw", also works better. I have not tried this myself, so can provide no guarantees about this, or what versions of Ghostscript this applies to. If you have any further info, please let me know.

            If you have a CMYK postscript or PDF file then the page Blog of John details how you can modify the delegate entry (Add a "-dUseCIEColor" ghostscript option) so ghostscript convert handles this this of postscript.

            Another possibility is to create a personal "Delegate which would invoke pdftoppm. Say the tag is called "pdfalt" which invokes the program "pdftoppm" or even "pdfimage" from the "xpdf" package.

            Then your stream would look something like this:


              convert pdfalt:image.pdf image.png

            Anyone like to give the delegate creation a go? Let us know!

            You may also like to try using "pstoedit" which can convert a postscript file to other vector formats, or passes the postscript into the ImageMagick API, to convert it to bitmap. I have not experiment or tested this, and would like some feedback.

            PDF Raster Image Extraction
            The rendering of any PDF pages to a specific size or 'density' is at the heart of the vector graphics using by PDF. It works great for text, or line drawings. But this also means that any raster image (pixel array) within the PDF has to be resized. But resizing is a 'lossy' operation, resulting in some image degrading, unless you use the original density of that raster image, which can vary from image to image within the PDF!

            It is thus advantageous to be able to extract the raster images from a PDF without any 'density' reference.

            You can extract the raster images directly using "pdfimages" program, which is part of either the poppler-utils or the "xpdf-utils software packages. These software packages also contain many other tools that you can find useful for PDF processing. See Poppler for Windows and Xpdf Reader.

            You may also like to look at the "mutool" from the package "MuPDF" by the same people that look after GhostScript.

            An online tool to extract text and images is Sumnotes (commercial with limited free trial).

            At a lower level Wolfgang Hugemann says you can extract any image contained by a PDF (especially from PDF's generated by scanners). Basically by extracting any byte sequence between "stream" and "endstream", and saving as a separate file.

            PDF Text Extraction
            You can use the GhostScript program "ps2ascii" or "pstotext".

            Or as an alternative that does both text and images, have a look at "pdftohtml" has an XML output that Ross Presser reports is "pretty good at reassembling paragraphs.".

            Also the "pdftk" program can 'uncompress' a PDF so it can be edited directly, and to 'repair' corrupt PDF's.

            Postscript/PDF Output Options
            The following settings are known to effect the output of Postscript, Encapsulated Postscript, and PDF image formats: "-page", "-gravity", "-compress", "-density",

            By default no compression is used on PDF image output, so PDF files can often be a lot bigger than necessary. The following table equated the IM compression modes with the resulting Postscript compression mode used.

            PS/PDF Compression Meanings
            Compression 	image '/Filter [ ... ]' setting
            "-compress none" 	'/ASCII85Decode'
            "-compress zip" 	'/FlateDecode'
            "-compress jpeg" 	'/DCTDecode'
            "-compress lzw" 	'/LZWDecode'
            "-alpha off -monochrome -compress fax"  	'/CCITTFaxDecode'
            "+compress"
            "-compress rle"
                any thing else 	'/RunLengthDecode'

            Recommended compressions for PDF is Zip (Deflate Compression) or Group4 (Fax) compression.


              convert image.gif -alpha off -monochrome -compress Zip -quality 100 \
                      -units PixelsPerInch -density 600  image_deflate.pdf

              convert image.gif -alpha off -monochrome -compress Group4 -quality 100 \
                      -units PixelsPerInch -density 600  image_group4.pdf

            These two commands produce much smaller PDF files than a direct conversion, of a black an white page. However which is smaller depends on the image and is impossible to determine without trying and testing the resulting size.

            Postscript/PDF Output Alternatives
            Remember that PDF is a vector image (document) format, and IM is a raster image processor. This means that any PDF document IM creates will basically consist of a single raster image per page.

            The images output in the PDF document will be fixed at a specific resolution (or pixel density), which can cause pixel distortion issues when viewed or printed at some other resolution. Also for text documents, using a raster image is wasteful, as plain text with fonts and formatting meta-data will always be a lot smaller and render better than a scanned raster image of the text.

            Because of this, other PDF creation programs may be better suited to your needs. This will let you keep images as images, and text and text, allowing you position the text and images together in a nicer more logical way, as well as insert text, and overlay arrows or connecting lines, in a more logical fashion.

            For example I suggest you look at the support programs provided by the TeX and LaTeX system. See Comprehensive TeX Network (CTAN).

            Another tool set is Multivalent Document Tools.

            Of course such programs are harder to automate, however I have in the past use the simple FIG vector graphic file format (see Xfig) to generate Postscript and PDF documents with text and graphics placed in an automatic way.

            Image to PDF convertors...

            The tool sam2p which is specialized in converting images to PDF files. So does all the preprocessing with ImageMagick and then making the final conversation using "sam2p". It even brings a small script to adjust the result to an A4 paper.

            From sam2p README:
            Q58) 	Can sam2p generate a PDF which is scaled proportionally (i.e. keeping the aspect ratio) to a specified page size, and centered on the page?
            A58) 	No, but the Perl script sam2p_pdf_scale.pl bundled with sam2p can post-process the file created by sam2p. For example, to scale and center a PDF on an A4 paper, do:

            ----8<----
            sam2p input.img output.pdf
            sam2p_pdf_scale.pl 595 842 output.pdf
            ----8<----

            Unfortunately it doesn't work with default PDFs created by IM.

            -- Sebastian Krause, from the IM Users Mailing List

            Multi-paged PDF Documents...

            You can use perl to combine multiple PDF files, without resorting to an IM, and its rasterization problem...

                ----8<----
                #!/usr/bin/perl
                #  Script   pdf-combiner.pl
                use strict;
                use warnings;
                use PDF::Reuse;

                prFile('combo.pdf'); # Output.
                for (qw/a b c d/) # Inputs.
                {
                  prImage("result_$_.pdf");
                  prPage();
                }
                prEnd();
                ----8<----

            You can also use a JAVA toolkit to merge IM generated images into a PDF producing a better PDF than a simpler one that IM will generate...

                ----8<----
                #!/bin/bash

                for x in ./*.jpeg
                do
                    echo $x to ${x}.pdf
                    convert $x -quality 75 ${x}.pdf
                done

                echo Merging...
                java tool.pdf.Merge *.pdf
                ----8<----

            Another user on IM Discussion Forums also suggested using PDFjam to merge multiple PDF pages together.

            PbmPlus / NetPBM Image File Format: PBM PGM PPM PNM PAM
            The PbmPlus or "NetPBM" image manipulation filters (unix command line).

            These image formats come in a variety of styles "PBM" (bitmap), "PGM" (grayscale), "PPM" (color), "PFM" (floating point, for HDRI), "PAM" (arbitrary format), and "PNM" (any NetPBM format). Each of these (except "PAM" and "PFM") can also be either in a 'raw' binary form (the default when writing by either IM or NetPBM) , or as plain ASCII text format, (set using "-compress None"). IM can of course read any of them.

            The format should be regarded as using "linear-RGB" colorspace only, and NOT using "sRGB" as most other image file formats. However a depth of 16 should be used when using "linear-RGB" so caution is recommended to avoid heavy round off errors with depth 8 images.

            The NetPBM formats typically saves one image per file. However IM, and many other NetPBM utilities will read and write files with multiple images simply concatinated together. As such when writing images it may be a good idea to set the appropriate "-/+adjoin" setting when writing files. (See Writing Multiple Image Sequences for details).

            The PPM file format is actually especially important to ImageMagick as it is the communication format used during the conversion of Postscript and PDF images via the "ghostscript" delegate. It is also a major format for video image processing such as from the "ffmpeg" command.

            Any 'quality' or value range can be used on input (up to 16 bit or 65535 'depth'). For example here is a highly unusual value range of 5, to generate a 'step gradient'. I know of no other image format that allows you to use such an odd-ball quality range.


              echo "P2 6 1 5   0 1 2 3 4 5" | \
                  convert - -scale 120x20  pgm_step_gradient.gif

                [IM Output]

            Also look at Resized Gradients were NetPBM text images are used to create very small (2 to 4 pixel) images.

            The above also demonstrates just how useful the 'ASCII' sub-formats can be. Espectally as a way of added images into shell scripts, or as a means of generating images from an array of numbers. For example see TXT: Enumerated Pixel Format.

            One example of this usage is shown in the Histogram Redistribution Methodology examples.

            PbmPlus/NetPBM vs ASCII Data Format
            Its ASCII output is probably the cleanest method of extracting the color values from a specific image, which again makes it idealy suitable for script and simple image processing.


              convert -size 20x2 xc: +noise random -channel G -separate +channel \
                      -depth 16  -compress none   pgm_random_values.pgm

            [IM Text]

            Note that when the output is plain text, and lines are not written so as to line up with the images row length. But you can re-format the output using the various UNIX text utilities. For example you can use the "tr" text utility to replace and compress multiple commas and spaces to single newline, will place all values one value per line, making it easier for a script to process.

            Also with IM you can only specify 'depth' of 8 or 16 for the output quality for PGM and PPM. While the PbmPlus formats allows the use of any 'maxval' for its values, even one that is not a power of two! It does have a hard limit of 16 bit depth (maxval 65535). A finer control of the actual 'maxval' of the NetPBM image is currently not possible, though could be added via a special coder setting in the future. (if requested).

            Here is another example outputing a 9x9 array of grayscale values from 0 to 255, extracted from the rose built-in image. I used "pnmtopnm -plain" so we get a newline at the end of each pixel row.


              convert rose:[9x9+0+0] -colorspace gray -transpose -depth 8 PGM:- |\
                pnmtopnm -plain

            [IM Text]

            Older variants of this NetPBM command include "pnmnoraw" and "pnmtoplainpnm", to do the same thing as "pnmtopnm -plain". Check your NetPBM packages man page, as the developers can't seem to make up their minds as to how it should be done.

            Any of these PbmPlus programs will output a newline at the end of 'image row', which the ImageMagick coder does not do. This can make image processing in scripts a lot easier.

            Here is an example of outputing a very small ASCII PBM bitmap.


              convert label:O pbm: | pnmtopnm -plain

            [IM Text]

            Note that PBM bitmaps does not even need to output spaces between values, though they are allowed (IM outputs them, PbmPlus utilities do not). Also note that for bitmaps white='0' (background) and black='1' (foreground). This is a standard for bitmaps formats like XBM and PBM, and ImageMagick understands this convention.

            If this is not desirable Negate the image, or use Level Images by Color to set the desired colors of the bitmap image.

            PbmPlus/NetPBM Depth Control
            Sometimes you want more control of the depth of PGM and PPM images, for example to use a percentile range of values from 0 to 99.

            One method is to use the NetPBM program "pamdepth", which can convert images to any range (up to internal limits of 65335). Here for example is an image array of values but using a 0 to 99 range of output values.


              convert -size 9x9 radial-gradient: -depth 16 PGM:- |\
                pamdepth 99 | pnmtopnm -plain

            [IM Text]

            Here is another example but this time using the Reversed Level operator to set output value range. This can give you more control over the transformation of values, but the 'maxval' in the PGM image does not match the max value of the image.


              convert -size 9x9 radial-gradient: +depth +level 0,99 PGM:- |\
                pnmtopnm -plain

            [IM Text]

            The "+depth" in the above command is vital to set the image file depth to the same as the IM quality level. All that is needed is to reset (or ignore) the third line to a value of '99', and optionally compress the image back to a 'raw' binary NetPBM image format. However because PbmPlus/NetPBM has a maximum depth of 65535 (16 bit) this would only work for IM Q8 or Q16 versions.

            PbmPlus/NetPBM Comments
            IM will read, write, and preserve 'comment' lines in the header of the PbmPlus/NetPBM file format. For example...


              convert -size 2x2 xc:grey -set comment "by Anthony" -compress none PGM:-

            [IM Text]

            However that said most applications including PbmPlus itself will ignore such comments, and even lose them when it processes the file.


              convert -size 2x2 xc:grey -set comment "by Anthony" PGM:- | pnmtopnm -plain

            [IM Text]

            PbmPlus/NetPBM vs ImageMagick
            The PbmPlus/NetPBM image processing suite was once a rival of ImageMagick for command-line image processing, but uses a completely different (more low level) pipeline filtering philosophy, for image handling and processing. This makes it easy to use in shell scripts, but more difficult to use for general or very complex image processing. It also means the image is converted to and from the image file format a lot more frequently, and generally requires the use of many temporary files.

            PbmPlus/NetPBM images do not generally deal with Transparency (though the newer PAM format does), and does not provide a general way of passing image meta-data with the image data.

            All the PbmPlus/NetPBM formats (like the ImageMagick internal format, see MIFF Image Streaming) can handle a stream of multiple images, simply by concatenating or appending the images together, one after the other. This makes it very well suited for pipelined, multi-image streaming, methods of image processing, such as for video processing. However be warned that some PbmPlus/NetPBM programs only deal with single images and will not handle a stream of multiple images.

            However as it is more low-level, and pre-dates ImageMagick, it is often selected for raw image outputs such as video image output and handling. PbmPlus images is also more often used for scientific data, and as such images are typically stored as 'linear-RGB' colorspace rather than the more common non-linear 'sRGB' colorspace. Caution is advised.

            Both packages can co-exist, and I have been known to use a PbmPlus/NetPBM implementation for some things, instead of ImageMagick. Typically when using a specific low level image processing, or scripting using arrays of values stored in an image form. The two packages work together well, and recommend both be installed and used for serious image work.

                I was actually the one to make the vital 1995 patch release of NetPBM, during a time when little work was being done on that software. Because of this I have a good understanding of the PbmPlus software and its simple image file format.

            Since then it has been redeveloped a number of times by different people, and finally seems to have become a proper open source project. The various programs seem to be maturing and start to work together better.

            However its main problems: an of lack of meta-data and complexity; remain. But its simplicity as a file format is its biggest advantage, making it ideal for very low level image and data manipulation.

            TIFF

              The TIFF format is the propriety format for PhotoShop.  However it is so
              bloated with features, and has been modified by just about every application
              that has cared to use it, that no program, not even photoshop can handle ALL
              its variations.  Photoshop however has the best chance at reading it.

              I would steer clear of the TIFF image file format unless you are
              specifically working with photoshop, or the application accepts no other,
              better defined, image file format.

              I don't use the TIFF image file format, or Photoshop. If you use this format
              with IM extensively, perhaps you would like to submit your findings to me,
              to include here.  That way you  can help your fellow TIFF users.

              Whether a specific software package can read a TIFF, all you can do is try
              it and see.  That is the problem with this format.



              TIFF and Density (resolution) in photoshop...

              See Photoshop and Density
              for the details and solutions to this problem



              JPEG to TIFF conversion...

                convert image.jpg image.tif

              This will either save the image inside the TIFF file using JPEG compression
              (which was inherited from the JPEG input.  Or it will error such as...

                  Error: "JPEG compression support not configured"

              This is caused by the TIFF library not including JPEG compression support.

              Either way  THIS IS BAD.

              You can get around this problem by changing the setting to use a different
              compression algorithm:

                  convert image.jpg -compress zip  image.tif
                  convert image.jpg -compress lzw  image.tif
                  convert image.jpg +compress      image.tif

              WARNING:  -compress Group4  with a TIFF works, but ONLY if you remove all
              transparent and semi-transparent pixels from the image.  Typically you can
              make sure this is done the same way as JPEG images above, using
                 -background {color} -alpha remove
              See Removing Transparency from Images
              just before the final save (the first only works for single images).



              TIFF (and MIFF)  floating point precision files (Add to IM v6.2.6-5)...

              This is especially good for HDRI image processing (which uses floating point
              inside IM itself)

              For single precision (float) set...
                     -depth 32 -define quantum:format=floating-point
              For do8uble precision (doubles) set...
                     -depth 64 -define quantum:format=floating-point

              14 bit TIFF images...
                   convert logo: -sharpen 0x1 -depth 14 logo.tif

                   tiffinfo logo.tif

                   Image Width: 640 Image Length: 480
                   Resolution: 72, 72 (unitless)
                   Bits/Sample: 14
                   Compression Scheme: LZW
                   Photometric Interpretation: RGB color
                   FillOrder: msb-to-lsb
                   Orientation: row 0 top, col 0 lhs
                   Samples/Pixel: 3
                   Rows/Strip: 2
                   Planar Configuration: single image plane
                   DocumentName: logo.tif
                   Software: ImageMagick 6.2.8 07/27/06 Q16 https://legacy.imagemagick.org

              12 bit TIFF images...

              To convert 16-bit TIFF images to 12-bit:
                    convert image.tif -depth 12 image-12.tif

              Pure black and white images...

                   convert image ...  -type truecolor -type bilevel   image.tiff

                Results in normal images and the smallest filesize, and correct
                black/white handling in Photoshop, Microsoft Windows Picture and Fax
                Viewer.
                   TIFF discussion,
                   RQuadling.


              Enden and fill-order
                The order in which TIFF data values are stored is controled by
                   -endien                   Global order of the bytes
                   -define tiff:endian       Tiff format container endian
                   -define tiff:fill-order   Bit order within a byte

                Each takes a value of either MSB (default) or LSB, however
                the "tiff:fill-order" will be set to the value of "tiff:endian"
                if that is defined, but not from the global endian value.

                The "tiff:endian" property is the endianess of the image container. The
                "-endian" property is the endianess of the image pixels. They may differ.


              Save a TIFF file format with only one row pre strip

                      -define tiff:rows-per-strip=1.
                To save more rows per stripe increase the number
                      -define tiff:rows-per-strip=8
                You can also specify the 'endian' ordering for binary integers in the format
                      -endian MSB          -endian LSB

                For smaller TIFF images (other than by compression, you can also try to
                use options and settings like   -depth 8   to reduce the color quality
                or   +matte  to remove the alpha or transparency channel from the image.

                IM will save a greyscale image as a greyscale TIFF, if no non-grayscale
                colors are present. You can force it to save as non-greyscale with
                      -depth 8  -type TrueColor


              Added IM 6.6.4-3
                Allow you to set the "Software Creation:" meta-data (property)
                to something other than "Image Magick 6.**"
                    -set tiff:software "My Software"


              Windows Picture and Fax Viewer, Windows Explorer

                These can can only display TIFFs that have certain Photometric
                Interpretation values, such as RGB.  IM Options...
                    -compress LZW -type TrueColor

                toggle the photometric interpretation  (Added IM 6.3.2-10)
                    -define quantum:polarity=min-is-black
                    -define quantum:polarity=min-is-white


              Multi-Page TIFF
                If you want to split a multi-page tiff into separate pages, IM may have
                problems as it will still use up a lot of memory to hold previous pages
                even if you use a command like...
                    convert "a.tif[i]" b%03d.tif

                This might be regarded as a bug, or perhaps a future improvement.

                The better solution may be the non-IM "tiffsplit" program.


              TIFF and EXIF profiles

                Cristy reported: The libtiff delegate library supports the EXIF profile
                but it was unreliable and caused faults too often so we commented out the
                call.

                To get the EXIF attributes try this.

                  identify -verbose -define tiff:exif=true image.tif

            The TIFF format can have a bitmap mask in the form of a clip path, which can be enable using the "-clip" operator. You can use that 'clip' mask your image with that path using...


              convert image_clip.tif  -clip \
                      ...do_various_operations... \
                      +clip-mask  image_masked.png

            See Write or Clip Masks for more details.
            BMP, Windows Bitmap

              The Windows desktop icon image format BMP (short for bit-mapped) is a very
              unfriendly image format and should probably be avoided if possible.

              ImageMagick supports 8, 24, and 32-bit BMP images.

              Add -colors 256 to the end your command line (before the output image
              filename) to create a 8 bit colormapped BMP image rather than a 24 bit BMP
              format.  Extra colors can be added to images after performing operations
              like rotates, and resize.  See Color Quantization for more info on -color.

              The presence of any transparency controls whether it uses a 24 (RGB) or 32
              bit (RGBA) format BMP image. You can use "+matte" to turn off transparency
              in an image.

              If all colors are gray-scale a 'directcolor' greyscale image is generated.
              I think -type truecolor will stop this behaviour.


              If you have an older program cannot read the default BMP4 images written by
              ImageMagick, (for example a Windows Background Image), you can enforce the
              generation of a BMP3 format image using...

                   convert image BMP3:image.bmp

              This format should have no transparency and should be a 'printable image',
              whatever that means.  In other words 'Windows' compatible.

              However, if a PNG input file was used and it contains a gAMA and cHRM chunk
              (gamma and chromaticity information) either of which forces "convert" to
              write a BMP4. To get a BMP3 you need to get rid of that information. One way
              may be to pipeline the image though a minimal 'image data only' image file
              format like PPM and then re-save as BMP3.  Messy, but it should work.

                  convert image.png  ppm:- | convert - BMP3:image.bpm

              IM can not produce BMP's at depth levels other than 8.  However you can
              use NetPBM image processing set to do the final conversion to other depth
              levels (This needs at least a Q16 version of IM)...

                   convert image +matte -colors 16 ppm:- |\
                     pnmdepth 4 | ppm2bmp > image.bmp


              Format limitations....

              The header for a BMP2: format only allows the description of the width,
              height and bit depth (bits per pixel) of an image. The bit depth can be one of
              1, 4, 8 or 24.

              For comparison, the bmp3: format allows bit depths of 0, 1, 4, 8 ,16, 24 and
              32 and has extra fields which specify x and y resolution (in pixels per metre)
              and compression of the image data.

            ICO

              To create a multi-resolution ICO format image simply create all the image
              sizes you require and write them all to the same ICO file.

                convert icon-16.bmp icon-32.bmp icon-64.bmp \
                        icon-128.bmp icon-256.bmp   myicon.ico

              Update

                convert icon-256.png  \
                        -define icon:auto-resize="256,128,96,64,48,32,16" \
                        myicon.ico

            You can now add this to you web pages using
              <LINK REL="shortcut icon" HREF="myicon.ico">

            However many web browsers will now accept most image formats, not just the
            ICO format.

            RAW Camera Image Formats (CRW,CR2,NEF,X3F,etc.)
            Most digital cameras, with the exception of the Sigma Foveon sensor and some Sony cameras, convert the image produced by the lens into digital data by using millions of sensors which detect the brightness of one specific colour, Red, Green or Blue. In order for the camera to respond to colour in approximately the same way that the human eye does, there are twice as many green sensors as there are of red or blue because our eye is much more sensitive to green light. The sensors are arranged in what is called a Bayer array. For a description and diagrams of this arrangement see, for example, Understanding Digital Camera Sensors.

            The conversion of the data from a Bayer array into the more familiar RGB pixels requires a process called demosaicing. Once this operation has been done we still do not have an image worth displaying. Even with the extra green pixels, the camera's sensor still does not perceive colour the way we do. If you take a piece of white paper and look at it in bright sunlight and then go indoors and look at it under a fluorescent light, it will look white under both conditions. But if you photograph the sheet of paper under those same conditions using default camera settings, the paper will show slightly different colours when displayed on a screen. The reason is that although the back of our retinas will "see" the same light reflected off the paper as does the camera, our brain will interpret that light for us and we will perceive the paper as white. The camera simply measures the amount of red, green and blue light reflecting off the paper and under a fluorescent light there will be more blue light than there is under sunlight so the paper in that image will look bluer than the one taken in sunlight. To produce images which both show a white sheet of paper requires that they be "white balanced", also referred to as gray balanced or colour balanced. For more about white balancing see Understanding White Balance

            There are still other aspects of the raw file which must be done, such as setting a correct gamma, but without going into further detail it is clear that the raw file needs a lot of processing before it can become an image that we can view on a monitor.

            Camera raw files are often referred to as digital negatives. If you take a photo and have the camera generate a JPG image, it will have done the demosaicing and all the other adjustments. But if, for example, you forgot to set the correct white balance in the camera before taking the photo, you can't really do much with the JPG to correct the situation because so much information about the original image has been lost. If, on the other hand, you had produced a raw file from the camera instead of a JPG, during the conversion from raw you can choose a particular white balance setting along with other parameters and if the resulting image doesn't look right you can go back, change the settings and convert it again until it does look right. This is similar to the ability to produce more prints from film negatives. Without the film negative you wouldn't be able to get an 8x10 blowup of one of the 4x6 snapshots you get when the film was first developed.

            While ImageMagick can handle a large variety of different formats, it does not 'know' how to convert raw camera files, so IM uses the "dcraw" program as a delegate program to convert the raw file into a format that it does understand, either a TIFF (with the '-T' flag) or PNM. Note that it is designed for raw camera images, and not those from, for example, a scanner. The "dcraw" program can handle a large number of different raw formats including those from cameras manufactured by Canon, Fuji, Kodak, Nikon and Sony.

            You can determine whether "dcraw" will recognize your raw files by asking it to identify a sample. For example the command:


              dcraw -i CRW_9641.CRW

            Which returns...

            CRW_9641.CRW is a Canon EOS 10D image.

            When IM calls dcraw to do a conversion, using the delegate (list using "-list delegate"), specifies two flags which affect image processing:

             dcraw -w -4 -O output_file input_file
                

            The '-w' flag means that dcraw will use the white balance information in the raw file if it can be found. If the info can't be found, dcraw will use an average of the whole image as a basis for white balancing.

            The '-4' flag means that dcraw will only de-mosaic and white balance the raw photo and output the result as a 16-bit linear image (48 bits per pixel), suitable for the default Q16 version of IM.

            Because '-w' and '-4' are the only two image processing flags specified, there are some defaults that dcraw will use. The output colour space will be sRGB and no ICC profiling is done (on my system, dcraw was compiled without the LCMS library so it can't do profiling).

            The fact that the '-4' flag is set means that many processing steps have been omitted, including levels adjustment and gamma correction, and so the resulting image will look dark. The intention is that the user is going to process the image with an image editor such as "Photoshop" or "Paint Shop Pro", or even "ImageMagick" and do their own adjustment of the levels, gamma and so on. In this case, the image should be output to a format that supports 16 bits per colour. (For example TIFF).

            Note that just because dcraw produces a 16-bit file doesn't mean that all 16 bits contain useful data. For example, a raw image from a Canon 10D digital SLR has 10 bits per colour. More recent cameras by Canon and other manufacturers have 14 bits per colour.

            If you want your raw photos converted completely you will have to remove the '-4' flag so that dcraw does the de-mosaicing, white balance, brightness and gamma correction and so on. In this case dcraw outputs an 8-bit file (24 bits per pixel). If you are going to do further processing of this image it would be best to output it as a PNG and avoid the JPEG compression artifacts. The JPEG format should only be used as a final step for actual use. In fact, it is always a good idea to use a lossless format such as PNG (or IM internal format MIFF) for intermediate steps in image processing.

            A special DCRaw Delegate can be added which will let you control how you read the 'raw' camera image formats.

            For further information look on the DCRaw WebSite, and also the DCRaw Tutorial Website which has some information about many of dcraw's optional flags and including histograms of raw images using various flags.

            Also see DCRaw by Example.

            The above notes were first extracted from an IM Forum Topic Converting RAW images, by jhfry, with major re-writes by el_supremo.

            MPEG, M2V and AVI Movies

              IM is not very efficient at creating movies.  It will do the job though
              requires the external program "mpeg2encode" to do much of the dirty work.

              The problem is that IM is not designed to handle video, but static images or
              small sequences of images.  That is not to say it can't do it, but that is
              not its goal.  In particular it generally reads in all images into memory
              and process them from there.  For a large or long video this is not very
              efficient.

              For processing on a small sequence of frames however it really can't be
              beat.  In fact just about every Linux Video manipulation program uses
              ImageMagick to generate titles, fancy scene changes, and other effects to
              complete the post-processing development of a larger video development.  The
              process however is kept to small video sequences.

              However lets have a look at what IM can do.

              Frames to Video

              There are some reports that unless the images are the right aspect ratio is
              correct this will fail on older mpeg players,  use the MPEG II extension
              (m2v:) instead.

              Also use m2v to avoid heavy compression pixelization that can occur
              using...

                  convert *.jpg glacier.mpg

              EG instead use...

                  convert *.jpg m2v:glacier.mpg

              Note you may need lots of temporary space to do a large animations
              You can specify a different directory from the normal /tmp using...

                  setenv MAGICK_TMPDIR /data
                  convert -limit memory 0 -limit map 0 *.jpg image.m2v

            Alternatives...

              To converting PNG images to MPEG2 Video streams, instead of MNG Multi
              PNG-files, use the following delegation...

                   png2yuv -j file%08d.png -I p -f 25 -b 1 | \
                     mpeg2enc -f 3 -q 3 -b 5000 -o out.m2v

              For more info see mjpeg.sf.net


              IM forums reported decent results with an open source project called "ffmpeg", which seems to be a fairly standard
              linux package install.

                 ffmpeg -f image2 -i %03d.jpg -vcodec mjpeg -y anim.mpg

              Extracting an MVG with a transparent background
                  convert -background none -size 320x240 sample.mvg out.png


              Michael Lenh wrote...
              I finally was able to create a very sexy video using mplayer

                mencoder "mf://data/p*.png" -mf fps=40 -o particle.avi -ovc lavc

              You can see the results at...

                http://www.mathematik.uni-ulm.de/~lehn/particle.avi
                http://www.mathematik.uni-ulm.de/~lehn/temperature.avi


              mabu in a IM Forum Discussion said to
              "USE MENCODER, wow it's like 1000 times faster and actually WORKS"...

                 mencoder -nosound mf://*.jpg -mf w=800:h=371:type=jpg:fps=15 -ovc lavc -lavcopts vcodec=mpeg4:vbitrate=2160000:mbd=2:keyint=132:v4mv:vqmin=3:lumi_mask=0.07:dark_mask=0.2:mpeg_quant:scplx_mask=0.1:tcplx_mask=0.1:naq -o output.mpg

              It probably has extra options I don't need but it makes a nice time-lapse
              from .jpg files.


              Dean S. Messing uses transcode...

                 find . -type f -name '*.png' | sort > filelist
                 transcode -x imlist,null\
                        --use_rgb\
                        -y raw,null\
                        -f 60\
                        -i filelist\
                        -g 4096x2160 \
                        -j 540,1024,540,1024\
                        -o video.avi\
                        -H 0

               You can leave out -j  (clip window) if you want. -g is output size.

               Wolfgang Hugemann suggests a new alternative known as 'VirtualDub' under
               Windows Vista, which will let you run a video, or convert directly from
               a folder of image frames.

               WARNING: "mplayer" apparentally does not like mpeg file with
               only one frame. "ffplay" however seems to have no problems.


               Video to Frames

               Both "mplayer" and
               "mencode" are more efficient at converting video into a series
               of frames than IM is.  On top of this is can handle just about any video
               (and audio) codec available.

               For example to grab 5 frames from 1 1/2 minutes into a video, scaled to
               320x240, you can use...

                  mplayer file.mov -vf scale=320x240 -ss 01:30 -ao null \
                          -vo png:z=3 -frames 5

               Other alternatives include the "ffmpeg" open source library, though that is also part of the
               "mplayer" handling.

            MNG, Multiple-image Network Graphics
            Contributed by Barry Loo from the Example Ming Animation discussion.

            MNG (pronounce ming) is an open format based on PNG, and provides an animated bitmap alternative to GIF and others. It allows for transparency (both semi and full), compression (both lossy and lossless), and up to 32-bit color depth.

            The increased color depth is what really sets this format apart from others. GIF only supports up to 256 colors total, which is fine for many graphics; however, photographs and gradients will suffer.

            Most animation options that can be used in creating GIF animations can also be used to create MNGs.


            convert -size 101x101 radial-gradient: \
                    \( -clone 0 -level 00,100% +level-colors ,#F00 \) \
                    \( -clone 0 -level 10,100% +level-colors ,#F12 \) \
                    \( -clone 0 -level 20,100% +level-colors ,#F24 \) \
                    \( -clone 0 -level 30,100% +level-colors ,#F36 \) \
                    \( -clone 0 -level 40,100% +level-colors ,#F46 \) \
                    -delete 0  -duplicate 1,-2-1 -set delay 1x30 -loop 0 pulsing.mng

                [IM Output]

            The above command generates a radial-gradient image, which is then cloned and adjusted to create a red to brighter red-orange pulse. This is then duplicated to create a reversed Patrol Cycle before creating a 30 second, looped MNG animation.

            Unfortunately, most Web browsers do not currently support MNG, and many video players only show one pass though the looped animation. If you click on the above missing image frame, you can download the animation and view it using IM Animate Command.

            For more information on the MNG format, visit MNG Web Site.

            DPX, Digital Picture Exchange Format
            This format is used in Motion Picture and Effects industry that makes particular use of the extensive header information and the format's flexibility in being able to handle high dynamic range and logarithmic colour values at a variety of bit depths using RGB or YCbCr pixel descriptions. It is based on, but largely supersedes, Kodak's Cineon format that has more a more film specific header.

            One example of it's use would be when scanning film for use in post production. Each frame would be stored as an individual .dpx file ranging from 2k (2048 pixels wide) to 8k (8192 pixels wide - for IMAX frames) at anything between 8 to 64 bits per colour component. A sequence of these might then be processed using compositing software, altering the colour or adding visual effects. Once complete they might then be recorded digitally to tape or projected back on to film.

            The colour values for each pixel are often stored logarithmically (particularly if the sequence is destined to be transferred back on to film) which more naturally reflects the density of how colour information is stored in the emulsion on the original film. When viewed without alteration logarithmic files appear to have very low contrast, and so require a 'look up table' to translate the logarithmic image to something that resembles what you might see if the image was transferred back to film and projected in a cinema. Apart from making the image linear (like most typical computer images) and adjusting the gamma level this table sets where the black and white point lies.

            For a 10 bit logarithmic image where each colour component value ranges from 0 to 1023 the black and white points are normally set at 95 for black and 685 for white. What this means is that the logarithmic file stores colour values that are lighter than what the linear version will display as pure white and darker than what it will display as pure black. This extra information therefore remains available for an effects artists who might wish to alter the brightness of the image after it has been stored as a dpx file.

            As an example, had this information been lost, reducing the brightness of an image uniformly would result in highlights becoming darker, whereas with this extra information the highlights instead reduce in size and start showing details that were previously too bright to be seen. The latter is far closer to what happens in the real world.

            The header can contain Film and/or Television specific data related to a production. For example the television header can contain a SMPTE time code so that shots exported as a dpx sequence from a production's edit can be easily replaced once any effects have been added. The film header holds information about the reel of film the frames originated from and various camera settings that were used while filming. All these details will then stay with the images as they are passed between post-production companies.

            Adding a time code to DPX files
            You can add a time code to any dpx file using the following:


              convert -define dpx:television.time.code=10000215 \
                      originalFile.00001.dpx    alteredFile.00001.dpx

            Carrying out this command for each of several thousand files that form a sequence from a film or animation would clearly take a very long time. A simple script can be used with ImageMagick to automatically increment the time code for each frame in a sequence.

            For example see the Perl Script dpx_timecode.pl.


            A copy of the above was added to the main IM documentation at Introduction to Motion Picture Formats.

            The above is courtesy of Seth Dubieniec <seth.info_AT_dubieniec.co.uk>, from a long IM Forum Discussion on the DPX Format. He is currently developing DPX applications, so more DPX info is likely to be coming.

            Extra Notes (unformatted)...

            Adding  -depth 10  causes IM to output a  10 bit DPX file.
            -- James Fancher


            If you want to set the gamma, for example, in the output DPX image...
                 -define dpx:television.gamma=1.7

            The colorspace of the DPX image is defined by the image element descriptor and
            transfer-characteristic. If the transfer characteristic is
            PrintingDensityColorimetric we set the colorspace to LogColorspace. Only if
            the colorspace is Log do we apply the gamma and black/white points to convert
            to the RGB colorspace. Its possible the program you are using is not
            conforming to the SMPTE standard or ImageMagick is not interpreting the
            standard correctly. Post an URL to your two DPX images and we will download and
            try to determine if ImageMagick has a bug or if the program you are using is
            buggy.

            The following will work with ImageMagick 6.3.8-3

              convert -colorspace log AfterEffectsFile.dpx -set gamma 0.5 \
                      -set reference-black 95 -set reference-white 685 image.jpg

            Alternatively, take a look at the SMTPE documentation
            -- Cristy


            You can add text user data to the dpx file by using

              convert image.dpx   -set dpx:userdata "some text"    new.dpx

            -- Cristy

            PSD
            A PSD image file is the Photoshop Working image file format, just as XCF is the GIMP working file format, and MIFF is ImageMagick's own working file format.

            They usually contain multi-images, with first image being an all-in-one merger of the current working image. That makes it useful for seeing the working image as it currently stands and is typically used for 'thumbnailing'.

            All the other images in the multi-image file format are the images that are used to generate that first combined image. That is the individual working layer images, the user was working on at the time it was saved.

            So if you just want the 'final' image I suggest you append a " '[0]' " to the input filename to junk the working images, and just use the all-in-one first image.

            However if you plan to work with the individual layer images then use " '[1--1]' " to skip the first image. If no extra layer images are found than the first image will be returned instead. I do NOT recommend using "-delete 0" as that will return no images at all if no layer images follow that first image.

            Extra notes... If you can provide more information or like to submit a summary of using IM for this format, then please do...

               For PSD with a CMYK image you may need to get IM to use the
               right provide when converting (make sure you IM was installed with the LCMS
               delegate library) ....

                 convert Test_CMYK.psd -strip -profile USWebCoatedSWOP.icc \
                         -profile sRGB.icc Test_RGB.png

               See Profiles above for more info.


               If a PSD image contain a 'preview' image.  This image is returned as the
               last image of a two image read.

               To ensure IM never reads the last image use...
                   convert test.psd[0--2] -flatten test.jpg
               That is read all images, except the last. But always read the first.
               This can not be done after the read using a "-delete".

            WMF
            Another vector format often used for scalable clipart used by the Microsoft Office set of programs. The input can be scaled changing the "-density" before reading the image.

            See also Vector Image Formats.

            Flash Animations (SWF)
            Flash animations are currently not supported by IM.

            But just for completeness Scott Bicknell reports that the SWF Tool utility "swfextract" It can extract jpeg or png frames from a flash animation.

            Wolfgang Hugemann also thinks the Windows freeware tool "IrfanView" may be able to do this as well.

            Sounds like a good delegate candidate to me.

            Webpage Conversion to Image (HTML)
            If IM loads a HTML it will look for a html2ps to convert the html to postscript which it can then render as an image. This does not work very well, but does work.

            Using a full web browser is a much better method as it is designed to do the task in the best possible way. The simplest method to use a browser is to just load the page in a browser and then take a screen shot of it. This gets a perfect image of the page but limited to the window size of the browser.

            Another variation is to have the browser output the page as postscript rather than have IM convert it. This should page the website into smaller pages quite nicely.

            Under LINUX you can to start a virtual X windows Display server that is large enough to run a browser that shows the whole web site. This can be a VERY tall display. The browser is then run in it and set to fill the entire display. The web site is loaded and again grabs a screen shot. I have seen a script that can even automate that whole complex process. However you can end up with a VERY long image. It is also difficult to know just how big to make the display.

            Basically it is NOT easy and the best solutions only use IM for the final image processing, not the html to image generation.

            PCL Printing Format
            IM PCL is version 6 PCL by default.

            For version 5 you need to convert your image to black and white.

            For example...


              convert image.png -monochrome image.pcl

            Kodak PhotoCD or ProPhotoCD (PCD)
            The Kodak PhotoCD file is a multi resolution image file format. That is each file contains the same image at 6 different sizes forming something known as a 'pyramid image'. First image in the file is the lowest resolution (smallest size) and the last the highest resolution (largest size at 3072×2048 pixels).

            As users typically what the largest resolution image for processing the way to convert a PCD image to some other format like JPG is to grab the sixth or (index 5) from the image file.

            For example...


              convert -colorspace RGB image.pcd[5] image.jpg

            The "-colorspace RGB" option is needed in order to get the colors right.

            Information courtesy of Wolfgang Hugemann <ImageMagick_AT_Hugemann.de> from the Magick-Users Mailing list.

            Raw RGB, and Gray Data
            Imagemagick has a some file formats for dealing with raw image data, specifically "RGB:", and "GRAY:". As well as provide settings defining that data.

            For example to output RGB raw data...


              convert image.jpg -depth 8  image.rgb

            The "-depth" setting specifies the size of the integers written (and later read). In this case 8 bit values with 3 bytes per pixel for RGB, (a 24 bit image). Specifying an appropriate depth is always recomended for handlign raw image data.

            A "-depth" of 16 bits, will produce 2 bytes per value, in which case you may also need to specify the "-endian" or byte order, to be either 'MSB' (most significate byte first), or 'LSB' (least significate byte first, the default).

            Note that rgb is purely the image data, it does not even contain the width and the height of the image! Some applications 'assume' the data is a specific size, so you may need to use IM to ensure that data is this size.

            For example This resizes and pads the image to ensure it is 512x512 pixels in size.


              convert image.jpg -resize \>512x512 \
                      -background black -gravity center -extent 512x512 \
                      -depth 8  image.rgb

            When reading raw RGB (or GRAY) data into ImageMagick you will need to specify how big the image is. For example..


              convert -size 512x512 -depth 8 image.rgb    image.png

            This will exactly define how much data Imagemagick will read in.

            Sometimes the raw data may have some extra header information attached. To allow IM to skip over this information you can specify an 'byte_offset' in the "-size" setting.

            For example skip a 48 byte header...


              convert -size 512x512+48 -depth 8 image.rgb    image.png

            This is the only time I know of where IM will make use of a third number in the "-size" setting.

            For more examples of using raw image data (grayscale) see the IM Discussion forum topic How to convert raw image to compressed tif?.

            Floating Point Data

            You can also read (and write) RGB using normalized floating point numbers.
            This however requires the use of special coder -define settings.
            See HDRI floating point file formats
               https://legacy.imagemagick.org/Usage/basics/#hdri_formats


            RGB floating point Image generated using C Code (HDRI)...

               float red = 1.0f;
               float green = 1.0f;   /* appropriate data */
               float blue = 1.0f;

               /* for exach pixel in image... */
               fwrite (&red, sizeof(float), 1, file);
               fwrite (&green, sizeof(float), 1, file);
               fwrite (&blue, sizeof(float), 1, file);

            Reading Options....

              convert -size 200x100 -depth 32 -define quantum:format=floating-point
                      -define quantum:scale=65536.0   -endian lsb   input.rgb
                      output.png

            The quantum:format defines to read floating point numbers from the file.
            While the -depth defines the floating point size (32 = floats, 64 = doubles).

            The quantum:scale  defines how to scale the floating point numbers from
            normalized 0.0 to 1.0 values to the in-memory 16bit Quality levels needed
            by my Q16 version of IM.
https://legacy.imagemagick.org/Usage/text/
            Creating text labels, or adding text to images is probably one of the most basic and common operations for which ImageMagick is used. It is also one of the most simplest, but with scope for some very fancy results. As such this is a good place to start our exploration of IM's capabilities.

            Text Operators in ImageMagick
            ImageMagick has a lot of different ways in which you can draw text within an image, highlighting the versatility of the image processing library. This page details specific methods and styles of drawing text.

            What you have to keep in mind as you study these examples is that ImageMagick is primarily an image converter and modifier. As such each of methods provided are simple text drawing operators, such as adding labels and copyright messages to images. See Annotating Images.

            All the text operators also understand and use a set of standard text processing settings such as, the "-font", "-pointsize" to use. Also the "-fill" color setting and for more complex text drawing the "-strokewidth", "-stroke" and "-undercolor" colors. In cases where you actually create a new image, such as label and captions, the "-background" color setting is also used.

            And finally the newer "-kerning" and "-interword-spacing" modifiers.

            What ImageMagick is not, is a full formatted text and document processor. If you want heavy text processing, you are better off using a full interactive word-processor, or batch text formatter like "TeX" (or or one of its flavors (see A Complete Text Processing System below). The output of these programs (generally postscript format) can then be converted into an image and further modified by ImageMagick. That is, use the right tool for the right job.

            That said some mixed font handling can be done. For a starting point look at Creating Lines of Mixed Font Styles, near the bottom of this page.

            Now, lets now look at the basic ways you can convert text into images. Later in the next section (Compound Fonts we'll look at generating some interesting font effects.

            Label - Simple Text Label
            Basic Labels
            Creating a font image using a "label:" image, is the more typical way of drawing a font quickly in ImageMagick. The biggest advantage is that generates its own canvas according the current "-background" and "-fill" color settings, which is sized to match the drawn text.

            For example here is a typical generated label.


              convert -background lightblue -fill blue \
                      -font Candice -pointsize 72 label:Anthony \
                      label.gif

            [IM Output]

            The above is probably the most typical usage of label, with a font selection and "-pointsize" defining the results. But it by far the least interesting way of generating text labels.

                The 'label:' image generated will also have the 'label' Image Property meta-data set to the same string. Some file formats, such as MIFF and PNG, will save that specific property and can be used in later image processing programs. For and example of using 'label' meta-data, see Montage using Saved Meta-Data for examples.

            If you also specify a "-size" then the generated label image will be created at that size.


              convert -background lightblue -fill blue  -font Candice \
                      -size 165x70 -pointsize 24 label:Anthony     label_size.gif

                [IM Output]

            You can also use "-gravity" to set the position of the label within that larger box.


              convert -background lightblue -fill blue  -font Candice \
                      -size 165x70  -pointsize 24  -gravity center \
                      label:Anthony     label_gravity.gif

                [IM Output]

            Of course if you do not set a "-size" for the label, no extra space will be available in the generated "label:" for "-gravity" to use, making it rather useless.

            The problem with using BOTH "-size" and "-pointsize" together is that the text could 'overflow' the specified image size.


              convert -background lightblue -fill blue  -font Candice \
                      -size 165x70  -pointsize 72  -gravity center \
                      label:Anthony     label_overflow.gif

                [IM Output]

                Before version 6.5.2-4, IM would completely ignore the "-pointsize" setting if a "-size" setting is also given. This causes the text in the above images to be auto-sized according to the 'best fit' handling (see next set of examples).

            Best Fit to Image
            The biggest trick to using labels to generate images of a specific "-size" is NOT to specify a "-pointsize" for the label. When this happens IM will have the freedom to try and select a font size that best fits the image size requested. That is the drawn text will be adjusted to fit the given size!


              convert -background lightblue -fill blue  -font Candice \
                      -size 165x70  label:Anthony     label_size_fit.gif

                [IM Output]

            As you can see by setting a "-size" setting, you could end up with some extra space to the right or below the image.

                When IM creates a 'bestfit' label, the actual pointsize it used is also saved into the 'label:pointsize' Image Property, allowing you you use that information later. This was added to IM v6.6.2-7, during the forum discussion Pointsize Reporting

            You can still adjust the position of the label in that extra space by adjusting the "-gravity" setting.


              convert -background lightblue -fill blue  -font Candice \
                      -size 165x70 -gravity center label:Anthony     label_size_gravity.gif

                [IM Output]

            Of course if you do not set a "-size" for the label, no extra space will be available in the generated "label:" for "-gravity" to use, so it only makes sense when you ask for the image to be a specific size.

            Now for the best news. If the "-size" setting you give only contains just width or the height for the label, the font will be adjusted to best fit that given dimension. The other dimension not specified will then be auto-adjusted to fit that text!


              convert -background lightblue -fill blue -font Candice \
                      -size 160x  label:Anthony     label_size_width.gif

                [IM Output]

            Basically that means the above "label:" will always be 160 pixels wide, with the largest font size for that width. The height of the label will then be adjusted to suit.

            The same thing will be done if the height is specified but not the width.


              convert -background lightblue -fill blue -font Candice \
                      -size x40  label:Anthony     label_size_height.gif

                [IM Output]

            This label is 40 pixels high, the undefined pointsize of the text was adjusted to fit that height, and then the undefined width was set to fit the drawn text. Exacly as you would expect.

            Of course in this case there will again be little if no extra space for any "-gravity" setting to play with.

            Labels over Multiple Lines
            The "label:" generator can (as of IM version 6.2.5) generate multi-line labels.


              convert -background lightblue  -fill blue  -font Ravie -pointsize 20 \
                      label:'ImageMagick\nRules - OK!'     label_multiline.gif

                [IM Output]

            As you can see "label:" understands the use of '\n' as representing newlines. This means you may have to pre-process your input text to ensure that any special characters are escaped when placing the data on the command line. See Special Escape Characters in Text Arguments below for more details.

            As "-gravity" also effects "label:" generation (as of IM version 6.2.6), you can use it to 'justify' multi-line labels.


              convert -background lightblue -fill blue -font Corsiva -pointsize 24 \
                      -gravity center    label:'ImageMagick\nExamples\nby Anthony' \
                      label_centered.gif

                [IM Output]

            One important feature of IM is that it can read the text data to use from a file. This is done by prefixing the filename with an 'at' character '@', and using this as the string argument.

            For example, here we create a label from my workstations 'message of the day' file...


              convert -background lightblue  -fill blue \
                      label:@/etc/motd   label_file.gif

            [IM Output]

            You can also read the text for a label from the standard input pipeline. For example here I convert the output of a quote generator to a multi-line label.


              mesgs ImageResolution |\
                convert -background lightblue  -fill blue \
                        label:@-   label_file_multiline.gif

            [IM Output]

            Notice that the filename I used was just a '-' character. This means that the file is to be read from standard input. Remember you can use the '@filename' to read ANY command line string arguments into IM. This includes all the other text input methods given below. However it can only be used to replace the whole string argument, not a part of a string argument.

            Note also that in the above examples, an extra blank line was added to the label image. This blank line is caused by a final newline in the input text file. Unless you somehow strip the final newline from the input file (see caption: example below for method to fix this), "label:" will always have this blank line from input text files.

                Most older versions of IM (before v6.2.5), do not handle multiple line labels. In these versions the lines would have been appended together to form a single, very very long line.

            Vertical Labels
            Of course you can also add newlines to the input text too. For example here I take a simple word and add a newline between each and every letter, to create some centered vertical text.


              echo -n "Vertical" | sed 's/./&@/g; s/@$//' | tr '@' '\012' |\
                convert -background lightblue -fill blue -font Ravie -pointsize 24 \
                        -gravity center    label:@-   label_vertical.gif

            Note that the "sed" command adds a '@' character after every character, except at the end of the string. The "tr" then replaces the '@' characters with newlines. It also assumes the input text does not end with a newline, which would cause an extra blank space to be added at the bottom of the resulting image.

                [IM Output]

            Users running linux, and thus using the GNU version of the "sed" command can remove the "tr", and replace the '@' with '\n' in the sed command, so it directly inserts the newlines between each character.

            See also the special attribute Inter-Line Spacing which can be used to adjust the space between the characters.

            Caption - Word Wrapped Label
            The "caption:" image from text input generator, is in most respects exactly like "label:" except that instead of expanding the size of the text to fit a specified "-size" setting, it word wraps any long lines that do not fit into the specified "-size" width.

            The "-size" setting is not optional however and must at least specify a maximum width in pixels.

            For example here is a caption of a long line that will not fit into the width specified.


              convert -background lightblue  -fill blue  -font Corsiva -pointsize 36 \
                      -size 320x   caption:'This is a very long caption line.' \
                      caption.gif

            [IM Output]

                The 'caption:' image generated will also have the "caption" Image Property meta-data 'set' to the same string, allowing you to re-use that information later. All the common image file formats will save this information with the image. See Montage using Saved Meta-Data for examples.

            By default the text is all left justified, however as of IM version 6.2.0, "caption:" respects "-gravity" for text justification purposes.


              convert -background lightblue  -fill blue  -font Candice -pointsize 40 \
                      -size 320x  -gravity Center  caption:'ImageMagick Rules OK!' \
                      caption_centered.gif

            [IM Output]

            If you do provide a height as well as a width to the "-size" setting, then the image height will be set to that height as well. You can then also use the "-gravity" setting, to position the text vertically.


              convert -background lightblue  -fill blue  -font Gecko -pointsize 32 \
                      -size 320x100  -gravity South caption:'Captions at their height!' \
                      caption_height.gif

            [IM Output]

            Please note however that if the text will not fit (height-wise) into the "-size" you specified with the given "-pointsize", then the text will overflow the box. The current "-gravity" setting will naturally determine what part of the text is cut off.

            For example this is exactly the same as the previous example, but with an image "-size" that is too small for the result.


              convert -background lightblue  -fill blue  -font Gecko -pointsize 32 \
                      -size 320x60  -gravity South caption:'Captions at their height!' \
                      caption_height_toosmall.gif

            [IM Output]

            Best Fit Caption
            As of IM v6.3.2, if you provide both the width and the height of the final image, but do not define the "-pointsize" of the font (or turn off the pointsize with "+pointsize"), IM will attempt to automatically adjust the size of the font so as to best fill the "-size" of the image you requested.

            For example, here I ask ImageMagick to fill a fairly large area...


              convert -background lightblue -fill blue -font Candice -size 320x140 \
                      caption:'This text is resized to best fill the space given.' \
                      caption_filled.gif

            [IM Output]
            And now a much smaller thinner area, for the same font and text string.


              convert -background lightblue -fill blue -font Candice -size 80x110 \
                      caption:'This text is resized to best fill the space given.' \
                      caption_filled_sm.gif

                [IM Output]

            Note that the ONLY difference between the last two examples is the "-size" of the image generated. IM fitted the text and word wrapping so as to try and best fill the image size specified.

            This is extremely useful for fitting an unknown bit of text into a given space, without it overflowing the area bounds. However internally it is equivalent to running caption multiple times as IM searches for the right point size to use to best fill the given space. In other words it can often be 10 times or more slower than if you supplied a specific "-pointsize" to use.

            Captions with Paragraphs
            The "caption:" image operator (as of IM v6.2.5) understands the use of the '\n' shell escape (and thus you need to double backslash '\\' to escape backslashes), as meaning a new line or paragraph. Before this version separate paragraphs would have to be processed by separate "caption:" operations.


              convert -background lightblue -fill blue \
                      -font Ravie -pointsize 24 -size 360x \
                      caption:"Here I use caption to wordwrap.\nTwo separate lines." \
                      caption_multi_line.gif

            [IM Output]

            You can read the text to be drawn from a file, or standard input (from a previous pipeline command), using the '@' filename prefix, just as as we can with "label:".


              mesgs FilePrivate |\
                convert -background  lightblue  -fill blue  -pointsize 12 \
                        -size 320x  caption:@-  caption_file.gif

            [IM Output]

            As you can see newlines in the input text will (as of IM v6.2.5) will be treated as paragraph separators. This includes any final newlines in the input file. Of course "label:" will not word wrap the lines, but preserve them.

            If you really want a file to be treated as a single paragraph, then you will need to replace the newline characters with a space character, so your text is all on one line. For example, here we take the same text, but replace the line feeds with spaces, then replace any multiple spaces between the words, with a single space...


              mesgs FilePrivate |      tr '\012' ' ' | sed 's/  */ /g' |\
                convert -background  lightblue  -fill blue  -pointsize 12 \
                        -size 320x  caption:@-  caption_one_line.gif

            [IM Output]

            As you can see this works a lot better.

            However often what you want is to treat a blank line as a paragraph break. That means you need to remove all newlines, except those involved with blank lines. Here is a special "sed" command to convert such text into the format needed by "caption:". In this case the text is the first page of the "convert" manpage.


              man convert | col -b | expand | \
                sed '/^$/d; :loop y/\n/ /; N; /\n$/! b loop;  s/   */ /g; s/^ //' |\
                  head -n 7 |    convert -size 400x  caption:@-  caption_manual.gif

            [IM Output]

                There is no 'justified' text option to caption. But the pango: text formatter (using an external library), does have that feature, and a lot more.

            Text Attributes
            Orignal the settings that effect text handling included: "-font", "-fill", "-pointsize", "-size", and "-gravity". We have already introduced many of these attribute controls above. But there are other attribute controls that are not used as often, and originally did not effect "label:" or "caption:" text image generation.

            As of IM v6.3.2 you can also use the "-stroke", "-strokewidth", and "-undercolor". "label:" or "caption:". For example here I make use of a lot of different settings to control the attributes of the IM text image rendering...


               convert -background white -fill dodgerblue  -font Candice \
                       -strokewidth 2  -stroke blue   -undercolor lightblue \
                       -size 165x70 -gravity center label:Anthony     label_color.gif

                [IM Output]

            For more details on these settings see Undercolor Box below, and Stroke, StrokeWidth in the drawing section.

                At this time, you can not use tiling images defined using "-tile", "-fill", "-background", and "-origin", with either "label:" or "caption:". Only solid colors can be used. Attempting to so will just produce an undefined (black) color.

            Pointsize, Density and the Actual Font Size
            Pixels are dots on the display or in an image, and that is what IM works in.

            On the other hand, images are printed at a specific resolution (specified as 'dots per inch' (dpi) or pixels per inch (ppi)). As such an images resolution effects how other programs will size an image onto a specific media. EG: It effects the images physical size in the real world.

            The resolution (density or dpi) of an image is irrelevant to the pixel size of an image, and the amount of space an image takes in memory or on disk. It is also, in general, irrelevant to most IM image operations. As such, to ImageMagick, the resolution is just a set of numbers stored with the image, and is normally ignored. The only time the resolution or density of an image becomes relevant is for fonts and for converting vector formats like postscript, pdf, MWF, to the raster image formats IM handles.

            The "-density" setting tells IM how many pixels (dots) per inch (ppi) is present on the output device, which it can then use to adjust the image generation and font sizes to match.

            For example by default IM works with a "-density" setting of 72 ppi, which is a typical setting for displaying images on a monitor or webpage. As a fonts size is specified in 'points' (using "-pointsize" and by definition 1 point is 1/72 inches, then a 72 point font should produce text sized to be roughly 1 inch high...


              convert -pointsize 72 label:Hello  pointsize.gif

                [IM Output]

            However most modern displays have a better resolution than this, typically somewhere between 90 to 120 pixels per inch (ppi). As such...


              convert -density 90 -pointsize 72 label:Hello  density.gif

                [IM Output]

            Should produce a label that is 1 inch high on a 90 dpi display. It is on my display! You can measure the height of these images on your screen, to check on your displays resolution.

            As the number of pixels per inch is larger, the drawn font is also naturally larger in terms of the number of pixels in the image, and thus producing a larger image. Different image programs often have a different default density, and this may cause fonts to appear differentially when drawn by different programs, even at the same point size.

            Note that "-pointsize" actually means the line separation of a font (actually its drawing area height), and does NOT refer to the actual height of the drawn letters! As such one font can appear larger or smaller than another font, at the same pointsize and density. Only the line spacing of the fonts will actually be the same, anything else is dependant on the font and the font's designer.

            As such with a default "-density" of 72dpi (at which 1 point = 1 pixel) a 12 point font should have 12 pixels separation between the baselines to two lines of text.

                Note that the height of a generated "label:" image is based on the images drawing area or bounding box, which is often, the fonts line spacing and pointsize. This is not always the case, as such just appending lines of text vertically is actually incorrect font handling!

            Some fonts may even extend well beyond the normal line separation boundaries, extending well above or more commonly below the line spacing. This is especially true of hand script fonts.

            The look of a font is also effected by the fonts "-pointsize" and "-density".

            Doubling a fonts pointsize ("-pointsize 24") will also produce a font that looks about the same size as one with doubled density or resolution. However because a font is designed to look a particular way, the thickness of lines in a font may not change much at a larger point size. That is the larger font size is slightly different.

            But if you just double the density ("-density 144"), a 12 point font will be drawn with its dimensions doubled, should still look like the original 12 point font, just drawn at a larger scale with better smoothing of the edges.

            However at very low resolutions the physical size limitations of the pixels may also effect the look of a font. This means thin lines may be thickened at lower densities due to the large pixel size the density is defining. The relationship between 'density' and 'pointsize' is all a very complex issue, and one that only a professional font graphic designer can understand fully, and design their fonts to handle correctly.

            According to Lithium from the IM Forums...

                I think it is a feature of TrueType font renderer. TrueType glyph is not only a set of curves, it may contain multiple levels of detail and instructions that adjust point coordinates according to output size in pixels, which is more visible for small size in pixels. Because of that, small text looks different (and more clear, one can notice) than shrunk large text. 

            FUTURE Example: difference between font at same 'pixel' size, but different density and point size.

            Basically increasing one of these factors while decreasing the other by the same amount may not produce the same result. Particularly with regard to line thickness and overall 'style' of the font. You are better off adjusting the right factor for what you are doing. Use "-density" when scaling a font for an output device, or later resizing of the font, and use "-pointsize" for normal font size changes.

            If you would like to know more about fonts, then have a look at the document TrueType Fundamentals (PDF), which I found very interesting.
            Label Image Bounds
            When using some exotic fonts, the font may use extended characters, and in the past IM had lots of trouble creating labels for these fonts. That is the text overflows the provided canvas.

            For example here are two capital letters in a 'LokiCola' font reminiscent of a certain famous softdrink.


              convert -background lightblue -fill blue -font LokiCola -pointsize 64 \
                      label:HC  label_overflow_font.gif

                [IM Output]

            As you can see IM manages to contain this font in a label without cutting of the fonts leader or trailing graphics.

                Before IM v6.3.2, "label:" would have chopped of the 'H' lead-in and parts of the tails from both characters, in the above example.

            The reason this problem existed is because the fonts 'glyphs' or character description draw outside the fonts defined boundaries for specific letters, allowing them to overlap (generally either above or below) the other characters within the font.

            This is a problem with the way the font itself is designed and defined, and was not the fault of IM, though IM now handles these odd situations in the best interests of the users. In other situations it could still be a problem, and one that can not be solved simply due to multi-line text interactions. For more information see Bounding Box Overflow examples below, for a more precise description.

            Unicode or UTF8 Format Text
            This method of supplying string arguments to IM is very important as it allows you to do things which ordinarily could be very difficult to do from the command line. Specifically handling 'unicode text', or selecting specific characters using character codes.

            Now if you can type unicode characters into commands or scripts you can use them directly..


              convert -background lightblue -fill blue -pointsize 32 \
                      label:' é è à ù ç Ö ÿ ‘ ’ “ ” ° ² ³ € x ÷ '    label_i8n.gif

            [IM Output]

            However few people have keyboards or editors properly set up to handle unicode character input. Even if you can not directly type unicode characters, one simple solution is to just 'copy-n-paste' the desired characters from some existing UTF-8 text file, or web page. I do!

            If the UTF-8 text you wanting to draw has already been generated you can read it directly from a file using '@filename'. For example here I create a Chinese label from a UTF-8 encoded Chinese text file (without a final newline in the file).


              convert -background lightblue -fill blue -pointsize 48 \
                      -font ZenKaiUni label:@chinese_words.utf8   label_utf8.gif

            [IM Output]

                The font used in the above example is a special one, with the full set of Chinese Glyphs defined, such as the fedora linux fonts 'SimSun' (or in the font file "gkai00mp.ttf"), "ZenKaiUni" (in the file "ukai.ttf") or "ShanHeiSunUni" (in any of the files "uming.ttf" or "zysong.ttf" or "bsmi00lp.ttf").

            Note that the windows font 'Mincho' (used in a later example) also defines many of the Chienese Glyphs but incompletely. If you use it with the above you will get some question marks for undefined glyphs.

            The special script "imagick_type_gen" was used to find, extract the fonts proper name, and add the font into an ImageMagick "type.xml" configuration file.

            We can also generate UTF-8 strings from unicode character codes using the 'GNU' "printf" program (on linux systems) to convert unicode numbers to the specific UTF-8 encoded string, in this case proper typeset opening and closing quotes (again no final newline in the UTF-8 input).

            Here for example I generate the UTF-8 text using unicode character codes, and feed it using a command pipeline (read from 'stdin' using "@-"), rather than from an actual file.


              env LC_CTYPE=en_AU.utf8 \
                printf "\u2018single\u2019 - \u201Cdouble\u201D" | \
                  convert -background lightblue -fill blue -pointsize 36 \
                          label:@-  label_quotes.gif

            [IM Output]

            On other systems (like Mac OSX and Windows) you can use the perl "printf" to output an UTF-8 encoded character string from unicode character codes.


              perl -e 'binmode(STDOUT, ":utf8"); \
                print "\x{201C}Unicode \x{2018}\x{263A}\x{2019} Please\x{201D}";' |\
                  convert -background lightblue -fill blue -pointsize 36 \
                          label:@-  label_unifun.gif

            [IM Output]

            For more information and to look up the unicode character codes for various languages and symbols see Unicode Character Code Charts.

            Not only can unicode characters contain international characters, but with the right font you can also use special 'symbol' sets it defines. The most famous these is the 'DingBats' symbol font. This font has become so common that it is now part of the standard Unicode fontset.

            For example here I extract the first 24 characters of the 'DingBats' unicode symbol area using a special "graphics_utf" shell script I wrote to generate a 'block' of unicode characters as UTF-8 text.


              graphics_utf -N 2701 2718 |\
                convert -font Mincho -pointsize 32 label:@-   label_dingbats.gif

            [IM Output]

            The question marks in the above are specific characters which were not defined by either unicode, or in the windows 'Mincho' font. More specifically the symbol that was part of the original 'dingbat' font is present in unicode, but using another unicode character code, than the expected dingbat code. See Dingbats Unicode Specification Chart for more detail, and its referal to the correct unicode character to use for the 'missing' dingbat characters.

            Rather than a question mark, many fonts would just print a box or a blank character for such undefined characters. If you see too many such characters, or missing characters in your output, you probably should be using a different font.

            Other symbol sets also available as part of the enormous unicode character font include: Tolkan runic symbols, mathematical symbols, roman numerals, arrows, Braile and technical symbols. It is a large set to explore, and the "graphics_utf" shell script can help you explore it.

            Here is another example of unicode characters which the Microsoft 'Mincho' font can render. In this case from the "Miscellaneous Symbols" section...


              graphics_utf -N 2620 2630 |\
                convert -font Mincho   -pointsize 40 label:@- label_misc.gif

            [IM Output]

            Using unicode within DOS scripts is must harder than under UNIX and LINUX. Special notes on using unicode from that environment has been provided by Wolfgang Hugemann, in Windows Character Encoding.

            Symbol Fonts
            More commonly used by people looking for special text images, are special 'symbol fonts'. These are much smaller than the full large Unicode font, as they replace only the normal standard ASCII characters (letters and numbers) with a different set of specific shapes and images, though sometimes (rarely) they also have more symbols in the Latin meta-characters area.

            The 'DingBat' font symbols started out in this way, but as mentioned above they are now part of the Unicode character set.

            For example, one symbol I rather like to use comes from the font "WebDings". It is a rather nice 'curvy heart' symbol, which is replaces the normal 'Y' character in that fonts defintion...


              convert -size 20x20 -gravity center -font WebDings label:Y label_heart_20.gif
              convert -size 40x40 -gravity center -font WebDings label:Y label_heart_40.gif
              convert -size 60x60 -gravity center -font WebDings label:Y label_heart_60.gif
              convert -size 80x80 -gravity center -font WebDings label:Y label_heart_80.gif

            [IM Output] [IM Output] [IM Output] [IM Output]

            The important thing to remember is that all truetype fonts are actually a special type of Vector Image Format. With multiple images (one for each character) in the font. As they are vector images, it means the font should allow you 'draw' a character, shape or symbol at any just about any size (scale), using the controls provided by "-size", "-pointsize", and "-density".

            As you can see above, the 'curvy heart' can be 'rendered' at pretty much any size I desire.

            Some fonts are very specialized. For example you can get a font file from IDAutomation called "IDAutomationHC39M.ttf" that can be used to generate barcodes. For example...


              convert -font IDAutomationHC39M -pointsize 16 label:'*314-76*' \
                      -bordercolor white -border 5x5  label_barcode.gif

                [IM Output]

            Here is some other interesting symbols I have found in various symbol fonts I have collected for one reason or another...


              convert -pointsize 48 -font WebDings label:' " _ ~ ) - '  label_webdings.gif
              convert -pointsize 48 -font LittleGidding label:' x o w ' label_ltgidding.gif
              convert -pointsize 48 -font WingDings2      label:'ab'    label_wingdings2.gif
              convert -pointsize 48 -font Zymbols  label:' ? , - I Z '  label_zymbols.gif
              convert -pointsize 48 -font TattoEF  label:' B Y D I H '  label_tatooef.gif
              convert -pointsize 48 -font SoundFX  label:' V 3 t f 9 '  label_soundfx.gif

            [IM Output] [IM Output] [IM Output] [IM Output] [IM Output] [IM Output]

            This is only a small sample of what is available. Huge libraries of just about every symbol, shape, or image, imaginable is available on the WWW for you to browse and download.

                Remember that each drawn character has two separate parts that can be drawn: the 'filled' area (which I showed above), and the 'stroke' or outline, which can look very different to the filled area. Each of these areas can be drawn separately, or in different colors, so it may be a good idea to examine a promising symbol or shape more closely, in a number of ways. You may get a very surprising result. See Compound Fonts, Stroke for some examples of doing this.

                Many creators of symbol fonts generate the shapes using a simple scanner and bitmap to vector converter, without any proper design or cleaning of the image or shape. Caution is recommended when looking at such 'scanned' fonts.

            The last font shown above is one such example of a 'scanned' font, giving it a poor looking 'dotty' quality, when compared to the other more properly designed fonts.

            Inter-character Kerning
            As of IM v6.4.7-8 you can use "-kerning" to insert extra inter-character space between each letter in text strings. For example


              convert -pointsize 12               label:Anthony   label_kerning_0.gif
              convert -pointsize 12 -kerning 1    label:Anthony   label_kerning_1.gif
              convert -pointsize 12 -kerning 2.5  label:Anthony   label_kerning_2.gif
              convert -pointsize 12 -kerning 5    label:Anthony   label_kerning_5.gif
              convert -pointsize 12 -kerning -1   label:Anthony   label_kerning-1.gif

                [IM Output] [IM Output] [IM Output] [IM Output] [IM Output]

            Note that the actual kerning value can be a floating point value, or even a negative value.

            For another example of using a negative "-kerning" value see the Joined Compound Font example.

            Inter-Word Spacing
            Also as of IM v 6.4.8-0 the option "-interword-spacing" can be used to modify the size of a space character used between words. For example


              convert                        label:'I Love IM!'  label_wspace_off.gif
              convert -interword-spacing 1   label:'I Love IM!'  label_wspace_1.gif
              convert -interword-spacing 10  label:'I Love IM!'  label_wspace_10.gif
              convert -interword-spacing 25  label:'I Love IM!'  label_wspace_25.gif

                [IM Output] [IM Output] [IM Output] [IM Output]

            Note how you can not only increase the size of a space character between the words but also decrease the default size.

            Note however that spaces will cause the words to be re-aligned to pixel boundaries (unlike Inter-character Kerning above) so the output of a label with spaces set to zero will still be different to a label that does not contain any spaces at all.

            Both the Inter-character Kerning and the Inter-word Spacing will also effect the results of IM's ability to automatically fit a text string to a specific sized image.


              convert -size 150x                       label:'I Love IM!' label_wsize_of.gif
              convert -size 150x -interword-spacing 25 label:'I Love IM!' label_wsize_25.gif
              convert -size 150x -interword-spacing 50 label:'I Love IM!' label_wsize_50.gif

                [IM Output] [IM Output] [IM Output]

            What is happening is that by setting the "-interword-spacing" the 'space' character size no longer changes with the rest of the text size. Thus as IM trys to work out the best "-pointsize" the amount of space between each word is fixed, and thus play no part in the fitting of the text into the given fixed width. As a consequence the larger the "-interword-spacing" the smaller sized font that is needed to actually to fit the line of text into the same specified image width.

            A negative value can be used, and can in fact to make words overlap, or produce unusual effects using specific characters and fonts. But make it too negative and undefined behaviours can creep in. Caution is advised if you try this.

            While the above is not an example of text justification (though it looks like it), you can use these options as a starting point to providing proper text justification.

            If you really need that level of text formating and justification, then you may be better off looking at other methods of generating pre-formated text or Postscript, such as the command line basied "TeX" or "LaTeX" software. Better still you could use SVG (rsvg library version), or Pango Markup Language (see below), to generate justified text.

            Inter-Line Spacing
            As of IM v6.5.5-8 an another option was added "-interline-spacing". This was heavilly requested by users in light of the previous settings, and in many ways is much more useful.

            Basically it will add or subtract this many pixels between the individual lines of text. That is you can use it to expand or squash together the individual lines of text.

            For example....


              convert                         label:'First\nSecond'  label_lspace_off.gif
              convert -interline-spacing  5   label:'First\nSecond'  label_lspace_5.gif
              convert -interline-spacing 10   label:'First\nSecond'  label_lspace_10.gif
              convert -interline-spacing 20   label:'First\nSecond'  label_lspace_20.gif
              convert -interline-spacing -5   label:'First\nSecond'  label_lspace-5.gif
              convert -interline-spacing -10  label:'First\nSecond'  label_lspace-10.gif

            [IM Output] [IM Output] [IM Output] [IM Output] [IM Output] [IM Output]

            To make best use of this setting you need to be able to calculate the normal line spacing for a specific font. This is the actual definition of "-pointsize", which with the current resolution or "-density" setting defines the line spaceing of a font. It does not actually define the fonts actual height or line thickness, though it effects these aspects of a particular font.

            So taking a "-density" of '72' dots per inch, and knowning that by defintion there are 72 'points' per inch. you can calculate that a 12 point font will have a line spacing of 12 pixels.

            With that information you can 'double-space' your 12 point text lines by using a setting of "-interline-spacing 12". This will add 12 extra pixels between lines.


              convert -density 72 -pointsize 12 -interline-spacing 12  -font Arial \
                      label:'First\nSecond\nThird'  label_lspace_double.gif

                [IM Output]

            Of course as previously seen for interword size, adding a constant number of pixels between text elements will tend to make the text smaller when automatic pointsize handling is used. That is a final image "-size" is provided without a "-pointsize" setting.


              convert -size x70  -interline-spacing 18  -font Arial \
                      label:'First\nSecond\nThird'  label_lspace_size.gif

                [IM Output]

            Using a negtive interline spacing can also be used as a rough and ready method of vertically 'bolding' a line, simply by repeating that line, and subtracting 1 more pixel than the baseline separation.


              convert -density 72 -pointsize 12 -interline-spacing -13 -font Arial \
                      label:'Bolded Word\nBolded'  label_lspace_vbold.gif

                [IM Output]

            Of course this will not work if you really want two lines, and not just bolding text. It also works better with a fixed width font.

            Special Escape Characters in Text Arguments
            We have already introduced the special escape characters used in various text arguments, above. Specifically you can escape special characters like newlines using backslash '\', or you can insert extra information into the string using percent '%' escapes, as defined on the Image Properties page.

            Also there is a special '@' escape that if used at the start of a line will use the rest of the text argument as a filename to read the data from the file specified (or STDIN in '-' is used).

                Some system (like ubuntu) disable the use of the '@{file}' escape using security policy. Type convert -list policy to see what policies and where they are set from are present on your system.

            Not only do these escape characters effect "-format", for use by the "identify" (as well as "-identify" and the "info:"), but they also effect "label:", and "caption:" text to image generators, and control the image meta-data setting options "-label", "-comment", "-caption". And finally they are also used by "-annotate".

                While backslash '\' is used by the "-draw" 'text' method, the percent '%' escapes are not as it interferes with ImageMagick's SVG image handling. This was one of the reasons the "-annotate" operator was created for IM version 6.

            The other important point about escape characters is that while they are used for command line text arguments. At no time do they apply within the data being read from a text file (usually read in using the '@' escape).

            This means you do not need to worry about escaping 'escapes' for text file data, but it also means you have to process file data yourself outside of IM if you need to insert information into the text.

                Protecting input text file from escape handling was finalised in IM version 6.3.3.

            For example here I set and the report an images 'label' and 'comment' meta-data using the two methods to set that information from a source text file. The "info.txt" file contains the string [IM Text], (no final newline).


              convert -label   @info.txt  rose:      -format '%l label'   info:
              convert -comment @info.txt  rose:      -format '%c set "'   info:
              convert  rose: -set label   @info.txt  -format '%l caption' info:
              convert  rose: -set comment @info.txt  -format '%c set "'   info:

                
            [IM Text]

            Notice that IM did not expand any of the escape character sequences that it read in using the '@' file read escape. This is important as it means that any time IM reads text from a file, it will never handle any special characters that was present in that file.

            IM reads text files, as literal text, without any escapes

            Unfortunately this also includes any final newline that may be present in the file (or stream) that is being read! This can result in an extra 'blank' line in the resulting image, when the input text has a newline on the end (a very common practice). For example...


              echo "Anthony" | convert label:@-  label_stdin.gif

                [IM Output]

            As you can see the label not only contained the input string but also an extra blank line due to the newline character that the "echo" command added on the end.

            If you don't want that final newline, you will need to remove it yourself. This however could be a tricky matter, depending on where and how the text is sourced or created, and what API, you are running IM from.

            The best way is to try not to generate that final newline to begin with. For example using a '-n' flag to "echo".


              echo -n "Anthony" | convert label:@-  label_stdin_2.gif

                [IM Output]
            Or using something that does not add extra newlines unless you specifically request it.


              printf "Anthony" | convert label:@-  label_stdin_3.gif

                [IM Output]
            Or you can 'junk' that final newline using a tricky little perl one-liner...


              echo "Anthony" | perl -0777 -pe 's/\n$//' |\
                 convert label:@-  label_stdin_4.gif

                [IM Output]

            In other API's you can look for that final newline before feeding the text to an IM command via a 'piped open'.

            User defined option escapes
            A major problem is trying to use escaped information from one image, in some other image, such as when generating a separate "label:", or "caption:" image.

            This is a very difficult problem, and the current solution, (for a single image) is to create a special 'user option', that is attached to an image being processed. This 'setting' can then be looked up by the "label:", "caption:", or "-annotate", as a percent escape sequence, when needed.

            For example here I create a completely new label image using information from the built-in rose image. That information source image is then deleted, though I could just as easily append the new label to the original image.


              convert rose: \
                      -set option:roseinfo 'rose image\nsize = %w x %h\nwith %k colors' \
                      label:'%[roseinfo]'  -delete 0   label_escape.gif

                [IM Output]

            Yes the above is tricky, but that due to some internal IM core library limitations that are involved. See Accessing Data from other images for more details.

            Escaping Escapes
            If you must feed a string as an argument to IM (especially as an API call), but don't want IM to expand escapes, you can simply 'escape' all three escapes using an extra backslash '\'. Note the '@' only needs to be 'escaped' if it is the first character, and for backward compatibility, percent escapes can also be escaped by doubling it. That is '%%' will produce a single percent. For example...


              convert -background lightblue -fill blue -font Candice -pointsize 48 \
                      label:'\@ \\n \% 5%% '    label_escapes.gif

                [IM Output]

                Before IM version 6.3.2, you could not use a backslash to escape an initial '@' to turn off the 'read from a file' function. In that case the only way to escape an initial '@' was to read it from a file. This was not very practical in API's.

            Here is a similar 'escape the escapes' example for "-annotate"...


              convert rose:  -fill white -stroke black  -font Candice  -pointsize 20 \
                      -gravity center   -annotate 0 '\@ \\n 5%%'  annotate_escapes.gif

                [IM Output]

            Of course as previously shown, reading the text from a file (using the '@' escape), will always be treated as literal, without any special meaning. This avoids the need for any pre-processing of the text, just watch out for any final newlines.


              echo -n '@ \n 5%' |\
                convert rose:  -fill white -stroke black  -font Candice  -pointsize 20 \
                        -gravity center    -annotate 0 '@-'   annotate_escapes_file.gif

                [IM Output]

            In other words when reading from a file you don't have to worry about escaping things, but can just write exactly the text you want IM to use.

            Escapes on Older versions of IM
            The above definitions were only finalised in IM version 6.3.3. Before this escapes were sometimes handled in some options, and sometimes not, according to any requests, problems, and complaints, sent by IM users.

            This was especially the case with regards to the percent escapes with "label:" and "caption:", which was for a period deemed as 'non-sensible'.

            For example whether you see a '%c' in the following label image is very version dependant (at least before IM v6.3.3).


              convert -background lightblue -fill blue -font Candice -pointsize 48 \
                      label:'ab%cde'    label_percent.gif

                [IM Output]

            If you see a 'abde' (percent escape applied) or 'ab%cde' (percent not applied) depends on exactly what version of IM you are using.

                IM v6.2.4, percent escapes were removed from "label:" and "caption:" as being non-sensible.

            However they returned in IM v6.3.2, as a new '%[fx:...] construct, which can reference any image, made percent escapes in text to image generators useful again. See FX Expression Escapes.

            This 'what is escaped' was also a problem with regard to the handling of escapes from files. Before IM v6.3.3, the following would have produced two lines, rather than a single line.


              echo -n ' Love \n/ Hate ' |\
                convert -background lightblue -fill blue -font Ravie -pointsize 18 \
                        label:@-    label_escapes_file.gif

                [IM Output]

            As the results of escape handling vary greatly from version to version, in IM's older than v6.3.3, I recommend that scripts test its escape handling, adjust themselves if it is important to the programs correct working.

            If anyone like to create an automatic test for IM scripts, please contribute. Or if you find such as test, please let me know.

            Pango - Basic Formatted Text
            The "pango:" text coder (fully working as of IM v6.7.6-3) works in much the same way as the Label and Caption coders. It provides a limited text formatting language on systems in which "Pango" is installed. On Linux and MacOSX systems pango is standard, on Windows it is optional.

            Here is a simple example without using any special pango formatting...


              convert -background lightblue pango:"Anthony Thyssen" pango.gif

                [IM Output]

            However you should note that some of the previous Text Attributes will not work with pango, basically due to its text formatting requirements. For example while you can set a "-background" color, you can not set the default fill, or undercolor, nor the specific font to use. This is because these attributes are selectable via the Pango Markup Language instead (see below).

            It is recommended that you use "-size" to define width and height limits to the output image, to which pango will automatically word wrap (or character wrap, for chinese) the input text.


              convert -background lightblue -size 150 \
                      pango:"Anthony Thyssen is the main author of IM Examples" \
                      pango_size.gif

                [IM Output]

            And you can even have Pango 'justify' the text properly using the Define, "pango:justify"...


              convert -background lightblue -size 150  -define pango:justify=true \
                      pango:"Contributions to IM Examples are welcome via the IM Forum." \
                      pango_justify.gif

                [IM Output]

            Note however that while text can be justified, spaces and newlines are still taken into account by the text formatted.

            Also pango understands the use of TAB's (unlike label and caption).


              printf "col1\tcol2\nabc\txyz\n123\t789" |\
                 convert -background lightblue  pango:@-  pango_tabs.gif

                [IM Output]

                Note that while the "printf" command above can generate tab characters, using the '\t' escape, IM does not understand the use of such an escape. It does however understand the '\n' escape sequence in strings.

            However generating columns using TAB's does not work very well as you can't easily define the 'tab-stops' outside the API. As such using TAB's in this way is not recommended, except as line and paragraph indentation .

            Pango Markup language
            The real power of pango however is in the "Pango Markup" language, which is enabled by default. You can turn off pango markup using "-define pango:markup=false", but then you may as well be using Caption instead.

            The "Pango Markup" is much like HTML, in that you use a set of "<...>" markup tags hidden in the text, and which is used to control how the text is to be formatted.

            Here are some guides on the Markup Language (without the API junk)

                The Pango Markup Language
                Pango Text Attribute Markup Language
                (from Gnome)
                Pango Text Attribute Markup Language
                (From GTK)
                Pango Script Gallery (examples)

            For example..


              convert -background lightblue -gravity center -size 180x \
                      pango:"The <b>bold</b> and <i>beautiful</i>" \
                      pango_formatting.gif

                [IM Output]

            The "<span ... >" tag is the main tag to use in pango mark up. It allows you to control the exact size, color, and position of the contained text. For example..


              convert -background lightblue \
                   pango:'  Some  <span size="49152" rise="-20480"
                            foreground="red" background="blue"
                             > Big Red on Blue </span>  Text  ' \
                   pango_span.gif

            [IM Output]

            Note that most numerical values are multiplied by a factor of 1024 as such the the value of "size="49152"" in the above example, means a text pointsize of 48 points. While the negative rise ("rise="-20480") means to lower the text position by 20 points (or pixels at 72dpi).

            But instead of specifing a pointsize for the text I can also use a special size label such as "size="x-large"". See the source code of the next example.

            Watch out for the quotes within quotes in the above. The quotes within the tags are required. However newlines and extra space within tags will take no part in the formatting of the text. As such hiding extra newlines in a markup tags, or in a markup comment "<!-- ... -->", can be very useful. Again see the source text of the next example.

            As a final example of the power of pango formatting here I use it to format a pre-prepared file "pango_test.txt". This contains most of the common pango markup tags you are likely to use. Compare this markup file to the resulting image below.


              convert -gravity center pango:@pango_test.txt  pango_test.png

            [IM Output]

            Pango Notes and Problems

            Gravity
                I have not been able to get pango to selectively center just a single line of text. You can only center everything, or nothing via the "-gravity" setting.

                The reason for this appears to be because pango is designed to generate separate text labels for applications. That is titles are usually generated separately to the main body of displayed text.

                Pango is is not meant to be a whole scale text page formatting engine.

            Fonts
                Pango can change fonts in the middle of rendering. It already does so easily for bold and italic text. However the font specification is from GTK, and as such uses a different system to ImageMagick in general.

                You can find out more about fonts using GTK, by running the "gtk-demo" program, and double clicking "Pickers" and the "Text Widget".

            Defines
                There are lots of special Defines that can be used to globally control various aspects of pango text formatting. These are currently listed on the Pseudo File Formats, though I have not explored all of them myself.

                These are the ones I have used...

                -define pango:markup=false
                    Turn off the markup language tags. Any tags are then included in the output. No pango formatting within the text is possible. this is especially useful in debugging, letting you see exactly what pango sees for its input.

                -define pango:justify=true
                    Justify text across the width of the image size. That is add extra intra-word spacing so both left and right edges of a block of text lines up.

            More Information on Pango
            To see just what is posible see Pango Script Gallery

            If you do something interesting with pango, please contribute. Either mail me (Address in page footer), or post it on the IM Discussion Forum.

                On systems with pango installed you can also use the command "pango-view" for generate pango formated images. However its default 'density' or 'dpi' setting is your display (IM uses 72 dpi by default) and as such may vary from host to host.

            Text - Pages of Plain Text
            The "text:" input format is designed to convert plain text into images consisting one image per page of text. It is the 'paged text' input operator of ImageMagick.

            In other words its purpose is to convert the larger preformatted text files into pages in much the same way that printers print plain text onto separate pieces of paper.

                Do not confuse the "text:" file input format with the similar "txt:" input format. The latter will first attempt to read the file as a 'IM pixel enumeration' image format.

            That doesn't mean that a plain text file with a ".txt" will fail. In fact such a file will probably be converted as you would expect, as the "txt:" file format will automatically fall back to the "text:" format if an enumerated image is not recognised.

            Handling text in this way however had a number of problems. First the text is drawn onto a large canvas, leaving you with the problem of removing the unused space, if such space is not wanted. The other is that lines are not 'word-wrapped' but will overflow canvas and get truncated if they are too long. And finally, for very long text files, multiple pages (images) will be generated unless some extra precautions are taken.

            On the other hand, "text:" will handle just about any text file, without modifying the final image size produced, or word-wrapping very long lines. You also do not need to pre-process and special characters as you would if you used the text on the command line. Finally and more importantly if a fixed width font (like Courier) is used, files with spaced out columns of data, will still have that data in spaced out columns.

            Basically "text:" will convert the input file 'AS IS'.

                The input text data read from the file is essentially passed directly to the font library to draw the UTF text. As a consequence of this some control characters may be drawn using unusual 'glyphs'. This includes TAB and FORMFEED characters, which, at the time of writing, the 'freetype' library gets wrong.

            If this is a concern, you may like to pre-process your text file using a filter program, such as "expand", to convert TAB characters into the appropriate number of spaces.

            When drawing text, a large 'letter' sized page is created (or the page size or type specified with a "-page" )at the current resolution (set with "-density"). By default (at 72 dpi) this will be '612x792' pixels in size, which for most purposes is very large.

            For example here is a direct conversion of the plain text formatted manual for the "convert" command, into an image (it is large so to see it select the 'page' image on the right to see it)...


              man convert | col -b | expand | \
                convert -font CourierNew  text:- -delete 1--1 text_manpage.gif

                [IM Output]

                The above manual to image conversion however generates multiple pages (images), so I Deleted the second and later ones to leave me with just the first page, instead of a GIF animation of all the pages.

            I could also have appended a Read Modifier, '[0]' input filename, such as "text:-'[0]'", to tell IM only to read the first image generated. Though at this time all the page selection is still handled by generating all pages and deleting the unwanted pages.

            I purposely used the 'fixed-width' font 'CourierNew' in the above so as to preserve the character spaced formatting that is present in the printed page.

            Note how this output varies from that of caption: above. The overall look of this image can also be improved by using the same techniques given in Postscript section next.

            If you just want to know how big say a 'A5' page is at 100 dpi, then this command generates a single blank page, of that size and returns its size in pixels. The filename, "/dev/null", is a special UNIX file that is always empty.


              convert -page A5 -density 100 -units PixelsPerInch  text:/dev/null \
                      -format 'Page Size at %x = %w x %h pixels'  info:

            [IM Text]

            Trimming Text Pages
            Because the text is being 'drawn' onto a large canvas, you will likely want to remove all the unused space produced. This can be done by using the image operations "-trim", "+repage", then to make it look reasonable, re-adding some edge space using "-border". Of course you will also need to match the "-background" color you used as the "-bordercolor" you are re-adding.

            Sounds complex? It isn't really, for example...


              echo "    Hello Cruel World    " |\
                convert -background  lightblue  -fill blue  -pointsize 18 \
                        text:-    -trim +repage  -bordercolor lightblue  -border 3 \
                        text_trimmed.gif

            [IM Output]

            In the above example "-trim" is used to remove the vast amount of extra white space in the "text:" page image. This however will also remove any leading spaces in front of a line!

            There is however an interesting technique which will allow you to "-trim" the image down to the size of the actual text drawn onto the page, including any leading and trailing spaces in the input. This uses a special "-undercolor" setting (looked at in detail later).


              echo "    Hello Cruel World    " |\
                convert -background  white -undercolor lightblue  -fill blue \
                        -pointsize 18   text:-  -trim +repage \
                        -bordercolor white  -border 3    text_boxed.gif

            [IM Output]

            The extra space at bottom of the text is a result of the last 'newline' character in the text input, creating an extra blank line in the image. But as you can see the leading and trailing spaces of the input text was preserved.

            If you use a transparent background color in the above, you can then flatten the trimmed image to convert the undrawn areas into the same color as the 'undercolor' used.


              echo "    Hello Cruel World    " |\
                convert -background  none  -undercolor lightblue  -fill blue \
                        -pointsize 18   text:-  -trim +repage  \
                        -bordercolor lightblue  -border 3 \
                        -background lightblue  -flatten    text_box_trimmed.gif

            [IM Output]

            The result of the above (except for the added "-border" is actually almost exactly what IM now produces using a "label:" and reading from a '@' escaped filename. However "label:" does it in a faster, and far cleaner way (via the "freetype" library rather than a postscript conversion).

            You can specify a smaller "-page" size, either in pixels (see next example), or using a media page size (such as 'A5'), using the "-density" or pixel resolution setting. You can also specify the offset at which to start drawing the text on the page, relative to the top left corner. For example...


              echo "This is a long line that shows that 'text:' does not word wrap." |\
                 convert -background  lightblue  -pointsize 18 \
                         -fill blue  -page 320x95+50+10  text:-'[0]' +repage  text_page.gif

            [IM Output]

                Almost all other image creation operators use the "-page" setting to set a larger virtual 'canvas' and an 'offset' for the image on that canvas, generally for the purpose of layering images or generating animations. Because of this it is probably a good idea to reset your page setting using "+page" after any "text:" or "ps:" operation, or you may get unexpected results for any secondary images you may latter read in on the same command line.

            This also is why I added a "+repage" operator to the above example otherwise the text is offset, and the image generated is also offset!

            For more details of using this offset see Page Image Attributes.

            Note how in the last example, any text line that is too long to fit the width of the page will overflow the page, and not be 'wrapped'. This will effectively crop and junk the end of the lines. Also if there are too many lines, then "text:" will generate multiple pages and thus multiple images, one for each page generated by the postscript translation of the text file.

            If you are only interesting in the first page of text, or just want to avoid the possibility of multiple images, add a '[0]' to the "text:" filename, to tell IM to only read the first page generated after the text has been converted to images (see previous example).

            Postscript/PDF - Pre-formatted Text and Graphics Input
            (or other vector image formats)
            The following gives a standard vector image handling technique that can not only be used for "PS:" (postscript) images but all other images handled using vector graphics. This includes image formats such as: "PDF:" (portable document format), "TEXT:" (paged plain text), and even "SVG:" (scaled vector graphic) and "WMF:".

            This method can be expanded to give you a very fine control of exactly how the text will look as an image. For example with the right 'text to postscript' filter, you can control the word wrapping, justifications, multiple font handling, bolding, borders, titles, filenames, dates, and other fluff in the postscript image.

            However as this section is about text to image, it means you need to first convert your text to a formatted postscript file. There are lots of external programs that can be used to do this. For example "a2ps", "enscript" or "pstext".

            Essentially you can use a word processor (like 'OpenOffice' or 'Word', or even 'Notepad'), OR if you want a batch text processing system you could use at 'TeX' and 'LaTeX' to generate your pre-formatted text (see A Complete Text Processing System below). These programs are all designed to handle the complexity of mixing plain, bold, different size, and font text together, along with word-wrapping, justification and paragraphing controls. The output from these programs can then be passed to IM to convert it to an image of the size and quality you desire.

            So lets first generate some postscript (converting text from a personal fortune program).


              mesgs LN-ManKzinWars | \
                a2ps -q -1 --rows=10 --prologue=bold \
                     --center-title="Postscript via 'a2ps'" \
                     --header='' --left-footer='' --right-footer='' \
                     -o ps_version.ps

                [IM Output]

            Now we can convert that into an image, trimming the result (as per "text:" examples above) to remove the excess blank areas from the default page/canvas generated.


              convert ps_version.ps'[0]' \
                      -trim +repage   -bordercolor white -border 3  ps_version_raw.gif

            [IM Output]

            Note the use of '[0]' to limit the input to just the first page. If your postscript image generates multiple pages, it will still be completely processed by the "ghostscript" delegate, but IM will only read the first image returned, rather than generate multiple images, one image per page. If you postscript is very large, you may like to use other postscript utilities to limit the number of pages before processing it with IM and "ghostscript".

            As you can see postscript converted to the default "-density" of 72 dpi, often does not look as good as it should, with only a minimal amount of anti-aliasing. This is particularly the case when dealing with postscript fonts, which are not designed to work at these low-resolutions.

            To improve this, you can use a Super Sampling technique to generate a better image. In this case you ask "ghostscript" draw the page at a higher resolution (or image "-density"). You can then "-resample" (a specalized resize) to bring this larger image back to a more 'normal' screen resolution density.


              convert -density 196   ps_version.ps'[0]' -resample 72 \
                      -trim +repage   -bordercolor white -border 3  ps_version.gif

            [IM Output]

            The value '196' is 3 times the final 72dpi, which means when "-resample" is used approximately 3×3 pixels are merged down into each pixel. This produces better anti-aliasing pixels along the edges of the text improving the overall look of the result.

            Also note that using a larger density or resolution is not quite the same as just enlarging a font. The font definitions could have adjustments for handling low resolution situations. For example compare the hole in the letter 'e' in the two images. The original version is sharper due to special handling within the font, even though over all the latter super sampled version is clearer. For more information see Resolution, Pointsize, and Actual Font Size below.

            You don't have to use the values above, as sometimes slightly different value may produce a better or more desirable result. Of course having "ghostscript" generate an image 2, 3, or even 4 times larger also means IM will take 4, 9 or 16 times longer to generate the image! It will also use that much more memory and temporary disk space! But the results are generally worth it. The best idea is to just try it out for your own document, and see what gives you the best results.

            Also if you need more anti-aliasing, rather than using an even larger input resolution, you could try blurring the image by a sub-pixel amount (say '-blur 0x0.7') before you reduce its size. I have also sometimes found that a very small amount of unsharpening after the resize (a common photoshop technqiue), can improve the overall final result.


              convert -density 196   ps_version.ps'[0]' \
                      -blur 0x0.7 -resample 72 -unsharp 0x0.7 \
                      -trim +repage   -bordercolor white -border 3  ps_unsharp.gif

            [IM Output]

            But I would be careful of these adjustments, as it could make things worse.


            If you like to have a transparent background instead of white, you can specify a "-channel" setting of 'RGBA', to include the alpha channel in the image. Of course you will need to use an image format that can handle semi-transparent colors.


              convert -channel RGBA -density 196  ps_version.ps'[0]' -resample 72 \
                      -trim +repage   -bordercolor none -border 3  ps_transparent.png

            [IM Output]

            Notice that the banner still uses an off white color for its backgrounds, rather than also being made transparent or semi-transparent. That is because the postscript generated actually draws that background, replacing the default background of the page (be it white or transparent).

            Making the background transparent like this will allow you to overlay your postscript image on a specific background color.


              convert ps_transparent.png -background skyblue -flatten  ps_bgnd_color.gif

            [IM Output]

            Using a Alpha Compositing Method you can even overlay it onto a specific background image, or a tiled background.


              composite -tile bg.gif  ps_transparent.png  -compose DstOver \
                        ps_bgnd_tiled.gif

            [IM Output]

            As almost all postscript printers only can darken paper or an overhead transparency, (this includes color printers), when the above is printed the banner would be made semi-transparent automatically.

            If you also want IM do the same thing, as what a printer would do, you can use a special 'Multiply' alpha composition, to overlay the 'white background' image, onto the desired 'paper' background.


              composite -tile bg.gif  ps_version.gif  -compose Multiply  ps_multiply.gif

            [IM Output]

            If you have a color postscript image, you also can simulate a pure black and white printer onto colored paper by using the special 'BumpMap' compose method. This will grey-scale the source overlay image, before it uses uses multiply to composite the images together.

            You can also generate the grey-scale image equivalent of an overhead transparency slide. This basically uses the opaque, white background image (from above) as a 'mask' which to set shaped transparent image using the Alpha Shape Operator


              convert ps_version.gif -negate -background black -alpha shape  ps_overhead.png

            [IM Output]

            Like the "text:" converter above, the "ps:" converter also makes use of the "-page" setting to set the canvas size of the image 'media' onto which the page is drawn. Though offset supplied will be ignored. However as most postscript files define the drawing media size internally, this is usually not necessary.

                Most other image creation operators use the "-page" setting to set a 'virtual canvas' and an ofset on that virtual canvas (for example to generate GIF animations). As such it is probably a good idea to reset it using "+page" after using it for a "text:" or "ps:" image read operation, otherwise you may get unexpected results with the later images.

            For more details of using this offset see Page Image Attributes.

            As a final practical example, have a look at my Ray Traced Tetrahedron image. Other similar images can be seen in Studies into Polyhedra.

            The background page was generated from the same data used to produce the displayed 3D mathematical object. The text data was converted using "a2ps", then IM was used to convert this to an image. Onto this image other pre-prepared line drawings of the same mathematical object was added to the page. This final image (saved in 'targa' or TGA format) was then passed to the "PovRay" ray-tracer for inclusion in the final image or ray traced scene.

            Using GhostScript Directly
            While this not strictly IM, Richard Bollinger has reported that running the "ghostscript" delegate directly is much more efficient, producing an order of magnitude faster processing due to less file handling, by IM.

            For example instead of running...


              convert -density 300x300 -compress Group4 file.ps  file.tif

            You can get GhostScript to do it directly.


              gs -dBATCH -dNOPAUSE -sDEVICE=tiffg4 -r300x300 \
                 -sOutputFile=file.tif  file.ps

            This prevents the need for IM to generate a large temporary file (for security and pipelined image handling). As a result of this, direct use of GhostScript can save quite a lot of file handling and IO processing, and can produce a major performance boost when processing postscript and PDF files.

            However "ghostscript" can not resize images, (other than adjust the output density or resolution) and will probably not be able to output the image in the image file format you require, or at the quality you want. But you can always then feed the GhostScript output to ImageMagick to finish the task.

            That is especially the case if you want to super-sample the results (higher resolution input, to resized smaller output).

            GhostScript can be a difficult program to figure out how to use, or fix for specific types of postscript. Cristy constantly battles with these issues on behalf of IM users, and in this he has done a super effort. Unfortunately in dealing with the many things that can (and does) happen, IM can not provide a simplified method for postscript/PDF via GhostScript.

            Draw - Draw Text on Existing Canvas
            By using the low level "-draw" operator to draw the font we get a lot more control, especially as to the exact position of the font, and the size of the image it is drawn into.


              convert -size 320x100 xc:lightblue  -font Candice -pointsize 72 \
                      -fill blue  -draw "text 25,65 'Anthony'" text_draw.gif

            [IM Output]

            However to use it we need to generate a background image of the appropriate size to draw the font, which can be tricky when drawing some unknown text. See Auto Sizing of Font Images for ways to solve this problem.

            A lot of extra options, beyond the standard text options also effect how "-draw", actually draws text on an image. Not only can you specify a "-fill" color, but you can also specify a "-undercolor", as well as an edge or "-stroke" color, both of which are turned off by default (set to a color of 'none'.

            The "-fill" color can also be replaced by a "-tile" image pattern, while the stroke edge width can be changed using "-strokewidth". Then the relative position of the drawn text can be changed a with "-gravity" setting.

            For example here I used many of the extra features I just mentioned.


              convert -size 320x100 xc:lightblue  -font Candice -pointsize 72 \
                      -tile bg.gif  -undercolor dodgerblue  -stroke navy  -strokewidth 2 \
                      -gravity center  -draw "text 0,0 'Anthony'" text_options.gif

            [IM Output]

                As of IM version 6.2.4, the "-draw text" operation no longer understands the use of '\n' as meaning newline, or the use of percent '%' image information escapes. (See Drawing a Percent Bug).

            These abilities, and problems, however remain available in the new IM v6 operator "-annotate". See the Annotate Text Drawing Operator below.

            All the above options can also be used within the "-draw" (MVG - Magick Vector Graphic) string. However if you set the above option within the draw argument, that option will only apply to that specific draw MVG string.

            On top of this the draw MVG format can do much much more, such a text rotation and font 'decorating' and of course you can also draw various shapes like circles onto the image.

            For example here we draw underlined, and rotated text, overlaid on a couple of background circles.


              convert -size 320x120 xc:lightblue \
                      -draw "fill tomato  circle 250,30 310,30 \
                             fill limegreen  circle 55,75 15,80 \
                             font Candice  font-size 72  decorate UnderLine \
                             fill dodgerblue  stroke navy  stroke-width 2 \
                             translate 10,110 rotate -15 text 0,0 ' Anthony '" \
                      draw_mvg.gif

            [IM Output]

            If you really want to make maximum use of "-draw" for creating your image, I suggest you look at the Drawing Examples Page.

            Undercolor Box
            The "-undercolor" color setting, as demonstrated above, and later below, will color the defined drawing area for that character and font. generally it just fits the drawn character. This is particularly the case the left and right edges of the drawn font, as the top and bottom edges are usually larger enough to accommodate all the characters. The drawing area basically represents the character 'cell' boundaries surrounding the area in which the font is drawn.

            The major use of using the "-undercolor" option, is as a simple and quick way to clear a 'noisy' background from around the text. For example look at Annotating on Top Images. However it is recommended you also add an extra space character at the start and end of the string being drawn in that case.

            Bounding Box Overflow
            One of the biggest problems you will probably come across when drawing text, or just generally handling fonts, is that not all fonts obey the normal rules.

            A font designer can 'draw' individual characters (or 'glyphs') anywhere relative to the current text position (known as the caret). The font position does not even have to move forward, and in some international fonts could even move backward!.

            The result of this freedom of design is that some 'glyphs' do not fit inside the defined drawing area which the font declares the character fits into, especially on slanted, or script-like fonts where some parts of the letters extend well outside the bounds and into the areas used by later (or previous) characters.

            The worst font I have seen in this regards is the 'LokiCola' font, which draws around half of its capital letters with long wavy tails, well beyond the bounds of the individual character cells. The font basically assumes each capital letter will be followed by 3 or more lowercase letters.

            To show this I'll draw a number of the font's capital letters separately, allowing you to see just how far the letters could extend beyond the cell 'undercolor' or drawing bounds. I also use a couple of them to form the fonts name, so you can see just as they were designed to be used, and why they overflow their bounding boxes.


              convert -size 500x200  xc:lightblue \
                      -font LokiCola  -pointsize 72  -undercolor dodgerblue \
                      -draw "text  15,65 'L'"   -draw "text 130,65 'C'" \
                      -draw "text 245,65 '1'"   -draw "text 360,65 'H'" \
                      -gravity South -draw "text 0,10 'Loki Cola'"    draw_undercolor.gif

            [IM Output]

            Also note how the 'H' actually overflows on the left side as well as the right side of its drawing area. This can make it difficult to use at the beginning of lines.

                Remember this problem is NOT a bug in IM, but caused by the interaction of the font library IM uses, and the settings within the font itself, usually on purpose by the font designer. IM just uses the results as they are programmed in the font, which does not always produce what the user intended. Caution is thus advised with unusual fonts.

            Annotate - Text Drawing Operator
            With IM version 6, a new font drawing operator, "-annotate", was made available. This operator is in may ways much simpler that using a "-draw text" operation, but as it uses the 'annotate()' API (Application Program Interface), it is also more powerful.

            While the operator does make use of the "-draw" primitives, it does so in a more complex way, such as expanding special escape characters to add extra image information and even multiple lines, and applying a coordinate system transform to the drawn text to produce slants and rotations.

            Because of this, the operator is now the preferred text drawing operator for all ImageMagick text drawing and image annotation, and this is now reflected in these example pages.

            Here is a basic example using this operator.


              convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                      -fill blue  -annotate +25+70 'Anthony'    annotate.gif

            [IM Output]

            One of the extra features of the "-annotate" operator is that it can rotate the X and Y axis of the drawn text completely separately to each other. This is done by providing the angle in which to rotate each axis as a 'image size' in the operators argument.

            Just to show how complex a single "-annotate" operation can be, here is a boxed, stroked, and slanted image...


              convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                      -tile bg.gif  -undercolor dodgerblue   -stroke navy -strokewidth 2 \
                      -annotate 0x20+20+67 'Anthony' annotate_opts.gif

            [IM Output]

            In this example all four annotate arguments are given. Specifically, X axis rotation, Y axis rotation, and the fonts X and Y position on the background image.

            Also note that the fill pattern (set with "-tile") is also slanted with the font. That is because it is drawn using a sheared/rotated coordinate system, which also shears and fill pattern tiled within the drawn text.

            Further example of this shearing capability is the Sheared Shadow Font example. Compare that with the Slanted Font created with the equivalent "-draw" MVG string.

            For a table summarizing the effects of the "-annotate" shearing operation, see Annotate Argument Usage.

            For example here is some slightly rotated text ...


              convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                      -annotate 350x350+20+90 'Anthony' annotate_rotated.gif

            [IM Output]

                Note that the angle given to "-annotate" must be positive for IM to understand it correctly). The exception to this is if a comma-separated 4 number form of Geometry Argument is used. For example "-annotate '-10,-10,20,90' 'Anthony'", could have been used in the last example.

            This can be used to generate angled condensed labeling. For example...


              convert -size 100x60 xc:skyblue \
                      -annotate 300x300+20+50 "First" \
                      -annotate 300x300+35+50 "Second" \
                      -annotate 300x300+50+50 "Third" \
                      -annotate 300x300+65+50 "Fourth" \
                      -annotate 300x300+80+50 "Fifth" \
                      annotated_labels.jpg

                [IM Output]
            You can also add other information about the current image to the Annotated string using escape characters. For example lets overwrite the built-in "rose:" image with information about the images size. To center the text on the image we use a "-gravity" setting, and turn off any and all rotations and offsets by using an "-annotate" argument of '0'.


              convert rose:  -fill white -stroke black  -font Candice -pointsize 20 \
                      -gravity center   -annotate 0 '%wx%h\nPixels'    annotate_rose.gif

                [IM Output]

            For more information see Special Escape Characters in Text Arguments below.

            For other examples of annotating text onto a larger image in various ways (such as centered on the side, or rotated in the bottom-right corner) see Practical Text Annotation Examples.

            Automatically Sized Annotated Text Canvases
            Often you need much more control than what "label:" can provide. For example you want to use a tile or gradient image, requiring you to Annotate the text. Unfortunately you then need to know in advance the size of the canvas you need for your Annotated Text.

            Here is a typical example of the problem. When I first set up this command I set my size to the results I wanted, and at first it worked quite well. But then I got this...


              convert -size 480x80   gradient:yellow-green \
                      -font ArialBkI -pointsize 70 -tile gradient:blue-red \
                      -annotate +10+65 'Gradient Fun'    funfont_gradients.jpg

            [IM Output]
            Unfortunately when guessing at the canvas size I had miss-spelt the word 'Gradient' in that above (missing the letter 'i'). Of course when I fixed that spelling, my image size was now wrong, producing incorrect result shown above.

            What we need is to be able to use the "-annotate" operator, but with the canvas sized to fit the Annotated Text.

            One solution is to use a much larger canvas, then "Trim" the background to the right size. I also added a "Border" to add a little extra space around the font and the final edge of the image, for a better look.


              convert -size 800x120 xc:black -font Corsiva -pointsize 100 \
                      -tile tile_disks.jpg   -annotate +20+80 'Psychedelic!' \
                      -trim +repage  -bordercolor black  -border 10   funfont_groovy.jpg

            [IM Output]

            This method is much better than trying to make a guess at just how big your final image should be, however "Canvas Trim", will not trim a tiled multi-colored background.

            The better solution is to create the canvas using "label:", to generate the canvas of the right size. A Draw Color Fill is then used to tile an image over the canvas (and the label text), and finally we Annotate our text using another tiling image.


              convert -font Ravie -pointsize 72  label:'Get Wet!' -border 10 \
                      -tile tile_aqua.jpg   -draw "color 0,0 reset"  \
                      -tile tile_water.jpg -gravity center -annotate +0+0 'Get Wet!' \
                      autosize_wet.jpg

            [IM Output]
                Note that position of the text in a centered "label:" image may not exactly match the position of a centered "-annotate" operation. The two methods follow completely different processing algorithms, and as such may not match. Especially when unusual fonts are involved.

            Auto Sized using 'Undercolor Box'
            Rather than using a "label:" image, you can draw the font on a large canvas using an Undercolor Box and a large stroke width, before trimming the canvas to fit.

            For example


              convert -size 500x100 xc:lightblue -font SheerBeauty -pointsize 72 \
                 -gravity center -undercolor white -stroke none -strokewidth 3 \
                 -annotate +0+0 ' Invitation ' -trim +repage -shave 1x1 \
                 invitation_box.jpg

            [IM Output]
            The amount of space around the font can be adjusted using the "-strokewidth" setting. The only important requirement is that the initial canvas be a color different to the background color, ('lightblue' in this case) and is larger than the final result.

            Just a word of warning, some fonts draw characters well outside the individual character drawing area. (For example see Undercolor Box above). In this case the above result will work, but may require you to use a transparent canvas, and then overlay the result over white (using an operation like "-background white -flatten" for example), to convert the unused and still transparent areas to white. However that character will likely be touching an edge of the resulting image. Basically you can't really win, in all situations, just try your best.

            Coloring a Gray-scale Text Image
            I purposefully generated the above image as a grey-scale black and white image, as this can be used as a masking template. From a pure image like this you can then color the background and the foreground of image either separately or both at the same time.

            Here for example I use the Level by Colors Operator, "+level-color", to globally modify the image colors so as to assign the foreground and background colors with specific values.


              convert invitation_box.jpg -colorspace sRGB \
                      +level-colors navy,lightblue invitation_colored.jpg

            [IM Output]

            For example here I use Composite Masking to replace background and foreground with pattern images.


              convert invitation_box.jpg -colorspace sRGB \
                      \( +clone -size 300x150 -tile gradient:LightYellow \
                                                         -draw "color 0,0 reset" \) \
                      \( +clone -size 300x150 -tile plasma:tomato \
                                                         -draw "color 0,0 reset" \) \
                      -reverse  -composite      invitation_rose.jpg

            [IM Output]

            The Reverse Operator in the above is used to reorder the images, so the first image becomes the third 'masking' image of the composition. The foreground ("plasma:") image then becomes first, and the background in the middle.

            For other techniques of coloring a gray-scale image like this, see Using a Mask to Limit the Composed Area. And more generally Using Masks with Images.

            For other methods of generating gradients for tiling see Gradients of Color, Sparse Points of Color, and Randomized Canvases.

            Fonts
            Under Construction


            As for ordering the font paths, that is simply ordering the fonts specified in
            the XML files.

            The start point is the system fonts, followed by the system installed
            "type.xml" file, on my system this is "/etc/ImageMagick-6/type.xml".

            This system installed "type.xml" file is typically just a list of 'include'
            other type-* files.  And the order of the includes will specify the order of
            Extra System Fonts, verses Ghostscript Fonts.

            After that file other "type.xml" files are looked for, such as in 'home'
            directories, or even current directory.

            Later fonts will NOT replace earlier fonts, as such if two fonts have that
            same name, only the first one will be noted by IM. (a security measure).

            To see the fonts loaded use
                convert -list font

            It lists "Path:" of the type file each font list was found in, but the
            paths are listed in REVERSE order, with system fonts at the end.

            I have for example a personal Font named "Courier", but it is not listed in
            the above list as it was defined after the "Courier" that was found in the
            "System Fonts" area, (which is listed at the end of the above output).

            On the other hand my own personal font "CourierNew", is listed, as it does not
            clash with any system or system config defined font.

            To see what font glyph file is selected for soem specific request
            use...
              convert -debug annotate xc: -font Courier \
                      -annotate 0 'Test' null: 2>&1 |
                grep '^ *Font '

            Determining Font Metrics, without using an API
            [diagram] A particular font and its individual characters contain a lot of information. Such information can be very useful to have, especially if you are wanting to use IM for piecing together the text of many different fonts.

            It is also important to remember that most fonts are proportional fonts, meaning that each individual character will have a different width, and a different 'natural' advance of the caret (or origin). As such each specific 'string' of characters will be rendered (drawn) a different length without any real regard to the actual number of characters used in the string.

            The exception to this are 'Fixed-Width' fonts, such as "Courier", "Typewriter", or "Terminal" fonts, in which all characters have the same width, allowing you to generate columns of text easily.

            The Debugging Setting "-debug annotate" can be used to get IM to directly report a TTF font's metrics, for a specific string. For example...


              convert -debug annotate  xc: -font Candice -pointsize 24 \
                      -annotate 0 'Test' null: 2>&1 |\
                grep Metrics: | fmt -w80

            [IM Text]

            As you can see you get a mixed bag of information you can use: from the declared bounds of the drawn string (which is not nessarilly the strings actual bounds), relative to the origin; to the amount the 'carat' (origin) should advance before drawing the next string.

            The full debug output (which is rather verbose, and not shown in the above) also reports the actual font file used (twice) so you can also use it to check that you have the right font too.

                The "-debug annotate" method was added to IM v6.3.9-2


            Older techniques
            This debug output however may not be convenient, or you may have to handle IM's that are older than this version. The following are older examples where the text is actually drawn in various ways and colors, and then information (as integers) extracted from the resulting image.

            For example lets find out the dimensions of the 'Ravie' font relative to a fixed baseline, at 72 point.

            Here is the image we will be studying, as a reference. You don't actually need to drawn and save it as an image, as we are only extracting data, not an image. the colors of this image will be modified so we can look at the white and black parts separately using "-trim" to extract the metrics used.


              convert -size 100x150 xc:lightblue -font Ravie -pointsize 72 \
                      -fill black -undercolor white  -annotate +20+100 'A' font_drawn.gif

                [IM Output]

            For the basic basic font metrics, we first draw the font itself with a transparent color ('None'), so that we can measure find the size and location of the bounding box or drawing area of this specific character, for this font. Note that for height information you can just draw anything.


              convert -size 100x150 xc:lightblue -font Ravie -pointsize 72 \
                      -fill none -undercolor white  -annotate +20+100 'A' -trim  info:

            [IM Text]

            From the results above we can see that a 'Ravie' font at 72 points, will have a total bounding box height of 74 pixels. The top of the box is 42 pixels from the top of the image, as the baseline which was positioned at a 100 pixels y coordinate, the box starts is 100 - 42 or 58 pixels above the baseline. That leaves 74 - 58 or 16 pixels for the bounding box below the baseline for the descenders.

                Note that not all fonts limit their drawing to within their defined drawing bounding box! However some letters can extend far outside those boundaries. That is why the above example sets a "-fill" color of 'none'. That way ill behaved fonts will not effect the above measurements.

            Also note that the distance separating lines (baselines actually) should be purely determined by the point size of the font, and has nothing to do with how the font is drawn. In out example, as the font has a point size of 72 points, and a point is defined as 1/72th of an inch, then the baselines should be 1 inch apart. With a current output resolution (density) of 72 pixels per inch, that means the baselines will be 72 pixels apart.

            Interestingly enough that means that for this font, with a 74 pixel bounding box, the font has a two pixel overlap for the drawing area between the lines of properly single spaced text!

            Also from the above measurements we can see that in drawing the string "A" in this font at this point size, the next character should be drawn 66 pixels to the right of the starting point (known as the caret). This is the strings 'logical' length. That is the 'caret' or start point for the next character should start at 20 + 66, or at '+86+100' (the baseline does not change vertically). Be warned that some Arabic fonts can in fact draw right to left, so the 'caret' offset will be negative.

            That gives use the font metrics for the character 'A' but what about physical dimensions of drawn 'A' relative to the 'caret' or start point. Well just swap the two color settings...


              convert -size 100x150 xc:lightblue -font Ravie -pointsize 72 \
                      -fill black -undercolor none  -annotate +20+100 'A'  -trim   info:

            [IM Text]

            Height-wise the character was within its defined drawing boundaries, with its height going from 100 - 43 or 57 pixels above the baseline (hard against its bounding box) to 60 - 57 or only 3 pixels below the fonts baseline. In other words this letter does not have a 'descender' drawn in area below the baseline.

            From this we can see that the 'A' draws from 3 pixels before the caret (positioned at +20, but final image is at +17), to 70 - 3 or 67 pixels after the caret position. In other words this font is slightly wider than its horizontal bonding box, when drawn.

            Note that while this gives you the actual drawn string length, this is different to the caret offset needed when appending text, (which is defined by the strings bounding box, and not its drawn length). In other words text should be appended together using their bounding boxes, and not their actual drawn length size as we have do in other examples.

            Of course if you get a very ill-behaved font, you may like to check how far a specific string draws beyond its bounds so that you can still provide space for it, say at the end of a line.

                The dimensions extracted from a font will also vary with the current "-strokewidth" used for drawing the font. If you increase the size of the outline stroke, then the dimensions (and bounding box size) needed to draw the font is also expanded by the same amount to accommodate the thicker outline.

                Dimensions also vary with the operating system, (type and version) and the version of the delegate font drawing library IM is using on that system, even when the exact same font library and IM version has not changed. Caution is recommended when different computers could be used for text drawing, as results can vary even for the same font.

            For more information see the document TrueType Fundamentals (PDF). This shows that even my generalizations above may not always hold true, though is generally the case.

            Note the above examples will only return dimensions in whole pixels, where all the dimensions used by fonts are floating point numbers. In fact whether a font is even drawn from a whole pixel (caret) starting point, can be application dependant, and effect the resulting look of the font.

            Creating Lines of Mixed Font Styles
            Creating a single line using multiple fonts, point sizes, and styles is not something IM is really designed to do. It gets even worse when you also start to consider things like text justification, word wrapping, and wrapping around images and other things.

            This is the sort of thing that programs like Word Processors, Web Browsers, Document Printers do very well, usually under user interaction, but few can do so well under program control.

            One exception to this is "TeX", and its family of programs (see A Complete Text Processing System below), so if you are serious about processing text graphically, I suggest you look at this program family.

            Another alternative is to look at various document 'pretty' printing programs such as a HTML converter. You can use these to convert program generated documents into postscript which IM can then happily post-process into whatever image format or style you want.

            An API solution (using the C MagickWand API interface) has been created by "El Supremo" (from the IM discussion forums) in his FontMetrics program. and here is Example Output of "FontMetrics".


            Now while IM command-line is not designed for 'word processing', it does not mean you can't use it for such. It is just more difficult. Here I will give some examples of mixing text in different fonts and styles, to give people a starting point.

            The simplest solution people usually think of is to just append "label:" images together...


              convert -font LokiCola     -pointsize 36  label:'LokiCola ' \
                      -font Candice      -pointsize 24  label:'Candice ' \
                      -font SheerBeauty  -pointsize 48  label:'SheerBeauty' \
                      +append   wp_label_append.jpg

            [IM Output]

            However as you can see all the images are vertically aligned to the top of the image, and unless you use similar fonts, will not look very good.

            Alternatively, you can use an append justification trick to align them along the bottom.


              convert -size 1x50 xc:none +size \
                      \( -background white -font LokiCola -pointsize 36 \
                         label:'LokiCola ' \
                         -clone 0 +swap  -background none -append \) \
                      \( -background white -font Candice  -pointsize 24 \
                         label:'Candice ' \
                         -clone 0 +swap  -background none -append \) \
                      \( -background white -font SheerBeauty  -pointsize 48 \
                         label:'SheerBeauty' \
                         -clone 0 +swap  -background none -append \) \
                      -delete 0   -gravity South -crop 0x50+0+0   +append \
                      -bordercolor none  -border 1 -trim  +repage \
                      -background white -flatten    wp_label_bottom.jpg

            [IM Output]

            What this did was to add some extra padding to the top of each label, and cropping them all to the same height before appending them horizontally. After that a simple "-trim" and a "-flatten" was used to set the height of the line to the highest label, and fill in the background.

            As you can see this produces a better job, but a small font tends to produce subscript like behaviour, rather than properly aligned text.

            What we really need to do is align all the text strings by their 'baselines' and that is very difficult without access to more textual information. This information is easily obtainable under a program API, but much more difficult from the command line. One method is shown in the previous example section.

            However it is possible to align words by their baseline without actually collecting baseline information. While "label:" text images do not provide any clue as to the images baseline, you can specifically draw images at a fixed baseline.

            Without an API you also can not directly find out how long or high drawn text is, so you first need to use a canvas that is large enough to ensure that we don't loose any information about text image. Then to preserve trailing spaces and text height you also have to make good use of the ("-undercolor") feature available to text annotation and provide a boundary for image trimming.

            So lets see how you can do it from the command line.


              convert -size 500x100 xc:none  -fill blue  -draw 'line 15,0 15,99' \
                      -undercolor white -fill black \
                      \( -clone 0   -font LokiCola    -pointsize 36 \
                         -annotate +5+60 'Loki Cola ' \) \
                      \( -clone 0   -font Candice     -pointsize 24 \
                         -annotate +5+60 'Candice ' \) \
                      \( -clone 0   -font SheerBeauty -pointsize 48 \
                         -annotate +5+60 'Sheer Beauty' \) \
                      -delete 0 -trim +repage  +append \
                      -transparent blue  -trim +repage \
                      -background white -flatten   wp_draw_baseline.jpg

            [IM Output]

            As before the trimming of the images is done in two steps.

            First draw the text on a base image which contains a vertical blue line. Thus when we trim the text, only the width of the text image will be trimmed, leaving all the words at the same baseline height.

            After appending them together, we can now remove the blue construction line by making it fully-transparent. If you are generating just a black and white image, the better way would be to just extract one of the non-blue channels instead, which ensures you really do get all of the construction line. A second trim will then trim the top and bottom sections, shrinking it to the largest bounding box.

            A final flatten to the same color as the as the bounding box then removes all evidence of its use in constructing the line.

            As you can see all the text is now properly baseline aligned, regardless of the font or the pointsize used.

            Of course in these examples I only used black on white text. Other colors can be used, as long at they don't interfere with the construction line and transparent background used for text alignment.

            With this technique you can now generate mixed font text lines, and vertically append them all together into a larger document.

            You can also see that doing all this is a lot of work, work that is normally hidden from the user by word processors and web browsers. If you do plan to do a lot of this sort of stuff, I do suggest you look into the alternatives I previously mentioned.

            Form Filling
            You have an image of some standard fill in form and you want to fill in the fields which are in well known positions. So you have a data file such as "text_data.txt" shown here...
            [IM Text]

            The fields are text width, gravity (justification), color, position x, y and the actual text to place for this field.

            Now you can use a simple looped shell script to generate a text label as described by the above, assigning the appropriate text in the defined text positions in a form (background) image.


              cat text_data.txt |
              while read width gravity color  pointsize x y text
              do
                convert -size ${width}x -gravity $gravity -fill $color -background wheat \
                            -pointsize $pointsize  -page +${x}+${y}  label:"${text}"  miff:-
              done |
                convert -size 200x100 xc:   -   -flatten    text_layered.jpg

            [IM Output]

            The 'form image' in this case is just a blank image, but really could be anything. I also set the background color of the labels to 'wheat' so the area filled in is visible, but you would normally set this to none.

            The above does not use temporary files, but instead uses a pipeline of MIFF format images. This is an example of using a Image Streaming Format, in which individual images are simply appended together, on after the other in a file or pipeline.

            This is only a starting point. The form fields can come from some definition file, while the text to fill in from a database or other data source. Other attributes can also be set such as the font to use, text rotations and so on. You could also include both width and height, or if the text should be word-wrapped using Caption should be used rather than a Label.

            See also Pins in a Map for another example of this technique, much like the above.

            Text Processing Alternatives
            The ideal way of generating fully formatted text files and documents is to use ImageMagick as part of a larger image and text processing system.

            Tool	used for...
            ImageMagick    	Image batch processing and preparations
            Gimp 	GUI image editing for one off problem fixing
             
            LyX 	GUI word processing, built to generate...
            LaTeX 	Text processor for documents, and books...
            TeX 	Underlying Text format
            (positions symbols and fonts on pages)
            Metafont 	TeX Font generator

            Basically ImageMagick can do a lot of things, that does not mean it is the best tool for those things. For larger document preparations you are better off treating it as only one part of a larger whole.

            The various 'TeX' tools given above are usually a standard install for most Linux systems, and can combine text and images into an unified whole. More importantly it keeps text as text, and formats the text appropriately, as you specify, doing almost all the hard work of word and page wrapping, and arrangement with the images. But without filling a 'doc' file with useless formatting garbage. You have full control, or can leave it to make the decisions.

            They provides a way of generating any type of document, from a simple page, newsletter or even a full book If you are serious about document generation, then these tools are well worth looking at and learning.


            Pango (Linux and MacOSX only) also provides an alternative. It provides many text to image processing features not available in ImageMagick. For example TABs, justification, margins, headers, and so on. It even has a markup language of some kind to allow font changes in the middle of text.


            Other solutions also include the many text to postscript conversion programs, such as "a2ps" which I demonstrate in generating an example postscript file in Postscript Handling above. This converts and formats may different types of text files, with word wrapping, bolding and tab control, as well as a reasonably nice header, footer, border, and multi-page options. Of course this is indirect image processing via a Postscript or PDF intermediate language.

            Another is to layout the text using SVG, or the ImageMagick Drawing Command, though you will then need to deal with the layout. There are lots of tools out there to convert text into images, and most can be combined with ImageMagick to post-process the text image and merge it into your image. This lets ImageMagick get on with what it does best, image processing.
https://legacy.imagemagick.org/Usage/fonts/
            Drawing text is only the start of what is possible with ImageMagick. Here we look at modifying the basic text drawing ability of IM to create fancy fonts and special effects, which you can then use on your web pages and documents.

            Compound Font Effects
            Plain old text as images is boring, but with very little effort you can overlay and color text so as to produce some very weird and wonderful effects.

            To do this we need to draw text multiple times, overlay different tiles and colors, and apply some of the many image operators available to generate more interesting special effects from the original, boring text.

            Note that many of these effects can be applied to other images besides a basic font such as we are using. In particular you can use the effects on clip-art images.

            Tiled Font: You are not limited to drawing fonts in a fixed color. You can use a tile pattern over the font.


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                       -tile pattern:checkerboard   -annotate +28+68 'Anthony' \
                       font_tile.jpg

            [IM Output]

            Note that the "-tile" setting overrides any "-fill" color for the "-draw" operator.

                As of IM v6.3.2 you can specify a tile image using the "-fill" setting instead, This usage is however is not recommended as many operators that using the "-fill" color will not understand a tiling image, and default to using 'black' instead.

            The tiling image can be offset relative to the background image origin by specifying a "-origin" setting, BEFORE you set the "-tile" image. The image is rolled by the amount specified during its assignment as the fill tile.

            Gradient Font: The tile used does not have to be small either, but can be the size of the whole canvas.


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                       -tile gradient:   -annotate +28+68 'Anthony' \
                       font_gradient.jpg

            [IM Output]

            Upside Down Font:


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                       -fill Navy     -annotate 180x180+300+35 'Anthony' \
                       font_upsidedown.jpg

            [IM Output]

            Hard Shadow: Drawing the font twice with an offset, you can make a simple 'hard' shadow effect.


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                       -fill black -draw "text 28,68 'Anthony'" \
                       -fill white -draw "text 25,65 'Anthony'" \
                       font_shadow.jpg

            [IM Output]

            Sheared Shadow: As the "-annotate" font drawing operator can rotate the vertical dimension separately to the horizontal dimension, you can specify some odd ball rotation 'slewing' or 'shearing' of the font. This is great for making weird shadows, or making your own italic or slanted font.


               convert -size 320x115 xc:lightblue  -font Candice -pointsize 72 \
                       -fill Navy      -annotate 0x0+12+55   'Anthony' \
                       -fill RoyalBlue -annotate 0x130+25+80 'Anthony' \
                       font_slewed.jpg

            [IM Output]
            To see a table summarizing the effects of the text rotations, see Annotate Text Option.

            Of course the Candice font is not a good font to show this effect, and other details may need to be added to make it the result look more 3D like. For example Blurring the shadow with distance.

            Slanted Font: You can also use "-draw" to slant your font too, though it is a little trickier, as it involves extra MVG (Magick Vector graphics) actions, to warp the drawing surface. As the surface is being warped it is a good idea to set the font location first using 'translate' before warping.


               convert -size 320x100 xc:lightblue  -font Candice -pointsize 72 \
                       -fill Navy -draw "translate 28,68  skewX -20  text 0,0 'Anthony'" \
                       font_slanted.jpg

            [IM Output]
            To see a table summarizing the effects of the text rotations, see Annotate Text Option.

            Of course the Candice font is not a good font to show this effect, and other details may need to be added to make it the result look more 3D like. If you come up with anything interesting, pass it on to me, so it can be shared with the rest of the world.

                Both "-annotate" and "-draw skew?" operations actually rotates the X and Y axis of the drawing surface. This is different from the effects of using "-shear" on an existing image, which lengthens the sheared axis of the image so the height (or width) or the image does not change due to the operation.

            Stamped Font: By drawing the font three times in darker and lighter and the original colors you can make a stamp like indent.


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                       -fill black     -annotate +24+64 'Anthony' \
                       -fill white     -annotate +26+66 'Anthony' \
                       -fill lightblue -annotate +25+65 'Anthony' \
                       font_stamp.jpg

            [IM Output]
            Notice how the last 'draw' of the font erases the middle portion of the font. This can only be done on a solid colored background, See Using a Mask Image to see how we can use this on a random background that isn't a solid color.

            If you swap the two colors you will of course get a raised font, instead of a indented font.

            Extruded or 3d block font: can be generated by repeating the font multiple times.


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                       -fill gray -annotate +29+69 'Anthony' \
                                  -annotate +28+68 'Anthony' \
                                  -annotate +27+67 'Anthony' \
                                  -annotate +26+66 'Anthony' \
                                  -annotate +25+65 'Anthony' \
                                  -annotate +24+64 'Anthony' \
                       -fill navy -annotate +23+63 'Anthony' \
                       font_extrude.jpg

            [IM Output]
            Note that this is NOT a simple shadow, but a proper thickening of the drawn font.

            This is very repetitive and can be used for any 'shaped' image. For another example of this see Adding Thickness to a Thumbnail.


            Outlined Font: We can create an outlined font using multiple drawing with small position offsets.


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                       -fill black  -annotate +24+64 'Anthony' \
                                    -annotate +26+64 'Anthony' \
                                    -annotate +26+66 'Anthony' \
                                    -annotate +24+66 'Anthony' \
                       -fill white  -annotate +25+65 'Anthony' \
                       font_outlined.jpg

            [IM Output]
            As this is also very repetitive, it is not a good outline solution.

            As ImageMagick allows you to draw the font outline by setting the "-stroke" setting, much better solutions exist. (See the Stroke Fonts below).

            Regardless, multiple redraws like this, for generating an outline can be very useful with pre-prepared clip-art images, such as what you can find all over the Internet. It is also useful technique for other graphic libraries and programs (Like "GD" from "PHP", etc) where a "-stroke" setting is not available for use.

            Another reason for showing this style of outlining, is that the result may be better when outlining a font with very sharp points.

            For example here we draw the font 12 times to show up the sharp points of the font. The outline here was also drawn to be a little thicker.


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                        -draw "fill black text 27,67 'Anthony' \
                                          text 25,68 'Anthony' \
                                          text 23,67 'Anthony' \
                                          text 22,65 'Anthony' \
                                          text 23,63 'Anthony' \
                                          text 25,62 'Anthony' \
                                          text 27,63 'Anthony' \
                                          text 28,65 'Anthony' \
                               fill white text 25,65 'Anthony' " \
                       font_outlined_12.jpg

            [IM Output]

            You will also notice that the drawing -fill" color can be changed inside the "-draw" argument.

            Multi-Color Outline: The other reason this technique is useful is that you are not limited to just one outline color in drawing the font. By re-drawing the font 12 times in 5 different colors in a very carefully designed sequence, you can make a colorful "raised" font, with some edge color smoothing.


               convert -size 320x100 xc:lightblue \
                       -font Candice -pointsize 72  -gravity center \
                       -draw "fill navy         text  2,2  'Anthony' \
                              fill navy         text  0,3  'Anthony' \
                              fill navy         text  3,0  'Anthony' \
                              fill dodgerblue   text  0,2  'Anthony' \
                              fill dodgerblue   text  2,0  'Anthony' \
                              fill dodgerblue   text -2,2  'Anthony' \
                              fill dodgerblue   text  2,-2 'Anthony' \
                              fill lavender     text -2,-2 'Anthony' \
                              fill lavender     text  0,-3 'Anthony' \
                              fill lavender     text -3,0  'Anthony' \
                              fill skyblue      text  0,-2 'Anthony' \
                              fill skyblue      text -2,0  'Anthony' \
                              fill blue         text  0,0  'Anthony' " \
                       font_colourful.jpg

            [IM Output]
            There are better methods to create a raised font like this, but this works, is simple, and only uses a few colors, rather that a whole range of colors.

            Outline (Stroke) Font: The "-stroke" setting allows you to draw an outline of the font directly. Normally the stroke color is set to "none", so is not used. The thickness of the stroke is varied with "-strokewidth", which defaults to a good value of 1.


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                       -fill white  -stroke black  -annotate +25+65 'Anthony' \
                       font_stroke.jpg

            [IM Output]
            And here is an example with a heavier stroke width of 3.


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                       -fill white -stroke black -strokewidth 3 \
                       -annotate +25+65 'Anthony'        font_stroke_3.jpg

            [IM Output]
            Notice how the stroke color eats away not only the outside of the font, but the inside as well. For more detail see the results of my Stroke and Stroke Width Options.


            Thick Stroke: By again redrawing the font a second time, but without the stroke turned on, the internal parts of the lines are removed, creating a more pleasing thickly outlined font.


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 -fill white \
                       -stroke black -strokewidth 5 -annotate +25+65 'Anthony' \
                       -stroke none                 -annotate +25+65 'Anthony' \
                       font_stroke_thick.jpg

            [IM Output]
            Using the -stroke" setting is taken even further, in Stroke and StrokeWidth Options where is aspect of drawing operators are explored in greater depth.

            Thin Stroke: By turning off the fill color, you can leave just the outline of the font.


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                       -fill none  -stroke black   -annotate +25+65 'Anthony' \
                       font_stroke_thin.jpg

            [IM Output]
            Doubled Outline: By redrawing using multiple stroke thicknesses, you can generate a double outline! The first draw can use any fill color to fill the inside of the font, or left as none as we did here to leave the background alone. However the last font draw must be with done with a fill setting of "none", or it will not work.


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                    -fill none  -stroke black  -strokewidth 3  -annotate +25+65 'Anthony' \
                    -fill none  -stroke white  -strokewidth 1  -annotate +25+65 'Anthony' \
                    font_stroke_double.jpg

            [IM Output]
            Unlike the 'stamped font' previously, the above did not require the middle part the of font to be erased. As such this will work on any background without complication.

            Psychedelic Font: In a similar way by slowly reducing the stroke width size while swapping colors, a psychedelic outline effect can be easily generated.


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 -fill white \
                       -stroke black -strokewidth 25 -annotate +25+65 'Anthony' \
                       -stroke white -strokewidth 20 -annotate +25+65 'Anthony' \
                       -stroke black -strokewidth 15 -annotate +25+65 'Anthony' \
                       -stroke white -strokewidth 10 -annotate +25+65 'Anthony' \
                       -stroke black -strokewidth  5 -annotate +25+65 'Anthony' \
                       -stroke none                  -annotate +25+65 'Anthony' \
                       font_psychedelic.jpg

            [IM Output]
            You can make it even more psychedelic by using clashing colors, different stroke widths, or even moving the font position around a little. Experiment and see what you can come up with.

            Balloon Effect: Here I did exactly the same as the "Thick Stroke Font" above, but purely by accident I used a white stroke color when re-drawing the font. This resulted in an interesting enlargement of the font, with a thick outline. The 'puffy' looking font is as if had been inflated like a balloon.

            This just shows that it pays to experiment to see what you can find.


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                   -fill black  -stroke black  -strokewidth 5  -annotate +25+65 'Anthony' \
                   -fill white  -stroke white  -strokewidth 1  -annotate +25+65 'Anthony' \
                   font_balloon.jpg

            [IM Output]


            Joined Characters: By using a small negative Character Space Kerning setting (adding IM v6.4.7-10) and drawing the font twice (such as in the previous example), you can cause all the characters in a 'thick' font join together, so as to produce an interesting variation.


              convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                      -kerning -6  -strokewidth 4 -fill white \
                      -stroke black   -annotate +28+68 Anthony \
                      -stroke none    -annotate +28+68 Anthony \
                   font_joined.jpg

            [IM Output]

            Overlapped Characters: A variation on this however is to draw each and every character separately so that each character is overlaid on top of the previous characters.


              convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                      -stroke black -strokewidth 4 -fill white \
                      -stroke black -annotate  +28+68 A  -stroke none -annotate  +28+68 A \
                      -stroke black -annotate  +90+68 n  -stroke none -annotate  +90+68 n \
                      -stroke black -annotate +120+68 t  -stroke none -annotate +120+68 t \
                      -stroke black -annotate +138+68 h  -stroke none -annotate +138+68 h \
                      -stroke black -annotate +168+68 o  -stroke none -annotate +168+68 o \
                      -stroke black -annotate +193+68 n  -stroke none -annotate +193+68 n \
                      -stroke black -annotate +223+68 y  -stroke none -annotate +223+68 y \
                      font_overlapped.jpg

            [IM Output]

            This however requires you to work out (manually or automatically using a script) the appropriate position for each character. The natural width of each character can be determined by generating labels of each character without any "-strokewidth" setting. See Determining Font Metrics for examples.

            Note unlike when using the "-kerning" setting (previous example) each characters position in the above was adjusted artistically by different amounts rather than just some simple fixed amount. For example, only a little overlap between the 't' and the 'h', but a lot more overlay between the 'n' and 'y' characters.

            Jittered Characters: if you go so far as drawing individual characters (overlaping or not) then you can place them in a 'jitter' or randomized pattern, particularly with different up-down offsets.

            You can even take this to an extreme to generate a special effect such as...


              convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                      -stroke black -strokewidth 4 -fill white \
                      -stroke black -annotate  +26+80 A  -stroke none -annotate  +26+80 A \
                      -stroke black -annotate  +95+63 n  -stroke none -annotate  +95+63 n \
                      -stroke black -annotate +133+54 t  -stroke none -annotate +133+54 t \
                      -stroke black -annotate +156+67 h  -stroke none -annotate +156+67 h \
                      -stroke black -annotate +193+59 o  -stroke none -annotate +193+59 o \
                      -stroke black -annotate +225+59 n  -stroke none -annotate +225+59 n \
                      -stroke black -annotate +266+54 y  -stroke none -annotate +266+54 y \
                      font_jittered.jpg

            [IM Output]


            Fuzzy Font: A straight spreading of a font color using "-blur" operator. This operator allows you to take an image and spread it out in all directions. This allows you to generate softer looking shadows, and or spray paint like effects. The following examples show the effects you can achieve with this.


              convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                      -fill navy  -annotate +25+65 'Anthony' \
                      -blur 0x3   font_fuzzy.jpg

            [IM Output]

            Note that blur is applied to the WHOLE image at the point the operator is given. If you want to use a blur an existing image, you will have to draw the font separately (on a transparent background), then overlay it on the background image.

                The "-blur" (or "-gaussian") operator modifies a much larger area than you might suspect. If your background canvas is not large enough you may get an error from these operators. If this happens add extra space to the image, say using "-border", or add a limit to the working radius (first argument) of the operator.

            Also the blurring of the image generally makes the use of "-trim" afterward fairly useless. Manual trimming, or other adjustments may be needed whenever you use blurring on an image.

            Fuzzy Shadow: Use the fuzzy font as an offset for a soft shadow. Note that we also used a larger spread value.


              convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                      -annotate +30+70 'Anthony'   -blur 0x4 \
                      -fill white  -stroke black  -annotate +25+65 'Anthony' \
                      font_shadow_fuzzy.jpg

            [IM Output]

            Soft Shadow: The "-shadow" operator will not only allow you to generate and position soft fuzzy shadows for images containing transparency, but will also allow you to set use any color and set a general transparency level.


              convert -size 300x100 xc:none -font Candice -pointsize 72 \
                      -fill white  -stroke black  -annotate +25+65 'Anthony' \
                      \( +clone -background navy  -shadow 70x4+5+5 \) +swap \
                      -background lightblue -flatten  -trim +repage  font_shadow_soft.jpg

            [IM Output]

            For more information about the "-shadow" operator, see Generating Shadows.

            As of IM v6.3.1, the "montage" command can also generate soft 'shaped' shadows of images containing transparency. This means you can shadow a "label:" image very easily.


              montage -background none -fill white -font Candice \
                      -pointsize 72 label:'Anthony' +set label \
                      -shadow  -background lightblue -geometry +5+5 \
                      font_montage_shadow.jpg

            [IM Output]

            However you do not have any control over the offset, color, or amount of blur of the montage shadow (as yet).

            Soft Outline: use the fuzzy font as the outline border. This is like using the original font as a mask to a spray gun.


              convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                      -annotate +25+65 'Anthony'    -blur 0x5 \
                      -fill white  -annotate +25+65 'Anthony'   font_outline_soft.jpg

            [IM Output]

            Note that the edge is very light as not only is the black color spread out, but the background color spreads inward, making the edge only 50% dark.

            One way to fix this is to use a Shadow Outline, with a Level Adjustment to fix that lightness, though that uses some very advanced image processing techniques.

            Denser Soft Outline: Another way to fix the lightness of the soft outline is to blur a font that has a wide stroke outline. This effectively moved the 50% blur point further away from the edge of the font. It will also allow an even larger the blur value to be used, allowing the black color to spread out further.


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                       -stroke black -strokewidth 8 -annotate +25+65 'Anthony' -blur 0x8 \
                       -fill white   -stroke none   -annotate +25+65 'Anthony' \
                       font_denser_soft_outline.jpg

            [IM Output]

            As a practical example of this method see the examples generated in Adding image labels to thumbnails and the last example in Annotating on Top of Images.


            Distance Blurred Shadow: With the introduction of Variable Blur Mapping you can now blur a shadow so that be becomes more blurry with the apparent distance of that shadow from the casting object.

            For example here I took the Sheared Shadow Font and blurred the shadow so it is unblurred at the top, and more blurry at the bottom.


               convert -size 320x40 xc:lightblue  -font Candice -pointsize 72 \
                       -fill RoyalBlue -annotate 0x125+20+0 'Anthony' \
                       \( -size 320x45 gradient:black -append \) \
                       -compose Blur -set option:compose:args 20x5+45 -composite \
                       \( -size 320x60 xc:lightblue \
                          -fill Navy    -annotate 0x0+20+59   'Anthony' \) \
                       +swap -append   font_var_blur.jpg

            [IM Output]

            Note that I did not just use a circular blur, as light falling on a slanted surface will form ellipses, not circles. As such the blur also needs to form ellipses too. Basically I used an Elliptical Blur variant to achieve this effect.

            One final point, using the annotate angle arguments for creating the sheared text (see Annotate Argument Usage), is probably not the best way to generate the initial 3d shadow like this. Basically it can not make the shadow shorter or longer, like a real shadow, as it only does a rotational shear.

            A better method is to use a three point Affine Distortion which gives you the better control over the placement of the shadow (See 3d Shadows, using Affine Shears). Of course you will still need the Variable Blur technique to make look right.


            Dirty Print Font: The pixels are spread out slightly, and then blurred, and thresholded a few times to smooth out the final outline. The result is a font that looks like it was printed on course newspaper.


              convert -size 320x100 xc: \
                      -font Candice -pointsize 72 -annotate +25+65 'Anthony' \
                      -spread 1 -blur 0x1 -threshold 50% -blur 0x1 font_dirty_print.jpg

            [IM Output]

            This font was from the discussion How to dirty a font which includes other more complex methods.


            Beveled Font: The Shade Operator can be used to generate very nice looking 3D font with a beveled and smoothly curving edge.


                convert -size 320x100 xc:black -font Candice -pointsize 72 \
                          -fill white   -annotate +25+65 'Anthony' \
                          -shade 140x45  font_beveled.jpg

            [IM Output]
            This is much nicer than the stamped font, but shade will only generate grey-scale images. On the other hand, there are a lot of methods which can replace the grey scale of the above result with whatever colors you need.

            The biggest problem with using shade to 'bevel' a font is that the thickness of the bevel is not readilly adjustable. It is basically fixed to an approximatally 5 pixel thickness, regardless of the font size used.


            Conical Font: By using the new Morphology Distance Method (as of IM v6.6.2) combined with the Shade Operator you can make the whole font look like it is a 3 dimensional mountain ridge.

            This does requires some special handling of the anti-aliasing pixels as per Distance with an Anti-aliased Shape, but the result is a cone shaped mountain-like font.


              convert -size 320x100 xc:black -font Candice -pointsize 72 \
                      -fill white   -annotate +25+65 'Anthony' \
                      -gamma 2  +level 0,1000 -white-threshold 999 \
                      -morphology Distance Euclidean:4,1000 -auto-level \
                      -shade 135x30 -auto-level +level 10,90% font_conic.jpg

            [IM Output]

            By adding a bit of "-adaptive-blur" you can smooth the result to generate a better and strangely shiny look to the resulting font.


              convert -size 320x100 xc:black -font Candice -pointsize 72 \
                      -fill white   -annotate +25+65 'Anthony' \
                      -gamma 2  +level 0,1000 -white-threshold 999 \
                      -morphology Distance Euclidean:4,1000 -auto-level \
                      -shade 135x30 -auto-level +level 10,90% \
                      -adaptive-blur 0x2  font_conic_smoothed.jpg

            [IM Output]

            Moving the "-adaptive-blur" to before the use of Shade will cause the edges to be blured, but not the central ridge (skeleton) of the font shapes. The result look like the sharp ridges are pushing up into a rubber sheet.


              convert -size 320x100 xc:black -font Candice -pointsize 72 \
                      -fill white   -annotate +25+65 'Anthony' \
                      -gamma 2  +level 0,1000 -white-threshold 999 \
                      -morphology Distance Euclidean:4,1000 -auto-level \
                      -adaptive-blur 0x2 \
                      -shade 135x30 -auto-level +level 10,90%  font_conic_ridge.jpg

            [IM Output]

            Using a different Distance Kernel, such as Chebyshev, works better with more regular looking fonts, such as the Arial font family.


              convert -size 320x100 xc:black -font ArialBk -pointsize 70 \
                      -fill white   -annotate +5+70 'Anthony' \
                      -gamma 2  +level 0,1000 -white-threshold 999 \
                      -morphology Distance Chebyshev:1,1000 -auto-level \
                      -shade 135x30 -auto-level +level 10,90% font_chebyshev.jpg

            [IM Output]

            Inner Bevel Font: Limiting the distance by clipping the distance function will bevel just teh edges of the shape.


              convert -size 320x100 xc:black -font Candice -pointsize 72 \
                      -fill white   -annotate +25+65 'Anthony' \
                      -gamma 2 +level 0,1000 -white-threshold 999 \
                      -morphology Distance Euclidean:4,1000  -level 0,5000 \
                      -shade 135x30 -auto-level +level 10,90% font_inner_bevel.jpg

            [IM Output]


            Arched Font: The "-wave" operator (see Sine Wave Displacement for details), will shift the pixels of the image vertically, to form an arch. Verticals will remain vertical, with the characters being sheared to produce the curve.


                convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                -fill navy  -annotate +25+65 'Anthony' \
                -background lightblue -wave -50x640 -crop x110+0+10 \
                font_wavy.jpg

            [IM Output]

            Note that to use "-wave" to create an arch you need to use 'wave length' that is twice the width of the image (2 × 320 or 640 pixels). Also as "-wave" adds extra space to the image by the amount it is arched, requiring that space to be trimmed or cropped afterward.

            It is a simple, fast but effective way of making an arch of text.

            Arc Font: The General Distortion Operator also provides other text/image warping methods. The 'Arc' method for example will bend a font into a true circular arc, rather than the vertically shifted 'arch' of the previous example.


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                       -fill navy -annotate +25+65 'Anthony' \
                       -distort Arc 120  -trim +repage \
                       -bordercolor lightblue -border 10  font_arc.jpg

            [IM Output]


            Circle Font: You can even take it to extremes and wrap the text into a complete, or almost complete circle.


               convert -font Candice -pointsize 32 -background lightblue \
                       -fill navy label:"Anthony's IM Examples" \
                       -virtual-pixel background  -distort Arc 340 \
                       font_circle.jpg

            [IM Output]

            See Arc Distortion for more options and possibilities.

            Spiral Font: Adding a little rotation to slant the font at an angle before wrapping it, the circle can be converted into a spiral.


               convert -font Candice -pointsize 32 -background lightblue \
                       -fill navy  label:"Anthony's IM Examples" \
                       -rotate 12 -virtual-pixel background -distort Arc 360 \
                       -trim -bordercolor lightblue -border 5x5  font_spiral.jpg

            [IM Output]

            The height of the text (radially) however remains constant, it is not stretched or compressed as it gets closer into the center, producing strong aspect distortion to characters. You could solve that by using a perspective distortion as part of the text rotation, to adjust the font hight, before applying the Arc distortion.

            The problem with this technique is that you can only do one twist of the spirl, though with multiple lines and some care to line up the lines, you could generate multiple spirals.

            If you try this, please submit an example back to me?


            Vibrato Font: The "-wave" operator that we used in the Arch'ed Font above can also be used at a higher frequency and smaller amplitude to make a vibrating font. Also by adding some rotation operations, you can even make the vibration at whatever angle you like!


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                       -fill navy  -annotate +25+65 'Anthony' \
                       -background lightblue -rotate 85  -wave 2x5   -rotate -85 \
                       -gravity center  -crop 320x100+0+0 +repage font_vibrato.jpg

            [IM Output]

            For more information on using distorts like this see example page on Warping Images, and especially the Wave Distortion Operator.

            Comet Font: One of the specialised blurs operators, "-motion-blur" allows you to create a comet like tail to objects in an image.


               convert -size 340x120 xc:lightblue  -font Candice  -pointsize 72 \
                       -fill navy   -annotate +45+95 'Anthony' -motion-blur 0x25+65 \
                       -fill black  -annotate +45+95 'Anthony' -motion-blur 0x1+65 \
                       font_comet.jpg

            [IM Output]

            You can liven this compound font up by using different colors to make a real fiery event.

            You can also do much more with Specialized Blurs, however this whole aspect of IM is still experimental and the syntax of these operators may change in the near future.

            Smoking Font: combining this with wave and you can make the comet font look like smoke, a smell, or even flames are rising off the font!


               convert -size 320x120 xc:lightblue  -font Candice  -pointsize 72 \
                       -fill black  -annotate +25+95 'Anthony'  -motion-blur 0x25+90 \
                       -background lightblue -rotate 60  -wave 3x35  -rotate -60 \
                       -gravity center  -crop 320x120+0+0 +repage +gravity \
                       -fill navy   -annotate +25+95 'Anthony'   font_smoking.jpg

            [IM Output]



            Do you have an interesting transform to add to the above list?

            Using a Mask Image with Fonts
            Drawing a "Stamped Font" on a background image is actually a lot more difficult that most of the methods of generating fancy fonts I detailed above. The reason is that part of the original font is erased, which presents a problem when drawing it on a background that is not a simple solid color.

            Here is the composite font image we generated above.


               convert -size 320x100 xc:lightblue -font Candice -pointsize 72 \
                       -fill black      -annotate +24+64 'Anthony' \
                       -fill white      -annotate +26+66 'Anthony' \
                       -fill lightblue  -annotate +25+65 'Anthony' \
                       font_stamp.jpg

            [IM Output]

            If we try to draw the font on a transparent background (PNG format image), using exactly the same method, we just fail...


               convert -size 320x100 xc:transparent -font Candice -pointsize 72 \
                       -fill black        -annotate +24+64 'Anthony' \
                       -fill white        -annotate +26+66 'Anthony' \
                       -fill transparent  -annotate +25+65 'Anthony' \
                       trans_stamp.png

            [IM Output]

            What happened was that we tried to erase the center part of the font with the "transparency" color. But as you can see drawing with transparency, just draws nothing! So the result above was the same as if the last 'erase' -annotate" operator do not work at all.

            There are about half a dozen solutions to this problem. I will present three such methods here, while others are talked about in various other places in the IM example pages.

            Probably the simplest is not to fix the above font at all, but to use a 'mask' when drawing it onto the background image to tell the "composite" command, to ignore the middle section.

            A "composite" mask image is a grey-scale image, pure black for parts that will be transparent, and pure white for any parts that you want completely visible (opaque). Any grey shades will be draw as semi-transparent, merging into the background colors underneath.

            Well our image above is almost right, so lets just mask out all the parts we don't want. We start with a black background (fully transparent), then draw anything we want in white, and anything we don't want in black.


               convert -size 320x100 xc:black -font Candice -pointsize 72 \
                       -fill white   -annotate +24+64 'Anthony' \
                       -fill white   -annotate +26+66 'Anthony' \
                       -fill black   -annotate +25+65 'Anthony' \
                       mask_mask.jpg

            [IM Output]

            Note that the mask we created is not just black and white, but has various shades of grey along the edges of the areas due to anti-aliasing (See Anti-Aliasing Examples for details). These grey pixels makes the final image edges smoother, and is very important, as these pixels represent semi-transparent (only half visible) pixels.

            Now that we have a mask, we can mask out the unwanted sections of the image. We can do this while we are drawing (overlaying) the image onto a plasma background. Note the order of all three image arguments (font, background, then mask).


              convert -size 320x180 plasma: -shave 0x40 plasma_background.jpg
              composite trans_stamp.png   plasma_background.jpg   mask_mask.jpg \
                        mask_result.jpg

            [IM Output]

            A three argument "convert -composite" form of this is...


              convert plasma_background.jpg  trans_stamp.png  mask_mask.jpg \
                      -composite  mask_result2.jpg

            [IM Output]

            Good result, but we now need two images to draw the compound font. It would be better if, we only need one image, with the mask built directly into the the image itself.

            Basically we want to completely replace the alpha channel of our font image with a copy of the font image mask we created. That is we merge the font image (supplying the colors of the pixels) directly with its mask (supplying the images alpha channel).

            The alpha composition setting 'CopyOpacity' does this replacement. Note the order of the arguments in the command. In this case, the font itself is the background image, while the mask is the image being overlaid into the background image.


              composite -compose CopyOpacity   mask_mask.jpg   trans_stamp.png \
                        trans_stamp3.png
              composite trans_stamp3.png   plasma_background.jpg  mask_result3.jpg

            [IM Output] [IM Output]

            The result of all this is that the central part of the font has been, finally, properly erased by making it fully transparent. The resulting single image can thus be overlaid onto any background easily, without needing any extra masking image.

                Shrinking a larger transparent font stamp like the above creates a very good watermark. Shrinking will make the outline less opaque and less pronounced, just as a watermark should be. The two colors also ensure the mark is reliably visible on both very light and very dark images.

            For more information on using image masks, see Editing Image Masks.

            Advanced Font Processing
            By combining the above techniques together, with appropriate colors and other fancy fonts that are available, you can make some fantastic effects, which often look completely different to the original techniques shown above.

            More Complex Fonts - an example
            For example here we generate a very complex and colorful bit of text.


              convert -font Times-Bold -pointsize 64 \
                                 -background none  label:"Colorful Arc" \
                      \( +clone -sparse-color Barycentric '0,%h blue %w,0 red' \
                         \) -compose In -composite \
                      -virtual-pixel transparent -distort arc 120 \
                      \( +clone -background black -shadow 100x2+4+4 \
                         \) +swap -background white -compose over -layers merge +repage \
                      colorful_arc.jpg

            [IM Output]

            The complex command above is laid out so as to perform each major image processing step on separate lines.

            First the text image is created. Then a Two Point Gradient is generated as a color overlay. Other coloring methods such as Blurred Random Images, Fractal Plasma, or Tiled Canvases could also have been used.

            The color overlay then used to color the text using the In Alpha Composition operator. The colored text is then distorted using an Arc Distortion, and finally a Shadow is generated and Layer Merged under the text. That last method also Removes the Transparency, replacing it with white, before saving to JPEG.

            For more information on such complex image processing see, Complex Image Processing and Debugging.

            Neon Sign
            Here is another simple example. By using a Soft Outline font on a dark background, but using all the same colors, and an appropriate font, you can generate a simple 'Neon Sign' effect...


              convert -fill dodgerblue -background black -font Anaconda -pointsize 72 \
                      label:' I M  Examples ' -bordercolor black -border 30x30 \
                      \( +clone -blur 0x25 -level 0%,50% \) \
                      -compose screen -composite    neon_sign.gif

            [IM Output]

            And with just a little more work, you can animate it too! But I'll leave that as an exercise for the reader.

            See Advanced IM Examples for special effects such as "Gel" Effects, and "Aqua" Effects. For some examples of other font effects you may like to try and implement see XaraXone, Using Contour Tool. IM can easilly create contour effects such as those shown.

            Metallic Effect
            This effect is essentually a rounding, and Color Lookup Table replacement effect. See discussion Metallic Effect. Working Example by snibgo


# Generate a blured input font shaped mask
# first blur-level is a rounding or 'puddling' effect
# the second blur is the important one for the metallic effect.
            convert -background none -pointsize 160 -font Candice label:" Anthony " \
                    -blur 0x5 -channel A -level 40%,60% +channel \
                    -blur 0x3    metallic_input.png

# Metallic Color Lookup Table
            convert \
              -size 1x1000 gradient:  -gamma 0.9 \
              -function Sinusoid 2.25,0,0.5,0.5 \
              \( gradient:'rgb(100%,100%,80%)-black' -gamma 1 \) \
              +swap \
              -compose Overlay -composite \
              -rotate 90 \
              metallic_clut.png

# Give blurred font a metallic look
#  * first create a vertial gradient
#  * then merge this with a 'shade' reflective gradient
#  * before applying the color to the resulting gradient
#  * finally add a shadow.
            convert metallic_input.png -set colorspace RGB \
              \( -clone 0 -alpha off \
                 -sparse-color Barycentric "0,0 White  0,%[fx:h-1] Black" \
                 -alpha on \
              \) \
              \( -clone 0 -alpha extract -shade 135x45 -auto-gamma -auto-level \
                 -alpha on -channel A -level 0%x10% +channel \
              \) \
              -delete 0 -compose Overlay -composite \
              metallic_clut.png -clut  -set colorspace sRGB \
              \
              \( +clone -background navy -shadow 80x2+5+5 \
              \) +swap -background None -compose Over -layers merge \
              \
              -trim +repage metallic.png
https://legacy.imagemagick.org/Usage/annotating/
            This document presents various ways of annotating a large image with either text or some other image. The annotation may be bold and highly visible, or subtle and hidden.

            Reasons for annotating images are varied, but are usually either to

                Mark the image with information about what the image is about.
                Point out or highlight some aspect of the image.
                Add copyright or logos to the image as a form of copy protection. 

            ImageMagick provides a lot of ways to do these things, but not all are easy to discover from the manuals on your own. This page tries to present the common methods used. Many of the specific methods are discussed more fully on other example pages.

            If you are interested in annotating or watermarking a GIF animation, I suggest you first look though this document, then jump to Annotating GIF Animations, to start you off.

            Annotating Images
            The basic problem with labeling an image is doing so the text is readable no matter what the image. The following show many methods, show of which can be expanded to do more complex tasks.

            In these examples, I am limiting myself to the default font of ImageMagick. You are encouraged to use different fonts and point sizes appropriate to what you want to achieve.

            Labeling Below (or Above) an Image
            Append a Label with centering is now possible, from IM v6.4.7-1, as Image Appending now follows the gravity setting, for alignment purposes.


              convert dragon.gif   -background Khaki  label:'Faerie Dragon' \
                      -gravity Center -append    anno_label.jpg

                [IM Output]

            By reordering the images you can append the label above the image.


              convert dragon.gif   -background Orange  label:'Faerie Dragon' \
                      +swap  -gravity Center -append    anno_label2.jpg

                [IM Output]

            Splice and Draw is very simple way of adding extra space to an image to allow us to draw/annotate the label into the image.


              convert dragon.gif \
                      -gravity South   -background Plum   -splice 0x18 \
                      -annotate +0+2 'Faerie Dragon'   anno_splice.gif

                [IM Output]

            The same method can be used to draw a label above the image, just replace the gravity setting of 'South' with 'North'. Easy!


              convert dragon.gif \
                      -gravity North   -background YellowGreen  -splice 0x18 \
                      -annotate +0+2 'Faerie Dragon'   anno_splice2.gif

                [IM Output]

            The "-draw" operator is no longer recommended for direct drawing onto images, unless part of more complex drawing functions. See the section on Text to Image Handling for more details of other text drawing methods and techniques.

            Label using Montage The montage command in ImageMagick is often overlooked by users as only useful for creating a display of a whole directory of images. It does provide a very simple way to add labels an image.


              montage -label "Faerie Dragon"  dragon.gif \
                      -geometry +0+0 -background Gold anno_montage.jpg

                [IM Output]

            Montage can also add a frame and other things to the image for you, so this form of labeling has a lot of extra possibilities beyond that of simple labeling of the image.


              montage -label "Faerie Dragon" dragon.gif \
                      -font Candice -pointsize 15 \
                      -frame 5  -geometry +0+0 anno_montage2.jpg

            For more info about using montage see Montage, Arrays of Images. 	[IM Output]

            Label using Polaroid An alternative to using montage, is to use the Polaroid Image Transformation, to generate a rather fancy commented image.


              convert -caption "Faerie Dragon" dragon.gif -gravity center \
                       -background black +polaroid anno_polaroid.png

            Warning this image is distorted, (curved and rotated) with some randomization, as such the final image size can vary, unless rotation is disabled. It also contains complex shadow and transparency effects, so a PNG format image was used to save the resulting image. 	[IM Output]

            You can reduce the 'fuzziness' in the resulting image caused by the rotation by using a 'Super Sampling' technique. See Polaroid Image Transformation for an example of this.

            Labeling on top of the Image itself...
            The problem with writing text directly on a picture is that you can't be sure the text will be readable in the color you have chosen. The image being drawn onto could be black, white or a rainbow of colors.

            Outlined Label: The simplest method is to draw the string with a outline to separate the text from the image. However as the "-stroke" font setting adds thickness to a font both inward and outward, reducing its effectiveness (See Stroke and StrokeWidth for more information.

            The better way to draw an font with a background outline is to draw the text twice.


              convert dragon.gif -gravity south \
                      -stroke '#000C' -strokewidth 2 -annotate 0 'Faerie Dragon' \
                      -stroke  none   -fill white    -annotate 0 'Faerie Dragon' \
                      anno_outline.jpg

                [IM Output]

            As you can see it works, but not very well. It does work better with a thicker font, than the default 'Times' or 'Arial' font.

            For more details of this technique see Thick Stroke Compound Font.

            Draw Dim Box: The more classical method of making the annotated text more visible is to 'dim" the image in the area the text will be added, then draw the text in the opposite color. For example...


              convert dragon.gif \
                      -fill '#0008' -draw 'rectangle 5,128,114,145' \
                      -fill white   -annotate +10+141 'Faerie Dragon' \
                      anno_dim_draw.jpg

                [IM Output]

            This method works well, but as you can see I decided not to use "-gravity" in this example to place the text, as the darkened rectangle cannot be positioned with gravity (this may change in the future). Also its size and position can depend on the image and final text size, which may require some extra math calculations.

            Undercolor Box: Instead of trying to draw the background box yourself, you can get ImageMagick to use an 'undercolor' on the box. See Text Undercolor Box.

            The text 'undercolor' (as used in the library API), can be specified on the command line using the "-undercolor" option.


              convert dragon.gif  -fill white  -undercolor '#00000080'  -gravity South \
                      -annotate +0+5 ' Faerie Dragon '     anno_undercolor.jpg

                [IM Output]

            As you can see it is a lot simpler that drawing the dimmed box yourself, though an extra space at the start and end of the drawn text is recommended, to pad out the box slightly.

            Composited Label: The more ideal solution is to prepare a text image before-hand and then overlay it as an image.

            Here we create a simple label on a semi-transparent background, and overlay it.


              convert -background '#00000080' -fill white label:'Faerie Dragon' miff:- |\
                composite -gravity south -geometry +0+3 \
                          -   dragon.gif   anno_composite.jpg

                [IM Output]

            This last technique has very some distinct advantages. The dimmed box can be sized to fit the label, and it can be position with "-gravity" to position it correctly, without needing any specific knowledge of the image it is being added to, or of the drawn font being used.


            Also you are not limited to using just a simple dimmed box. Instead you can prepare very complex font image, either before-hand, so you can apply it many times, or on the fly on a per image basis. Just about all the Compound Font Effects styles are also available to you, allowing you to make your text additions very exciting and professional looking.

            Auto-Sized Caption: With the release of IM v6.3.2, the "caption:" can now automatically adjust the size of text to best fit a box of a particular size.

            But to make proper use of this for an overlay you really need to know how wide the image being annotated is. Here I gather that info then create and overlay a caption such that the text is automatically sized to best fit the space provided, with word wrapping.


              width=`identify -format %w dragon.gif`; \
              convert -background '#0008' -fill white -gravity center -size ${width}x30 \
                      caption:"Faerie Dragons love hot apple pies\!" \
                      dragon.gif +swap -gravity south -composite  anno_caption.jpg

                [IM Output]

            This technique is ideal for overlaying image comments onto an image, though doing so on the command line has its own problems as you are creating a new image, not annotating an old image. See User defined option escapes for a solution to this problem.

            Fancy Label: As a final example I will overlay a text string created using a fancy soft outlined font to make sure it remains visible, but without creating a rectangular box for the annotation.


              convert -size 100x14 xc:none -gravity center \
                      -stroke black -strokewidth 2 -annotate 0 'Faerie Dragon' \
                      -background none -shadow 100x3+0+0 +repage \
                      -stroke none -fill white     -annotate 0 'Faerie Dragon' \
                      dragon.gif  +swap -gravity south -geometry +0-3 \
                      -composite  anno_fancy.jpg

                [IM Output]
            If you are planning to composite the same label (say a copyright message) onto a lot of images, it would probably be better to generate your label separately and compose that label onto each image using the "mogrify" command.

            The "-geometry +0-3" offset in the above is used to position the composite overlay closer to the edge, as the soft fuzzy outline of this image is often larger that is necessary.


            All the above examples should of course be adjusted to suit your own requirements. Don't be a sheep and follow what everyone else does. Experiment, and give your own web site or program a distinct flavor from everyone else. And more importantly tell the IM community about it.

            FUTURE: select the black or white color based on the images relative
            intensity.  This uses a number if very advanced techniques.

              convert input.jpg  -font myfont -pointsize 25 \
                  \( +clone -resize 1x1  -fx 1-intensity -threshold 50% \
                     -scale 32x32 -write mpr:color +delete \)  -tile mpr:color \
                   -annotate +10+26 'My Text'              output.jpg

            Explanation:  Copy of image is resized to 1 pixel to find the images
            average color.  This is then inverted and greyscaled using -fx, then
            thresholded to either black or white, (as appropriate).
            This single color pixel is now scaled to a larger tiling image, and
            saved into a named memory register (mpr:).

            The image is then used to set the fill tile, for the annotated text.
            Their is however no simple method (at this time) to set the outline -stroke
            color of the draw text to its inverse.

            Other techniques are to use some text as a 'negate image' mask, or even a color
            burn or color dodge compose operation, to distort the image with the text.

            Overlaying Images
            The "composite" command and the "-composite" image operator in ImageMagick provides the primary means to place image on top of other images in various ways. The details of these methods are given in Alpha Compositing Examples Page.

            However there are more higher level operators that also make use of alpha compositing of images. These include Image Layering, as well as Positioning Images with Gravity, further down this examples page.

            The default compose method of compose is "Over" which just overlays the overlay image onto the background image, handling transparencies just as you would expect.

            The background image also determines the final size of the result, regardless of where the overlay is placed (using the "-geometry" option). It doesn't matter if the overlay is in the middle, halfway off the background image, or far far away, the output image is the same size as the background image.

            The geometry position of the image is also effected by "-gravity", so the positioning of the overlaid image can be defined relative to any of nine (9) different locations. See "Positioning Images and Text" below.

            On top of "-geometry" of the compose overlay, individual images can also have a page or canvas information (set using "-page" and "-repage" options), that can effect the final position of the images. This image specific information is however not effected by "-gravity".

            On with the examples...

            Overlaying is probably the most common form of image annotation, and is very simple to do. Here I overlay a 32x32 icon of a castle in the middle of a prepared button frame.


              composite -gravity center  castle.gif  frame.gif  castle_button.gif

            [IM Output] + [IM Output] ==> [IM Output]

            You can also position the sub-images exactly. Here we set a hand to point out the small craws of the faerie dragon.


              composite -geometry +31+105  hand_point.gif dragon.gif \
                        dragon_claw_pointed.jpg

            [IM Output] + [IM Output] ==> [IM Output]

            Exactly how an image is drawn on the background is controlled by the "-compose" setting. The default as used above is "-compose over" which just overlays the image on the background. Most of the other compose methods provided are not very usable except in very specific situations, but here are some of them. For more details of this setting and its effects see Alpha Compositing.

            Bumpmap is a tricky compose method and basically darkens the background image in accordance to the brightness of the overlay image. Anything that is white in the overlay is handled like it is transparent, while anything black becomes black on the output image. It is a bit like using the overlay as an ink stamp and that is a good way of picturing this operation.

            As a hint, overlaying with a bumpmap works best with light colored images. So you may need to prepare the bumpmap image before using.

            Here we resize our dragon image before using "-compose bumpmap" to draw it on a paper scroll image.


              composite \( dragon.gif -resize 50% \) scroll.gif \
                        -compose bumpmap -gravity center   dragon_scroll.gif

            [IM Output] + [IM Output] ==> [IM Output]

            Bumpmaps can also be used to set an overall effect on an image, in this case we tile a light colored background pattern over our dragon. Remember that a bumpmap image is treated as a grey-scale image, so any color in our overlay image is lost.


              composite -compose bumpmap  -tile rings.jpg \
                        dragon.gif  dragon_rings.jpg

            [IM Output] + [IM Output] ==> [IM Output]

                The "-tile" option above only works for compose operations using the "composite" command. In "convert" you will have to use the "tile:" image generator with a "-size" to specify the extent. You can of course make your source image overlay larger than the background image you are overlaying, as the result will be the size of the background or destination image.

            Multiply compose method is best known for its ability to merge two images with white backgrounds (like onto a page of text). Unlike the 'bumpmap' compose method, it does not pre-convert the overlaid image into grey-scale.


              mesgs PictureWords |\
                  convert -pointsize 18 text:-  -trim +repage \
                          -bordercolor white -border 10x5   text.gif
              composite -compose multiply -geometry +400+3 \
                        paint_brush.gif  text.gif  text_multiply.gif

            [IM Output] + [IM Output] ==> [IM Output]

            ASIDE: The complex command to generate "text.gif" above is just to create a typical text only image, the "mesgs" command just outputs a specific quotation, like "fortune" does but with more control.

            This method works very well in a lot of situations, but generally only if one (either) image is basically black (or greyscale) on a mostly white background. If both images contain regions of color, then you may get unusual results.

            In other words, this technique is perfect for overlaying line drawings, diagrams or images of text, on white (or reasonably light colored) images, such as images of printed or scanned pages.

            Water Marking
            Watermarking is an important job, as it provides a way of marking an image as belonging to some company or web site. Unfortunately this involves trashing the image in some way, to the detriment of the image itself.

            The basic goals of watermarking is

                The mark should be clearly visible regardless of whether the image is light or dark in color.
                It should be difficult to erase.
                and it shouldn't be too annoying to viewers. 

            All these factors are in conflict, and this is one reason why watermarking is so difficult to do well.

            Watermarking with Symbols
            One of the simplest, and most annoying forms of watermarking is to just to place a very small but specific image somewhere on the image being watermarked. Here we generated an image (using "logo:") that we want to watermark, using a small 'eyes' symbol.


              convert logo: -resize x180  -gravity center  -crop 180x180+0+0  logo.jpg
              composite -geometry +160+13 eyes.gif   logo.jpg  wmark_symbol.jpg

            [IM Output] + [IM Output] ==> [IM Output]

            The best idea for the placement of the small image is to add it so it looks to be actually part of the original image. In the above I added the "eyes" image so it looks almost like it is part of the wizards hat, (you don't want it to become too integrated into the image either). Consequently, this technique requires the human touch, which makes it impossible to fully automate.

            The small image can also be very difficult to remove, as it destroys completely the part of the image it overlaid. And if done well, is hardly noticeable, unless you are specifically looking for it.

            I have seen it used to good effect in many places on the web. One web site used a small dagger-like symbol. Images stolen from that website became very obvious when I spotted that same dagger symbol on images I found on other web sites.

            Watermarking with Text
            Just drawing text on an image is also a simple way of watermarking, and any of the label on image examples above can be used as a type of wartermark.

            However to do this properly you should use two different colors to prevent the text from disappearing when drawn on different colored backgrounds. As such some sort of Compound Font Effects should be used.


              convert logo.jpg  -font Arial -pointsize 20 \
                      -draw "gravity south \
                             fill black  text 0,12 'Copyright' \
                             fill white  text 1,11 'Copyright' " \
                      wmark_text_drawn.jpg

            This works well and can be automated, but it is too bold to be used as a good watermark as it stands out too well from the image.

                [IM Output]

            But by doing some preparation, an image with transparent background can be created that will be less evasive. For details of the steps being used to generate the watermark text, see Font Masking. Also the mask examples of Masking Images may be useful for you understanding.


              convert -size 300x50 xc:grey30 -font Arial -pointsize 20 -gravity center \
                      -draw "fill grey70  text 0,0  'Copyright'" \
                      stamp_fgnd.png
              convert -size 300x50 xc:black -font Arial -pointsize 20 -gravity center \
                      -draw "fill white  text  1,1  'Copyright'  \
                                         text  0,0  'Copyright'  \
                             fill black  text -1,-1 'Copyright'" \
                      +matte stamp_mask.png
              composite -compose CopyOpacity  stamp_mask.png  stamp_fgnd.png  stamp.png
              mogrify -trim +repage stamp.png

            [IM Output]

            Now we have a watermark font we can apply it to our image...


              composite -gravity south -geometry +0+10 stamp.png  logo.jpg \
                        wmark_text_stamped.jpg

            As you can see the watermark is not as bold as before, and even uses shades of grey rather the pure white and black. Even so it is still highly visible no matter what the background. The Compound Font Effects page details a lot of font styles that can be used in this way without overwhelming the image being watermarked. 	[IM Output]

            You can also tile the text over the whole image.

            Here we also avoid the need for an intermediate image by using a 'pipeline' of commands, with the output of one, feeding the next.


              convert -size 140x80 xc:none -fill grey \
                      -gravity NorthWest -draw "text 10,10 'Copyright'" \
                      -gravity SouthEast -draw "text 5,15 'Copyright'" \
                      miff:- |\
                composite -tile - logo.jpg  wmark_text_tiled.jpg

            This takes advantage of the fact that an image (like a photograph, not a diagram) will generally have some areas in which the tiled test string will be visible. You might like to make the text semi-transparent for your own watermarking (using say a half transparent grey such as "'#80808080'").

            You may also like to keep this tiling technique in mind with the following proper watermarking techniques.

                [IM Output]

            Watermarking with Images
            ImageMagick also provides a number of options that are specifically useful for more subtle watermarking, over a larger area. This is usually what is more commonly referred to, when you 'watermark' an image.

            To the right is a "water dragon" image I will use for these demonstrations. It has some transparency, which I used to check that IM is doing the right thing with respect to transparency, avoiding any horrible 'square' look to the results. 	[IM Output]

                Before IM version 6, the options "-watermark" and "-dissolve" were broken with their handling of the alpha channel (transparency) for the overlaying image, producing some very strange effects.

            Watermark compositing was meant to watermark images, and while it works, it tends only to work with pure white and black overlay images, producing ugly edge artifacts.


              composite -watermark 30% -gravity south \
                        wmark_image.png  logo.jpg    wmark_watermark.jpg

            For more detailed information on this option see the Watermark Option Usage page.

                [IM Output]

            Dissolve was found by me and others to work better.


              composite -dissolve 25% -gravity south \
                        wmark_image.png   logo.jpg  wmark_dissolve.jpg

            This works very well, but parts of the watermark will disappear on images with pure white and black pixels. That is dissolving white on white and black on black will not be visible in the final image. As these two colors are very common, it is better to do some extra pre-processing of the watermark so that is uses various shades of grey rather than pure white and black. (See "Greyed Dissolve" below) 	[IM Output]

            For more detailed information on this option see the Dissolve Option Usage page.

            Tiled: You can also tile the watermark across the background image instead of just adding it in one location. Just replace your gravity position with "-tile" instead. Of course in that case you may want to make the watermark even less intrusive.


              composite -dissolve 15 -tile \
                        wmark_image.png   logo.jpg  wmark_tiled.jpg

                [IM Output]

            Greyed Bumpmap: To use bumpmap properly as a watermark the image needs some preparation to make both white and black a lighter grey color range, using a Grey-Scale Adjustment technique. If this is not done the result would be very very bold.


              convert wmark_image.png  -fill Gray91 -colorize 80  miff:- |\
              composite -compose bumpmap -gravity south \
                        -  logo.jpg    wmark_bumpmap.jpg

                [IM Output]

            The biggest problem with bumpmap as a watermark is that the operation will only darken an image. As such this technique is fairly useless for very dark images.

            Greyed Dissolve: The same preprocessing technique can also be useful with dissolve method so the white parts of the watermark image darken slightly on white background, and ditto also to lighten black areas of the watermark on black parts of the image.


              convert wmark_image.png  -fill grey50 -colorize 40  miff:- |\
              composite -dissolve 30 -gravity south -  logo.jpg wmark_dissolve_grey.jpg

                [IM Output]

            This I'd say is just about ideal as a watermark, satisfying all the requirements. I would however further adjust the final dissolve to make the watermark even less noticeable.

            Tiled Greyed Dissolve: This is exactly as above but tiled over the image with an even lower dissolve value.


              convert wmark_image.png  -fill grey50 -colorize 40  miff:- |\
              composite -dissolve 15 -tile  -  logo.jpg wmark_dissolve_tile.jpg

                [IM Output]

                The "composite" command does not know how to handle multi-image files such as animations. However other methods do allow you to do this. See Modifying Animations, Annotating for examples of annotating and overlaying multi-image files.

            Positioning Images and Text with Gravity
            The 'Gravity' of the Situation
            As you can see above, being able to position images and text in a larger image can be just as important as anything else. Naturally the "-gravity" setting is one of the most important aspects of this.

            On the ImageMagick Mailing list, Tim Hunter declared
                “ Gravity will make you crazy until you get the hang of it. ” 
            This is a sentiment to which I agree wholeheartedly.

            Gravity will only be applied in the following situations...

                Any operation that involves a 'geometry' like setting, like "-crop" and "-geometry" positioning of images for Alpha Composition, including Multi-image Layered Composition.

                It is also used, as means of specifying the text justification by the various text to image generators such as "label:" and the text justification by the various text to image generators such as "caption:".

                The "-annotate" text drawing operator also uses it for text positioning as well as justification.

                And finally it is used by the "-draw" method for its 'text' and "image' methods, and ONLY those methods.

            However "-gravity" is NOT used for

                Any image list or layer operators, such as "-mosaic", "-flatten" and most "-layers" methods, and especially not in GIF animations.

                All of these operations uses image offsets on a larger virtual canvas (set using the "-page", "-repage" meta-data settings) to position images. Such offsets are always relative to the top-left corner of the images virtual canvas. No understanding of "-gravity" is used in this methodology.

                Any other "-draw" method does not use "-gravity" for positioning. It is also unlikely to do so as "-gravity" is not defined under the SVG draft which IM follows for these low level functions.

            What does all this this mean?

            First and most importantly it defines the origin point that "-geometry" uses to position overlay text and images relative to the images edges, sides and center, without the user needing to know the actual size of the image. This is its primary function.

            Secondly it defines horizontal and vertical justification of the overlaid object (text or image) relative to that defined point of gravity. For example, with 'East' gravity the text or image will be placed to the right (right justification) of the defined point.

            Justification should technically be a separate setting to "-gravity", though closely related, however IM currently combines both into a single setting.

            There is a push to separate the two aspects such if a "justification" setting is undefined it falls back to using the current "-gravity" setting. If you find you need this, request it from Cristy (via the mail list). If enough users ask for it I am sure it will eventually be implemented.

            Image Positioning using Gravity
            Here is an example of using gravity to position images on a background.


              composite label:Default                      rings.jpg gravity_default.jpg
              composite label:Center    -gravity center    rings.jpg gravity_center.jpg
              composite label:South     -gravity south     rings.jpg gravity_south.jpg
              composite label:East      -gravity east      rings.jpg gravity_east.jpg
              composite label:NorthEast -gravity northeast rings.jpg gravity_northeast.jpg

            [IM Output] [IM Output] [IM Output] [IM Output] [IM Output]

            Note that the actual position of the image is also justified according to the the "-gravity" setting. That is a gravity of "South" will center the image at the bottom of the larger image, but above that gravity point. This will become more important later with text rotation.

            The other thing to remember is that the position specified by any "-geometry" setting is relative to the position gravity places the image. Not only that the direction of the position is also modified so that a position direction is inward.

            For example the "-gravity South -geometry +10+10" will move the label image further into the background. That is the Y direction of the geometry position has been reversed, while the X direction was left alone.


              composite label:Default   -geometry +10+10 \
                        rings.jpg gravity_default_pos.jpg
              composite label:South     -geometry +10+10 -gravity south \
                        rings.jpg gravity_south_pos.jpg
              composite label:NorthEast -geometry +10+10 -gravity northeast \
                        rings.jpg gravity_northeast_pos.jpg

            [IM Output] [IM Output] [IM Output]

            You can also use "-gravity" with "-draw image", to multiple images with a single command.


              convert rings.jpg \
                      -gravity Center     -draw "image Over     0,0 0,0 'castle.gif'" \
                      -gravity NorthEast  -draw "image Bumpmap  0,0 0,0 'castle.gif'" \
                      -gravity SouthWest  -draw "image Multiply 0,0 0,0 'castle.gif'" \
                      gravity_image.jpg

                [IM Output]

            And you can also now use "-composite" to overlay images onto the background as well...


              convert rings.jpg \
                      -gravity Center     castle.gif  -compose Over     -composite \
                      -gravity NorthWest  castle.gif  -compose Bumpmap  -composite \
                      -gravity SouthEast  castle.gif  -compose Multiply -composite \
                      gravity_image2.jpg

                [IM Output]

            For more detail of about the "-compose" settings used above see Alpha Composition. For other methods of overlaying combining and overlaying multiple images into one single image, see The IM Examples section Layers of Multiple Images.
            Text Positioning with Gravity
            That is all well and good for images but what about drawing text directly on images. Well the same basic effects as for images apply.

            As mentioned above gravity will also effect the positioning of text using either the "-draw" 'text' method, or the better "-annotate" text drawing operator.


              convert rings.jpg -resize 120x120  \
                      -gravity northwest  -annotate 0 'NorthWest' \
                      -gravity east       -annotate 0 'East' \
                      -gravity center     -annotate 0 'Center' \
                      -gravity south      -annotate 0 'South' \
                      -gravity northeast  -annotate 0 'NorthEast' \
                      gravity_text.jpg

                [IM Output]

            There is one very important difference between positioning images and text. If you draw a text string, without defining any form of "-gravity", the string will be drawn relative to the 'baseline' of the font.
            For example, lets actually do this...


              convert rings.jpg -annotate 0 'String' gravity_text_none.jpg

                [IM Output]

            If you look carefully you will only see the small loop tail of the 'g' in 'String' was visible at the top edge of the resulting image. The rest of the string has been drawn outside the background image.

            However if you set "-gravity" to 'NorthWest' the text will be positioned as if it was an image. That is relative to its bounding or undercolor box as defined by the font.
            For example...


              convert rings.jpg -gravity NorthWest -annotate 0 'String'  gravity_text_nw.jpg

                [IM Output]

            The reason for the distinction is to ensure that IM text drawing remains compatible with other vector drawing image formats like the "SVG". These formats do not use gravity, so turning on gravity tells IM to follow the same rules as image placement when doing text drawing, rather than the vector graphics rules, involving the font 'baseline' and 'start' point of the text.

            If you do turn on gravity and then want to later turn it off, you can use either "-gravity none" or "+gravity" to reset it back to the default 'no gravity' setting.

            Lets apply a text offset and draw both the default 'None' and 'NorthWest' arguments for "-gravity", just so you can see how closely the two forms are related.


              convert rings.jpg \
                      -gravity NorthWest -annotate +10+20 'NorthWest' \
                      -gravity None      -annotate +10+20 'None' \
                      gravity_text_pos.jpg

                [IM Output]

            While it may not look it in this example, these two strings can overlap, particularly with regard to descenders on letters such as 'g', and 'p'. That this the two string are not properly separated by 'pointsize' units, but only by the fonts baseline height.

            The best idea is not to mix the two modes in your own image processing. Either use gravity, or don't. The choice is yours.

            Text on Left Edge using Gravity
            As a final example here is the way to actually annotate centered along the left edge of an image.

            The problem here is that when you rotate text, it rotates around the text 'handle'. Unfortunatally this handle is set by gravity BEFORE the text is rotated, and as such does not work very well, unless you use restrict yourself to 'centered text'.

            For example here is a typical 'first try' to positioning text so that it is positioned along the center of the left edge of the image. Of course it fails rather unexpectally!


              convert rings.jpg \
                      -gravity West -annotate 90x90+10+0 'String' \
                      gravity_text_left_fail.jpg

                [IM Output]

            As you can see the text was positioned on the left edge, but only so that start (where the pre-rotated 'handle' is) is centered.

            The cause of this problem is that in IMv6 the "-gravity" setting is also directly used to set the text 'justification' (which sets the 'handle' used to position the text).

            There is some animated demos of gravity effects on rotated text written in PerlMagick API (Download "im_annotation.pl". I also created a shell script version of the same program, "im_annotation", and "im_annotation_2".

            A trick to making this work to rotate the whole image first then use center south! It is a non-sensical solution, but it works.


              convert rings.jpg -rotate -90 \
                      -gravity South -annotate +0+2 'String' \
                      -rotate 90  gravity_text_left.jpg

                [IM Output]

            An alternative method is shown below in Text Positioning using Distort.

            Text Positioning using Draw
            While in the above I used a 'text offset' to position the text relative to the "-gravity" point, it is not the only way to do so. The other method is to use a "-draw translate" option to position the text.

            This has the advantage in that you can arrange to position text without gravity effects, while still using gravity to 'justify' the positioning 'handle' within the text.

            In these examples I added some extra construction lines (which are also not gravity effected) to show how the position is applied from the center point of the image.

            Text with an offset...


              convert -size 100x100 xc:white -gravity Center \
                      -fill cyan  -draw 'line 50,50 70,70' \
                      -fill red   -draw 'line 68,70 72,70 line 70,68 70,72' \
                      -fill blue  -draw "text 20,20 'Offset'" \
                      text_offset.jpg

                [IM Output]

            Text with a translation...


              convert -size 100x100 xc:white -gravity Center \
                      -fill cyan -draw 'line 50,50 70,70' \
                      -fill red  -draw 'line 68,70 72,70  line 70,68 70,72' \
                      -fill blue -draw "translate 20,20 text 0,0 'Translate'" \
                      text_translate.jpg

                [IM Output]

            As you can see both produce the same effective result. But as the "-draw text" requires you to give an offset that was part of its arguments, it is more commonly used to position the drawn text from the command line.

            However while both of these methods produce the same result, they will produce completely different results when text rotation is also applied. Basically due to the order in which the actions are being applied.

            Draw Rotated Text
            There are two separate ways of positioning drawn text: use a 'text offset', or 'translate' the text to the final position. The effects of these two positioning methods produce very different results when rotation is also applied. The reason for this is complex, but essentially involves how IM does Drawing Surface Warps.

            Having said that lets look at what happens if you rotate some text using the two different positions.

            Just an offset, without rotation...


              convert -size 100x100 xc:white -gravity Center \
                      -fill cyan -draw 'line 50,50 70,70' \
                      -fill red  -draw 'line 68,70 72,70  line 70,68 70,72' \
                      -fill blue -draw "text 20,20 'None'" \
                      rotate_none.jpg

                [IM Output]

            Rotating Text with an offset...


              convert -size 100x100 xc:white -gravity Center \
                      -fill cyan -draw 'line 50,50 50,78' \
                      -fill red  -draw 'line 48,78 52,78  line 50,76 50,80' \
                      -fill blue -draw "rotate 45 text 20,20 'Offset'" \
                      rotate_offset.jpg

                [IM Output]

            Rotating Text with translation...


              convert -size 100x100 xc:white -gravity Center \
                      -fill cyan -draw 'line 50,50 70,70' \
                      -fill red  -draw 'line 68,70 72,70  line 70,68 70,72' \
                      -fill blue -draw "translate 20,20 rotate 45 text 0,0 'Translate'" \
                      rotate_translate.jpg

                [IM Output]

            This is actually what most people want. Though the offset rotation can be useful for some special effects. Note how order of these Drawing Surface Warps are reversed to the order they are given. The rotation is performed first, and the translation is performed second. If you reverse the 'rotate' and 'translate' methods you will get the same result as an ordinary 'text offset', a rotated offset.

            The "-annotate" operator was designed specifically to make positioning rotated text easier, by specifically asking IM to draw the text with rotation, instead of 'doing surface warping'.

            Annotate with rotate and offset...


              convert -size 100x100 xc:white -gravity Center \
                      -fill cyan -draw 'line 50,50 70,70' \
                      -fill red  -draw 'line 68,70 72,70  line 70,68 70,72' \
                      -fill blue -annotate 45x45+20+20 'Annotate' \
                      rotate_annotate.jpg

                [IM Output]

            The problem with the above examples is that the IMv6 "-gravity" setting not only refers to the position on the background image, but also the position in the overlay image that is to be drawn.

            IMv7 will be adding 'Text Justification', which refers to the overlay position, as a separate (but related) setting to gravity (background position).

            Text Positioning using Distort
            Using SRT Distortion with Layering Images, is particularly good method for placing images (or text in images).

            Basically it allows you complete low level control over both the point at which the image is placed, as well as how the image is to be arranged at relative to that point.

            To start with here we create a 'text image' with a transparent background and simply 'layer' the image onto the background image.


              convert rings.jpg -background none label:'Some Text' \
                      -flatten  layer_simple.jpg

                [IM Output]

            As you can see the text simply added to image at top left corner.

            Lets rotate it using distort (layers variant) -- Not the use of parenthesis to limit what image we distort!


              convert rings.jpg \( -background none label:'Some Text' \
                         +distort SRT 70 \
                      \) -flatten  layer_rotate.jpg

                [IM Output]

            Note that the text position was NOT changed! All that happens was that the distort rotated the text around the center point (the handle), but so that relative to the 'virtual canvas' that point did not move. Thus when the now larger image is Flattened its point of rotation 'the center of the text image' did not move.

            The next step is to move that handle, but for this we need to use almost the full set of SRT Distortion arguments.

            Because we want to continue to use the 'center handle' as well we need to use some Image Property Percent Escapes, or more specifically FX Percent Escapes.

            So lets place the center at '+60+60' in the background image


              convert rings.jpg \( -background none label:'Some Text' \
                         +distort SRT '%[fx:w/2],%[fx:h/2] 1 70 60,60' \
                      \) -flatten  layer_translate.jpg

                [IM Output]

            Another way of moving a 'layer image' is using the Repage Operator. Especially a relative move using a '!' flag. The 'handle' for this is by the nature of layer images, the top left corner.

            The SRT Distortion Operator will not only translate the image using the handle specified, but can use sub-pixel (floating point) positions for both of those handles. That is it can distort the text by sub-pixel increments to any location, without the integer restrictions most other operations have.

            The final example is placing the 90 degree rotated text on the left edge.

            The handle of the text to rotate around and position will this time be at the be the center bottom of the text, before it was rotated. That is a calculated position of '%[fx:w/2],%h'.

            Position on the background image must also now be calculated to be the center left edge, ('0,%[fx:h/2]'). The problem is the SRT Distortion Operator does not have access to the background image when it is distorting the text image.

            The solution is to do this position calculation when the background image available, and save it into some 'personal setting' which can then be added to the distort arguments. This technique is looked more closely in Extract Information from Other Images.

            So here is the result. First calculate the position on the background image. Then distort the text image so its 'handle' is also moved to that pre-calculated position.


              convert rings.jpg -set option:my:left_edge '0,%[fx:h/2]' \
                      \( -background none label:'Some Text' \
                         +distort SRT '%[fx:w/2],%h 1 90 %[my:left_edge]' \
                      \) -flatten  layer_on_left.jpg

                [IM Output]

            The 'my:' string can be anything that does not clash with existing prefixes. That is I use it to hold MY settings, separate to any other settings ImageMagick may use for coders or specific options. Prefixing 'my:' is a good choice for this.

            Percent escapes are handled purely as string substitutions, and in fact we could generate the whole Distort option as a string. The only problem is you can not do math on your 'my:' settings, after they have been set. So any mathematics must be done before hand. This is something that will be looked at for IMv7, so that FX expressions use % escape variables.
https://legacy.imagemagick.org/Usage/thumbnails/
            One of the biggest uses ImageMagick is put to is the creation of thumbnails for family photo albums, sports and hobby pages, catalogs, and so on. Typically for use on the world wide web or in photo CDs.

            This page provides examples and techniques used to generate thumbnails.

            Thumbnail Storage
            I would like to first start with one very important point.

            The original image from video cameras and photo scanning should be kept in a safe place in the original format, preferably a non-lossy format (not the JPEG image format), without any modification resizing or other change, except possibly a file name change. Of course a scanned image can be re-scanned, but it is far better to re-use your original source than to re-do it from a already degraded copy later.

            This is VERY important as any form of modification will mean a loss of some information in the image, and provides a source from which you can re-work your image for other uses. The original image does not have to be your working image, which may be resized or color adjusted for display, just be sure to have your image saved and backed up somewhere safe for future use.

            The next thing to do, even before you create any thumbnails, is to decide how you want to save your thumbnail relative to your normal sized image format, then stick to that scheme. This is especially important for web pages.

            Schemes include...

                Save the main photo image in the lossy JPEG format at the size you want or need, then use the same name for the generated thumbnail but using the GIF image format. EG Same filename but a different format and suffix.

                Main Image: photo_name.jpg Thumbnail: photo_name.gif

                Store the thumbnails with the same name in a sub-directory called for example "thumbs" or whatever is convenient for you.

                Main Image: photo_name.jpg Thumbnail: thumbs/photo_name.jpg

                Use the same format as the original image, but with an extra string added to the file name. Typical string additions include "_tn", "_small", "_thumb", etc...

                Main Image: photo_name.jpg Thumbnail: photo_name_tn.jpg

                Some combination of the above.

                There is no reason why you cannot save thumbnails in different image format, with an extra image suffix appended to the filename, and saved in a subdirectory!

                Main Image: images/photo_name.jpg Thumbnail: thumbs/photo_name.jpg.gif

                This is actually quite common on the WWW, and I have even seen the the two directories stored on completely separate machines!

            The first scheme can use "mogrify" to generate all your thumbnails, without destroying the original image, by using a "-format" setting to specify the output image format.

            As of IM v3.2.0, the second scheme is now also possible to do with "mogrify" thanks to the addition of a special "-path" setting that specifies a different directory in which to save the modified images.

            For example, this converts JPG images into GIF thumbnails in a "thumbs" sub-directory that was just created.


              mkdir thumbs
              mogrify  -format gif -path thumbs -thumbnail 100x100 *.jpg

            The other methods will require you to either, first make a copy of the original image, before running "mogrify", create a special script to process the images, or some other DIY method. A number of the simpler non-IM techniques are detailed at the end of the example section for Batch Processing - Without using "mogrify".

            Whatever method you choose the important thing is to choose a scheme for thumbnail storage, and then stick with it. By using the same scheme for all your thumbnails you can then write shell or Perl scripts to make thumbnail generation and even generation of the HTML links easy. More on this later.

            Selection of the Thumbnail format
            The format in which you save a thumbnail can make a big difference to its final size on disk and download speed for web pages. In this regard I recommend you study the summary of the various Common File Formats.

            Specifically you should note...

                JPEG compresses well and is lossy, but is designed for large real world images, not small thumbnails. It also does NOT allow any form of transparency. In summary, the format is good for large images, bad for thumbnails. Watch out for profiles (see next section).

                While JPG is not recommended for thumbnails, for viewing images on the WWW it is recommended you use smaller 800x600 pixel image, at a much lower "-quality" percentage (say 50 or even 30%), though it will not look very good.

                It has also been suggested that using "-sampling-factor 2x1" will also produce a smaller JPEG image size.

                I do not recommend the full original image never be placed directly on the web, unless temporarily (at a referenced location) for a friend to download. Remember do not link to it, (even by directory indexing), and never for more than a day, or it may be Googled.

                GIF works for simple small images, and compresses okay. It has a color limit of 256, but for small images this is rarely noticeable. It can also do cartoon like animations of images, not that that is needed for thumbnails, unless you really what to get fancy.

                What is a problem is that the format only has Boolean (on/off) transparency, which makes for horrible looking borders on shaped images. The solutions to that is to design the thumbnail to only use Boolean transparency, or arrange it so it can only be used on a specific background color. For details see the examples on GIF's on a background color or pattern.

                PNG is the modern ideal format for thumbnails. It has a good compression, and internal format styles. It is non-lossy, and can display all colors, and these days it is understood by almost all browsers, (though for Microsoft Internet Explorer, before v7, needs some java scripting added to web pages).

                More importunately this format understands semi-transparent color, making shadows and edges sharp and clear, or faded and blurry as you wish. This format however does not do animations, though the related MNG format does. Very few browsers seem to support that format however.

                For thumbnails you can reduce the size of the final image by reducing the depth and number of colors, as well as setting a higher "bzip" compression quality (first digit in "-quality") for your final thumbnail image.

                For example, the following is suggested for small PNG thumbnails that does not involve transparency.


                        -strip  -quality 95  PNG8:thumbnail.png
                    

                Which uses a smaller, 8 bit, or 256 color limited, PNG format.

                You can also re-process the final image though secondary applications (See Non-IM PNG Processing) which can automatically find the best PNG compression for that specific image. There are also programs to do that color reduction to the smaller internal PNG format, while preserving semi-transparent colors. This is something IM currently does not handle. .

            One final word about formats... No matter what format you use for your thumbnails, if you must save an intermediate unfinished image, use a PNG (without any color reduction) or MIFF image format. Doing this will preserve as much color information about the image as possible in the intermediate stage. Only do color reduction, or save to GIF or JPEG formats as an absolute final step.

            This is important, so I repeat...
            Do NOT use JPEG, PNG8, or GIF for intermediate working images!
            Better to use PNG or MIFF.

            Profiles, Stripping, and JPEG Handling
            Many images from digital cameras, scanning software, and some paint programs (photoshop is notorious for this), save extra information about the image in the form of profiles. This includes image formats such a JPEG, PNG, TIFF and as of IM v6.2.4-1 GIF. Of course the IM specific format, MIFF also does this. (See Image Profiles for more detailed information).

            These profiles can be up to 60 Kb in size, so can make a big difference to your file size, and by default IM will preserve this profile information. Thumbnails have no need for this data and often not even the main image needs it.

            You can also remove the profiles from your images with the IM commands...


              convert input.jpg  -strip output.jpg

              mogrify -strip  *.jpg

            You can also use the option "-profile '*' " to remove the profiles.

            It is however recommended you only strip profiles when you modify an image, especially if reducing it in size for web displays, or thumbnail images.

            Stripping profiles while resizing, particularly for generating smaller thumbnail images, is so common that both "-resize" and "-strip" were combined into a new operation, just for this very purpose. Naturally enough this resize operation is called "-thumbnail".

            For example...


              convert -define jpeg:size=240x180 image.jpg -thumbnail 120x90 thumbs/image.gif

              mogrify -path thumbs -format gif -define jpeg:size=240x180 -thumbnail 120x90 '*.jpg'

                Before IM v6.5.4-7 the "-thumbnail" would strip ALL profiles from the image, including the ICC color profiles. From this version onward the color profiles will be preserved. If the color profile is not wanted then "-strip" all profiles.

            The "mogrify" will of course generate thumbnails for a whole directory of JPEG images, but be careful it does not overwrite any thumbnails you want to keep. For a number of other non-IM methods for looping over a large number of images see the example section for Batch Processing - Without using Mogrify.

            For very large images the "-thumbnail" resize operator goes further and first scales the image down to 5 times the final thumbnail size first, before doing the actual resize operation. This speeds up the thumbnail generation further.

            However for thumbnailing JPEG images, an even better method of limiting the initial image size can be used, by just not reading the whole image into memory in the first place.

            The "-define jpeg:size=" setting (as shown in the above example) is a special hint to the JPEG image library to reduce the amount data that is read in from VERY BIG JPEG images. See Reading JPEG Files.

                Before IM v6.5.6-0 this coder setting was extracted from the "-size" setting. This caused problems when users used "-size" for image creation but then had JPEG reading produce unexpected results. As such this was changed to be a special coder setting instead.

            In older versions of IM you may need to reset the setting using "+size before reading JPEG images, because of this 'dual' role.

            From IM version 6.2.6-2, a new Read Image Modifier was added, which lets you resize the input image immediately after it is read in. This option will work with ANY image format, not just JPEG image. It is however no substitute for using a "-define jpeg:size=" setting for JPEG images.

            As such the recommended way of resizing ANY input image format is now...


              convert -define jpeg:size=240x180 input.img'[120x90]' \
                      -strip  output_thumbnail.gif

            Well on with the practical IM thumbnail examples...

            General Thumbnail Creation
            Generate Thumbnails in General (specific height)

            Lets convert a large sample JPEG image to a GIF thumbnail 90 pixels high with the width automatically adjusted (within the 250 pixel width limit) to preserve the aspect ratio of the image.


              convert -define jpeg:size=500x180  hatching_orig.jpg  -auto-orient \
                      -thumbnail 250x90   -unsharp 0x.5  thumbnail.gif

                [IM Output]

            Note that I used the "-thumbnail" option above. This not only resizes the image, but strips any and all profile and comment information that may be present in the original JPEG image. Also as it uses the "-sample" resize operator for the initial downsizing of the image, it is faster, while producing reasonable results for small thumbnails.

            I also set a minimum "-define jpeg:size=" for the image being read in. This is passed to the JPEG library, which will return an image somewhere between this size and double this size (if possible), rather that the whole very large original image. Basically don't overflow the computers memory with an huge image when it isn't needed.

            The JPEG size hint I use is at least double that of the final thumbnail so that resize will still generate a reasonable looking result.

            The "-auto-orient" operator ensures that the image, if from a digital camera, is rotated correctly according to the camera's orientation. This is not needed for the 'desktop' image I am using, but I included it in the above for digital camera users. Note however that orientation can still go wrong, especially for photos viewing directly down or up, such as when taking photos of documents.

            The result is a thumbnail of a specific height, but variable width. I use this thumbnail for my own web pages so that a series of image in a row, will all match up height wise, forming a neat look.

            The 250 pixel width limit in the above is important. If left unset, (EG: using "-thumbnail x90" ) IM would could have problems when generating thumbnails of very long thin images such as those shown in Web Line Images. The result in that case would be very very long, enlargement of the image, instead of a small thumbnail.

            Some people (including myself) find that while IM's resize is one of the best implementations (See IM Resize vs Other Programs), the result is still a little blurry. As such you can improve the above result by sharpening the image slightly (using "-unsharp") after the "-thumbnail" resize operation. For more information see Sharpen Resized Images -- Photoshop Resize Technique, But really it all comes down to a matter of personal taste.


            The "mogrify" version is the same as the "convert" command (with no initial input images), but will but will generate automatic thumbnails of every JPEG image in the current directory. The image argument is quoted so that IM itself will scan the directory, and not the command line shell. This prevents 'line limit overflow errors' on directories containing a huge number of images.


              mogrify  -format gif -define jpeg:size=500x180 -auto-orient \
                            -thumbnail 250x90 -unsharp 0x.5  '*.jpg'

                Note that "mogrify" will blindly create thumbnails, replacing any existing images of the same name. GIF images in this case. Extreme caution is always advised when using this command.

            Backup copies are always recommended before doing any processing.

                Instead of specifying a different format (using "-format") so as to prevent "mogrify" from overwriting the original source images, you can use a "-path" setting to define a separate thumbnail directory. You can use both output options.

            While "mogrify" can output the new images with a different suffix ("-format") or directory ("-path"), they are your only options using this command.

            If you are also wanting to change the name of the image, such as adding a "_tn" or "_sm" to denote thumbnail or small versions of the image, then I recommend you create a shell script to do the job for you, processing them one at a time using "convert".     I wrote such a script to do this, while simultaneously generating HTML indexes at the same time.
            Resize Thumbnail to Fit
            Another form of automatic thumbnail generation is shrink image to fit a fixed sized box, say "100x100" but keeping the images aspect ratio. Well that is the default meaning for a resize geometry setting.

            However I prefer not to enlarge images which already fit such a box. For that you need to add a ">" to the geometry string.


              convert -define jpeg:size=200x200 hatching_orig.jpg \
                      -thumbnail '100x100>' rectangle.gif

                [IM Output]

            As before the aspect ratio of the image is preserved, as such the thumbnail is unlikely to be exact 100 pixels square. However at least one of the images dimensions will be 100 pixels.

            Pad Out the Thumbnail
            The next most common request is to generate thumbnails that fill out the image with borders of a specific color (usually 'black', or 'transparent' but for these examples I will use 'skyblue') so the thumbnail is exactly the size you wanted.

            For example: An image which is 400x300 pixels shrunk to fit a 100x100 pixel box will normal (with the above) have a size of 100x75 pixels. We want to add some padding borders to the top and bottom of the image (and to the sides to be sure) to make the final thumbnail image always 100x100 pixels in size.

            There are a number of ways to do this, and as of IM v6.3.2 the best way is using the Extent Operator.


              convert -define jpeg:size=200x200 hatching_orig.jpg -thumbnail '100x100>' \
                      -background skyblue -gravity center -extent 100x100 pad_extent.gif

                [IM Output]

            As of IM version 6.2.5, you can also use a Viewport Crop, and flatten the result onto a background color.


              convert -define jpeg:size=200x200 hatching_orig.jpg -thumbnail '100x100>' \
                      -gravity center  -crop 120x120+0+0\! \
                      -background skyblue  -flatten    pad_view.gif

                [IM Output]

            The key difference between usingExtent and a Viewport Crop is weather you want a minimal Virtual Canvas or have the whole area 'padded out'.

            Another method to pad out an image is to overlay the thumbnail onto a background image (actual image, solid color or tiled canvas) that is the right size, in this case the 128x128 "granite:" built-in image.


              convert -define jpeg:size=200x200 hatching_orig.jpg -thumbnail '100x100>' \
                      granite: +swap -gravity center -composite pad_compose.gif

                [IM Output]

            This method is probably the best method to use with older versions of IM (such as IM v5), though the "-composite" operation will need to be done by the separate "composite" command, rather than the above single command method.

            However an image processing point of view all the above are actually doing the same thing.

            Cut the Thumbnail to Fit
            An alternative, is rather than pad out the image to fit the specific thumbnail size we want, is to instead cut off the parts of the image that does not fit the final size.

            Of course this means you actually lose some parts of the original image, particularly the edges of the image, but the result is an enlarged thumbnail of the center part of the image. This is usually (but not always) the main subject of the image, so it is a practical method of thumbnail creation.

            As of IM v6.3.8-3 the special resize option flag '^' was added to make this easier. We just resize using this flag then crop off the parts of the image that overflows the desired size.


              convert -define jpeg:size=200x200 hatching_orig.jpg  -thumbnail 100x100^ \
                      -gravity center -extent 100x100  cut_to_fit.gif

                [IM Output]

            As you can see the thumbnail of the image is much larger and more detailed, but at a cost of cutting off the sides off the original image.

            For more information on this option see Resize to Fill Given Area.

                Before IM v6.3.8-3 when this special flag was added, you would have needed some very complex trickiness to achieve the same result. See Resizing to Fill a Given Space for details.

            Area Fit Thumbnail Size
            The last two methods will often make an image very small with a lot of extra padding, or, it will cut off a lot of the image so as to completely fill the space. However by using a different resize flag, it is possible to get a thumbnail that is between these two extremes.

            For example a 100x100 pixel thumbnail has 10,000 pixels. Now if we ask resize to size out image to something around that many pixels in size (using the resize '@' flag), you will have an image that will need both a little padding and a little cutting. This maximizes the size of the resulting thumbnail, while not cutting away too much.

            For example...


              convert -define jpeg:size=200x200 hatching_orig.jpg  -thumbnail 10000@ \
                      -gravity center -background skyblue -extent 100x100  area_fit.gif

                [IM Output]

            As you can see the thumbnail has some padding, and the image has some cropping, but the result is probably about the best fit of image to a given thumbnail space.

            Fit to a Given Space Summary
            In summary, here are the results of the three methods for thumbnailing an image to a specific sized area. All three methods use exactly the same code, with just with a slight change in the resize argument/flag used.

            [IM Output]
            Padded Fit
            resize, no flag 	[IM Output]
            Area Fit
            resize, '@' flag 	[IM Output]
            Cut to Fit
            resize, '^' flag


            Square Padding and Cropping
            The above padding and cropping methods assume you know the final size of the area in which you want the image to fit. But that is not always the case.

            Sometimes you want to simply 'square an image', either by 'padding' it out (external square), or 'shaving' the edges (internal square).

            From the IM Discussion Forums on Squaring Images a number of methods were developed.

            External Squaring can be done using Mosaic to create a larger background canvas using a rotated copy of the image.


              convert thumbnail.gif \
                      \( +clone -rotate 90 +clone -mosaic +level-colors white \) \
                      +swap -gravity center -composite    square_padded.gif

                [IM Output]

            Internal Squaring on the other hand is a little harder and requires more work to achieve. This one uses some heavy mask handling to generate a smaller canvas.


              convert thumbnail.gif \
                      \( +clone +level-colors white \
                         \( +clone -rotate 90 +level-colors black \) \
                         -composite -bordercolor white -border 1 -trim +repage \) \
                      +swap -compose Src -gravity center -composite \
                      square_cropped.gif

                [IM Output]

            An alturnative way is to use a no-op distort using a distort viewport crop/pad the image (See Distort Viewport Centered Square Crop). Essentually it uses a 'percent escapes' to do the calculations needed for an Extent type of operation.

            External (padding) square...


              convert thumbnail.gif  -virtual-pixel white -set option:distort:viewport \
                 "%[fx:max(w,h)]x%[fx:max(w,h)]-%[fx:max((h-w)/2,0)]-%[fx:max((w-h)/2,0)]" \
                 -filter point -distort SRT 0  +repage  square_external.gif

                [IM Output]

            The Virtual Pixel setting is used to specify the padding color.

            Internal (cropped) square...


              convert thumbnail.gif   -set option:distort:viewport \
                 "%[fx:min(w,h)]x%[fx:min(w,h)]+%[fx:max((w-h)/2,0)]+%[fx:max((h-w)/2,0)]" \
                 -filter point -distort SRT 0  +repage  square_internal.gif

                [IM Output]

            Curtisy of Fred Weinhaus's Tidbits Page.

            This is a simplier version, but will lose any meta-data (like comment strings or profiles) the image may have.


              convert thumbnail.gif -set option:size '%[fx:min(w,h)]x%[fx:min(w,h)]' \
                      xc:none +swap -gravity center -composite square_internal_2.gif

                [IM Output]

                IMv7 will allow you to do the above mathematics directly as part of a crop or extent argument, which will prevent loss of image meta-data.

            Manual Cropping
            The normal way I generate thumbnail images for use on my web pages, is a mix of automatic and manual scripts. The final setup of my images are..

                I use a PNG or TIFF for the original ,VERY large, scan of the photo. OR the original JPEG image downloaded from a digital camera. Basically for the unmodified original source image, for archiving. I also now like to include the string "_orig" in this images filename.

                A smaller JPEG image format for a web viewable image when the thumbnail is clicked or selected. This image is resized to fit a 800x800 pixel box, which is a size suitable for viewing by most web users. I typically add a "_md" for medium sized image, in the filename.

                And lastly a GIF thumbnail resized to a fixed 90 pixel high, and variable width. This allows centered rows of thumbnails on web pages to look reasonable neat and tidy, but which automatically fills the browser windows width, no matter what size browser they are using. Again I typically now include a "_tn" in the images filename, to denote that it is a thumbnail.

            I first generate the web viewable JPEG images (medium size) using "mogrify" from the original scanned image. This is reduces the download time and viewing size of the image to something that is practical for the typical web user (who could be logged in via modem).

            From these images I generate an initial set of thumbnails, again using "mogrify". However I often find in typical photos that the subject of the thumbnails becomes too small to make an effective thumbnail, when viewed.

            To fix this I examine the automatically generated thumbnails, and in about half the cases manually create my own 'zoomed in on subject' thumbnail.

            I read in the JPEG image, and crop it down the main subject of the image effectively 'zooming in' on the subject of the photo, and removing bulk of the background context of the image. This is then smoothed and thumbnailed, either using a "convert -thumbnail", or more often in the same graphic program I am viewing and cropping the images with (usually "XV", see below).

            So instead of a thumbnail where the people in the photo are hardly visible (left), I have manually cropping around the subject, highlighting the main point of the photo (right), before thumbnailing. That allows users to see the image content more clearly and thus better decide if they actually want to download and look at the larger JPEG version of the image.

            Queensland KiteFlyers, Ron and Val Field
            [IM Output]
            Automatically
            Generated
            Thumbnail 		[IM Output]
            Manually Cropped
            and Resized
            Thumbnail
            (Click on either image for original scanned photo)

            This is of course more manually intensive, but only needs to be done once per image, and only on images that have a lot of space such as in the above example. Also I only do this for images I am putting the web.

            Of course as "mogrify" will overwrite any existing, possibly hand generated thumbnails, you cannot use it again after you perform any manual thumbnail generation. The "mogrify" command is useful, but also very dangerous as it overwrites lots of images. Always think before you run "mogrify" globally across all your images.

            HTML Thumbnail Pages
            Once I have all the thumbnail images sorted out in the directory I use a special perl script called "thumblinks" I wrote that look for the images (JPEG photos and GIF thumbnails), and generate HTML links, and even full HTML photo pages.

            The script will read and include size of the GIF thumbnail size in the HTML, and attach pre-prepared header and footer files around the thumbnail links. The script will also remove any thumbnail links from the list it generates, if it finds an existing link in the header or footer file itself.

            This may sound complex, but it makes my HTML page generation very fast and flexible, and ensures ALL image thumbnailed images in a directory have been added to that directories index page, while still letting me comment on specific images in the index header. It also makes the page independent of the users window size, automatically adjusting to suit.

            For a simple example of my "thumblinks" script output see Tomb of Castle Artworks.

            For a quick example and starting point for generating such links look at the examples of using the identify command.

            FavIcon Web Page Link Thumbnail
            The "favion.ico" icon often looked for by web browsers on the top level web page of a web site, for that whole site. That image is a special multi-resolution image format and can be created as follows.


              convert image.png -alpha off -resize 256x256 \
                      -define icon:auto-resize="256,128,96,64,48,32,16" \
                      favicon.ico

            The 'image.png' can be anything you like, but should be square. If it isn't that should also be the first step in the above.

            You can also include larger resolutions such as 128 or 256 pixels, but few browsers would make use of them. The 16 and 32 pixel sizes are much more commonly used in such ICO files so special emphesis on those my be useful. Also remember that many browsers will color reduce the images so are to reduce the space used to store it in an users bookmarks file.

            This brings us to one other point. As only the smallest of images are typically used, with further color reduction, it is recommented to keep the images as small and as well defined as posible.

            Here is an example of manually resizing images for an ICO file format.


              convert image.png  -background white \
                      \( -clone 0 -resize 16x16 -extent 16x16 \) \
                      \( -clone 0 -resize 32x32 -extent 32x32 \) \
                      \( -clone 0 -resize 48x48 -extent 48x48 \) \
                      \( -clone 0 -resize 64x64 -extent 64x64 \) \
                      -delete 0 -alpha off -colors 256 favicon.ico


            As mentioned only the "favion.ico" image found on the top level directory of a web site is generally used, however you can also specify the location of the link thumbnail image by adding the following HTML tag to the headers of your pages...


              <LINK REL="icon" HREF="/path/to/favicon.ico" type="image/x-icon">
              <LINK REL="shortcut" HREF="/path/to/favicon.ico" type="image/x-icon">

            The "/path/to/favicon.ico" can be an absolute or partical URL/URI to the location from which the browser should pick up the web pages thumbnail image. The use of 'REL="shortcut"' is specific to Internet Explorer (before IE9), and not offically part of the HTML specification.

            It is posible to merge the two HTML tags together using 'REL="shortcut icon"' however by keeping the tags separate you can make use of a non-ICO image file format (such as SVG) for non-IE browsers, such as firefox.

            Remember if this html element is not used the "favicon.ico" file found on the top level directory of the web site is used instead (if present).

            The ICO image format is universally understood by all modern browsers. All except Internet Explorer also can use JPEG, PNG, and GIF image file formats, for the link thumbnail. A few like FireFox can even make use of animated GIF's or SVG image file formats. However as these latter formats can not typically hold multiple images at different resolutions and color counts, it is probably better to stick with the ICO file format for the "favion.ico" image.

            Other Non-IM Techniques
            The "XV" program I use for manual image processing also generates thumbnail images, in a sub-directory called ".xvpics". The format of the images in this directory is the programs own special thumbnail format (ignoring the filename suffix in that directory). These thumbnails are limited to 80x60 pixels so are a little on the "small" size (unless you hack "xv" to use larger thumbnails -- see link below).

            IM understands the "xv" thumbnail format (which is based on the "NetPBM" image format), so you can generate all the thumbnails quickly using XV, then convert the XV thumbnails of the JPEG images, into GIF images for further processing...

               xv -vsmap &               # generate thumbs with the "Update" button
               rm .xvpics/*.gif          # delete XV thumbs of existing "gif" thumbnails
               mogrify -format gif .xvpics/*.jpg
               mv .xvpics/*.gif .        # move the new "gif" thumbnails to original dir

            If you are sick of the small size of XV thumbnails, particularly with larger modern displays, you can hack the XV code. See my XV modification notes, which allows you to get XV to use a larger thumbnail size. I myself use 120x90 pixel thumbnails.

            Further Processing -- Adding Fluff
            The above is only the beginning of what you can do to make your thumbnails more interesting. Beyond the basic thumbnail image you can add borders, rotations even with some random selection of style to make your thumbnail gallery that much more interesting.

            Additions to thumbnails like this, is what I term 'fluff', as in the extra lint you find covering your clothes after you wash your clothes. That is, it adds unnecessary extras to the thumbnail, but which can make web pages and index images that much more interesting.

            Be warned that many of the following methods and processing is very complex and my require a deeper knowledge of the various image processing options options of ImageMagick.

            Adding image labels
            During your thumbnail creation you can also add labels either above, below or even on top of your thumbnail.

            This sort of image processing is however covered more thoroughly in Annotating Images with Labels. Just remember to use the "-thumbnail" or "-strip" rather than a "-resize" in those examples.

            For example...


              convert thumbnail.gif \
                      -background Lavender -fill navy -font Candice -pointsize 24 \
                      label:Hatching   -gravity South -append \
                      labeled.gif

                [IM Output]

            With the use of Compound Fonts you can overlay some very fancy labels onto the image itself.

            Here for example I used a Denser Soft Outline Font technique to annotate the thumbnail, darkening the area around the text to ensure it always remains readable.


              convert -define jpeg:size=400x400  hatching_orig.jpg  -resize '120x200>' \
                  \( +clone -sample 1x1\! -alpha transparent -sample 1000x200\! \
                     -font SheerBeauty -pointsize 72 -gravity Center \
                     -strokewidth 8 -stroke black  -fill black  -annotate 0,0 '%c' \
                     -channel RGBA -blur 0x8 \
                     -strokewidth 1 -stroke white  -fill white  -annotate 0,0 '%c' \
                     -fuzz 1% -trim +repage -resize 115x \
                  \) -gravity North -composite           -strip annotated.gif

                [IM Output]

            Note how I do not use the pre-generated "thumbnail.gif" image, or use the Thumbnail Resize Operator to strip the profiles and comments from the image.

            I then used "+clone", "+sample", and "-alpha", to generate a larger transparent working canvas, which also contains a copy of the original image's meta-data. This lets me use the images 'comment' string with the annotate "-annotate" operator, to supply the text to overlay on the image.

            Only at the end after I have composed the text overlay do I clean up and "-strip" that information.

            Raised Button

            The "-raise" operator was basically created with the one purpose of highlighting the edges of rectangular images to form a raised button. It is a simple, fast, and effective thumbnail transformation.


              convert thumbnail.gif  -raise 8   raised_button.gif

                [IM Output]

            The same operator has a 'plus' form that can be used to make a sunken highlighting effect.


              convert thumbnail.gif  +raise 8   sunken_button.gif

                [IM Output]

            Bubble Button

            With some trickiness the "-raise" operator can be used to produce a smooth 'bubble-like' raised button.


              convert thumbnail.gif -fill gray50 -colorize 100% \
                      -raise 8 -normalize -blur 0x8  bubble_overlay.png
              convert thumbnail.gif bubble_overlay.png \
                      -compose hardlight -composite  bubble_button.png

            [IM Output] ==> [IM Output] ==> [IM Output]

            See Light Composition Methods for more information about this type of technique.

            For more effects like this see Self Framing (Internal) below, and to take it to the next level see Lighting Effect Mask below.

            Adding Borders

            The humble simple "-border" operator can be used to generate some a complex framework around an images.


              convert thumbnail.gif \
                      -bordercolor black -border 3   -bordercolor white -border 2 \
                      \( -background black -fill white -pointsize 24 \
                         label:Hatching   -trim +repage \
                         -bordercolor black -border 10 \
                      \) -gravity South -append \
                      -bordercolor black -border 10   -gravity South -chop 0x10 \
                      border_framework.gif

                [IM Output]

            Simple Frame

            In a similar way the "-frame" operator makes it easy to add a frame around the image


              convert thumbnail.gif   -mattecolor peru  -frame 9x9+3+3  framed.gif

                [IM Output]

            This operator also has a lot more options to create a dozen or so different styles of frames. You can see examples of the possibilities in Frame, adding a 3D-like border.

            Montage Framing

            The montage command provides a much easier way of doing all the above, and much more. It cannot only generate thumbnails (or whole pages of thumbnails), but it can label the thumbnails to include information like filenames, disk size, and dimensions, or an user specified string.

            Here is a simple use of "montage" to generate a framed thumbnail.


              montage -define jpeg:size=240x200  -label '%c'  hatching_orig.jpg \
                      -frame 6  -geometry '120x100>'  montage_simple.gif

            The label comes from JPEG image file comment, which was added long ago to the image using the Non-IM command "wrjpgcom". See Non-IM JPEG Processing for more details. 	[IM Output]

            Even with just "montage" you can get really fancy with your thumbnail generation.


              montage -define jpeg:size=400x180  -label '%c' hatching_orig.jpg \
                      -thumbnail '200x90>' -geometry '130x100>'  -mattecolor peru \
                      -frame 6  -bordercolor skyblue  -font LokiCola  -pointsize 18 \
                      montage_fancy.gif

                [IM Output]

            See the "Montage, Arrays of Images" for more details.

            You may be especially interesting in the Montage HTML Thumbnail Image Maps example. This creates a HTML index page of thumbnails in which clicking on the thumbnail will bring up the original image, in the same directory.

            Soft and Blurred Edges
            The Vignette Operator provides a simple means to add a blurry edge around an image.


              convert thumbnail.gif -alpha set \
                      -background none  -vignette 0x4  vignette.png

                [IM Output]

            Of course as this thumbnail uses semi-transparent color so it needs to be saved in the PNG format.

            The Morphology Distance method provides a true transparent 'Feathering' of an image's edges.


              convert thumbnail.gif -alpha set -virtual-pixel transparent -channel A \
                      -morphology Distance Euclidean:1,10\! +channel feathered.png

                [IM Output]

            The maximum distance of the transparent area is controled by the special 10\!' distance scaling flag. This was only added in IM v6.6.1-6.

            This has the added advantage of also working for shaped images, though a more complex initialization is needed to correctly preserve and anti-aliased pixels in the distance formula. See Feathering Shapes using Distance for more details.

            The feathering here is a pure linear gradient, and can be further adjusted using Sigmoidal Non-linearity Contrast Operator to give it a smoother more tapered look in a number of different ways.

            You can also Feather Images using Blur, using the same method of adding a transparent Virtual Pixels before bluring just the alpha channel. This generates a more softer feathering to the image, as well as noticeably rounded the corners of the image.


              convert thumbnail.gif -alpha set -virtual-pixel transparent \
                      -channel A -blur 0x8  -level 50%,100% +channel  soft_edge.png

                [IM Output]

            The extra "-level" operation (adjusting only the transparency channel) ensures the edge becomes fully transparent, rather than only half transparent. However it does fall sharply toward zero at the actual edge, due to the sigmoidal-like curve that blur generates.

            It also has an additive effect in the corners, causing them to become rounded, while with a shaped image with a sharp concavity, it can cause fully-transparent pixels to become semi-transparent. As such for shapes you may need to mask the result against the original image (using Dst-In Composition). For rectangular thumbnails however the result is satisfactory.

            You can see another example of using this type of feathering in Layered Thumbnails.

            If instead of doing a level adjustment on the blurred feather, you can Threshold the blurred alpha channel at '50%', so as to add psuedo-rounded corners to the above thumbnail image.


              convert thumbnail.gif -alpha set -virtual-pixel transparent -channel A \
                      -blur 0x8  -threshold 50% +channel rounded_corner_blur.gif

                [IM Output]

            While very simple, the result is not a really nice way to round off the corners of the image. First the corners are not actually circular, but a 'hyperbolic' curve. Second the result is not a smooth anti-aliased curve, but shows 'jaggies' caused by the aliasing effect of Threshold Operation. This image can however be save to a GIF file format. See GIF Boolean Transparency for details.

            Also note that the "-blur" operation can become very slow when you work with a large argument for generating a larger rounded corner. As such this method of rounding corners on a large scale is not recommended at all.

            For a more unusual blurred edge effect, you can use a Radial Blur on just the alpha channel.


              convert thumbnail.gif -alpha set -virtual-pixel transparent \
                      -channel A -radial-blur 0x45 +channel  radial_blur_edge.png

                [IM Output]

            This works better for perfectly square images.

            As the amount of angled blur becomes larger, you will eventually generate a circular like Vignette edge.


              convert thumbnail.gif -alpha set -virtual-pixel transparent \
                      -channel A -radial-blur 0x100 +channel  radial_blur_vignette.png

                [IM Output]

            The two step-like artifacts that can be seen is caused by the two image size dimensions. No 'step' will be seen for a square image. Adding a little extra normal blur to the last example can also improve the step problem.

            Rounded and Shaped Corners
            While thresholding a Soft Blurred Edge (see above) will generate a rounded corner suitable for the Boolean transparency of GIF, it does not generate a smooth 'anti-aliased' corner.

            The proper way to generate an image with rounded corners, or of any other shape is to actually cut out each corner using a mask of the shape wanted.

            The following method from Leif Åstrand <leif@sitelogic.fi> that multiplys a full image mask to generate the appropriate result.


              convert thumbnail.gif \
                 \( +clone  -alpha extract \
                    -draw 'fill black polygon 0,0 0,15 15,0 fill white circle 15,15 15,0' \
                    \( +clone -flip \) -compose Multiply -composite \
                    \( +clone -flop \) -compose Multiply -composite \
                 \) -alpha off -compose CopyOpacity -composite  rounded_corners.png

                [IM Output]

            Basically extracts the white transparency mask from the original image, with just one black rounded corner. This is then flipped and flopped to produce a mask with all four corners rounded. And finally that mask is applied to the original image.

            For much larger images, you may be better off applying a much smaller mask to each individual corner to reduce the total amount of processing needed. That is more individual processing steps, but overall less processing of the actual pixels.

            For example, here is the same thing but cutting a simple drawn triangular shape from each corner. This will work with much larger images.


              convert thumbnail.gif -alpha set  -compose DstOut \
                  \( -size 20x15 xc:none -draw "polygon 0,0  0,14 19,0" \
                     -write mpr:triangle  +delete \) \
                  \( mpr:triangle             \) -gravity northwest -composite \
                  \( mpr:triangle -flip       \) -gravity southwest -composite \
                  \( mpr:triangle -flop       \) -gravity northeast -composite \
                  \( mpr:triangle -rotate 180 \) -gravity southeast -composite \
                  corner_cutoff.png

                [IM Output]

            If you don't want transparency, but some other color, you can still do the above and then Remove Transparency. This can be important for JPEG images.

            However an even simpler solution (in terms of complexity and memory usage) has been found in a IM forum discussion. This overlays colored corners ('Red' in this case) rather than making them transparent.


              convert thumbnail.gif \
                \( +clone -crop 16x16+0+0  -fill white -colorize 100% \
                   -draw 'fill black circle 15,15 15,0' \
                   -background Red  -alpha shape \
                   \( +clone -flip \) \( +clone -flop \) \( +clone -flip \) \
                 \) -flatten  rounded_corners_red.png

                [IM Output]

            Unfortunately this method can not be used to simply 'erase' the image corners to transparency, due to an interaction with a 'background canvas' of the Flatten Operation, a future layering operator may solve this.

                The last example will fail for versions of IM before v6.6.6-5 due to both the "-flip" and the "-flop" operators not handling the virtual canvas offset correctly.

            Using a Polar Cycle Trick we can generate a perfect anti-aliased circle mask for any sized thumbnail. Of course we will only use the distorted image as a mask for the original image, so as to get the best result.


              convert thumbnail.gif -alpha set \
                \( +clone -distort DePolar 0 \
                   -virtual-pixel HorizontalTile -background None -distort Polar 0 \) \
                -compose Dst_In -composite -trim +repage circle_masked.png

                [IM Output]

            We will take this style of image processing further in Border with Rounded Corners below. There we not only cutting out corners, but also overlay appropriate framing images.

            Torn Paper Edge
            Leif Åstrand <leif@sitelogic.fi>, contributed the following IM code to generate an edge that looks like it was torn from a fibrous paper (like newspaper)...


              convert thumbnail.gif \
                      \( +clone -alpha extract -virtual-pixel black \
                         -spread 10 -blur 0x3 -threshold 50% -spread 1 -blur 0x.7 \) \
                      -alpha off -compose Copy_Opacity -composite torn_paper.png

                [IM Output]

            One improvement may be to make it look like you ripped it from a newspaper corner.


              convert thumbnail.gif -bordercolor linen -border 8x8 \
                      -background Linen  -gravity SouthEast -splice 10x10+0+0 \
                      \( +clone -alpha extract -virtual-pixel black \
                         -spread 10 -blur 0x3 -threshold 50% -spread 1 -blur 0x.7 \) \
                      -alpha off -compose Copy_Opacity -composite \
                      -gravity SouthEast -chop 10x10   torn_paper_corner.png

                [IM Output]

            This could be improved by adding 'paper' colored borders and a curved shaped mask, so that it looks like the image was ripped roughly by hand. Adding a 'soft shadow' (see next) will also 'lift' the resulting image from the background, making it look like it was a separate piece.

            As always, suggestions and contributions are welcome.

            Adding a Shadow
            The "-shadow" operator makes the Generation of Shadows of any shaped image easy.

            For example here an I add a semi-transparent colored shadow, to the thumbnail.


              convert thumbnail.gif -alpha set \
                      \( +clone -background navy -shadow 60x0+4+4 \) +swap \
                      -background none -mosaic   shadow_hard.gif

                [IM Output]

            But you can just as easily create soft fuzzy shadows, too.


              convert -page +4+4 thumbnail.gif -alpha set \
                      \( +clone -background navy -shadow 60x4+4+4 \) +swap \
                      -background none -mosaic     shadow_soft.png

                [IM Output]

            Note that I again used a PNG format image for the thumbnails output. That is because the shadowed image will contain a lot of semi-transparent pixels, which GIF cannot handle. (Yes I am repeating myself but it is important).

            If you do plan to use GIF or JPG format you will need to use a more appropriate "-background" color for the web page or larger canvas on which you plan to display your thumbnail, as these formats do not handle semi-transparent colors.

            Warning, while the above works for individual thumbnails, it will generally fail when you want to layer multiple thumbnails over the top of each other. The reason is that shadows do not accumulate together, in the same way that normal images do. To see how to handle shadows from multiple layered images see Layers of Shadows.

            Adding Some Thickness
            Adding a thickness to an image or a shape look a bit like adding a hard shadow (see above), but isn't quite the same, and needs some extra work to get right.

            This is actually very tricky as we create a colored, mask of the image which is then replicated multiple times and layered under the original image (using 'DstOver' composition) with increasing offsets to give the image thickness.


              convert thumbnail.gif -alpha set \
                      \( +clone -fill DarkSlateGrey -colorize 100% -repage +0+1 \) \
                      \( +clone -repage +1+2 \) \
                      \( +clone -repage +1+3 \) \
                      \( +clone -repage +2+4 \) \
                      \( +clone -repage +2+5 \) \
                      \( +clone -repage +3+6 \) \
                      -background none -compose DstOver -mosaic  thickness.gif

                [IM Output]

            You get the idea. Each '\( +clone ... \)' line adds one extra pixel to the image in a south by south-easterly direction.

            Also as no semi-transparent pixels are involved (at least for a rectangular image) you can use the GIF image format for the result.

            The major problem with this technique is that it is hard to specify a thickness as a variable argument or at different angles, unless you write a specific script to add thickness. Also the edge of the angled parts of the thickness is not anti-aliased, so there is lots of room for improvement.

            Polaroid-like Thumbnails
            You can make your thumbnail image look like a polaroid photo, give it a shadow, and even rotate it a little so as to appear to be just sitting on a table.


              convert thumbnail.gif \
                      -bordercolor white  -border 6 \
                      -bordercolor grey60 -border 1 \
                      -background  none   -rotate 6 \
                      -background  black  \( +clone -shadow 60x4+4+4 \) +swap \
                      -background  none   -flatten \
                      poloroid.png

                [IM Output]

            A more complex version of the above was added to IM v6.3.1-6 as a "-polaroid" transformation operator. For example...


              convert thumbnail.gif -bordercolor snow -background black +polaroid \
                      poloroid_operator.png

                [IM Output]

            Note that the image not only has the polaroid frame, but the photo has also been given a bit of a 'curl' with appropriate shadow adjustments, giving the resulting image more depth. The plus (+) form uses a randomized angle, while the normal minus (-) form lets you provide the angle of rotation. Special thanks to Timothy Hunter for the idea behind this technique.

            You can even add a "-caption", set your own shadow color, specify your own rotation (or none at all).


              convert -caption '%c' hatching_orig.jpg -thumbnail '120x120>' \
                      -font Ravie -gravity center -bordercolor Lavender \
                      -background navy  -polaroid -0     poloroid_caption.png

                [IM Output]

            For more information on using this operator see Complex Polaroid Transformation.

            For these examples though, I'll continue to use a DIY creation method, as I need finer control of the borders and shadowing effects to demonstrate proper photo 'stacking'.

            And here we go... By making multiple copies of the photograph, (or using other images), and adding polaroid borders, you can then randomly rotate and stack them up to produce a nice looking pile of photos.


              convert thumbnail.gif \
                 -bordercolor white  -border 6 \
                 -bordercolor grey60 -border 1 \
                 -bordercolor none  -background  none \
                 \( -clone 0 -rotate `convert null: -format '%[fx:rand()*30-15]' info:` \) \
                 \( -clone 0 -rotate `convert null: -format '%[fx:rand()*30-15]' info:` \) \
                 \( -clone 0 -rotate `convert null: -format '%[fx:rand()*30-15]' info:` \) \
                 \( -clone 0 -rotate `convert null: -format '%[fx:rand()*30-15]' info:` \) \
                 -delete 0  -border 100x80  -gravity center \
                 -crop 200x160+0+0  +repage  -flatten  -trim +repage \
                 -background black \( +clone -shadow 60x4+4+4 \) +swap \
                 -background none  -flatten \
                 poloroid_stack.png

                [IM Output]

                The " `convert ...` " embedded command in the above example generates a random floating point number from -15 to +15. For more infomation on using IM as a mathematical calculator see FX Expressions. An alturnative is to assign random numbers to shell variables and substitute them into the above command instead.

            Of course you could substitute a set of different images rather than repeating the same image when creating the stack. Or select a set of rotates angles so they are all reasonably different, or are more pleasing to look at. If you are really good you can even offset the rotated images (jitter their position a little) so they are not all stacked up perfectly centered. But you get the basic idea.

            If you really want to avoid the use of the PNG format, due to its current problems with some browsers, you can use the GIF image format. To do this you must be willing to accept some color limitations, and know the exact background color on which the image will be displayed. The 'LightSteelBlue' color in the case of these pages.


              convert thumbnail.gif \
                      -bordercolor white  -border 6 \
                      -bordercolor grey60 -border 1 \
                      -background  none   -rotate -9 \
                      -background  black  \( +clone -shadow 60x4+4+4 \) +swap \
                      -background  LightSteelBlue  -flatten    poloroid.gif

                [IM Output]

            For details about this technique (and more) see GIF images on a solid color background.

            The above 'stacked polaroid' technique graciously provided by Ally of Ally's Trip and Stefan Nagtegaal for Muziekvereniging Sempre Crescendo, both of which use Polaroid-like thumbnails extensively on their web sites.

            In the IM User Forum, the user grazzman went a little further by overlaying images onto a rotating canvas to create a photo spread.


              convert -size 150x150 xc:none -background none \
                      -fill white -stroke grey60 \
                      -draw "rectangle 0,0 130,100" thumbnail.gif \
                            -geometry +5+5 -composite -rotate -10 \
                      -draw "rectangle 0,0 130,100" thumbnail.gif \
                            -geometry +5+5 -composite -rotate -10 \
                      -draw "rectangle 0,0 130,100" thumbnail.gif \
                            -geometry +5+5 -composite -rotate +10 \
                      -trim +repage -background LightSteelBlue -flatten \
                      poloroid_spread.gif

                [IM Output]

            Of course for a photo spread like this you really need to use a set of different photos rather using the same image over and over as I did here.

            There are a few caveats you may like to consider with this technique.

                The framing has been hardcoded into the above, and depends on the size of the thumbnail image. In a real application the framing may be moved to the thumbnail generation stage rather than in the above photo spread.
                As "-rotate" also expands the size of the canvas the position in which images are added is changing, unless you place them using an offset from "-gravity center" position.
                And finally, a constantly rotating the background frame is not a good idea in terms of quality. Rotating an already rotated image, adds more pixel level distortions to the result than doing one rotate for each separate image before being overlaid. 

            A similar randomized stacking of photos over a larger area was developed for Stas Bekman's Photography, but with a different bordering technique.

            A more generalized method for creating some sort of ordered or programmed layout of photos and images, is shown and described in Examples of Image Layering, as well as in Overlapping Photos.

            Framing Techniques
            Here we will look at some advanced framing techniques that use some very advanced knowledge of how IM works to achieve the desired results.

            Self Framing (External)
            Self Framing is a technique that can be used to frame an image, using the image itself to generate the framing colors and patterns. That is to say the added frame is not fixed, but varies so as to roughly match the image being framed.

            You can do this in two ways. Extend the original image so as to create, an External Frame, or use part of the actual image itself to create an Internal Frame.

            For example, if we enlarge the image and dim it, before overlaying the original image on top, we get a very nice looking frame.


              convert thumbnail.gif \
                      \( -clone 0 -resize 130% +level 20%x100% \) \
                      \( -clone 0 -bordercolor black -border 1x1 \) \
                      -delete 0 -gravity center -composite  self_bordered.gif

                [IM Output]

                Instead of using Level Adjustments to brighten (or darken) the framing image, an alturnative way of making the border a lighter or darker color is to Color Tint the frame using something like...
            "-fill white -colorize 30%"

            Another way of color tinting the image to generate the frame, you can simply get IM to overlay a semi-transparent Frame on top of the enlarged image. However this requires you to know the size of the thumbnail so as to exactly resize it exactly the right amount to accommodate the generated frame.


              convert thumbnail.gif \
                      \( -clone 0 -resize 140x110\! \) \
                      \( -clone 0 -bordercolor black -border 1x1 \
                                  -mattecolor '#8884' -frame 9x9+0+9 \) \
                      -delete 0 -composite  self_framed.gif

                [IM Output]

            A variation of the above uses the special viewport control and the default Virtual Pixel, Edge setting to extend the edge of a blurred image to generate the extenal frame.


              convert thumbnail.gif \( +clone \
                         -set option:distort:viewport 150x120-15-15 \
                         -virtual-pixel Edge    -distort SRT 0  +repage \
                         -blur 0x3 +level 20%,100% \) \
                      \( -clone 0 -bordercolor white -border 1 \) \
                      -delete 0 -gravity center -compose over -composite \
                      self_blurred_edge.gif

                [IM Output]

            Just a word of warning. A small edge defect (such as a tree or leaf) can produce some undesirable results in a frame that was generated using only the edge of the image.

            The viewport does need to know the size of the original image to enlarge and offset that viewport the appropriate amount. However you can use FX Escape Expressions to calculate the viewport size (see examples below).

            An alternative is to use a blurred Virtual Pixel, Dither in the above example. This will spread the colors further and be not quite so 'edgy'. But if you add blurs before and after the expansion you use the dither to produce a cloth-like effect.


              convert thumbnail.gif \( +clone  -blur 0x3 \
                         -set option:distort:viewport '%[fx:w+30]x%[fx:h+30]-15-15' \
                         -virtual-pixel Dither  -distort SRT 0  +repage \
                         -blur 0x0.8  +level 20%,100% \) \
                      \( -clone 0 -bordercolor white -border 1 \) \
                      -delete 0 -gravity center -compose over -composite \
                      self_blurred_dither.gif

                [IM Output]

            The first blur modulates the average color, while the second adjusts how 'pixelated' or smooth the dither pattern is.

            Here is another example, this time using Virtual Pixel, Mirror, with a Soft Edge (blackened) which turned out to work very well for this specific image.


              convert thumbnail.gif  \( +clone \
                         -set option:distort:viewport '%[fx:w+30]x%[fx:h+30]-15-15' \
                         -virtual-pixel Mirror -distort SRT 0 +repage \
                         -alpha set -virtual-pixel transparent \
                             -channel A -blur 0x8 +channel \
                         -background Black -flatten \) \
                      +swap -gravity center -compose over -composite \
                      self_mirror.gif

                [IM Output]

            In all the above cases the frames are generated from the same image, which is then combined together to produce a frame based on the colors coming from the original image. The framing border is thus unique and matches each thumbnail image that is framed.

            Fred Weinhaus has created a script "imageborder" to make self framing images easier, with borders being generated from blurred magnifications of the original image, or some form of Virtual Pixel setting defining the contents.

            Self Framing (Internal)
            Rather than enlarging the image to add the new border, we can convert parts of the image itself into a border.

            We have already seen some techniques of adding a frame, inside the image itself. The Raised Button and Bubble Button techniques do this, using the "-raise" operator.

            Here we generate a lighter blurred version of the original image which is then overlaid using a mask also generated from the original image. A white edge is then added to separate that lighter blured version from the center un-modified part of the image.


              convert thumbnail.gif \( +clone -blur 0x3 +level 20%,100% \) \
                      \( +clone -gamma 0 -shave 10x10 \
                         -bordercolor white -border 10x10 \) \
                      -composite \
                      \( +clone -gamma 0 -shave 10x10 \
                         -bordercolor white -border 1x1 \
                         -bordercolor black -border 9x9 \) \
                      -compose screen -composite \
                      self_blurred_border.gif

                [IM Output]

            You can also use the Frame Operator to achieve something a little different to the previously seen Button effects. The trick is to first Shave the original image before applying.

            For example here I make a copy of the original image, shave and frame it using transparent frame, before overlaying that over the original image.


              convert thumbnail.gif \( +clone -shave 10x10 \
                        -alpha set -mattecolor '#AAA6' -frame 10x10+3+4 \
                      \) -composite  inside_frame_trans.gif

                [IM Output]

            The problem with this is that you will always 'lighten' or 'darken' (de-contrast) the flat parts of frame around the original image.

            To avoid this we can use the same technique as the Bubble Button technqiue. We generate a frame on a perfect grey canvas, and modiy it so as to generate a Lighting Effects Composition Mask, to adjust the colors of the original image.

            For example here I use a 'VividLight' composition with the framed mask image to better preserve primary colors.


              convert thumbnail.gif \
                      \( +clone -shave 10x10 -fill gray50 -colorize 100% \
                        -mattecolor gray50 -frame 10x10+3+4 \
                      \) -compose VividLight -composite  inside_frame_light.gif

                [IM Output]

            Like the Bubble Button you can also blur the lighting mask before applying. Here I used more normal 'HardLight' compose which does not enhance primary colors, with a blurred frame lighting mask.


              convert thumbnail.gif \
                      \( +clone -shave 10x10 -fill gray50 -colorize 100% \
                        -mattecolor gray50 -frame 10x10+3+4 -blur 0x2 \
                      \) -compose HardLight -composite  inside_frame_blur.gif

                [IM Output]

                Some Light Composition Methods may require you to Swap the Images before you compose them to get the correct lighting effect.

            To take this type of effect even further, producing much more complex results see the advanced Lighting Effect Mask.

            Simple Border Overlay
            One simple type of framing is to create a fancy frame, or shaped image into which you can place your image, under the frame.

            For example here we generate a simple frame slightly larger than our image with a fancy shaped hole. The shape was extracted from the 'WebDings' font (character 'Y'), but there are a lot of possible sources for fancy shapes that could be used for picture framing.


              convert -size 120x140 -gravity center -font WebDings label:Y \
                      -negate -channel A -combine +channel -fill LightCoral -colorize 100% \
                      -background none -fill none -stroke firebrick -strokewidth 3 label:Y \
                      -flatten +gravity -chop 0x10+0+0 -shave 0x10 +repage border_heart.png

                [IM Output]

            For other ways of generating an edge on an existing shaped image see the Edge Transform.

            You can also optionally give the frame a little depth by using a Shadow Effect.


              convert border_heart.png  \( +clone -background black -shadow 60x3+3+3 \) \
                      -background none -compose DstOver -flatten   border_overlay.png

                [IM Output]

            Now that we have a simple overlay frame, we can underlay the image in the center, underneath the frame by using a 'DstOver' composition.


              convert border_overlay.png  thumbnail.gif \
                      -gravity center -compose DstOver -composite   border_overlaid.jpg

                [IM Output]

            Now you can generate a library of pre-prepared frames to use with your images, such as this Autumn Leaves Image.


                convert thumbnail.gif  autumn_leaves.png +swap \
                        -gravity center -compose DstOver -composite \
                        border_leaves.gif

            [IM Text] + [IM Text] ==> [IM Text]

            Note that I swapped the order of the images and used 'DstOver' to place the second, main image 'under' the frame. That way it is the frame that determines the final size of the image, and not the original image. However doing this would also loose any meta-data the main image has (for the same reason).

            If you really want to preserve the thumbnails meta-data (such as labels and comments, such as a copyright message), then the best idea is to Pad Out the Thumbnail to the same size as the frame, than this use the default 'Over' composition to overlay the frame. That way the thumbnail is the 'destination' image and its image meta-data is preserved.

            Badge Overlay Example
            Here is another more complex pre-prepared overlay example this time using a correctly sized image (using extent as a crop method), from the IM Forum Discussion Composite Overlay and Masking.


                convert thumbnail.gif  -gravity center -extent 90x90 \
                        badge_overlay.png -composite     badge.png

            [IM Text] + [IM Text] ==> [IM Text]

            Note that the image itself is not distorted, just lightened and darkened slightly, a circle cut out and shadow added, all in the one overlay image. If this was a real badge, or 'glass bubble' then the image should also be distorted a little too (perhaps using a Barrel Distortion), but it works well without needing such distortion.

            For the next step in the 'badge' example, see Badge using Mask and Paint, which adds background transparency around the outside of the badge.


            Mask 'n' Paint Technique
            In many cases you don't just want to overlay a square border around an image, but also want to cut out the image edges, to transparency. For this you would typically use at least two images. One is the masked overlay containing the colors, shadows and highlights you want to add to the existing image. And a second image containing the parts you want to remove from the original image.

            The two images can be applied in two different ways. You can either 'mask' first to remove the unwanted parts from the image, then overlay the frame, or you can overlay a frame, and then mask the unwanted parts of both the original image and overlaid colors to transparency.

            Which method you use is critical, and the images involved will be designed for a specific technique. You can not use images for one method in the wrong order or things will not work properly.

            For example lets create more complex shaped border but this time don't worry about setting the background.


              convert -size 120x100 xc:none -fill none -stroke black -strokewidth 3 \
                      -draw 'ellipse 60,50 30,45 0,360  ellipse 60,50 55,30 0,360' \
                      -strokewidth 3  -draw 'ellipse 60,50 57,47 0,360' \
                      -channel RGBA  -blur 2x1    border_ellipse.png

                [IM Output]

            Now I purposely made this border blurry, to make the edge components much more semi-transparent. Even without that extra fuzziness, a border also contains a lot of semi-transparent anti-aliasing pixels, that make the edge look smoother and less jagged looking. It is vital when image processing that you consider these semi-transparent pixels, so as to preserve and set them correctly.

            To make it more interesting give this 'fuzzy' border a random bit of coloring.


              convert border_ellipse.png \
                      \( -size 120x100 plasma:Tomato-FireBrick -alpha set -blur 0x1 \) \
                      -compose SrcIn -composite     border_ellipse_red.png

                [IM Output]

            Okay we have a border, but we still need some way of defining what should represent the outside and inside of the border. Basically we need a mask to define these two areas.


              convert -size 120x100  xc:none -fill black \
                      -draw 'ellipse 60,50 30,45 0,360  ellipse 60,50 55,30 0,360' \
                      border_ellipse_mask.png

                [IM Output]

            The color of this 'mask' image is not important, just its shape, as it basically defined what parts will be classed as inside and what will be outside. The mask can be a gray-scale mask, or it can be a shape mask such as shown above. Though the later is typically more useful, and can even be a shape of the parts to erase, or the parts to be kept (as above).

            In this case the images are designed as a "mask 'n' paint" technique, meaning you should first erase the unwanted parts, then overlay the additional border colors (which also has a transparency mask involved).

            For example...


              convert thumbnail.gif -alpha set  -gravity center -extent 120x100 \
                      border_ellipse_mask.png  -compose DstIn -composite \
                      border_ellipse_red.png   -compose Over  -composite \
                      border_mask_paint.png

            [IM Output] + [IM Output] + [IM Output] ==> [IM Output]

            Two Duff-Porter Alpha Composition Operations are always is needed. One to make parts transparent, and another to overlay the additional colors to outline the border or frame. Two images are needed and as such be kept separate. Some formats like MIFF and GIF do allow you to save both images into the same file, for easier storage.

            Of course you can combine the two images to create a single simple overlay framing image, but only if you want to use a fixed non-transparency color for the outside parts of the result.

            For example pre-define the outside as a DodgerBlue color...


              convert border_ellipse_mask.png -alpha extract -negate \
                      -background DodgerBlue -alpha shape \
                      border_ellipse_red.png   -compose Over -composite \
                      border_ellipse_overlay.png

                [IM Output]

            But in that case you could simply underlay a solid color or some other background image under the previously generated double masked image...


              convert border_double_masked.png \
                      \( -size 120x100 plasma:Green-Green -blur 0x1 \) \
                      +swap  -compose Over  -composite     border_background.png

                [IM Output]

            The point is with two images, a 'mask' and 'overlay' image, you have a lot more freedom in how you add the border to the image. You could even define multiple 'mask' images, to define the different 'windows' of the 'overlaid' border image. You can also add optional highlights and shadows, rather than hard coding them into a single overlay framing image.

            Now for an important caveat. The edges of the masking image must not coincide with the edges of the overlay image.

            If they match up, you will not get the correct handling of colors along the coinciding edges, or generate other weird 'halo' effects. As such you need to make sure the mask edges fall somewhere within the fully-opaque region of the overlay image.

            Caution and fore-thought with the two masking operations is needed.

            Border with Rounded Corners
            As you saw above the Mask 'n' Paint Technique can be used to both add extra colors or 'fluff' to an image, but also remove parts, so as to shape the final image. This presents us with an alternative way of adding rounded corners to an image.

            The IM "-draw" operator comes with a 'roundrectangle' method that can be used to provide an interesting frame around the image. However you need to size the dimensions of this draw method to match the image. IM does provide methods to extract and even do mathematical calculations based on the image size.

            The coordinates at which to locate the rectangle is for the exact 'center' of the stroke-width used to define the rectangle (it can be a floating point value). Also it is given in terms of 'pixel coordinates' (see Pixel vs Image coordinates), which means that a value of 1,1 refers to the second pixel form the top and left edges, but more importantly it refers to the 'center' of the pixel which is in reality 1.5 units from the real top and left edges.

            Now we will use a stoke width (SW) of 3, that makes the image 3 pixels larger on all sides. It then means the rectangle will be positioned SW/2 - 0.5 or 1.0 pixels from the top left, and ImageSize + SW*1.5 - 0.5 or Image size + 4 pixels at the bottom right.

            Here we use IM itself to do these calculations, generating the exact draw command that are need using fancy FX escapes. This is saved as a Magick Vector Graphics File that can be directly used by draw in later commands.


              convert thumbnail.gif \
                      -format 'roundrectangle 1,1 %[fx:w+4],%[fx:h+4] 15,15'\
                      info: > rounded_corner.mvg

            [IM Text]

                If you can figure out the image size in a different way (using the shell, or other API language wrapper) you can substitute the appropriate draw parameters directly into the next examples, rather then use an FX mathematical expression. Basically the above makes this whole process independent of the actual size of the thumbnail. Any other way, including direct hard coding is also acceptable.

            Now we can use this to generate overlay and a mask image. As part of this we create a Transparent Canvas using the original image (which is first enlarged by the stroke-width), to get the size right.


              convert thumbnail.gif -border 3 -alpha transparent \
                      -background none -fill white -stroke none -strokewidth 0 \
                      -draw "@rounded_corner.mvg"    rounded_corner_mask.png
              convert thumbnail.gif -border 3 -alpha transparent \
                      -background none -fill none -stroke black -strokewidth 3 \
                      -draw "@rounded_corner.mvg"    rounded_corner_overlay.png

            [IM Text] [IM Text]

            And there we have the overlay border image, and transparency mask image, we need for the double masking technique. Note that the masks are for an image that is stroke width larger than the original image, and that the erasing shape mask (in white) does not cover the whole of the enlarged area, as there is a 1 pixel gap all around it.

            So lets apply it using the Double Masking technique...


              convert thumbnail.gif -alpha set -bordercolor none -border 3  \
                      rounded_corner_mask.png -compose DstIn -composite \
                      rounded_corner_overlay.png -compose Over -composite \
                      rounded_border.png

                [IM Output]

            And there we have have a bordered our image with rounded corners.

            The following is how you can do the above all in a single command with a little extra fanciness. However this all-in-one command will still generate a temporary file holding the generated draw commands needed for an image of the size given.


              convert thumbnail.gif \
                  -format 'roundrectangle 1,1 %[fx:w+4],%[fx:h+4] 15,15' \
                  -write info:tmp.mvg \
                  -alpha set -bordercolor none -border 3 \
                  \( +clone -alpha transparent -background none \
                     -fill white -stroke none -strokewidth 0 -draw @tmp.mvg \) \
                  -compose DstIn -composite \
                  \( +clone -alpha transparent -background none \
                     -fill none -stroke black -strokewidth 3 -draw @tmp.mvg \
                     -fill none -stroke white -strokewidth 1 -draw @tmp.mvg \) \
                  -compose Over -composite               rounded_border_in_one.png
              rm -f tmp.mvg      # Cleanup of temporary file

                [IM Output]

            A better way for doing rounded corners, especially with very large images will be to use a separate corner masking image technique, which we will look at below in Fancy Corner Overlays. In many ways this is an extension of the above method, but using separate masking for each corner of the image, so as to keep the working images small in size.

            Badge using Mask 'n' Paint
            Here is a much more complex "mask 'n' paint" example, that was developed from the image used previously in the Badge Overlay example above. The generation of the two images was 'fudged', and was discussed IM forums Composite Overlay and Masking. Idealy the two images would have been developed together.


              convert thumbnail.gif -alpha set -gravity center -extent 90x90 \
                      badge_mask.png -compose DstIn -composite \
                      badge_shading.png -compose Over -composite \
                      badge_trans_bg.png

            [IM Text] + [IM Text] + [IM Text] ==> [IM Text]

            Note that above I said that the you should avoid trying to align transparency edges and the mask edges. In the above example I did just that, and the edges of the resulting image will not be quite correct. However as the coloring is really only a subtile shading rather that a strong edge, it seems to work okay in this example. Caution however should be exercised.

            For the next step in the 'badge' examples, see Badge using Paint and Mask, which reverses the order of the two composition operations, requiring a different set of images.


            Paint 'n' Mask Technique
            Rather than 'Mask then Paint' you can use a different set of images and overlay the additional colors first, before masking out the background. That is you can perform a 'Paint then Mask'.

            That is you would take your image, and overlay the border which sets not only all of the final border colors, but also masks and colors some or all the parts outside parts the original image. You then use a separate 'outside' or 'clipping' mask to remove all the unwanted parts of the resulting image.

            Also note that both 'overlay' and 'masking' image defines the inside edge separately to the outside edge of the border. As a result one image does not completely define the whole border in a single image, which can make it a little harder to use. However it can be simpler to implement.

            For example...


              convert -size 120x90 xc:none -fill black -stroke black -strokewidth 0 \
                      -draw 'ellipse 45,45 55,37 0,360' \
                      -channel RGBA -negate -blur 0x3  +channel \
                      \( granite: -auto-level -blur 0,0.7 \) \
                      -compose ATop -composite border_paint.png

              convert -size 120x90 xc:none -fill black -stroke black -strokewidth 5 \
                      -draw 'ellipse 59,45 56,40 0,360' border_mask.png

              convert thumbnail.gif -alpha set \
                      border_paint.png -compose Over  -composite \
                      border_mask.png  -compose DstIn -composite \
                      border_paint_mask.png

            [IM Output] + [IM Output] + [IM Output] ==> [IM Output]

            Note how some parts of the overlaid colors are removed. This is the key feature of the Paint 'n' Mask technique, allowing you to use a simpler overlay, which is then adjusted by the mask.

            This method of image masking is what is used in the next Page Curl Corners example set, and again later in Fancy Corner Borders below.

            Page Curl Corners
            Fred Weinhaus created a special shell script called PageCurl which will, add a simple page curl to an existing image, using some very complex mathematics (in shell). For example...


              pagecurl thumbnail.gif  pagecurl.png

                [IM Output]

            Internally it is actually using the Paint 'n' Mask technique. That is first overlays a slightly too large 'curl overlay', then erases (masks) the rest of the image, including a small amount of the overlay, that will become the transparent corner.

            However if you want to apply a page curl to a lot of images, using the full script (above) is a rather slow technique. It does after all do a huge amount of mathematical processing (using IM itself as a floating point calculator), to actually calculate and generate the appropriate overlay and masking images.

            To apply a pagecurl to a lot of images it is better to use the script once so as to generate the overlay and transparency mask image once only. So lets extract those two images for a smaller 64x64 pixel images (using a special '-i "pagecurl" option added to the script for this purpose).


              convert -size 64x64 xc: miff:- | pagecurl -e 0.3 -i "pagecurl" - null:

                [IM Output] [IM Output]

            The above command creates two image files: "pagecurl_overlay.png" and "pagecurl_mask.png" shown. The input image itself does not matter as it is the masking images that we want. The 'page curled' result is just junked using the special "null:" image file format.


              convert thumbnail.gif -alpha set -gravity SouthEast \
                      -define compose:outside-overlay=false \
                      pagecurl_overlay.png -composite \
                      pagecurl_mask.png  -compose DstIn -composite \
                      pagecurl_thumbnail.png

                [IM Output]

            Of course these images are not the same size as our thumbnail or probably any image you are wanting to apply it to, but that does not matter, as we can use a couple of extra options to ensure they work as expected. Specifically, the "-gravity" setting ensures that the two overlay images are positioned in the lower right corner. And the special Define Setting 'compose:outside-overlay=false' will prevent the mask image from erasing the parts of the image not covered by the smaller image. See Outside-Overlay Setting for a full description.

            If you like to apply this to a lot of images you can use the "mogrify", using a special technique involving using "-draw" to do the Mogrify Alpha Composition. However this method of composition does not understand the special define setting, so it will only work with images, overlays, and masks that are all the same size.


              pagecurl -e 0.5 -i /tmp/pagecurl  {one image} null:
              mogrify {mogrify -format and -path options} -alpha set \
                      -draw 'image Over 0,0 0,0 "/tmp/pagecurl_overlay.png"' \
                      -draw 'image DstIn 0,0 0,0 "/tmp/pagecurl_mask.png"' \
                      {all images to be pagecurled}...

            Fancy Corner Overlay
            Here we look a bit deeper into used this 'double masking' technique to modify an image in different ways in different areas, rather than applying a single large mask or frame to the whole image. In this case we will only double mask the corners. The rest of the border (to match) is added separatally.

            [IM Output] The corner images I will use was generated from the original source (shown right) which I found in the DIY Frames Section of Anthony's Icon Library. There are others in this section, so you may like to have a look. If you find something on the net, please let me know as I like to collect interesting corners, and edging techniques.

            [IM Output] [IM Output] A color overlay and masking image was generated, from that initial image, so that we could use a Paint 'n' Mask technique, for overlaying the corner onto the image.

            Notice that these images, did not actually use any semi-transparent pixels, or even any shading of colors. As such this fancy border can be used to produce clean looking 'GIF' thumbnails for web pages.

            The complication with using corner masks, is that they only mask the corners of the original image. Because of this the original image first needs to be given the appropriate set of extra border colors. After that the two corner masks, must be composted onto each of the corners of the expanded image.


              convert thumbnail.gif   -alpha set  -compose Copy \
                      -bordercolor Black  -border 2 \
                      -bordercolor Sienna -border 3 \
                      -bordercolor Black  -border 1 \
                      -bordercolor None   -border 2 \
                      -bordercolor Black  -border 2 \
                      -bordercolor Peru   -border 3 \
                      -bordercolor Black  -border 1 \
                      \
                      -compose Over \
                      \( fancy_add.gif             \) -gravity NorthWest -composite \
                      \( fancy_add.gif -flip       \) -gravity SouthWest -composite \
                      \( fancy_add.gif       -flop \) -gravity NorthEast -composite \
                      \( fancy_add.gif -flip -flop \) -gravity SouthEast -composite \
                      -compose DstOut \
                      \( fancy_sub.gif             \) -gravity NorthWest -composite \
                      \( fancy_sub.gif -flip       \) -gravity SouthWest -composite \
                      \( fancy_sub.gif       -flop \) -gravity NorthEast -composite \
                      \( fancy_sub.gif -flip -flop \) -gravity SouthEast -composite \
                      fancy_border.gif

                [IM Output]

                Note that to preserve the transparent border that is being added, you must set "-compose" setting to 'Copy' rather than the default of 'Over'. If you don't then the transparency will be filled by the next border color added, in this case with 'Black'. See the Border Operator for details.

            The beauty of only using corner masks is that any size image can be framed using this technique, as long as it is large enough for the corner masks being added. That is you are not limited by the size of the framing images you have available.

            Of course each of the four corner images and the borders is the same all the way around the image, just rotated. That is the shadow or thickness effect is all 'inward'.

            To fix this you would need to generate a different corner peice for each and every corner, and the addition of the extra edges around the original image would need to be asymetrical. Basically it becomes much more complex, so as to produce true shadowing effects. A better solution may be to remove the shadow effect from the corner piece, apply it as before, but then add shadow effects globally. Caution is needed.

            Badge using Paint 'n' Mask
            The same badge image processing seen previously in Badge Overlay and Badge Mask 'n' Paint, can also be performed by painting then masking.

            Here we first paint all the colors an shades onto the then mask out the final transparency of the image.


              convert thumbnail.gif -alpha set -gravity center -extent 90x90 \
                      badge_paint.png -composite badge_shape.png -compose DstIn -composite \
                      badge_paint_mask.png

            [IM Text] + [IM Text] + [IM Text] ==> [IM Text]

            If this seems awkward for this specific image, you are right, it is.

            The reason that that we not only need to shade and highlight the original image, but we also need to fill out any areas that will contain shadow effects with black. Specifically any parts that will become fully transparent (and only pixels that really are fully transparent) will need to be painted with black.

            On the other hand semi-transparent pixels with shadow effects will have both a partial shade effect and a partial transparency mask. In other words shadows make an otherwise simple paint and mask technique awkward in the division of painting and masking effects.

            This is why a paint and mask technique is typically not used when dealing with semi-transparent additions to an image, such as when adding shadows or a flare stars.

            If the image did not contain any transparency-effects, than the paint process does not look so horrible, and can in many case be simplier than other techniques, as you can 'cut off' the painted overalys with the mask when finished. The Page Curl example was such a case, as we use the mask to trim the page curl overlay to make a seemless whole.

            Also note the gap between the hard black region and the shading effects in the paint image. This gap reflects warning I have mentioned before about ensuring that you do not overlap the results of any internal masking with the edges of any paint/overlay external mask. It is only in this specific case that this required gap becomes so obvious.

            For the next step in the 'badge' examples, see Badge using Lighting Effects, which merges the two masking images into a single mask/shading image.


            Lighting Mask Technique
            Glass Bubble Button
            The next level of complexity in thumbnail processing is the application of very complex lighting effects. The trickiness here is not so much the application of a lighting effect to an image, but the generation of the appropriate shading effect.

            For example using a Aqua Effect you can give an thumbnail a very complex shading effect that makes it look like it has been enclosed by a 'bubble' of glass. Also this works better with a thumbnail that has Rounded Corners.

            For lets generate a rounded corners mask for our thumbnail image, using a pure gray color.


              convert thumbnail.gif -alpha off -fill white -colorize 100% \
                 -draw 'fill black polygon 0,0 0,15 15,0 fill white circle 15,15 15,0' \
                 \( +clone -flip \) -compose Multiply -composite \
                 \( +clone -flop \) -compose Multiply -composite \
                 -background Gray50 -alpha Shape    thumbnail_mask.png

                [IM Output]

            Now that we have a pure gray 'shape mask' we want to use, I can apply the Aqua Effect effect to generate a lighting overlay, for this shape.


              convert thumbnail_mask.png -bordercolor None -border 1x1 \
                      -alpha Extract -blur 0x10  -shade 130x30 -alpha On \
                      -background gray50 -alpha background -auto-level \
                      -function polynomial  3.5,-5.05,2.05,0.3 \
                      \( +clone -alpha extract  -blur 0x2 \) \
                      -channel RGB -compose multiply -composite \
                      +channel +compose -chop 1x1 \
                      thumbnail_lighting.png

                [IM Output]

            With a final light/shade overlay image such as the above we can easily apply it to any thumbnail image of the right size.


              convert thumbnail.gif -alpha Set thumbnail_lighting.png \
                      \( -clone 0,1 -alpha Opaque -compose Hardlight -composite \) \
                      -delete 0 -compose In -composite \
                      glass_bubble.png

                [IM Output]

            Not only does this add the appropriate shading effects to any thumbnail of this size, but the same lighting image masks the thumbnail into the proper shape.

            It is important to note that only the color channels are used to apply the lighting effect, the alpha channel is not used in this process. Similarly when masking only the alpha channel is used, not the color channels. Without this seperation of channels for different effects, you will not get the correct result.

            For a discussion on extracting a lighting effect from images see the IM user forum topic Extracting light layer from two images.


            This can be taken much further however in that we can also directly add shadow effects to this lighting mask. The added color however must be pure black, and you need to ensure the lighting effect composition chosen will make an image perfectly black is the lighting mask is black.

            However this is actually how shadow effects are normally added to an image, as such you can just add shadows to the "lighting effect mask" directly, and all will be well!

            The same thing is true for adding lighting 'flares', but only using white pixels for the flare overlay.

            In essence a "lighting effect image" can again actually merge the two Mask 'n' Paint images back into a single image. As you will see in the next example.

            Badge using Lighting Effects
            Using the images from Badge using Mask 'n' Paint technique, I applied them to a pure gray canvas image, so as to quickly generate a "masked lighting effect" image, Actually I could also have used the other style of masking (Badge using Paint 'n' Mask) just as easily.

            I then apply the single masking image to the thumbnail reproducing the desired result.


              # merge "mask 'n' paint" images with a gray image,
              # to create a "lighting mask"
              convert -size 90x90 xc:gray50 -alpha set \
                      badge_mask.png -compose DstIn -composite \
                      badge_shading.png -compose Over -composite \
                      badge_lighting.png

              # Apply the single "lighting mask"
              convert thumbnail.gif -alpha set -gravity center -extent 90x90 \
                      badge_lighting.png \
                      \( -clone 0,1 -alpha Opaque -compose Hardlight -composite \) \
                      -delete 0 -compose In -composite \
                      badge_final.png

            [IM Text] + [IM Text] ==> [IM Text]

            Actually I rather like this form of masking as the mask image itself looks almost identical to the image you are after, just the colors are missing. That is after all how a lighting mask is created, just apply the effects to a perfect gray image, and you get a "lighting mask" image.

            Just remember that with this particular technique, the semi-transparent shadow must be pure black for it to work properly. You can not use a gray colored for any pixel that does not contain at least part of the original image. All transparent and semi-transparent areas must be pure white or black in color, with the appropriate level of alpha transparency.

            Why does only one image work? Previously we needed two images!

            The answer is that the masking image is limited only to only adding either pure black or white shades of color. By doing this the shading (lighting) effect, and its mask, is essentially merged into the color component of the "Lighting Effect Mask".

            As a result of this the alpha channel becomes free to hold the previously separate transparency mask for the final image.

            The limitation of this however is that you can only add white and black shades to the image. You can not add for example a gray color to the image being masked. Note however that it is posible to add some tints of primary and secondary colors of some color space, but only in a limited way, and I have never seen it used.

            In summery you can not add specific colors or fancy borders to the image, only shades and shadows, highlights and flares, or simple black or white text. However you should not attempt to mix or overlap added white and black effects, as the resulting gray anti-aliasing pixels between the two produces a shaded color from the underlying image, and not the expected gray color. That is the drawback with this technique!

            Masking images with distortions...
            What is more incredible is that as as the shading colors is just a gray-scale image, you can compress the lighting effects to just one color channel and the alpha channel mask.

            This can then be used to free two color image channels for other image processing effects! That is you can store other things into the single 'masking image'.

            Specifically you can add distortion effects into the same mask image! For more information on this see Unified Distortion Image which does exactly this! A sort of ultimate masking image.

            Framing using Edge Images
            [IM Image] One common way to add a complex border to an image is to use a pre-prepared framing images, to produce a frame such as the example shown (right).

            However you also need to be careful with generating frames. If you look at the given example carefully you will notice that it is not quite right. The shading of the generated frame is actually incorrect. The left and bottom frame edges should be swapped to produce a correctly shaded frame for a typical top-left light source.

            As such before we even begin, I would like to stress the importance of using the correct image, or the correctly modified image for each edge while framing your thumbnail or photo. It is very easy to get wrong, so double check your results when you think you have it right.

            The Frame Edge Images
            There are may types of images that can be used to frame an image.

            For example here is 'thin black with gold trim' frame that was modified from images provided by Michael Slate <slatem_AT_posters2prints.com>.
            [IM Image] [IM Image]

            There are two images, to provide two different lighting effects, one for the top and left edges, the other for the bottom and right edges. However the colors along the length of the image does not vary. As such you can either tile or stretch this frame to produce the length needed.

            A similar set of framing pieces are this 'thin ornate gold' tileable border images.
            [IM Image] [IM Image]

            As these images has some fine detail you cannot just simply stretch the image to the desired length. Nor can you just Rectangular Rotate these pieces to produce the other edge pieces, as doing so will get the shading of the fine detail wrong.

            A Diagonal Transpose distortion should however get the correct shading for the other edges. Extra caution is advised when reviewing your results, to be sure the both the overall shading and the fine detail shading is correct on all four sides of the image.

            Finally a framing image may only consist of a single image that can be used to generate all the framing edges, such as this 'bamboo' tiling frame image.
            [IM Image]

            The reason only one image is needed is that the frame has no specific 'inside' or 'outside' to it. Though the frame does have both overall and fine detail lighting effects that requires you to again be careful of how you rotate/flip/transpose the image for the other edges.

            The bigger problem with this frame is that if you just tile it simply, the macro detail becomes very regular, and as such you may need to randomise the tile offset, or even randomise the lengths of pieces being appended togther so as to give it a more natural look. More on this later.

            As you can see framing images can come in a variety of styles, and care must be taken to handle the chosen edging images in the correct way (with regard to lighting image), when generating the other missing edging images.

            Lengthening Framing Pieces
            Now in any use of these framing images, we will need to create a longer pieces that will cover the length of the image dimensions. There are only two basic ways in which this can be done.

            You can simply stretch the frame image using resize (without aspect preservation) so as to get the right lengths. This works for the first set of pieces shown above, which have no internal detail, but is not appropriate for any of the other framing images presented. Basically it will distort the internal detail, and may become a distraction to the look of the final image.

            However the other lengthening method, tiling, can be used for any framing image that has a repeating pattern or detail, which is the case with all the above images presented.

            If you are creating your own framing pieces, please be careful that the tiles do match up properly, and to a pixel boundary so as to ensure you have an uniform color and proper cycling of the detail in your framing images. It you don't you can get an artificial looking joint between the tiles, the become obvious because of the repeation of the tiles.

            In the real world picture framers also have the same problem in joining pieces together to make longer pieces. Basically it is very easy to get two different shades of wood, or very different grain pattern, that when 'dove-tailed' together, makes the joint very obvious. So really your not alone in this problem.

            The 'bamboo' framing images, will need to be tiled. Though as the detail is restricted to a small area on the image, you can get some interesting random tiling effects, that may need some randomized lengthing and shortening of the peices to remove. I will not go into this however, and will leave it as an exercise for those that are.

            For our examples, and because it works for just about all framing images I will use a simple constant tiling method to generate the longer edge lengths needed.

            Over-simplistic Append
            We can just lengthen the simple 'bamboo' frame above, by tiling it to the right length, then append the images together.

            The tiling is done simply by the special Tiled Canvas image generator "tile:" to tile an image that is being read in.


              convert thumbnail.gif \
                      \( -size 90x14  tile:bamboo.gif -transpose \) \
                      \( -size 90x14  tile:bamboo.gif -transpose \) -swap 0,1 +append \
                      \( -size 148x14 tile:bamboo.gif \) \
                      \( -size 148x14 tile:bamboo.gif \) -swap 0,1 -append \
                      frame_append.gif

                [IM Output]

            Note that the sizes used in the above two examples were calculated based on the known width (10 pixels) of the framing image, and the size of the image being framed (120x100 pixels). You will need to adjust the resize arguments appropriately for your images.

            One problem with tiling framing pieces (like bamboo) is that all the edges look like they are exact copies of each other! That is the framing looks artificial. In real life the frame will have been cut with pretty much random offsets, from longer pieces of real wood, or in this case bamboo.

            To fix that you will need to also give such tiles a slightly different Tile Offset for each edge of the image.


              convert thumbnail.gif \
                      \( -size 90x14  -tile-offset +50+0 tile:bamboo.gif -transpose \) \
                      \( -size 90x14  -tile-offset +0+0  tile:bamboo.gif -transpose \) \
                      -swap 0,1 +append \
                      \( -size 148x14 -tile-offset +70+0 tile:bamboo.gif \) \
                      \( -size 148x14 -tile-offset +25+0 tile:bamboo.gif \) \
                      -swap 0,1 -append       frame_tile_offset.gif

                [IM Output]

            This method of framing isn't too bad for this specific type of edge image, though for other types of frames it can look very silly. Basically the corners are not correct, and for most frames you really want to have the edge images meet at a 45 degree angle joint, just as you would have in a real picture frame.

            One solution to this is to pre-generate by hand appropriate corner images that we can now overlay onto this image to make it correct. This works well for a simple stretchable framing image (like 'black thin' framing image), but it will fail rather badly for a tileable image like 'bamboo' as the corner image will probably not fit the tile image properly.

            The better way is to generate corner joints directly from the tiled edge images. And I'll be showing you methods of doing this later.

            Extended Overlay Framing
            Also you can make this type of edge framing look even better by extending the frames beyond the bounds of the original image. This is often seen for a 'Home-Sweet-Home' type picture.

            To do this you will need to first enlarge the original image with lots of extra space into which the longer frame pieces are overlaid.


              convert thumbnail.gif -alpha set -bordercolor none -border 34 \
                      \( -size 144x14 -tile-offset +30+0 tile:bamboo.gif -transpose \) \
                      -geometry +20+10 -composite \
                      \( -size 144x14 -tile-offset +45+0 tile:bamboo.gif -transpose \) \
                      -geometry +154+0 -composite \
                      \( -size 178x14 -tile-offset +60+0 tile:bamboo.gif \) \
                      -geometry +0+20 -composite \
                      \( -size 178x14 -tile-offset +0+0  tile:bamboo.gif \) \
                      -geometry +10+124 -composite \
                      frame_overlaid.gif

            [IM Output]

            Note the measurements and positioning for this type of framing is not simple, and could use some randomization such as I hardcoded into the above example. Also you can improve the look further by rounding of the ends of the lengths of frame, with some additional and appropriate shading.

            A much better way of framing images in this manner is to generate the framing image as a complete unit, and just overlay it on a fixed size image (see Simple Border Overlay). However doing this means you can no longer slightly randomize the lengths and position of each framing piece.

            45 degree corner joints
            The better solution is to somehow add the framing images around the thumbnail in such a way as to actually create a 45 degree joint in each of the corners of the frame. This is not easy, and I went though a number of drawing and masking methods until I re-discovered a magical operator called Frame, 3D like Borders.

            The solution then was simple. Read in the image, and "-frame" it, to create a template which of the areas to be framed.


              convert thumbnail.gif -alpha set -bordercolor none \
                      -compose Dst_Out -frame 15x15+15  frame_template.gif

                [IM Output]

            Now note that this template as some interesting features. First it is transparent in the middle, where the main image will sit. Second it has four and only four distinct colors defining each area in which we want to place our framing images. It does not generate 'anti-aliaing' pixels of varing colors in the corners.

            Note that to make things easier the width of those areas (15 pixels) is width of the framing pieces we will add to the image. if the vertical edges were a different thickness to the horizontal edges, this technique would not work very well. In fact few methods would would well in such a situation.

            This image is the framing template and by tiling each of our framing pieces into the four differently colored areas using Color Fill Primitives, we will get our 45 degree corner joints, very simply and easily.

            For example...


              convert frame_template.gif \
                      -tile blackthin_top.gif -draw 'color 1,0 floodfill' \
                      frame_top_filled.gif

                [IM Output]

            You can repeat this process for the other three edges. Using transposes to ensure that the highlights and shaodws of the internal detail remain correct.


              convert frame_template.gif \
                      -tile blackthin_top.gif   -draw 'color 1,0 floodfill' \
                      -tile-offset +0+105 -tile blackthin_btm.gif \
                                                   -draw 'color 15,105 floodfill' \
                      -transpose \
                      -tile blackthin_top.gif      -draw 'color 1,0 floodfill' \
                      -tile-offset +0+135 -tile blackthin_btm.gif \
                                                   -draw 'color 15,135 floodfill' \
                      -transpose \
                      -gravity center thumbnail.gif -composite frame_filled.gif

                [IM Output]

            From an IM forum discussion 45 degree frame joints a simplier solution, involving pre-rotating the bottom edge was found. Here is the full example using the In Memory Register to save intermediate images.


              convert thumbnail.gif                -write mpr:image    +delete \
                      goldthin_top.png             -write mpr:edge_top +delete \
                      goldthin_btm.png -rotate 180 -write mpr:edge_btm +delete \
                      \
                      mpr:image -alpha set -bordercolor none \
                      -compose Dst -frame 25x25+25  -compose over \
                      \
                      -tile mpr:edge_btm \
                      -transverse -draw 'color 1,0 floodfill' \
                      -transpose  -draw 'color 1,0 floodfill' \
                      -tile mpr:edge_top \
                      -transverse -draw 'color 1,0 floodfill' \
                      -transpose  -draw 'color 1,0 floodfill' \
                      \
                      mpr:image -gravity center -composite    frame_gold.png

                [IM Output]

            As you can see we still have a problem, it looks very artifical in the top left and bottom right corner, due to a diagonal mirror effect that results from the tiling. To fix this we need to add a randomised "-tile-offset", so as to remove this mirror effect.

                Tile Offset setting was broken before IM version 6.3.9-9 in that the 'X' offset was being used for both 'X' and 'Y' offset values (the given 'Y' value was ignored). This means that the above example will probably incorrectly tile the bottom and right edges, in older releases of IM.

            Scripted Version

            This needs to be re-written using the last example as template

            You can of course do all the above in a single command. However lets do it in a scripted way. This version uses some in-line code to generate appropriate edging images from the base images provided using Simple Distorts and some randomized Image Rolls to improve the overall look of the tiled image. These can be adjusted depending on the type of edge framing image that was provided.

            The processed edging images are then tiled using an In-Memory Tile Image technique and the frame template (generated) is used to mask those images, as we did above.


              image=thumbnail.gif
                 image_w=`convert $image -format %w info:`
                 image_h=`convert $image -format %h info:`

              top=goldthin_top.png
              btm=goldthin_btm.png

                 width=`convert $top -format %h info:`
                 length=`convert $top -format %w info:`

              # Size of the new image ( using BASH integer maths)
              new_size=$(($image_w+$width*2))x$(($image_h+$width*2))

              # IM options to read a 'randomly rolled' version for the edge pieces
              lft="( $top -roll +$(($RANDOM % $length))+0  -transpose )"
              rht="( $btm -roll +$(($RANDOM % $length))+0  -transpose )"

              # IM options to 'randomly rolled' the top and bottom pieces
              top="( $top -roll +$(($RANDOM % $length))+0 )"
              btm="( $btm -roll +$(($RANDOM % $length))+0 )"

              # Frame the image in a single IM command....
              convert -page +$width+$width  $image  +page -alpha set \
                \( +clone -compose Dst -bordercolor none -frame ${width}x$width+$width \
                   -fill none -draw "matte 0,0 replace" \
                      -flip   -draw "matte 0,0 replace"   -flip \) \
                \( $top $btm -append -background none -splice 0x${image_h}+0+$width \
                   -write mpr:horz +delete -size $new_size tile:mpr:horz +size \
                   -clone 1  -compose DstOut -composite \) \
                \( $lft $rht +append -background none -splice ${image_w}x0+$width+0 \
                   -write mpr:vert +delete -size $new_size tile:mpr:vert +size \
                   -clone 1  -compose DstIn -composite \) \
                -delete 1  -compose Over  -mosaic   framed_script.png

            [IM Output]

            And there we have a perfectly framed image with 45 degree corner joints, with randomized tiling offsets.

            Yes it is a complex example. But that is to allow the use of In-Memory Tile Images so we can pre-process the framing images, all in the one command. This makes it more complex but also more versatile.

            The above code has been built into a shell script, which you can download ("frame_edges.tar.gz" from the IM Example Scripts directory). This tar file includes the script and a set of framing images, that the script understands how to process and use. It also adds a 'cardboard' border between the frame and the image proper.

            Future example
            Using tiling edges with matching corner peices.

            The edge images will need to match up to pre-prepared corner pieces, but also tile neatly across the fixed length of the image. That means that the whole tiled edge may need some stretching or compression so as to align the edge tiles with its corner pieces. To work properly teh edge tiles must repeat at least 3 or 4 times across the smallest image edge.

            An example of this type of tiled edge/corner is the implementation of a border of 'leaves' or 'fleur' effects.
https://legacy.imagemagick.org/Usage/photos/
            One of the prime uses of ImageMagick is the handling and modification of photographs that were taken with the new modern digital camera.

            These cameras generally take quite large, high resolution photos, and include in them meta-data about the time, scale, zoom, camera, orientation, and so on. There are even plans to link cameras to mobile phones, so that it can even make a guess as to where you were when the photo was taken and who might be in the photo (from what mobile phones are in font of it).

            Here we look at the basics of handling digital photos, and even converting them for other purposes, such as artistic renderings.

            Special thanks goes to Walter Dnes, a digital camera user, for his help in the enhancement of digital photos.

            Digital Camera Meta-Data, the EXIF Profile
            When a digital camera takes a photo, it also includes a lot of extra information in the JPEG save file. This meta-data is known as the EXIF profile, and is provided specifically for photographic labs and development. The ImageMagick "identify" with a "-verbose" setting will display this Exif information.

            Here is the EXIF data of a photo I took of a Pagoda, Kunming Zoo, in Southern China.


              identify -format "%[EXIF:*]" pagoda_sm.jpg |\
                  sed 's/\(.\{46\}\).*/\1/' | column -c 110

            [IM Text]

                The EXIF data, or any identify output, should be processed in a case in-sensitive way. Many older versions of IM for example, will output "EXIF:" (uppercase) rather than "exif:" (lowercase).

            Here is a similar example but using 'globbing' (shell-like) expression to limit output to EXIF fields involving Time...


              identify -format "%[exif:*time*]" pagoda_sm.jpg

            [IM Text]

            There is a lot of information about this photo in the EXIF profile. For example

                My camera is a Panasonic ('Make'), DMC-LZ1 ('Model')
                The camera was rotated ('Orientation'). But I must have corrected that rotation without adjusting the EXIF data. The camera was also tilted upward slightly, but that info is not recorded.
                The 'FocalLength' of '37mm shows that I did not make use of my cameras 'Optical Zoom' feature. My camera could go up to a 6X optical zoom for a 'FocalLength' of '366/10' or '222mm'.
                And 'DigitalZoomRatio' shows I did not digitally zoom either.
                The camera also used a fast 1/8 second 'ExposureTime', and an aperture 'MaxApertureValue' of 3mm, or 'FNumber' of '5.6' and a 'ISOSpeedRating' of '64'.
                The flash ('LightSource') was not used.
                The original image was 1728 by 2304 pixels ('ExifImageLength' and 'ExifImageWidth'). Though the actual image, if you like to check is smaller, so I must have cropped and/or resized it.
                And probably most importantly, it was taken around 14:05pm on 9th of July 2005, according to the 'DateTime' string. That assumes that I had the cameras time set correctly (which I did).
                More modern cameras may even have a GPS location and posibily a compass direction of the view! 

            Also included but not listed above is a small 'thumbnail' preview image that the camera used on its own display.

            There is also features to mark photos you want to be 'developed' or printed by photographic printers, and to adjust other printing parameters. However this is rarely used by most people.

            Many of these settings can be very useful to users, but the most useful to people is generally the date and time of the photo. This of course assumes that the date and time was set correctly on the cemera before the photo was taken. Also many people are interested in the orientation of the image so it can be rotated correctly when displayed, and That is what we'll look at next.

            All this data, and especially the preview image, can take up quite a lot of space in the image. And it may be that I don't actually want everyone in the world knowing that I was in Kunming, China in July 2005. As such you may like to remove EXIF data from your images before actually publishing it on the World Wide Web.

            Also the size of an image from a digital camera usually very large (and getting larger), allowing you to print it at photo quality level, but is far too large for use of the WWW, and especially not for thumbnails. As such unless you want users to actually be able to print photo quality images, I would not publish the original image directly.

            The above image for example has been cropped and resized for IM examples usage, but I purposely left the EXIF data intact for the example. Normally I would strip this information.

            Digital Photo Orientation
            I have been told that Photoshop will automatically rotate digital images based on the EXIF 'Orientation' setting, IM will also do this by including a "-auto-orient" operator, after reading in the image.

            However, and this is important
            JPEG Format is Lossy

            What this means is that any time you decode and save the JPEG file format you will degrade the image slightly. As a general image processor, IM will always completely decode and re-encode the format, as such it will always degrade JPEG images when it re-saves the image. For more information on the nature of the JPEG format see JPEG Image File Format.

            The point is to only use IM to correct digital photo orientation (using "-auto-orient") when you are also performing other image modifying operations, such as Thumbnail Creation, Annotating Images, Watermarking or even Exposure Adjustments.

            IM can extract the current orientation (as a number) from the photo using an Image Property Escape...
                


              identify -format '%[exif:orientation]' pagoda_sm.jpg

                [IM Text]

            IM provides a special "-orient" operator (use "-list orientation" to see possible values).
                


              convert pagoda_sm.jpg -orient bottom-right \
                             -format '%[exif:orientation]'   info:

                [IM Text]

            These meta-data setting methods, allow you to adjust the orientation of photos you have modified, especially ones you have rotated. Note that a correctly orientated photo has an orientation of 'Top-Left' or 1.

            Of course you should not remove the EXIF meta-data (using either "-strip" or "-thumbnail"), if you plan to use "-auto-orient" later in the image processing. Use it before stripping the image meta-data.

            If you do want to correct the orientation of your photo, without degrading or otherwise modifying your image, I suggest you use the JHead program. For example here I correct a photos orientation, and delete the built-in preview thumbnail all the digital photos in a directory.


              jhead -autorot  *.jpg

                The JPEG lossless rotation will only work correctly for images that have a size that is divisible by 8 or 16. This is true with most (but not all) digital camera photos. If you try this with an image that is an odd size the right or bottom edge blocks (containing the partial size) will not be positioned correctly in the final image, as these block can only exist on the right or bottom edge.

            For an example of this see this specific discussion

            The JHead program will also let you adjust the photos date (if your camera time was set wrong, or you have travelled to different time zones), extract/remove/replace the preview thumbnail, set the comment field of the image, remove photoshop profiles, and do basic image cropping (to remove that stranger exposing himself ;-) so on, without degrading the JPEG image data.

            I recommend this program, or other programs like it (see Other JPEG Processing Programs), to fix this information. Just be sure that it does not actually decode/re-encode the JPEG image data.

            One final point about orientation. If you pointed your camera almost straight up or down, the EXIF orientation setting may not resolve correctly. The same goes for angled or slanted shots. The orientation (and cameras) just have no senses for these situations.

            Your only choice for such photos is to do the rotates yourself using the lower level non-lossy "jpegtrans", or IM "-rotate", and then either reset the EXIF orientation setting (using JHead or the IM "-orient" operator), or just strip the EXIF profile.

            Other IM Lossy Modifications...
              If you are also resizing or otherwise modifying the image, such as reducing
              its quality and size for use on the web, then data loss is already a fact.
              As such during those operations IM can do similar things, allowing you to do
              all the required operations in a single 'load-save' cycle.

              Rotate ALL images to landscape   -rotate 90\<
                                   portrait    -rotate -90\>

            Color Improvements
            Before proceeding, it is recommended that you first look at Color Modifications for an introduction to general color modification techniques that will be used.

            Normalizing (using "-normalize") high-contrast line art and graphics can be great. But normalized photos may look unreal, and, as was said earlier, may not print well either. The "-contrast-stretch" operator can limit the "boundaries" of the normalization, but the "-levels" and/or "-sigmoidal-contrast" operator can make "smoother" adjustments (see Histogram Adjustments for a lower level discussion of what these operators do).

            The above input is courtesy of "Tong" form the IM Mailing List.

            Brightening Under-exposed Photos Contributed by Walter Dnes
            Sometimes there simply isn't enough available light to allow for a proper exposure. At other times, you may have to use shorter exposure times than optimal, in order to eliminate motion-blur.

            Underexposed digital photos can have darker areas preferentially brightened, without blowing highlights, by using the "-sigmoidal-contrast" operator, with a '0%' threshold level. See Sigmoidal Non-linearity Contrast for more details.

            Here is a minor underexposure example, which was taken at a free concert after sunset. This has lots of brightly lit areas, which are clear, but also dark areas I would like to make more visible.


              convert night_club_orig.jpg  -sigmoidal-contrast 4,0%  night_club_fixed.jpg

            [IM Output] ==> [IM Output]

                As always, you should use a non-lossy format like TIFF or PNG for intermediate work. The JPEG format is only used here to reduce disk space and download bandwidth for web publishing.

            Select image to see the enlarged version actually used by the examples rather than the small thumbnail shown.

            And here is a major underexposed example, which was a night-time shot from my balcony looking southwards towards the city of Toronto.


              convert night_scape_orig.jpg -sigmoidal-contrast 10,0%  night_scape_fixed.jpg

            [IM Output] ==> [IM Output]

            The main parameter controls the amount of brightening. The more brightening required the higher value used. And the grainier the output picture will look. This is due to the smaller pixel errors also being enhanced.

            Sigmoidal contrast brightening tends to de-emphasize the red end of the spectrum. You may end up having to select a parameter that results in the most natural flesh tones, rather than the brightness level you really want.

            In the case of major underexposure, you will end up with a glorified grainy black-and-white image after brightening. This is a physical limitation of digital image enhancement. If there's no colour data present, IM won't generate it for you. In real life the bricks on the right-hand side of my balcony are reddish, and the trees below are green.

            Binning -- Reducing Digital Noise Contributed by Walter Dnes
            A lot of serious photographers are unhappy with the side-effects of the "megapixel race" by digital camera manufacturers.

            Manufacturers pack more megapixels into a digital camera's sensor by making them smaller. Smaller pixels result in a noisier picture at the same ISO setting, which forces people to use lower ISO settings. Using lower ISO ratings to avoid noise requires longer exposure times. This, in turn, means that most consumer digital cameras are effectively useless indoors beyond the 10-foot range of their built-in flash for anything except a still-life picture taken with the camera on a tripod.

            Many digital camera users would gladly trade some pixels for less noisy pictures at higher ISO settings, but the marketeers who control the companies refuse to consider this as an option.

            Fortunately, the trade-off can be done after the fact on digital photos. The technical term is 'binning'. The simplified theory goes like so...

                Take an n-by-n grid of pixels, and average their components to obtain one "super-pixel".
                Signal is proportional to the combined pixel area, which means that the amount of signal has increased by a factor of n^2
                Noise is random. Which means that it is proportional to the square root of the combined pixel area, a factor of n. The net result is that SNR (signal-to-noise ratio) has increased by a factor of n. See Photo Glossary, Binning for more details. 

            When a 1600x1200 digital photo is binned down to 800x600 (i.e. a 2x2 grid) the signal-to-noise ratio is doubled. Similarly, a 2560x1920 picture binned 3x3 to 853x640 pixels will have a factor of 3 improvement in signal-to-noise ratio.

                In order to make use of binning, the photo image must be a whole number multiple of the final desired size.

            In ImageMagick, the special "-filter" setting 'box' will average groups of pixels down to a single pixel when you "-resize" an image (See Resampling Filters for details. This means that to do a 'binning' you only need to resize the image correctly.

            Under Construction

            Walter Dnes also provided the original script binn to perform the calculations, minimally crop the image and perform the 'binning'.

            Binning examples 3

            Binning examples 4

            Photo Conversion Cookbook
            Minor Rotation Correction -- Make a photo more level
            Typical situation. You have taken a photo, but the image isn't level, and you want to correct it.

            [IM Output]

            For example here is a photo I took using a hand held camera in Beijing, 2008, from the hill in Jingshan Park, immediately behind the Forbidden City. No it isn't of the Forbidden City itself, but a temple on the other side of the hill.

            Click on the thumbnail, to see a larger image.

            Yes the image is small, and you should apply the solution to the original image not a small thumbnail, but the techniques is the same for any image. In this case the image needs to be rotated by -1.8 degrees, to correct it.

            Now if you just simply rotate the image you will get a slightly larger image containing areas of color in the corners, making the correction look obvious and horible.


              convert beijing_tn.png -rotate -1.95  beijing_rotate.png

            Even if you were to crop the image back to its original size, such as demonstarted in Simple Image Rotations you will still get some colored corners.

                [IM Output]

            The simplist solution would be to now crop that result so as to remove those borders, but then your image becomes a rather odd size, which is again rather obvious that something has been done. Though the formula to do that clipping is not simple, but is demonstrated in Distortion Rotation Methods.

            The better solution is to not only rotate the image, but scale it slightly so as to produce a rotated image that is the same size as the original.


              angle=-1.95
              convert beijing_tn.png -distort SRT \
                 "%[fx:aa=$angle*pi/180;(w*abs(sin(aa))+h*abs(cos(aa)))/min(w,h)], $angle" \
                 beijing_rot_correction.png

                [IM Output]

            And the image is clean looking with a perfectly level wall.

            The angle calculation is reasonably straight forward trigonometry, using the pixel locations at the ends of a long straight line in the image. However I found that simply rotating the image at various small angles by trial and error will find a good rotation angle relatively quickly.

            When looking how good a particular angle is, take a very close zoomed in look at the pixels along the line or edge you using. The top of the wall in this photo. And remember in image rotations a left or anti-clockwise rotation is negative (due to Y-axis pointing downward).

            Also remember that if at all possible, always apply operations to the original image, avoiding the use intermediate images (and especially intermediate JPEG images). It is always better to apply any photo modification starting with the original source than any saved intermediate copy.

            Tilt-Shift Effect -- make scenery look like an artificial model
            [IM Output]

            The 'Tilt-Shift' is a technique which causes an image be be blurred at the top and bottom, while leaving the center of the image unblurred. It was originally done in very old bellow type cameras where the lens was tilted to bring the top and bottom of the image out of focus. Thanks of the introduction of Variable Blur Mapping, added to ImageMagick in v6.5.4-0 this is now easy to do.

            If you add to this a very high contrast so as to enhance shadows, and saturate the colors, a typical result is that a normal image can be made to look artificial. Almost as if you were taking a photo of a small, highly detailed, and brightly lit, model.


            The first thing we need to do, is enhance the colors in the image to give it a very high contrast, and perhaps brighten it a bit to make it look like it is very well lit with strong studio lights.


              convert beijing_md.jpg -sigmoidal-contrast 15x30% beijing_contrast.jpg

                [IM Output]

            Note how I used a strong Sigmodial Contrast Operation, to achieve these color effects. I did not just simply use a linear contrast as I did not want to 'clip' the brightest and darkest colors of the image. The contrasting value of '15' is a very very strong contrast. I also brightened the image a bit by offsetting the center of the contrast threshold to a '30%' gray value.

            If the colors of the contrast enhanced image does not come out cartoonish enough, you may like to try increasing the color saturation of the image, using the Modulate Operator. This image did not need it as it as the tiled roof and bright green trees already provides enough color effects.

            If you look at an enlargement of the image (Click on the thumbnail), you will see that even just enhancing colors gives the image a feel of artificial lights, though it does not look like a model, with too much detail to the cars in the background, and people in the foreground.

            Now for the tilt-shift.

            For this we prepare a gradient image that is white at the top and bottom, and black in the middle. Some people might use a linear gradient for this, but I find a parabolic gradient better.


              convert beijing_contrast.jpg \
                      -sparse-color Barycentric '0,0 black 0,%h white' \
                      -function polynomial 4,-4,1   beijing_blurmap.jpg

                [IM Output]

            Note that I used the original image itself with a two point Barycentric Sparse Coloring to generate a linear gradient over the whole image. That linear gradient is then modified using a basic Polynomial Function to make it a parabolic gradient with black in the middle.

            Now it is simply a matter of blurring the image according to the blur map to create a 'tilt-shift' effect. The result is that the original image looks rather like a scale model, rather than quick snap-shot of the real thing.


              convert beijing_contrast.jpg  beijing_blurmap.jpg \
                      -compose Blur -set option:compose:args 10 -composite \
                      beijing_model.jpg

            [IM Output]

            As you can see in the final image, the trees and the buildings look very artificial, due to the strong colors, while the blurring of the near and far parts gives the image a 'small' model-like feel to it. Though this must have been a very detailed model!

            The result could have been improved further by performing a Rotation Correction (see previous) as part of the tilt shift processing. A perfect camera orientation would simply added to the artificial feel.

            Of course you can string all these operations together to to it all in one command, and avoid temporary files, or loss of quality.


              convert beijing_md.jpg -sigmoidal-contrast 15x30% \
                      \( +clone -sparse-color Barycentric '0,0 black 0,%h gray80' \
                         -solarize 50% -level 50%,0 \) \
                      -compose Blur -set option:compose:args 10 -composite \
                      beijing_model.jpg

            In the above I replaced the parabolic gradient with a more traditional linear black-white-gray gradient (with the same slope) to the 'tilt-shift' blur map. The Solarize & Level technique was used to make the linear gradient peak horizontally about 1/3 from the bottom of the image. However I find that the area of focus in a linear gradient too small and not very practical.

            There are many other way of generating a suitable gradient for a tilt shift effect. For example using Resized Gradients. Or horizontally scaling a Shepards Sparse Color of single column of pixels. Sine curve gradients may also be useful.

            Speed Optimization
            The Variable Blur Mapping operation is essentually using a single pass 2-dimentional blurring method (equivelent to an uniform Gaussaian Blur). However you can get a general speed boost by doing the bluring operation in two 1-dimensional variable blur operations.

            For example here I first blur horizontaly, the vertially...


              convert beijing_md.jpg -sigmoidal-contrast 15x30% \
                      \( +clone -sparse-color Barycentric '0,0 black 0,%h gray80' \
                         -solarize 50% -level 50%,0 -write mpr:blur_map \) \
                      -compose Blur -set option:compose:args 10x0 -composite \
                      mpr:blur_map \
                      -compose Blur -set option:compose:args 0x10 -composite \
                      beijing_model_2pass.jpg

            The result is practially identical (though does differ somewhat), but is a lot faster to process.

            ASIDE: I believe that swaping the operations (blur vertical then horizontally) will generate a more accurite result for this type of blur mapping. basically as the horizontal blur is a constant in the direction of that blur pas, so should be done last.

            Problems with Tilt-Shift Effect vs A Real Model
            If you examine the resulting photo carefully, you will be able to tell it is a fake tilt-shift, and not a photo of a real model.

            You can see this in that the roof of the larger building is too blurry when compared to the base of the building. Even though it is about the same distance as the base. Similarly the base of the 'wall' is more blurry than the top of the wall. That is it can be seen to be a fake.

            The problem is that large vertical objects, should be blurred by the same amount over the whole surface, and not just variably blurred by height. Remember the blur gradient is meant to represent the focal depth, or distance of the various objects in the image, as such the surface of a vertical object should all be the same 'distance' and thus blurred by the same amount.

            To fix I would need to adjust the blur gradient to make those areas have a with a constant (or near constant) color of the 'base' of that object, relative to rest of the image. That is vertical surfaces have a constant blur amount while all the horizontal surfaces have a blur gradient.

            Basically the blurred gradient should represent the actual 'depth' of each point in the image, which for most images is a very complex gradient. This adjustment can be difficult to achieve, as it most likely requires some human interpretation of what is a horizontal wall and how far the object is in the image. It is also unlikely to be easily automated.

            What can you do with this effect? Mail me your tilt-shift images! I'll reference them here. Or perhaps you can correct the tilt-shift faults in the above example.
            PNG-JPEG Layered Images
            By separating a large newspaper or magazine page into a text layer that is saved as a PNG, and an image layer saved as JPG, both using just a white background, it is possible to use much less disk space than the two images combined!

            More importantally images can use a lossy compression (JPEG), the text components will remain sharp an clear (PNG).

            It sounds silly and weird but it is actually true. The separated images can save 3 to 4 times the disk space used by a single combined image.

            Usually the two images are generated during the publication process as separate layers. But you can also separate images after the fact too.

            The images are just overlayed together...


              convert  ny_family.jpg ny_family.png -composite   ny_family_merged.jpg

            [IM Output] ==> [IM Output] ==> [IM Output]
            Select the resulting images to see a larger copy.

            This uses a normal Over Composition, which requires the PNG (overlay) image to be transparent. This transparency comes in two forms. Either as a boolean (pure on/off) mask, such as seen in the above.

            Example code for image separation welcome.

            Overlapping Photos -- blurred overlaps of appended photos
            Creating a series of overlapping photos (and I don't mean a panarama) is a common task, especially in web site creation. But is can be tricky to do unless you have the right knowledge of IM operators.

            The simplest method is to use a Masked Composite of the two images, and a mask to select which image to overlay.

            First however you need to do simple mathematics. For this example, I am using two thumbnail images 120x90 pixels in size and I want to overlap them horizontally by 40 pixels. This means the resulting image should be 120 + 120 - 40 pixels wide, or a 200x90 pixel image.

            Next we need a mask. This needs to black one one side, white on the other, with a 40 pixel gradient in the middle, the size of the final output image. That is 120 pixels - 40 pixel gives an 80 pixel area for each of the two non-overlapped areas.

            So lets generate a masking image...


              convert -size 90x80 xc:white xc:black   -size 90x40 gradient: \
                      +swap -append -rotate 90    overlap_mask.png

                [IM Output]

            An alternative way of generating the masking image is to use Fred Weinhaus's "plmlut" horizontal gradient generator script. This has finer controls for the curvature of the gradient rather than a sharp linear gradient I generate above.

            Now that all of the math is out of the way, all that is left is to do a three image masked composition, using the mask we just generated. However we will also need to enlarge the destination (left) image so as to provide enough space for the overlapping right image (any color), and position the second image correctly using the appropriate gravity (right, or 'East').


              convert holocaust_tn.gif -extent 200x90  spiral_stairs_tn.gif \
                      overlap_mask.png  -gravity East -composite   overlap_photos.jpg

            [IM Output] [IM Output] + [IM Output] ==> [IM Output]

            And we now have two images, which are overlapped using a linear gradient.

            Of course the two commands can be merged into a single command, so that you don't need to save the 'mask' intermediate image. This is left as an exercise to the reader.

            A slight improvement is to use a more curved gradient over a larger overlap between the images. This reduces the sharp change visible at the start and end of the overlap area of the final image. Especially with images contain large areas of very different colors.

            For example, this uses some Distorted Gradient techniques to not only generate a smoother gradient curve, but also to rotate that gradient so as to have a highly angled overlap.


              convert -page +0-15 -size 1x30 gradient: \
                      -sigmoidal-contrast 5,50% -contrast-stretch 0 \
                      -set option:distort:viewport 180x90-90-45 \
                      +distort SRT 115 +repage \
                      holocaust_tn.gif -extent 180x90 +swap \
                      spiral_stairs_tn.gif +swap \
                      -gravity East -composite   overlap_angled.jpg

                [IM Output]

            Yes, the above is rather complex, but it shows just what is possible.

            If you plan to do more than two images, a better method is to use the mask to directly set the transparency of the second and later images. The multiple images can then be overlaid together using a techniques seen in Layered Image Examples.

            Some of these techniques do not require you calculate the final image size, as IM can do this for you. You only need to make sure you position the images correctly.

            For example, here I add a 30 pixel gradient to a second and third image, requiring the images to be placed every 90 pixels (width 120 minus 30 pixel overlap) from each other. When all images are given the appropriate transparency and positioning, we just Mosaic the layers together (all offsets are positive), letting IM figure out the final canvas size.


              convert -size 90x90 xc:white -size 90x30 gradient: -append -rotate 90 \
                      hatching_tn.gif \
                      \( chinese_chess_tn.gif -clone 0 \
                             -compose CopyOpacity +matte -composite -repage +90+0 \) \
                      \( holocaust_tn.gif -clone 0 \
                             -compose CopyOpacity +matte -composite -repage +180+0  \) \
                      \( spiral_stairs_tn.gif -clone 0 \
                             -compose CopyOpacity +matte -composite -repage +270+0 \) \
                      -delete 0   -compose Over  -mosaic     overlap_series.jpg

            [IM Output]

            Rather than pre-calculating the positions of the overlapping masked images, you can use techniques found in Append Overlap, as well as Incrementally Calculated Positions for longer image sequences.

            Final Notes:

            Overlapping photos like this works best for images with a reasonably common overall color.

            Also you may notice that for the images at either end of the sequence, a centered subject may not look very centered due to the overlap on one side of the image only. This problem can be improved either by fading the outside edge of those images into transparency, or chopping of some of outside edge to help re-center the subject of those images.

            ASIDE: It may be that doing the composition in a different colorspace may work better. Anyone like to experiment and report on your results, good or bad?

            Double Exposures -- mixing multiple photos of the same scene
            With old time film based cameras, there was a technique where a picture was take two or more times without 'rolling' the film. This allowed you to create what was known as double exposures, where two images taken at slightly different times were merged together. The result was often a ghosting or dimming of parts of the image which moved or changed.

            However with careful control of the subjects in the image, the lighting effects, and even the development process, it became possible to make some very weird or even 'impossible' photos. With digital images it is even easier as you have even better control of the images.

            Basically... Seeing may be believing, but cameras lie!

            For example suppose I wanted an image in which I appear in twice! Well that is easy to do. Here for example are the thumbnails of two quick photos I took specifically for this example, using a tripod and timer, which I'll use directly.
            [IM Output] [IM Output]
            Perhaps you can supply a better more amusing photo set?

            I will apply the double exposure techniques directly to these thumbnails, though more typically I would do this using original image files as inputs, so as to get a result of the highest quality.

            Now if I used a traditional film-like 'double exposure' with an old style camera, the result would be an average of these two images, generating see-thru 'ghosts' of myself. Here is the digital simulation of this technique...


              convert anthony_1.jpg anthony_2.jpg -average  anthony_ghosts.jpg

                [IM Output]

            However, what if I don't want ghosts, but properly solid images of myself. Well then you need to use a mask to select which parts you want to come from which image.

            This mask can be generated in two ways. You can just manually create the mask by dividing the image along the static or unchanging parts. A rather simple matter in this particular case...


              convert -size 100x90 xc: -draw 'rectangle 0,0 50,89' \
                      -blur 0x3  anthony_mask.jpg

                [IM Output]

            Note that I blurred the mask, so as to 'feather' the cut-over between the two images. And here I use a Masked Composition to merge the images.


              convert anthony_1.jpg anthony_2.jpg anthony_mask.jpg \
                      -composite  anthony_doubled.jpg

                [IM Output]

            How if you had two (or more) family photos, where some people had eyes closed, were speaking, pulling faces, or just looking away. You could pick and choose each 'head' from different images and merge the multiple images to form a montage, so as to get a photo where everyone is looking at the camera, and have their eyes open.

            By swapping the input images, or just negating the mask, you can remove me completely from the image, so get an unrestricted view of the static background.


              convert anthony_2.jpg anthony_1.jpg anthony_mask.jpg \
                      -composite  anthony_removed.jpg

                [IM Output]

            This can be handy when taking photos of a public monument, where you can't afford the expense of crowd control. Just take lots and lots of photos from a tripod, and hopefully you can combine them to remove everyone from the scene!

            An alturnative to generating a background image which you have hundredes of images (video) is to just create an average of all the images. This Turn all the people or other transient objects into a light haze of 'ghosts'. That can be an interesting effect in and of itself, but not always what is wanted.

            An average image can be an useful step, as once you have it you can compare it against each individual image to mask out the person (transient object) from each frame, before again combining the backgrounds together, to create a clean (no haze) background image).

            A major discussion on automatically generating a 'clean background' from video images is in IM Discussion Forum on Creating a Referance Image and Extracting change events.


            With a clean background photo, we we can threshold a difference image to mask out the parts of the image that changed. You may need to use some further blurring and threshold to expand that mask appropriately to cover not only the object within the image, but any shadows or reflections it may cast on the background scenery. A little trial and error may also be needed to get it right.


              convert anthony_removed.jpg anthony_2.jpg \
                      -compose difference -composite \
                      -threshold 5% -blur 0x3 -threshold 20% -blur 0x3 \
                      anthony_automask.jpg

                [IM Output]

            Now lets use this mask to mix my 'ghosts' image with the original image so it looks like my conscience is 'haunting' me for making such 'impossible' pictures.


              convert anthony_1.jpg anthony_ghosts.jpg anthony_mask.jpg \
                      -composite  anthony_haunted.jpg

                [IM Output]

            As a final point, all the above techniques assumes the photos were taken from a camera that was locked down securely on a stationary tripod. If this was not the case, but just taken from a hand held position, I can guarantee that the images will not match-up or 'align' properly, no matter how hard you tried to do it. In such cases you may require some Affine or even Perspective distortion of at least one of the two images to get the backgrounds to align properly. The more complex the background, the more exacting the needed re-alignment.

            If a flash was used, or the day was cloudy with variable light, you may also need some brightness adjustments to the photo. The cause is that most cameras 'auto-adjust' the brightness of the images, and a flash, or variable light can change its handling of the 'auto-level' adjustment for each and every image.

            As a final example, here is another image I created from two separate photos, of my nephew fencing with himself, in front of a climbing wall. As I was holding the camera and used a flash, I did need to do some affine distortion adjustments, as well as slight brightness adjustment to get the seamless result you see.
            [IM Output]
            Jacob vs Jacob

            If you were trying to decide if this photo was fake or not, you would look at the lighting, shadows and reflections. In the above, a close examination of the floor will show that the right 'Jacob' does not have a proper reflection on the floor (it was clipped by the photos edge). But you would really need to study the photo well to notice this!

            Now think of the possibilities you can use this 'double exposure' technique for. For example how about some Funny Mirrors. Email me your results!

            If you like to get into this further the research paper "Interactive Digital Photomontage", goes into using "Double Exposures" (or as it terms it "photo montage"), but making use of user selections expanded using "image segmentation", to select what parts of the image is to come from where.

            One example is if you have a number of photos of a large group of people, in each photo someone does not 'look good'. You can use this technique to select which person comes from which image so that you can get a perfect group photo where everyone is: facing front, with eyes open, and smiling!


            Protect Someone's Anonymity -- fuzzing out some part of a photo
            The above technique of using a 3 image composite mask can also be used in other ways. For example you can 'pixelate' and image, then use a mask to limit the effect to just the face of a person, so as to "Protect their Identity".


              convert zelda_tn.gif -scale 25%  -scale 400%  zelda_pixelate.gif
              convert zelda_tn.gif -gamma 0 -fill white \
                      -draw 'circle 65,53 50,40'   zelda_face_mask.gif
              convert zelda_tn.gif zelda_pixelate.gif zelda_face_mask.gif \
                      -composite   zelda_anonymity.png

            [IM Output] ==> [IM Output] [IM Output] ==> [IM Output]

            Of course you can do this all in one go, and even smooth the change from pixelated to normal. For example..


              convert zelda_tn.gif \( +clone -scale 25%  -scale 400% \) \
                      \( +clone -gamma 0 -fill white \
                         -draw 'circle 65,53 50,40' -blur  10x4 \) \
                      -composite  zelda_anonymity.jpg

                [IM Output]

            Of course rather than pixelate the offending part, you can also blur the area instead. Just replace the two "-scale" operators with a single "-blur" to fuzz out the details.

            This technique replacing a masked area can also be used to remove unwanted text and logos from images. For details see Hole Filling.

            Add a Texture to an Image
            The Hardlight alpha compositing method or even any of the various Lighting Composition Methods provide ways to give an image a texture pattern.

            For example here I add a texture of course fabric to a photo I took of a pagoda at the Kunming Zoo, in southern China.


              convert tile_fabric.gif -colorspace gray  -normalize \
                      -fill gray50 +level 35%      texture_fabric.gif
              composite texture_fabric.gif  pagoda_sm.jpg \
                        -tile   -compose Hardlight    photo_texture.jpg

            [IM Output] ==> [IM Output] ==> [IM Output]

            Note that if you want to actually tile the texture over the image you need to use the "composite" command rather than the more versatile "convert" command, though there are a number of other ways to Tile Images in Memory using convert.

            Also note that when adding a texture like this, the smaller details in the original photo can be lost by excess noise of the overlaid texture, textures should ge hept either simple, or their effect appropriatally moderated, such as the Decontrasting Level Adjustment used above.

            To use an image pattern as a texture it should be modified so that a perfect gray color is used for areas that is unchanged in the original image. That is the average color of the image should be about 50% gray. In the example I demonstrate one way that you can do this with just about any tileable image, though this specific method may not always work well.

            Such textures can be found all over the web, as various background patterns for web pages. They may not even look like a texture, be colorful, or even very bright or very dark. After adjustment however you will find that you can get some very interesting effects.

            Just as we did previously, you can limit what parts of an image is actually textured by creating an appropriate mask. For example lets create a mask of just the near 'white' sky in the pagoda photo.


              convert pagoda_sm.jpg -fuzz 10% -transparent white \
                      -alpha extract -negate  pagoda_mask.png
              convert pagoda_sm.jpg  photo_texture.jpg  pagoda_mask.png \
                      -composite  photo_texture_masked.jpg

            [IM Output] ==> [IM Output]

            Now imagine an picture of a lady wearing a dress. You can get any pattern shade it appropriately, and then overlay that on the original image so as to replace the dress with a completely different design.

            Of course there are lots of variations on the above to achieve the final result, and which specific technique you use is up to you, but the basic idea is the same. Texture the image, mask and overlay the result.

            As an aside, I also recommend you look at the Overlay alpha composing method, which is simply the same as Hard_Light composition, but with the two images swapped. There is also a lot of other Shading Composition Methods that can be used to texture an image in various ways.


            [IM Output]
            Chroma Key Masking -- Modifying by areas of specific color
            The photo to the left was given by an user in a IM Forum Discussion. he wanted to change the color of the girls shirt, which was a nice 'pink' color. The problem is the color is not just 'pink' but a whole range of different shades of 'pink'.

            As you have seen above, to make changed to an image, the first step is typically generating an appropriate mask of the area you are interested in. Here I will use a technique known as Chroma Key to generate mask that specific color.

            This technique generally looks for a specific color in an image for use as the mask. It is also the technique used for 'blue' and 'green' screen effects used extensively on TV and in Movies.


             
            This basically involves extracting the 'Hue' by Separating Channel Images, then looking up the 'hue shade' wanted. For example...


              convert shirt.jpg -colorspace HSL -channel Hue -separate shirt_hue.jpg

            However this Hue image has a couple of problems.

                First a 'pink' color is very close to 'red' which is at the division where Hue 'rolls over'. To ensure this is not a problem I use Modulate to adjust the hue away from that 'discontinuity' in the hue.

                This is not a problem for extracting a 'chroma key' for 'green' or 'blue' screens.

                This 'pink' color is also not a highly saturated color, but has a very low saturation value. This means its 'hue' is not as strong as it should be.

                The other problem is the gray background!!!!! Gray is has very little hue, so I need to remove any areas with little to no saturation from my final mask, or I'll be changing things in the background.

                Note that this is technically not needed if I limit changes to hue rolls, which does not effect unsaturated colors.

            In short, the input image would have worked better with a brighter stronger color that was also not as simial to skin (or hair) color. A strong blue or green shirt for example. But I will work with what I was given.

                [IM Output]

            So lest extract and combine the two channel masks. Note that Hue = Gray64 after the image hues was 'rolled' using module, and Saturated = Black for the grey background.


              convert shirt.jpg -modulate 100,100,33.3  -colorspace HSL \
                      -channel Hue,Saturation -separate +channel \
                      \( -clone 0 -background none -fuzz 5% +transparent grey64 \) \
                      \( -clone 1 -background none -fuzz 10% -transparent black \) \
                      -delete 0,1  -alpha extract  -compose multiply -composite \
                      shirt_mask.png

            That just leaves a number of small isolated 'specks' that can be removed with some Morphology Smoothing (-morphology Smooth Square). It isn't perfect but it will do the job. The better way would be to edit the mask by hand to clean it up.

            Now a mask can be used with Composite Masking much like we did with Double Exposures and Anonymity examples above.

            However If you are using a mask to modify an existing image (without distorting, or changing the images size), then it is easier to use it to define what areas are un-writable. These are known as Clip or Write Masks (see "-mask" 	[IM Output]

            Here I cleanup the previous mask of the small defects (optional), and negate it to define what areas I want to 'write protect'. Then I set this mask, shift the hues to turn 'pink' into a 'light blue' color, and save the resulting image.


              convert shirt_mask.png -morphology Smooth Square \
                      -negate   shirt_write_mask.png

              convert shirt.jpg  -mask shirt_write_mask.png \
                      -modulate 100,100,25     +mask shirt_blue.jpg

            Yes there is a slight 'pink' border, especially in the inside sleeve. Also a small area of skin on her arm turned a rather dark blue. Basically these are mask defects, and with a little more work in perfecting the mask you can fix these problems. But it is not bad result.

            One method of generating a better mask is to use a much larger higher resolution image. When the resulting image is later resized these small defects will (hopefully) also be reduced to insignificance.

                [IM Output]

            The real problem with this specific example, is the 'key color' is so close to a normal skin color you are really just asking for trouble! This is why people using this technique use 'green' and 'blue' screens, as those colors are as different as possible from 'skin' color of people in front of the screen.

            Note that you are better off NOT using JPEG as your source or working images. Really JPEG should only be used for your final images only! This is part of the reason why so many 'mask defects' was generated in the first place.

            Green Screen
            Future example, using Chroma Key Masking of a 'green screen background'. Expanded from the wikipedia artical, Chroma Key

            Real problems in 'green screen' handling is the 'color spill', with fine light color hair (blonde) and semi-transparent areas producing the worse color spill effects.

            Simplistic Colorspill removal (color fix)
            g(r,g,b) => (r, min(g, b), b)
            Alpha determination...
            a(r,b,g) => K0 * b − K1 * g + K2
            Using values of 1.0 for all K coefficients is good initial guess.

            As the Background color is well known, and once the 'alpha' is known you can use techniques shown in Background Removal using Two Backgrounds to remove any 'green screen halo' that may be present better that the first color formula.


            Artist Charcoal Sketch of Image
            The Charcoal Sketch Transform, offers users a very simple way of generating a simplified gray-scale rendering of the image.

            It does not work well for 'busy images' but for simpler images it can produce a very striking result.


                 convert holocaust_sm.jpg -charcoal 5 charcoal.gif

            [IM Output] ==> [IM Output]

            Children's Color-In Outline Image
            In a long discussion about Generating Coloring-In Pages on the IM Users Forum, the following cookbook recipe was developed to convert a simple photo into something children can color in.

            Here is the best result we have so far, applied to a photo I took of the holocaust memorial, Berlin.


              convert holocaust_sm.jpg \
                      -edge 1 -negate -normalize \
                      -colorspace Gray -blur 0x.5 -contrast-stretch 0x50% \
                      color-in.gif
              # For heavily shaded pictures...
              #     #-segment 1x1 +dither -colors 2 -edge 1 -negate -normalize \

            [IM Output] ==> [IM Output]

            The final operations in the above attempt to smooth out the lines and improve the overall result.

            Of course the above technique is only useful for images with good sharp color changes, and preferably a higher resolution image than I used above.

            For cartoon images that already have black outlines with a light colored background, the use of Edge Detection with the above method will directly produce a 'twinning' effect of the black outlines. You can see this effect in the twinned lines of tiles on the path leading into the memorial, in the lower-left corner.

            This is an artifact of the way Edge Detection works, and you can see more examples of this in that section of IM Examples.

            The solution is to negate images of this type before using "-edge" to outline the colored areas.


              convert piglet.gif -background white -flatten \
                      -colorspace Gray -negate -edge 1 -negate -normalize \
                      -threshold 50% -despeckle \
                      -blur 0x.5 -contrast-stretch 0x50% \
                      color-in_cartoon.gif

            [IM Output] ==> [IM Output]

            I also "-threshold" so I can then remove individual dots that "-edge" seem to like to generate. After that I again attempt to smooth out the aliased lines in the image.

            The above was added to in a discussion on GIMP Photocopy Filter to make use of the Compose Divide method, to find outlines.


              convert taj_mahal_sm.png -colorspace gray \
                      \( +clone -blur 0x2 \) +swap -compose divide -composite \
                      -linear-stretch 5%x0%   photocopy.png

            [IM Output] ==> [IM Output]

            The "-linear-stretch" operation in the above adjusts how black the dark areas of the images will be, while the "-blur" 'sigma' defines the shading sharpness.

            Pencil Sketch
            Using a Photoshop (PSP) tutorial on converting images to Pencil Sketches, dognose from the IM Users Forum, managed to create the equivalent ImageMagick commands. Here is his conversion, simplified into a few IM commands, allowing you to batch process lots of images into a 'artists pencil sketch' form.

            First we need a special "pencil.gif" image. This can take a long time, so for this example I made it a bit smaller, while preserving its ability to be tiled across larger images. See Modifying Tile Images for details of the techniques.

            This only needs to be done once and can then be re-used. As such you can generate a much larger one for your own use, so as to avoid any tiling effects. Ideally make it as large as the images you plan to convert.


              convert -size 256x256 xc:  +noise Random  -virtual-pixel tile \
                         -motion-blur 0x20+135 -charcoal 1 -resize 50% pencil_tile.gif

                [IM Output]

            Now it is only a matter of overlaying and blending this 'pencil' shading image with a photo. The pencil image is tiled to make a canvas the same size as the image we are processing. Then it is applied to the image using techniques found in Tiled Canvases. This is then merged into a gray-scaled copy of the original image.


                 convert pagoda_sm.jpg -colorspace gray \
                      \( +clone -tile pencil_tile.gif -draw "color 0,0 reset" \
                         +clone +swap -compose color_dodge -composite \) \
                      -fx 'u*.2+v*.8' sketch.gif

            [IM Output] ==> [IM Output]

            Note that as the "-blend" operator of the "composite" command is not available to the "convert" command, I opted to do the equivalent using the DIY "-fx" operator. There are probably better, faster but more complicated ways of doing this. (suggestions are welcome)

            This is not the final version, as the operator misses some edge enhancement aspects needed for outline some of the more lighter but sharp color changes in the image. Can you improve the above?

            The above algorithm was built into IM as an artistic transform "-sketch", though without the "-resize" smoothing for the generated 'pencil tile'...


              convert pagoda_sm.jpg -colorspace gray -sketch 0x20+120 sketch_new.gif

            [IM Output] ==> [IM Output]

            Vignette Removal
            When taking photos (digital or otherwise, the camera lens generally darkens the edges and corners of the image. This is called 'vignetting'. In fact this lens effect is so common, it is often faked on purpose using the "-vignette" operator. See the Vignette Transform.

            Martin Herrmann <Martin-Herrmann@gmx.de> wanted to remove camera vignetting from the photos. Basically he took a photo of a white sheet of paper in a bright light without using a flash. He then wanted to combine this with his actual photos to brighten the edges and corners of the image appropriately.

            Basically what we want to do is divide the original photo by the grey-scale image of the photo of the brightly lit white piece of paper and it will then brighten the parts of the image by the amount that the 'white paper' photo was darkened.

            This is basically the compose method 'Divide' which divides the 'source' image by the 'background' image. For example,


              convert nikon18-70dx_18mm_f3.5.jpg  vegas_orig.jpg \
                      -compose Divide -composite  vegas_fixed.jpg

            [photo] + [photo] ==> [photo]
            (click to see larger photo image)

            However as the photo of the 'white paper' will probably not be a true white, and you probably do not want to brighten the image by this 'off-white' color. To fix this we need to multiply the divisor image by its the center pixel color.

            Here is the final solution provided to Martin, which used the very slow FX DIY Operator. This pre-dated the addition of a Divise Compose Method which can be used to speed up this process enormously.

            The white photo was also grey scaled to remove any color distortion as well, note that I changed the ordering which will also preserve any 'meta-data' that was in the original (as it is the 'destination' image in this case.


              convert vegas_orig.jpg \( nikon18-70dx_18mm_f3.5.jpg -colorspace Gray \) \
                      -fx '(u/v)*v.p{w/2,h/2}'   vegas_fixed_fx.jpg

                [photo]

            If you look carefully at the enlarged photos, particularly the top-left and top-right 'sky' corners, you can see the vignetting effects, and the correction that was made.

            It is not a perfect solution, and could use a little more tweaking. For example rather than using a scaling pixel, we could pre-process the 'white page' image, and also adjust it for a better vignette removal result.

            Note that using JPEG is not recommended for any sort of photographic work, as the format can introduce some artifacts and inconsistencies in the results. The format is only good for storage and display of the final results.

            A major discussion on correcting vignettation is in the IM User Forums in the discussion Algorithmic vignetting correction for pinhole cameras?.

            Things that can effect vignettation include...

                Distance of film from lens, further away means more light spread.
                Area of the aperture 'circle' (lens or pinhole) due to angle of light.
                Arrangement of camera material around the aperture. For example the lens holder or pinhole thickness. 
https://legacy.imagemagick.org/Usage/lens/
            When taking photographs, the images generated are actually distorted by both lens effects and spherical perspective effects. If you plane to use photos you will generally need to correct for these effects, and that is what will be looked at in this section.

            The majority of this page was contributed by Wolfgang Hugemann.

            Introduction to Lens Correction
            Fisheye lenses and low-cost wide-angle lenses (or rather zoom lenses when set to short focal length) typically produce a pronounced barrel distortion. This distortion can however be mostly corrected by applying suitable algorithmic transformations to the digital photograph. One of the most-used lens correction algorithms, introduced by Panorama Tools and used by PTlens, is also offered by ImageMagick, as Barrel Correction Distortion Method.

            In this approach to the problem, the distortion is controlled by four transformation parameters a, b, c, d, which have to be chosen sensibly in order to correct the distortion produced by a specific lens (or rather a zoom camera when set to a certain focal length). Suitable values for these parameters can hardly be found by trial and error. In the following, we describe how to determine the lens correction parameters of this model effectively by the use of Hugin, a free graphical user interface for Panorama Tools, which is available for various operating systems.

            If you don't want to deal with the details of lens correction, you may skip the rest of this page and just buy PTlens, which offers sophisticated lens correction for a vast number of digital cameras and lenses at a reasonable price (by use of its large lens database). Nowadays, some digital cameras (such as the Nikon P7000) even incorporate lens correction in their internal image processing steps. For photographs taken with cameras that don't offer this possibility, ImageMagick enables you to integrate lens correction as one step of a larger image processing script.

            The following text is an abridged version of paper Correcting Lens Distortion (PDF) (dealing with applications in accident reconstruction). The explanations given here are a more hands-on approach, concentrating on the ways to get in hold of the adequate lens correction parameters.

            Non-scaling Restraint
            As described in the Barrel Distortions The barrel distortion is defined by the mathematical formula

              R = ( a * r^3  +  b * r^2  +  c * r  +  d ) * r

            with r as the distance to the geometrical image center of the digital photograph and R as the equivalent radius in the original image. As always with such mappings, the equation above defines a kind of "color look-up function", i.e. where to look for the color of the pixel at radius r. The radii r and R are normalised by half of the smaller image dimension (i.e. usually the height of the image), such that r = R = 1 for the midpoints of the upper and lower edge of the image. When correcting digital photographs, we should pay attention to the non-scaling restraint

              a + b + c + d = 1

            which obviously gives R = 1 for r = 1. Panorama Tools calculates the parameter d by the other parameters via

              d = 1 - a - b - c

            leaving us with three free model parameters, so the parameter d is typically omitted. ImageMagick will automatically calculate d by the non-scaling restraint, if it is omitted. So a typical ImageMagick command line for lens correction would look something like

              convert input.jpg -distort barrel '0.06335 -0.18432 -0.13008' output.jpg

            leaving the calculation of d to ImageMagick. The lens correction method of Panorama Tools that we are speaking of here assumes the optical axis of the lens and the centre of the image to be identical, which is not strictly the case in practice (due to manufacturing tolerances). Furthermore, it leaves effects like mustache distortion aside. Nevertheless, it seems to work astonishingly precisely in practice. [Graph]

            As demonstrated by the curve (a = 0.05, b = -0.25, c = 0.05), the relationship is typically used in the range 0 to 1.5 (aspect ratio 3:2), passes through the points (0,0) and (1,1) and must be degressive for r > 1.


            Ready-made Parameter Sets
            PTlens's current lens database, being the "marrow" of the program, is encrypted and can only be read by PTlens itself. Until February 2006, however, PTlens's database was coded in XML format, i.e. an easily editable text format. This 2006 version of PTlens's XML database is still (legally) available at Hugin's SourceForge Website and provides data for a lot of older camera models.

            When PTlens's database became encrypted, the authors of Hugin tried to establish a free XML coded lens database as an alternative. This database is called LensFun and can be downloaded. It comes with a complete programming interface, but all you basically need is the information for your camera in the XML file. As an example, the lens correction parameters for the once popular Nikon Coolpix 995 are found in the file compact-nikon.xml, which resides in the directory \data\db. The file can be examined by the use of a text editor or an XML viewer:


              <lens>
                <maker>Nikon</maker>
                <model>Standard</model>
                <mount>nikon995</mount>
                <cropfactor>4.843</cropfactor>
                <calibration>
                  <distortion model="ptlens" focal="8.2" a="0" b="-0.019966" c="0" />
                  <distortion model="ptlens" focal="10.1" a="0" b="-0.010931" c="0" />
                  <distortion model="ptlens" focal="13.6" a="0" b="-0.002049" c="0" />
                  <distortion model="ptlens" focal="18.4" a="0" b="0.003845" c="0" />
                  <distortion model="ptlens" focal="23.4" a="0" b="0.006884" c="0" />
                  <distortion model="ptlens" focal="28.3" a="0" b="0.008666" c="0" />
                  <distortion model="ptlens" focal="31" a="0" b="0.009298" c="0" />
                </calibration>
              </lens>

            As can be taken from the camera's technical data sheet, the zoom range of the Nikon Coolpix 995 is 8.2 – 31.0 mm, corresponding to 38 – 152 mm for 35 mm film cameras. This gives a crop factor of 152 / 31 = 4.90, which roughly corresponds to the 4.843 given the XML file. The coefficients of the correction by barrel distortion are supplied for six focal lengths, namely 8.2 mm, 10.1 mm, 13.6 mm, 18.4 mm, 23.4 mm, 28.3 mm and 31.0 mm. The coefficients a and c are, for this lens, set to zero, i.e. the distortion is described only by the second-order term b.

            Note that many lens's will also have values for a and c parameters as well, and these should also be interpolated in a similar way.

            If we have a photograph DSCN0001.jpg taken with a Nikon Coolpix 995 set to the shortest focal length, this photograph could be corrected by ImageMagick via


               convert DSCN0001.jpg -distort barrel '0.0 -0.019966 0.0' DSCN0001_pt.jpg

            (The file name extension _pt is used by PTlens to mark corrected images.)

            For the six focal lengths provided, the correction coefficient b can be read from the XML file. For other focal lengths, the suitable value can be determined by interpolation between the two neighbouring focal lengths. As an alternative, the dependency of b on the focal length f can be approximated by the polynomial

              b = 0.000005142 * f^3 - 0.000380839 * f^2 + 0.009606325 * f - 0.075316854

            So the focal length (as read from the EXIF information) is used to calculate the lens correction parameter b in the first step, and then, in a second step, the lens correction (i.e. barrel distortion) is performed using this value as the b parameter.

            The Windows section shows a VBScript Example in which the above equations are used, with the focal length being extracted from a Nikon Coolpix 995 photograph via identify.

            Calibrating from scratch
            Basic Approach
            When determining the lens parameters, all programs rely on the same paradigm: the ideal perspective mapping should map real world straight lines to straight lines in the image. So if a set of real-world points P0, P1, ..., Pn is known to lie on a straight line, their images p0, p1, ..., pn must also fall onto a straight line. Any deviation from this rule has to be attributed to lens distortion.

            We need two points to determine the two parameters defining a straight line (e.g. slope and intersection on the y-axis). Each additional point supplied will provide another equation to determine the lens correction parameters. So if our functional approach has only one free parameter b (as for the Nikon Coolpix 995 above), we would have to provide at least three points on a real-world straight line and its image in order to determine the sought lens correction parameter b.

            Putting it more concrete: The distortions model only uses the parameter b, i.e. the coordinates of the corrected image X1, Y1 can be calculated from the coordinates of the digital photograph by

            r = s * sqrt(x1^2 + y1^2)
            X1 = [(1-b) + b r^2] * x1
            Y1 = [(1-b) + b r^2] * y1
            Y1 = k1 * X1 + k2

            This results in one equation for each point supplied on the same straight line

            [(1-b) + b r^2] * y1 = k1 * [(1-b) + b r^2] * x1 + k2

            with: r = s * sqrt(x1^2 + y1^2)

            Thus three real-world points and their corresponding image points would suffice to determine the parameters describing the straight line and the lens distortion k1, k2, b.

            In practice, the coordinates of the real-world points are rarely known, such that one needs more than just three points to determine the sought parameters. Most calibration software uses a rectangular grid of straight lines (often a chequerboard) to generate a set of equations and then calculate the mapping parameters by a nonlinear least-squares fit. Some programs generate the set of control points on their own, often using pre-defined templates; other programs require the user to select the control points from the calibration image.

            Determining lens parameter sets with Hugin
            In the following, we will demonstrate how to determine a set of lens correction parameters by the use of Hugin. There is also a ready-made "Simple Lens Calibration Tutorial" on Hugin's Website, but at the time of this writing (2014), it seems to be too simple to provide reliable parameters that can later be used for a multitude of corrections.

            First of all, you have to get hold of a suitable test pattern. Basically, a checkerboard pattern with about 10 × 7 squares, printed on ISO 216 A3 or alike would do and is often used. Low-cost zoom lenses (so-called varifocal lenses) should however be set to infinite focus during calibration, as their true focal length might largely differ from that embedded in the EXIF for near focus.

            For fixed focus lenses you may as well use a checkerboard test pattern, which is especially recommendable when calibrating a fisheye lens, as it may be difficult to find a real-word object large enough to cover its field of view.

            So especially when calibrating zoom lenses / zoom cameras, you should rather take a photograph of a modern building, as proposed on PTlens' website. Follow the instructions given there. The photographs may show perspective distortion:
            [IM Output]
            perspective 	[IM Output]
            non-perspective

            Start Hugin, and click the 'Add images ...' button on the first tab and open the calibration image. (See hugin.sourceforge.net for a screenshot of Hugin's interface.) At the button of the tab set 'Optimise' to 'Custom parameters' (which will add a new tab named 'Optimiser', you would otherwise not come to see). On the 'Stitcher' tab, set the 'Projection' to 'Rectilinear'. On the 'Control Points' tab, you see your test photograph twice and you can define sets of points that lie on the same straight line by picking these point groups in both versions of the photograph.

            But do not pick the exact same points in both versions, such that the points are identical in both images, as this would mislead the optimiser to take the easy way and determine the parameters of an one-to-one correspondence. Instead, you should rather choose different points on the same line in both versions of the image. For test purposes, you can define a few of such point sets, at best near the edges of the image, where the straight lines are more distorted. You will find that definining such point sets in Hugin is a rather tedious business (which may be one of the reasons for the lensfun database being so small).
            Then switch to the 'Optimiser' tab and chose the parameters to optimise by left-clicking them with the ctrl-key pressed. (See hint at the top of the tab.) I would recommend to optimise 'Yaw(y)', 'Pitch (p)' and the lens parameters 'a', 'b' and 'c'. The horizontal field of view 'Hfov (f)' is calculated from the EXIF data in the test image, by use of the FocalLengthIn35mmFilm entry f:

             Hfov = 2 × arctan (18 mm / f) 

            with 18 mm being half of the width of a 35 mm negative (which measures 36 × 24 mm).

            Then press the button 'Optimize now!'. The resulting parameters 'a', 'b' and 'c' should fall below 0.01 for wide angle lenses and below 0.1 for fisheye lenses. If the values are larger, the optimisation has probably failed. If so, check the point sets on the 'Control Points' tab: the control points are probably out of order or not correctly associated with their corresponding lines.

            The optimiser also seems to be sensitive to the start set (mathematically speaking: the start vector) provided, i.e. setting all parameters to zero might be the wrong choice. You can edit the start vector by either double-clicking the values on the 'Optimiser' tab or by activating the check box 'Edit script before optimising' at the right buttom of tab page. This will bring up a text box prior to the optimisation, which will allow you to edit the corresponding section of the Hugin project file. Set the start vector a, b, c back to a0.0 b0.0 c0.0 (or some other suitable values) before re-starting the optimiser. Experience shows that it might help to set 'a' to some positive value, especially for fisheye lenses.

            For a camera equipped with a fixed lens, one does this calibration once and for all. For a camera with a zoom lens, one has to cover the entire range of focal lengths by calibrating at about five different focal lengths.

            When having determined such a parameter set, give it a test in ImageMagick via



              convert calibration_image.jpg -distort barrel 'a b c' flat.jpg



            replacing the values a b c with the ones just determined. The lines in the output image should be exactly straight, otherwise the optimisation has failed and needs to be performed with a deviating start vector or a corrected control point set.

            Defining point sets
            For a serious calibration, it is recommendable to manually edit the Hugin project file and define the point coordinates and point sets by other means. The project file is a plain text file with the extension PTO, you can open it with a simple text editor and supply a point list. A single line in its section # control points looks like this:

              c n0 N0 x175.0 y87.8 X1533.3 Y62.6 t3

            where x, y are the pixel coordinates in the source image (left image on the tab) and X, Y are the pixel coordinates in the target image (right image on the tab) – which are actually two versions of the same image in this special case. (Usually these would be two different images lying next to each other in a panorama.) The intro c n0 N0 is standard code and the trailer t3 is the numbering of the associated straight line, starting with the index 3. As you can take from the above example, the pixel coordinates may have fractional parts.

            Of course, x, y and X, Y have to lie on the same straight line. They must however not be identical, as the optimiser would refuse to work in this case (see above). The easiest approach to garantuee this, is to use the same points in both images but with reverse ordering for the target coordinates,e.g. use p1, p2, p3, p4 in the left image and P4, P3, P2, P1 in the right one.

            Determine the pixel coordinates in the source image by a point-picking tool. You can use any image viewer to do this, namely one that can store such data. A platform-independent tool for this would be Fiji. I (working under Windows) used polylines in WinMorph to do so.

            You should follow a pre-defined strategy when picking the points, e.g. pick the same count of points on each (more or less) horizontal line, going from left to right (i.e. follow a zig-zag line in the entire image, like the cathode ray beem in a tv tube). Such a strategy will simplify the ordering the target point coordinates. The text file lines defining source and target point coordinates can then be established either manually or by means of a software tool. (I use an Excel VBA subroutine to perform this task.) When ready, copy the point list to the corresponding section of the PTO file, save it and re-open it with Hugin. The result should look like this:

            [IM Output]
            Control point grid in Hugin

            A ready-made example, both with a calibration image and the corresponding Hugin project is provided in the ZIP file olympus_c2500l.zip.

            Re-engineering from camera created thumbnail
            There are several cases where we already have an image pair, one being barrel distorted, the other one being already corrected. This correction may have been performed with some other lens-correction software, which doesn't tell us about the correction parameters.

            Furthermore, a lot of contemporary cameras (2019) offer to perform the lens correction internally for JPEG images. However, this functionality is usually not applied to RAW images. (Well, it's raw.) Nevertheless, the RAW image contains a JPEG preview to which the correction has already been applied by the camera. ImageMagick can read RAW images by the use of dcraw. Thus one may convert the raw image to JPEG without lens correction and compare the result to the internally corrected JPEG thumbnail.

            In case of such an image pair, the correction parameters can be calculated straightforward. By picking corresponding point pairs in both images, we can directly establish the relationship between r and R.

            [RAW Image]
            Raw Image (barrel distorted) 	[Corrected Image]
            Corrected Thumbnail (to re-engineer)

            As shown in the above example, we are free of choice which point pairs to choose; these neither have to follow straight lines nor even have to lie on geometrical patterns. We just have to fill a table with corresponding values of r and R and then calculate a regression curve, for example by means of a spreadsheet diagram.

            [Calabration]
            Calibration Points 	[Regression]
            Regression (scaled)

            Hence the ImageMagick command line is


              convert barrel.jpg -distort barrel '0.0099 -0.0678 0.0014 1.0511' flat.jpg

            You can also apply the same command directly to the DNG camera format image "barrel.dng" directly too.

            Examples of Lens Correction
            Camp Mobile
            [IM Output]
            Original 	[IM Output]
            Corrected 	[IM Output]
            Difference

            The original photograph of the campmobile to the left had to be taken from a rather short distance during dusk, as space was limited due to a steep declivity at the back of the photographer. (The poor lighting conditions explain the blue tint which stems from severe lightening in the post-processing.) The original photograph shows pronounced barrel distortion, visible especially in the horizontal stripe near the top of the image and for the back corner of the build-up. The Nikon Coolpix 995 used for this shot is found in PTlens's database, so the distortion could readily be corrected, as seen in the middle.

            The image to the right shows the difference between greyscale versions the two photographs, calculated by subtraction of the two, followed by negation and extreme clipping and Gamma correction. Again, the effects of the correction are best illustrated by the horizontal stripe at the top. The white circle (indicating zero difference) results from the non-scaling restriction: the points on a circle with a diameter equal to the smaller dimension of the image remain unaltered.

            GoPro flattening
            The GoPro camera lens produces a pronounced barrel distortion, which seems to be part of its branding. For instance, the GoPro Hero 3+ silver edition has a fisheye lens with a fixed focal length of 2.77 mm, corresponding to a focal length of 16 mm in 35 mm film, if the entire photosensitive area is used. The GoPro Hero 3+ has three photo modes:

                10 megapixel = 3680 × 2760 pixel wide angle (16 mm in 35 mm film)
                7 megapixel = 3072 × 2304 pixel wide angle (16 mm in 35 mm film)
                5 megapixel = 2624 × 1968 pixel medium angle (23 mm in 35 mm film) 

            The GoPro Hero 3+ is equipped with a 1/2.3" sensor, which has a crop factor of 5.64. (Which gives a focal length of only 15.62 mm in 35 mm film, the 16 mm provided by the EXIF information probably being due to rounding.) The first two modes seem to use the entire photosensitive area; the reduced resolution obviously being achieved by sub-sampling. The distortion parameters are therefore the same, as can be proven in practice. The 5-megapixel mode obviously uses only part of the photosensitive area, as 3680 / 2624 × 16 ≈ 23. The lens parameters can be determined to

                wide angle:
                    a = 0.06335
                    b = -0.18432
                    c = -0.13009 
                medium angle:
                    a = 0.01359
                    b = -0.06034
                    c = -0.10618 

            In theory, the parameters of the second mode can be derived from the first, as the radii ri and Ri are coupled by the scale factor κ = 3680 / 2624 = 1.402, which leads to:

                a2 = a1 / κ³
                b2 = b1 / κ²
                c2 = c1 / κ 

            The above parameters, resulting from an independent optimisation, differ not much from these theoretical values.

            Correspondingly, the parameters for the various video modes can be derived either by optimisation or from the part of the sensor area that is used by this mode. For video, the horizontal field of view cannot be derived from the EXIF data. It can be calculated from the photosensitive area used, determined from the video itself (by taking footage under controlled conditions) or just estimated together with the other parameters, i.e. left as a free parameter in the optimisation.

            The parameters for HD video (1920 × 1080) are:

                a = 0.030530
                b = -0.124312
                c = -0.038543 

            These parameters can be used for a frame-wise correction with ImageMagick. As an alternative, they can be used to "flatten" the entire video by the AVIsynth plugin DeBarrel, which also uses the Panorama Tools lens correction model.
            Two Keyboards by el_supremo
            The photo that I took of my two keyboards has a very obvious barrel distortion in it, because it was taken at a focal length of 17 mm.

            [IM Output]

            This kind of distortion can be corrected with, for example, Canon's Digital Photo Professional (I have a Canon 50D camera). Other manufacturers of SLR cameras usually provide software to do this kind of correction for their lenses but I wanted to see how well the above examples would work on this photo.

            The first step is to go to the LensFun WebSite and download the latest version of their camera database.

            Unzip the package (winzip can unzip a .tar.gz file in Windows) and then in the "lensfun/data/db" directory look for the file which corresponds to your camera manufacturer. In my case I looked at "slr-canon.xml" which can be edited with any text editor.

            Now I find the information for the specific lens I am using which in this case is an "EF-S 17-85mm". The information for that lens looks like this:

            <lens>
              <maker>Canon</maker>
              <model>Canon EF-S 17-85mm f/4-5.6 IS USM</model>
              <mount>Canon EF-S</mount>
              <cropfactor>1.6</cropfactor>
              <calibration>
                <distortion model="ptlens" focal="17" a="0.021181" b="-0.055581" c="0" />
                <distortion model="ptlens" focal="20" a="0.019344" b="-0.043786" c="0" />
                <distortion model="ptlens" focal="22" a="0.015491" b="-0.026682" c="0" />
                <distortion model="ptlens" focal="28" a="0.008084" b="-0.007472" c="0" />
                <distortion model="ptlens" focal="30" a="0.005522" b="-0.001763" c="0" />
                <distortion model="ptlens" focal="35" a="0.003149" b="0.002207" c="0" />
                <distortion model="ptlens" focal="44" a="0" b="0.008269" c="0" />
                <distortion model="ptlens" focal="53" a="0" b="0.008792" c="0" />
                <distortion model="ptlens" focal="61" a="0" b="0.00738" c="0" />
                <distortion model="ptlens" focal="72" a="0" b="0.006226" c="0" />
                <distortion model="ptlens" focal="78" a="0" b="0.007095" c="0" />
                <distortion model="ptlens" focal="85" a="0" b="0.007288" c="0" />
              </calibration>
            </lens>

            The calibration entries give distortion values for a range of focal lengths from 17mm up to 85mm. If the focal length I needed was between two of those values, I could either choose whichever was closest or I could interpolate the values. Since the photo I'm correcting was taken at 17mm I need the information from the first line of the calibration information. That gives me the values:  a="0.021181"  b="-0.055581"  c="0"

            These are the three parameters which are used to correct the lens distortion.

            However for some older versions of IM, The barrel distortion correction requires a fourth parameter d. Fortunately, it is easy to calculate the value of d from the other three using this simple formula:  d = 1-a-b-c  That means:  d="1.0344".

                IM will work out the value of 'd' automatically, of it is not provided as a distortion argument, but some older versions of IM did not do this.

            That makes the actual Barrel Distortion, to correct the lens distortion...


                convert keyboards.jpg \
                      -distort barrel "0.021181 -0.055581 0" \
                      keyboards_ptlens.jpg

            [IM Output]

                Of course you should not save to JPEG until you have finished processing your image completely, due to the JPEG lossy compression.

            In the original photo the distortion is particularly obvious along the bottom of the music stand and along the upper keyboard. These distortions are almost completely gone in the output photo. A visual comparison of this result with that obtained from Canon's software shows essentially the same result.

            El-Supremo
https://legacy.imagemagick.org/Usage/montage/
            The original use of "montage" is to generate tables of image thumbnails, that is, to reference thumbnails of large collections of images, especially photos. And while it still can be used for that purpose, it can also do a lot more. This page examines what you can do with montage, and how you can use it on your own images.

            Montage, Introduction
            The "montage" command is designed to produce an array of thumbnail images. Sort of like a proof sheet of a large collection of images.

            The default "montage" with no options is very plain, with quite large containment squares, no frame, labels, or shadows.


              montage balloon.gif medical.gif present.gif shading.gif  montage.jpg

            [IM Output]

            Geometry - Tile Size and Image Resizing
            The "-geometry" setting, is the most important control of "montage". It defines the size of the individual thumbnail images, and the spacing between them.

            The size part of the geometry is used as an argument to the Resize Operator, including all its special purpose flags. The position part of the option is interpreted as the amount of border space to leave around the image, so making this smaller, will make the gaps between the images smaller.

            The default "-geometry" setting is '120x120>+4+3' which means to fit any image given into a box 120x120 pixel in size. If the image is larger shrink it, but don't resize smaller images (as per the Only Shrink Larger ('>') Flag. The 'tile' size is then set to the largest dimentions of all the resized images, and the size actually specified. That means you will never get a tile size that is smaller than the specified "-geometry" size.

            You can remove huge size of the tiles in the previous example space by modifing the "-geometry" default. For example by removing the 'size' component, none of the images will be resized, and the 'tile' size will be set to the largest dimensions of all the images given. For example here I ask montage to tile using the largest image given with a small gap between tiles. This is a very typical setting to use when all the input images are small and roughly same size.


              montage balloon.gif medical.gif present.gif shading.gif \
                      -geometry +2+2   montage_geom.jpg

            [IM Output]

            For example, here I replaced one image with a larger 'logo' image, but set a the resize setting to '48x48' to resize both smaller and larger images.


              montage balloon.gif medical.gif present.gif logo: \
                      -geometry 48x48+2+2   montage_geom_size.jpg

            [IM Output]

            And here I again restrict the resize to just images larger than the specified tile size.


              montage balloon.gif medical.gif present.gif logo: \
                      -geometry 48x48\>+2+2   montage_geom_larger.jpg

            [IM Output]

            As you can see the spacing between images appears to be larger than the requested 2 pixel spacing. But that is not the case. The tiles are still separated by 2 pixels, but the images themselves do not fill the 48x48 tile size requested. The 'logo' image was still resized to fit into the 48x48 pixel tile.

            If you don't want any resizing, then only define the spacing between the tiles.

            Alternatively, use a special size such as '1x1<' which tells IM to only resize smaller images to the given size. As no image can be smaller that 1 pixel, no image will be resized. The tile size will thus be again the largest dimention of all the images on the page. See Zero Geometry, caution required for reasons why you may like to do this.

            Geometry - Tile Spacing
            The positional part of the "-geometry" setting, will add space between the individual 'tiles', by adding a Border of those dimensions around the tiles before Appending them together.

            That means for the default "-geometry" setting, of '+4+3', the tiles will be spaced from the left and right edges of the final image by 4 pixels, and will have a 8 pixel (twice the size given) spacing horizontally between the tiles. The same goes for the vertical spacing.

            Note how the space bewteen the tiles when all the images were resized (second last example) is twice the size of the space around the edges.

            Tile Layout Controls
            The next most important option in "montage" is the "-tile" setting. This tells montage what limits you want on how the tiled images are to be laid out on the final result.

            In ImageMagick version 6 "montage" will make an educated guess as to how best to tile a given number of images, when you provide no "-tile" hints. It does however assume that the images being tiled are roughly squarish in nature, as it does not look at the images aspect ratios, when deciding on the tiling to use.


              montage font_1.gif      -geometry 16x16+1+1  tile_1.gif
              montage font_[12].gif   -geometry 16x16+1+1  tile_2.gif
              montage font_[123].gif  -geometry 16x16+1+1  tile_3.gif
              montage font_[1-4].gif  -geometry 16x16+1+1  tile_4.gif
              montage font_[1-5].gif  -geometry 16x16+1+1  tile_5.gif
              montage font_[1-6].gif  -geometry 16x16+1+1  tile_6.gif
              montage font_[1-7].gif  -geometry 16x16+1+1  tile_7.gif
              montage font_[1-8].gif  -geometry 16x16+1+1  tile_8.gif
              montage font_[1-9].gif  -geometry 16x16+1+1  tile_9.gif
              montage font_[0-9].gif  -geometry 16x16+1+1  tile_0.gif

            [IM Output] [IM Output] [IM Output] [IM Output] [IM Output] [IM Output] [IM Output] [IM Output] [IM Output] [IM Output]

                The strange "[1-5]" syntax is an UNIX shell shorthand, which is expanded into a list of filenames. The "montage" command itself does not see these characters, just the resulting list of files.

            ImageMagick is pretty good at figuring out the right "-tile" setting to use for a specific number of input images. Here is a table of number of input images and the tile setting IM will used to layout those images.
            Num Images	Tile Setting
            1 	1x1
            2 	2x1
            3 	3x1
            4 	2x2
            5 - 6 	3x2
            7 - 8 	4x2
                    
            Num Images	Tile Setting
            9 	3x3
            10 - 12 	4x3
            13 - 15 	5x3
            16 - 20 	5x4
            21 - 24 	6x4
            25 	5x5
                    
            Num Images	Tile Setting
            26 - 30 	6x5
            31 - 36 	7x5
            31 - 35 	7x5
            36 	6x6
            37 - 42 	7x6
            43 - 48 	8x6

            Note however that IM will not automatically select a 'perfect fit' 6x3 tile setting for 18 images, nor a 7x4 setting for 28 images.

            However if you specify a specific "-tile" setting, montage will always create an image big enough to hold that many 'tiles'.


              montage font_[1-7].gif  -tile 9x1  -geometry 16x16+1+1  tile_9x1.gif
              montage font_[1-7].gif  -tile 4x3  -geometry 16x16+1+1  tile_4x3.gif
              montage font_[1-7].gif  -tile 3x3  -geometry 16x16+1+1  tile_3x3.gif
              montage font_1.gif      -tile 2x3  -geometry 16x16+1+1  tile_2x3.gif

            [IM Output] [IM Output] [IM Output] [IM Output]

            As you can see montage created an image that is large enough to hold the number of tiles specified, regardless of how many images are available to fill the tile space requested, be it 7 images, or just 1 image.

            It will only fill the space row by row, no option is currently provided to do a column-by-column fill of the tile space.

                Before IM v6.1 montage would automatically truncate the extra space if the number of images did not use that space. As such a setting such as the first "9x1" image would have been truncated to produce a "7x1" tile image.

            Because of this, past users of montage often used large numbers such as "999x1" to generate a single row of images. Now such a argument will produce a very long image, and could take a long time for IM to complete. As such...
            Avoid the use of very large tile numbers in IM montage!

            You can avoid the problems of extra space, and multiple images, especially for an unknown number of input images, by removing either a row, or the column number, from the "-tile" setting. The missing number will be taken by montage as being variable and montage will only create enough tile space to hold ALL the input images, producing only one image, never multiple images.


              montage font_[1-7].gif  -tile x1  -geometry 16x16+1+1  tile_x1.gif
              montage font_[1-7].gif  -tile x2  -geometry 16x16+1+1  tile_x2.gif
              montage font_[1-7].gif  -tile x4  -geometry 16x16+1+1  tile_x4.gif
              montage font_[1-7].gif  -tile 4x  -geometry 16x16+1+1  tile_4x.gif
              montage font_[1-7].gif  -tile 5x  -geometry 16x16+1+1  tile_5x.gif
              montage font_[1-7].gif  -tile 9x  -geometry 16x16+1+1  tile_9x.gif

            [IM Output] [IM Output] [IM Output] [IM Output] [IM Output] [IM Output]

            This is the more typical use of the "-tile" setting, as it ensures the montage is sized correctly, while still allowing it some control in determining the final array size.

            Note the last image, in the above where we requested 9 columns of images. IM still generated the requested 9 columns, even though less than 9 images were given. On the other hand the first image (one row requested), is exactly the right length to hold all the images.

            If you have more input images than montage can tile into the space given by a "-tile" setting, then multiple images can be generated by montage, either resulting in image sequence numbers being added to the filename, or some sort of GIF animation, being created. See Writing Multiple Images for details.

            For example, here I have asked montage to save separate images for each page generated, by supplying a '%d' for the frame/scene/page number of each image filename.


              montage  font_*.gif  -tile 4x1  -geometry +2+2  multi_%d.gif

            [IM Output] [IM Output] [IM Output]

            Frame Decoration
            The best part of using montage to arrange images is that it provides a lot of extra controls to add extra 'fluff' around each image.

            For example, you can better define the images being displayed by adding a "-frame" around each image.


              montage balloon.gif medical.gif present.gif shading.gif \
                      -tile x1  -frame 5  -geometry +5+5   frame.jpg

            [IM Output]

            This is not like the same option in "convert" (See Adding a 3D frame example). The montage frame option will automatically figure out default values for the internal and external bevel of the frame. As such only a single argument number is needed.

            Border Decoration
            Sometime around IM v6.1.0, "-border" became a new decorative option of montage. It now adds extra 'padding' around each image, after it has been resized according ot the "-geometry" setting.


              montage balloon.gif medical.gif present.gif shading.gif \
                      -tile x1  -border 5 -geometry +5+5   border.jpg

            [IM Output]

                The "-border" decoration does not currently work when the Frame Decoration is also applied.

                Before IM v6.1.0 (approx) -border would been applied to images at the point in which it appeared in the "montage" command line, just like it would have with "convert".

            That is border would have been thus added to the image long before the images get resized (according to "-geometry"), which resulted in different border widths around each image depending on the size of the image at that point. It was to remove this inconsistancy that -border became a special montage setting.

            Shadow Decoration
            Adding a shadow with the frame is also quite good.


              montage balloon.gif medical.gif present.gif shading.gif \
                      -tile x1  -frame 5  -shadow  -geometry +5+5   frame_shadow.jpg

            [IM Output]

            Of course you don't actually need a frame to generate image shadows


              montage balloon.gif medical.gif present.gif shading.gif \
                      -tile x1  -shadow  -geometry +5+5  -background lightblue \
                      shadow_noframe.jpg

            [IM Output]

            As of IM v6.3.1 when 'soft shadows' were implemented, the shadows will now be shaped according to the transparency of the images being displayed!


              montage font_1.gif  font_7.gif  font_2.gif  font_0.gif \
                      -tile x1  -shadow  -geometry +3+5 -background none \
                      shadow_shaped.png

                [IM Output]

            As you can see the shadow used by montage is actually a semi-transparent color, allowing the background to affect its final color. This means if you create a montage with textured background, or use a transparent background and overlay it, the shadow will do the right thing.

            Of course you need to use an image format that can handle semi-transparent colors, like PNG. Remember because of GIF Boolean Transparency you can not use GIF image file format for this purpose.

            Note that shadows do not care about the "-geometry" spacing between the images. As such if the images are too close together, the shadow of previous images can be obscured by later images. For example...


              montage balloon.gif medical.gif present.gif shading.gif \
                      -tile x1  -shadow  -geometry +1+1  -background none \
                      shadow_spacing.png

            [IM Output]

            It is thus recommended at a reasonable amount of "-geometry" spacing be provided when using shadow.

            To avoid 'edge clipping' shadows to much, the "-shadow" option will add 4 extra edge spacing pixels the right and bottom edges of the final image. This is on top of the normal "-geometry" spacing provided. However as you can see above, this is not always enough space.

            Montage currently also provides no controls for the offset, color or the 'softness' of the generated shadow (at least not yet), but then, you didn't have such control with hard rectangular shadow that was provided by older versions of montage.

            Labeling Montage Images
            You can also tell montage to label the image with their source filenames, though you probably need to resize the image frames, or the labels may not fit, truncating the text label.

            In this case we added a "60x60>" to the geometry string, which tells IM to shrink larger images to fit into this space, but not to enlarge images if they are smaller.

            This is probably the most typical use of montage.


              montage -label '%f'  balloon.gif medical.gif rose: present.gif shading.gif \
                      -tile x1  -frame 5  -geometry '60x60+4+4>'  label_fname.jpg

            [IM Output]
            The '%f' is a special format character, which can pull out various details about the images in memory. See Image Property Escapes for details of other information you can extract from images.

            You don't have to use a "-frame" when labeling thumbnails. The labels are not shadowed, so that they remain clearly readable.


              montage -label '%f'  balloon.gif medical.gif logo: present.gif shading.gif \
                      -tile x1 -shadow -geometry '60x60+2+2>'  label_shadow.jpg

            [IM Output]

            And as of IM v 6.2.1 you can now re-label images after they have been read in using the "-set" image attribute operator.

            Lets use the "-set" operator to add more information about the images. And also few more montage settings...


              montage balloon.gif medical.gif logo: present.gif shading.gif \
                      -tile x1  -geometry '90x32+2+2>'  -pointsize 10 \
                      -set label '%f\n%wx%h'   -background SkyBlue   label_fname3.jpg

            [IM Output]

            As we showed in the examples above you can use the "-label" setting to define the default label for an image, as they are read in, or you can re-label the image afterward using the "-set" operator.

                Note that '%wx%h gives the current pixel width and height of the image as it is in memory. If the image size was modified, such as during input this may be different to the images in disk (or creation) size. Use '%[width]x%[height]' instead if you want its in memory pixel size.

            You can also label images differently by setting label of individual images. Either option can be used, though you will need to use of parenthesis to limit what images the "-set" operator will be applied to.

            Here for example we use both forms of labeling. But lets also add a title to the montage, just because we can...


              montage -label Balloon   balloon.gif  \
                      -label Medical   medical.gif  \
                      \( present.gif  -set label Present  \) \
                      \( shading.gif  -set label Shading  \) \
                      -tile x1  -frame 5  -geometry '60x60+2+2>' \
                      -title 'My Images'     titled.jpg

            [IM Output]

            You can turn off image labeling for the next image(s) by using a "-label '' " or "+label". However as you will see later these two settings are not quite the same. The same applies for a post reading, label "-set" operation.


              montage                    balloon.gif \
                      -label 'My Image'  medical.gif \
                      +label             present.gif \
                      -label ' '         shading.gif \
                      -tile x1  -frame 5  -geometry '60x60+2+2>'   labeling.jpg

            [IM Output]

            The last image shows how using a space for an image label, you can create a image label space, but leave it blank.

            This presents a good rule of thumb when using montage...

            Either label all your images, or none of them!

            You don't have to label your images during the montage operation itself. Both the MIFF and PNG formats, can store a label as part of their image format.

            Montage will automatically label any image read in that already contains a label. This is automatic and does not need to be specified, and I have used this technique to generate some very complex image montages. For example the montage array in Annotate Angle Examples was created using this technique.

            If you do not want this automatic labeling, you must specifically tell montage to reset all the labels being read in or created to the empty string, using "-label ''" before reading the image. Or you can just delete the label meta-data using "+set label" after reading the images.

            This is where "+label" differs from using an empty label ("-label ''"). The former will reset the default behavior back to automatically using any label meta-data that the image being read-in may have , while the later replaces the label with an empty string, which effectiavvly removes the label. You can also preserve the original label of the image using "-label '%l'", which can be usful as a NO-OP labeling option in image processing scripts.

            Note that "-set" cannot restore the original label of an image, once it has been modified or removed, either by using "-label" or "-set"


              convert -label 'medical'  medical.gif  label_medical.png
              convert -label 'logo'     logo:        label_logo.png
              convert -label 'rose'     rose:        label_rose.png

              montage           label_medical.png \
                      -label '' label_logo.png    \
                      +label    label_rose.png    \
                      -tile x1  -frame 5  -geometry '60x60+2+2>' label_control.jpg

            [IM Output]

            In the above you can see that the first image was labeled using the label supplied with the image itself. The second had the incoming label removed by a "-label '' " setting, while the third also used the images label because we turned-off the label setting with "+label".

            Using Saved Image MetaData
            When generating images for later use by montage it is important to know what sort of image metadata a specific image file format can save. For example only PNG, and MIFF image file format can actually store 'label' meta-data in their saved image file format...


              convert -label 'GIF'  balloon.gif  label.gif
              convert -label 'JPG'  medical.gif  label.jpg
              convert -label 'PNG'  present.gif  label.png
              convert -label 'MIFF' shading.gif  label.miff

              montage label.gif label.jpg label.png label.miff \
                      -tile x1  -frame 5  -geometry '60x60+2+2>' label_files.jpg
              rm label.*

            [IM Output]

            However all the common file cormats allow you to use 'comment' meta-data, which you can use by specifying a '%c' argument to "-label".


              convert -comment 'GIF'  balloon.gif  comment.gif
              convert -comment 'JPG'  medical.gif  comment.jpg
              convert -comment 'PNG'  present.gif  comment.png
              convert -comment 'MIFF' shading.gif  comment.miff

              montage -label '%c' comment.gif comment.jpg comment.png comment.miff \
                      -tile x1  -frame 5  -geometry '60x60+2+2>' comment_files.jpg
              rm comment.*

            [IM Output]

            This is often more useful for pictures saved in the JPEG file format, though JPEG image comments generally are too large (often whole paragraphs describing the image), for use as montage labels, as they will not be word wrapped (see Montage of Polaroid Photos for an alternative method of labeling using image 'comment' meta-data).

            Many other programs also automatically add 'made-by' labels and comments to images they save (YUCK) so some caution is recommended. The GIMP program particularly likes to add such comments and labels, unless you tell it not to, every time you save an image.

            Note that IM is generally not used to add comments to saved JPEG files, (due to JPEG Lossy Compression) unless processing them for other reasons. Instead they are usually added by some other method in order to avoid reading and re-writing the image data and thereby degrading the JPEG image files in which you are adding comments. See lossless JPEG Processing options, for some such methods.

            It is also important to note that labeling (and image 'comments') is not specific to montage. Montage just makes automatic use of image labels if present. Labels and comments are attached to images, and the their specific file formats, and is not montage or even IM specific.

            The PNG and MIFF file format also allow you to use a less commonly used 'caption' meta-data.


              convert  balloon.gif -set caption 'GIF'  caption.gif
              convert  medical.gif -set caption 'JPG'  caption.jpg
              convert  present.gif -set caption 'PNG'  caption.png
              convert  shading.gif -set caption 'MIFF' caption.miff

              montage -label '%[caption]' caption.gif caption.jpg caption.png caption.miff \
                      -tile x1  -frame 5  -geometry '60x60+2+2>' caption_files.jpg
              rm caption.*

            [IM Output]

            Actually both these file formats allow you to save ANY Image property Meta-data that may be present in an image when it is saved!


              convert  balloon.gif -set my_data 'GIF'  my_data.gif
              convert  medical.gif -set my_data 'JPG'  my_data.jpg
              convert  present.gif -set my_data 'PNG'  my_data.png
              convert  shading.gif -set my_data 'MIFF' my_data.miff

              montage -label '%[my_data]' my_data.gif my_data.jpg my_data.png my_data.miff \
                      -tile x1  -frame 5  -geometry '60x60+2+2>' my_data_files.jpg
              rm my_data.*

            [IM Output]

            Leaving Gaps in a Montage
            While you can leave extra space in a montage at the bottom by judicious use of the "-tile" setting and controlling the number of images given, leaving an empty tile space in the middle of a montage requires the use of a special image.

            The "null:" generated image was defined specifically for this purpose. The position in which it appears will not receive any label (even if one is defined), nor will it have any frame or shadow 'fluff' added. The tile is just left completely empty except for the background color (or texture) of the montage drawing canvas itself.


              montage -label 'Image' medical.gif null: present.gif \
                      -tile x1  -frame 5  -geometry +2+2   montage_null.jpg

            [IM Output]

            Note that to other IM commands the "null:" image is represented a single pixel transparent image. It is also used as a 'error image' for options like "-crop" or "-trim" which could produce a 'zero' or empty image as a result of the operation.

            This special image cannot be saved and then later used to leave gaps, currently it is only 'special' if given on the command line of "montage".

                There is no method, at this time to allow montaged images to span multiple rows or columns, as you can in HTML tables. Nor can you generate variable sized rows and columns to best fit the array of images being generated.

            If you really need this sort of ability you will need to develop your own montage type of application. If you do develop something, then please contribute, and we'll see about merging it into the existing montage application.

            Some solutions for this includes labeling and framing the image thumbnails yourself and then using either Append Images or use a more free form Layering Image technique.

            More Montage Settings
            The "montage" settings I have shown above are only the basic controls for montage. Their are a lot of other settings you may like to consider for your own needs.

            Montage Color Settings
            -background 	The color outside the drawn frame. Often this is set to the 'none' or 'transparent', for use on web pages. The -texture setting will be used instead if given.
            -bordercolor   	The fill color inside the frame for images, or any border padding. Any transparent areas in an image will become this color, unless no such decoration is added.
            -mattecolor 	The color used as the frame color. Note that the color is also made lighter and darker to give the frame a beveled 3D look. So this setting really defines 5 colors. (See also Framing Images)
            -fill 	The fill color for text labels and titles.
            -stroke 	The stroke color for text labels and titles.

            Montage Control Settings

                -tile {cols}x{rows}
                    The number of images across and down used to fill a single montage image. If more images were read in or created than fits in a single montage image, then multiple images will be created. (See Tile Controls above) 
                -title {string}
                    Set a title over the whole montage, using the same font (but larger) as that used to label the individual images. 
                -frame {width}
                    Create a frame around the box containing the image, using the width provided (must be at least 2, but 5 or 6 is a good value). If used any transparency in images will also become the border color. 
                -border {width}
                    Create a border around the image, using the width provided. If used any transparency in images will also become the border color. 
                -shadow
                    Generate a shadow of the frame. Note that no argument is required or expected. 
                -texture {filename}
                    Use the given texture (tiled image) for the background instead of a specific color. See the section on Background and Transparency below for more information. 
                -geometry {W}x{H}+{X}+{Y}
                    Resize images after they have all been read in before montage overlays them onto its canvas. It also defines the size and the spacing between the tiles into which the images are drawn. If no size is specified the images will not be resized. 
                -gravity {direction}
                    if the image is smaller than the frame, where in the frame is the image to be placed. By default it is centered. 

            Added to the above are all the font settings that the "label:" image creation operator understands (See Label Image Generator). These settings are used for the creation of labels added underneath the displayed image.

            These include settings such as "-font", "-pointsize" (ignored for "-title"), "-density", "-fill", "-stroke", and "-strokewidth".

            As long as any or all of the above setting are defined or reset, before the final 'output filename' argument, montage will use them as you have requested.

            Re-Using Settings for Image Read/Creation
            Note however that many of these options are also used for other purposes, in either the generation of images or during image processing. But thanks to the 'do things as you see them' command line handling on IM v6, this presents no problem to the "montage" command.

            That means you are free to use any of these option settings to read, create, or modify the images being read in, then reset those settings after all the images have been read in or created. The final setting value will be what montage will use for its final processing.

            This was not the case in versions of IM before version 6, in which it was generally impossible to separate image creation settings, from montage settings, without generating intermediate images (such as in the Image Labels example above).

            Here is a practical example of setting reuse. I wanted to make a table of some of the fonts I have been using in these example pages, then reset the settings to other values for the final processing of the images by montage.


              montage -pointsize 24  -background Lavender \
                      -font Candice      -label Candice      label:Abc-123 \
                      -font Corsiva      -label Corsiva      label:Abc-123 \
                      -font SheerBeauty  -label SheerBeauty  label:Abc-123 \
                      -font Ravie        -label Ravie        label:Abc-123 \
                      -font Arial        -label Arial        label:Abc-123 \
                      -font ArialI       -label ArialI       label:Abc-123 \
                      -font ArialB       -label ArialB       label:Abc-123 \
                      -font ArialBk      -label ArialBk      label:Abc-123 \
                      -font CourierNew   -label CourierNew   label:Abc-123 \
                      -font LokiCola     -label LokiCola     label:Abc-123 \
                      -font Gecko        -label Gecko        label:Abc-123 \
                      -font Wedgie       -label Wedgie       label:Abc-123 \
                      -font WebDings     -label WebDings     label:Abc-123 \
                      -font WingDings    -label WingDings    label:Abc-123 \
                      -font WingDings2   -label WingDings2   label:Abc-123 \
                      -font Zymbols      -label Zymbols      label:Abc-123 \
                      \
                      -frame 5  -geometry +2+2   -font Arial -pointsize 12 \
                      -background none  -bordercolor SkyBlue  -mattecolor DodgerBlue \
                      montage_fonts.gif

            [IM Output]
            Note the two stages to the "montage" command. Which I clearly marked using an extra almost empty line.

            The first part is essentially exactly as you would define multiple images using the normal IM "convert" command, and is processed in the same, 'do it as you see it' order.

            The second part, defines all the settings I wanted the "montage" command itself to use. That is the framing, image resizing, fonts and colors I wanted to use in the final montage image. I especially take care to reset the "-font" and "-pointsize" settings for the labeling underneath the montaged images.

            While you can separate the options of "montage" like this, you can actually define the montage settings at any time on the command line. As long as those settings do not interfere with your image creating and processing options, and are still defined correctly when the end of the command line is reached, "montage" will use them.

            ASIDE: You may like to look at the shell script I wrote to do something similar to the above (and which works with earlier versions of montage) to display a directory of truetype (.ttf) fonts, called "show_fonts". Another shell script example is "show_colors".

            Montage vs Convert Option Differences
            Now while "montage" generally allow you to use any "convert" settings and operators in reading and processing its input images, their are a few differences which need to be highlighted.

            These "convert" operators and settings are different when used within "montage".

                -tile
                    In "convert" the "-tile" setting defines an image to use as a texture instead of using the "-fill" color. In "montage" it defines how to layout the individual image cell 'tiles'. See Tile Layout Controls above for more detail.

                -frame
                    In "convert" this is an operator used to add a 3D frame border around images, and requires 4 arguments to work correctly (See Convert Frame examples). See Frame Decoration for more detail.

                -border
                    Sometime around IM v6.1.0 this operator became a special montage option. As such, like the previous frame option it only takes one number as an argument, rather than two arguments as per the Convert Border. See Border Decoration for more detail. 
                -shadow
                    The "-shadow" option in "convert" takes an argument which is used to create a soft blurry shadow to which can be place under a second copy of the original image. However in "montage" this is only a Boolean setting that just turns the rectangular shadowing abilities, on and off. See Shadow Decoration for more detail.

                -geometry
                    The "-geometry" option in "montage" is simply saved to provide the size of the images within each cell of the final montage, and the spacing between the cells. In "convert" it resizes just the last image, and sets the off set for Image Composition.

            If you really need to use the "convert" form of these options, then you will need to pre-process your images using "convert" before passing them to "montage".

            One method using intermediate files was demonstrated in the Image Labels example above.

            Another is to just do your processing in "convert" and just pipe the resulting multiple images into "montage". This separation is easy to do if you always do your image input handling first, then set the "montage" specific settings afterward, such as I have done in all these examples. This is especially shown in the last font example above.

            For example lets frame our images using the "convert" frame, and then frame them again using the "montage" labeled frames.


              convert -label %f   balloon.gif medical.gif present.gif shading.gif \
                      -mattecolor peru  -frame 10x5+3+0    miff:-  |\
                 montage  -   -tile x1  -frame 5  -geometry '64x56+5+5>' double_frame.jpg

            [IM Output]

            You can also see the extra arguments required by the "convert" form of the "-frame" operator.

            Indexes of Image Directories
            HTML Thumbnail Image Maps
            Montage is especially designed for generating thumbnail maps of images.

            For example here I have created an index of the Photo Images source directory, which holds the digital photos used for examples throughout IM Examples. Click the 'art' image below to view the result.


              montage -label '%t\n%[width]x%[height]' \
                      -size 512x512 '../img_photos/*_orig.*[120x90]' -auto-orient \
                      -geometry +5+5 -tile 5x  -frame 5  -shadow  photo_index.html

                [IM Output]
            IM Examples
            Photo Store

                Note the use of '%[width]x%[height]' instead of just '%wx%h'. This is important as the image is being resized as it is read in. The former will label the images with their original pixel size as it is on disk, while the latter will use the current resized size of the image. This is something that is easily overlooked by users.

            The result of this command were three files...

                photo_index.png 	The montage of all thumbnails of the images
                photo_index_map.shtml 	An HTML 'image map' for the thumbnail image
                photo_index.html 	The HTML thumbnail index page for the World Wide Web.
                This also includes a copy of the previous image map.

            Of course you don't have to generate an HTML index file if you only want an index image. In that case just replace "INDEX.html" in the command above with the image you want to generate.

            Note the use of the Image Property Escape '%t' for the image "-label". This is the filename of the image without any 'path' components. Though the HTML link will still contain the appropriate 'path' components allowing you to build the index image in a different directory to the images themselves.

            The source images "'*_orig.*'" in the above examples is quoted, so the "montage" command does the expansion of '*' itself, and not the command line shell. This avoids any command line length limits that you may have problems with. Also I do some initial resizing of images '[120x190]' as I read them (see Read Image Modifiers).

            For JPEG images I also specified a smaller "-size" setting so the JPEG library can do some very rough initial scaling, and not read the whole image into memory. If this is not done, then very large JPEG images could use up an enormous amount of memory and CPU cycles when there is no real need. I also "-strip" any profiles that the images may have. For more info see Profiles, Stripping, and JPEG Handling and Reading JPEG Images.

            Remember the montage "-geometry" option can also specify a final resize setting, though in this case it is isn't needed as I did it during the read process, so I don't set any 'size' in that setting.

            Finally the "-tile" option of '5x' is used to ensure all images appear in a single image, otherwise "montage could generate a multi-page HTML files, which are not correctly linked together. This will hopefully change, though HTML generation is not a primary goal of ImageMagick.

            For other ways of generating thumbnails and HTML index pages, read the Thumbnail Examples Page.

            Smaller HTML Index Maps, using JPEG images
            The above index image generated a PNG format index image. This was used because it is a non-lossy format, which can be important when the images being indexed are of wildly different colors. It also enables the use of the new 'soft shadows' features of montage if the background color is set to 'transparent' or 'none'.

            Very very old IM's will have generated a GIF image for the above. However, this has some heavy color reduction on the results as part of the formats limitations. It also did not allow the use of semi-transparent 'soft shadows' as PNG allows.

            JPEG also does not allow semi-transparency, but that is not a problem if you do not use a transparent background for the image. It is however a lot smaller than PNG, which provides a way to drastically reduce the size of the index image, especially for web use, and still handle a large range of colors.

            However, HTML output above only generates PNG format images, so you will need to not only convert the PNG to JPEG, but also some extra processing to fix the HTML file.


              montage -label '%t\n%[width]x%[height]' \
                      -size 512x512 '../img_photos/*_orig.*[120x90]' -auto-orient \
                      -geometry +5+5 -tile 5x  -frame 5  -shadow  photo_jpeg.html
              convert photo_jpeg.png photo_jpeg.jpg
              perl -i -lpe 's/src="photo_jpeg.png"/src="photo_jpeg.jpg"/' photo_jpeg.html
              rm -f  photo_jpeg.png  photo_jpeg_map.shtml

                [IM Output]
            IM Examples
            Photo Store

            The above commands are rather tricky so here is what happens...

                First I generate a montage thumbnail HTML index, as I did previously. This generated the files: "photo_jpeg.html" and "photo_jpeg.png"
                I then converted the PNG image to a smaller, lossy, JPEG image.
                Then I used a small 'perl' one line script to change HTML file to use the JPEG image instead of PNG.
                And finally I removed the PNG image, as well as the SHTML map file which I don't need. 

            And hey presto, we have a Thumbnail index using a very small JPEG image for the thumbnail index image.

            Here are comparisons of the file sizes of the thumbnail index image...
            [IM Text]

            That is the image used for the index is only about 15% of the size of the original PNG image. A big saving for a downloadable web page of thumbnails!

            You can make the JPEG image even smaller by using a smaller "-quality" setting, though the default setting produces a very reasonable result. Other possible options include using "-sampling-factor 2x1" to make it even smaller.

            Visual Index Images (a non-montage solution)
            An alternative to using montage, is to use a special "visual index" input format...


              convert  'vid:../img_photos/*_orig.*' vid_index.gif

                [IM Output]
            Visual Index of
            Photo Store

            And can also generate 'clickable' HTML index files.


              convert  'vid:../img_photos/*_orig.*' vid_index.html

                [IM Output]
            Visual HTML of
            Photo Store

            It is obvious that "VID:" uses montage internally to generate the index array. However you do not have the same controls as you do if you had used montage directly.

            Note that a VID HTML index creates a PNG format thumbnail image.

            A Montage of Polaroid Photos
            With the advent of a Complex Polaroid Transform it is now possible to generate quite a different style of montage, and montage indexing.


              montage -size 256x256 '../img_photos/*_orig.*' -auto-orient \
                      -auto-orient -thumbnail 128x128 \
                      -set caption '%t' -bordercolor AliceBlue -background grey20 \
                      +polaroid \
                      +set label   -background white  -geometry +1+1  -tile 4x \
                      polaroid_index.html

                [IM Output]
            Polaroid
            Montage

            Note that as I used "+polaroid" to frame and label the images, I needed to resize the image (using "-thumbnail") myself, and make sure the "-background" and image "-label" has been reset before actually creating the "montage" index array.

            The Polaroid Transform however tends to blur the text during the addition of the 'curl' to the thumbnail image. However you can improve the overall by generating the polaroid images at a larger size then shrinking the result by 50%. The only drawback is the reduced 'shadow' effect.


              montage -size 400x400  '../img_photos/*_orig.*' \
                      -auto-orient -thumbnail 200x200 \
                      -set caption '%t' -bordercolor Lavender -background grey40 \
                      -pointsize 9  -density 144x144  +polaroid  -resize 50% \
                      +set label   -background white  -geometry +1+1  -tile 5x \
                      polaroid_index2.html

                [IM Output]
            Sharper
            Polaroid
            Montage

            This fancy montage, as well as other techniques shown above was used to create a script "generate_index" to generate a montage thumbnail index in the actual "photo_store" directory.

            See Photograph Store Index for the results of this script.

            Special Techniques using Montage
            Montage into Columns
            By default "montage" can only place the images in the order given (typically sorted order) row by row. However sometimes you would like to have them shown in column order.

            This can not be done with a single command, but requires a pipe-line of at least two commands. For example here I generate a page of 5x3 tiles, using two montages.


              montage font_*.gif  -tile 1x3  -geometry 16x16+1+1  miff:- |\
                montage -  -geometry +0+0 -tile 5x1  montage_columns.gif

                [IM Output]

            Note that it is the first "montage" that creates the tiles and performs any of the geometry tile sizing, framing, labeling and spacing needed. It will then output one image for each column of tiles. The second "montage" then simply contatanates the columns into 'page' images without adding any more space between columns.

            If you only want a single image of a variable number of columns, then you can replace the second "montage" with a "convert" to concatanate without adding extra space of 'pages'. For example...


              montage font_*.gif  -tile 1x3  -geometry 16x16+1+1  miff:- |\
                convert - +append montage_columns_2.gif

                [IM Output]

            Overlapped Montage Tiles
            In the IM User Forum, during a discussion between, Fred Weinhaus , aka fmw42 and another user pooco, it was discovered that if you set the inter-tile space (set in the "-geometry" setting) to a negative number you can actually overlap the tiled areas into which the images are drawn.

            For example, here we use a negative horizontal inter-tile spacing, for a single row of images.


              montage null:   font_*.gif   null: \
                      -tile x1 -geometry -5+2  montage_overlap.jpg

            [IM Output]

            Rotating the images will make the overlapping series even more interesting...


              montage null: font_*.gif null: -background none -rotate 30 \
                      -background white -tile x1 -geometry -8+2  montage_rot_overlap.jpg

            [IM Output]

            Note that I needed to add a special "null:", spacing image at the start and end of the row of images so the images do not overflow the canvas, "montage" calculates and generates.

            This presents us with some interesting possibilities. For example you could generate a very interesting row of overlapping thumbnails, by making use of the randomly rotated Polaroid Transform.


              montage -size 400x400 null: ../img_photos/[a-m]*_orig.* null: \
                      -auto-orient  -thumbnail 200x200 \
                      -bordercolor Lavender -background black +polaroid -resize 30% \
                      -gravity center -background none -extent 80x80 \
                      -background SkyBlue -geometry -10+2  -tile x1  polaroid_overlap.jpg

            [IM Output]

            The use of extent in the above is used to remove the randomness of image size that "+polaroid" can produce on different 'runs', giving more control of the final spacing and overlap between images.

            This is a very interesting result, though it should actually be classed as a BUG, as this is not the intended purpose of "montage". I also would not expect any HTML image mapping to work correctly, without some fixing by the user.

            However a more complex, and user controllable solution for overlapping images is demonstrated using a scripted form of Layer Merging, which is the recommended and more logical solution. See examples in Programmed Positioning of Layered Images.

            Montage Concatenation Mode
            As you saw, montage has a special concatenation mode, which can be used to join images together without any extra spaces just like the "-append" option. I do however recommend you set the "-tile" option appropriately, so as to direct the appending either horizontally, vertically or in an array.

            For example here we use a "-tile x1" to append images horizontally.


              montage balloon.gif medical.gif present.gif shading.gif \
                      -mode Concatenate  -tile x1  montage_cat.jpg

            [IM Output]

            But you can also use it to just as easily create an array of images. Preferably, the images are the same size, so they fit together properly.


              montage balloon.gif medical.gif present.gif shading.gif \
                      -mode Concatenate  -tile 2x2  montage_array.jpg

            [IM Output]

            When concatenating images of different sizes, the images are concatenated with 'top' vertical alignment, then 'left' horizontal row alignment.


              montage medical.gif rose:       present.gif shading.gif \
                      granite:    balloon.gif netscape:   recycle.gif \
                      -mode Concatenate  -tile 4x  montage_cat2.jpg

            [IM Output]

            However vertical alignment goes weird when framing is also added.


              montage medical.gif rose:       present.gif shading.gif \
                      granite:    balloon.gif netscape:   recycle.gif \
                      -mode Concatenate  -tile 4x  -frame 5  montage_cat3.jpg

            [IM Output]

            Of course, framing is not really part concatenate mode, so if "-frame" is set before the "-mode" setting, it will be turned off. As such this quirk is not likely to be seen, except by mistake when you accidentally use a 'zero geometry' (see below).

                Montage Concatenation to the 'HTML' image indexing format, produces incorrect image maps. Basically the resulting image map will be as if the generated montage was a true equally divided 'array' of images, rather than a concatenation of the images in line. In other words it is wrong for lines of 'short' images.

            Zero Geometry, caution required
            With only "-geometry" spacing values (no image resizing specified), all montages image frames are set to the same size, so that both the widest and tallest image will fit, without being resized.

            This is itself an useful behaviour...


              montage present.gif rose: shading.gif \
                      -frame 5  -geometry +1+1   montage_geom_1.jpg

            [IM Output]

            However a 1 pixel gap was left around and between the image frames.

            But if you try to remove those gaps with a position of "+0+0", you run into a very unusual problem...


              montage present.gif rose: shading.gif \
                      -tile x1  -frame 5  -geometry +0+0  montage_geom_0.jpg

            [IM Output]

            The 'zero geometry' you specified (that is "-geometry 0x0+0+0" ), has the extra effect of putting montage in a 'concatenation' mode (see above), which is NOT what we were after in the above.

            For single images it also does not matter if we use a zero "-append" (and thus concatenation mode). The desired result is what we want, no extra borders. As such a "-geometry +0+0" is fine if you are only using "montage" to add a label to an image.

            The concatenation mode will however not be invoked if you specify a non-zero geometry 'size' for your images, even though you used a zero offset. This in turn gives us a tricky solution to our original problem.

            What we do a set a geometry image size of "1x1" but also tell IM, never to shrink images (using a "<" character) to this size! In other words, never resize an image ever, just use a zero offset, in a non-zero geometry argument.


              montage present.gif rose: shading.gif \
                      -frame 5  -geometry '1x1+0+0<'  montage_geom_1x1.jpg

            [IM Output]

            This brings up another good rule of thumb...

            Always set a non-zero geometry when using montage

            Even if it is only the 'fake' geometry such as I used above.

            Background and Transparency Handling
            By default images are overlaid onto the montage canvas, which is created using the "-background" color setting, as you can see here.


              montage font_9.gif  \( recycle.gif -set label recycle \)  medical.gif \
                      -tile x1  -geometry +5+5  -background lightblue   bg_lightblue.gif

                [IM Output]

            Instead of a solid color, you can instead use "-texture" to define a tile image to use instead of the "-background" color.


              montage font_9.gif  \( recycle.gif -set label recycle \)  medical.gif \
                      -tile x1  -geometry +5+5   -texture bg.gif      bg_texture.gif

                [IM Output]

            Adding frames (which add extra border space into the tiles) just adds more drawn 'fluff' on top of the background canvas.


              montage font_9.gif  \( recycle.gif -set label recycle \)  medical.gif \
                      -tile x1  -frame 5  -geometry '40x40+5+5>' \
                      -bordercolor lightblue  -texture bg.gif  bg_frame.gif

                [IM Output]

            Note that when framed, the "-bordercolor" setting will be used to fill in the inside the frame, effectively becoming the background color of the image. Also notice that any transparent areas of the image are also set to this color.

                Before version 6.1.4 of IM, what was seen in the transparent areas of images was undefined. In some versions you would see through the framed image to the background color or texture. On others you might get black, or white. In still other versions you would be able to see though all the layers and the final image would be transparent where the original image was transparent. Upgrade NOW if this is a problem for you.

            Also new to IM version 6.1.4 is the ability to use a special 1 pixel wide frame. This will basically remove the frame around the image cells completely, but retaining the internal "-bordercolor" padding around (and underneath) the image. For example compare a frame of '1' with the minimal frame width of '2'.


              montage font_1.gif  \( recycle.gif -set label recycle \)  medical.gif \
                      -tile x1  -frame 1  -geometry '40x40+5+5>' \
                      -bordercolor lightblue  -texture bg.gif  bg_frame_1.gif

                [IM Output]


              montage font_2.gif  \( recycle.gif -set label recycle \)  medical.gif \
                      -tile x1  -frame 2  -geometry '40x40+5+5>' \
                      -bordercolor lightblue  -texture bg.gif  bg_frame_2.gif

                [IM Output]

            But what if you want your montage to have a transparent background? Particularly, if you plan to use it on a web page containing a texture mapping.

            Simple, just use a "-background" color of 'None' or 'Transparent', without any "-texture" image to override that setting.

            For example here we generated a transparent montage. Note that "-geometry" is still used to add space around and between the images.


              montage font_9.gif  recycle.gif  medical.gif \
                      -tile x1  -geometry +2+2  -background none   bg_none.gif

                [IM Output]

            Of course if you also use "-frame", you need to make the "-bordercolor" transparent too.


              montage font_9.gif  recycle.gif  medical.gif \
                      -tile x1 -frame 5 -geometry '40x40+5+5>' \
                      -bordercolor none  -background none    bg_framed_trans.gif

                [IM Output]

            Note that the montage "-shadow" option is completely unaffected by all the above. it is applied according to the final transparent shape of the cells, before it is overlaid onto the background color or texture.


              montage font_9.gif  recycle.gif  medical.gif \
                      -tile x1  -shadow  -geometry '40x40+5+5>' \
                      -texture bg.gif  bg_shadow.gif

                [IM Output]


              montage font_9.gif  recycle.gif  medical.gif \
                      -tile x1 -frame 5 -shadow  -geometry '40x40+5+5>' \
                      -bordercolor none   -texture bg.gif  bg_shadow_framed.gif

                [IM Output]




            Any suggestions, ideas, or other examples of using "montage" are of course always welcome. The same goes for anything in these example pages.

            Montage Image Output Size

            The mathematics of montage is straight forward...

            Basically the montage width should be....
              (geometry_size + 2*frame_size + 2*geometry_offset) * images_per_column

            That is each 'cell' of montage has a fixed sized frame and spacing (border)
            added around it before the cells are appended together.

            In essence the size of montage is also a multiple of the tile size, which can
            make it easy to break up montage, or re-arrange the 'cells', if so desired,
            as they are simple fixed sized tiles in a rectangular array.

            The height is similar but with tha additional spacing needed for labels and
            the optional montage title, both of which are much more difficult to
            calculate, as they depend heavilly on text, font, pointsize, and density
            settings.

            There is also an effect of adding a shadow to the montage in this calculation,
            but that appears to be a simple small fixed addition to the bototm and right
            edges.  It does not appear to effect the tile size used.
https://legacy.imagemagick.org/Usage/layers/
            Overlaying multiple images onto each other to generate a larger 'composite' is generally known as using image 'layering'. These examples involve the combining of multiple 'layers' of images to produce the final larger more complex image.

            Layering Images Introduction
            As we have previously noted, ImageMagick does not deal with just one image, but a sequence or list of images. This allows you to use IM in two very special image processing techniques.

            You can for example think of each image in the list as a single frame in time, so that the whole list can be regarded as being a Animation. This will be explored in other IM Example Pages. See Animation Basics.

            Alternatively, you can think of each image in the sequence as Layers of a set of see-through overhead transparencies. That is, each image represents a small part of the final image. For example: the first (lowest) layer can represent a background image. Above that you can have a fuzzy see though shadow. Then the next layer image contains the object that casts that shadow. On top of this a layer with some text that is written over that object.

            That is you can have a sequence of images or 'layers' that each adds one more piece to a much more complex image. Each image layer can be moved, edited, or modified completely separately from any other layer, and even saved into a multi-image file (such as TIFF:, MIFF: or XCF:) or as separate images, for future processing. And that is the point of image layering.

            Only when all the image layers have been created do you Flatten, Mosaic, or Merge all the Layered Images into a single final image.

            Appending Images
            Appending is probably the simplest, of the multi-image operations provided to handle multiple images.

            Basically it joins the current sequence of images in memory into a column, or a row, without gaps. The "-append" option appends vertically, while the plus form "+append" appends horizontally.

            For example here we append a set of letter images together, side-by-side, to form a fancy word, in a similar way that individual 'glyphs' or letters of a 'font', are joined together.


              convert font_A.gif font_P.gif font_P.gif font_E.gif font_N.gif \
                      font_D.gif font_E.gif font_D.gif +append  append_row.gif

            [IM Output]

            The above is similar (in a very basic way) to how fonts are handled. Unlike real fonts you are not limited to just two colors, but can generate some very fancy colorful alphabets from individual character images. Many of these 'image fonts' are available on the WWW for download. A very small set can be found in Anthony's Icon Library, in Fonts for Text and Counters, which is also where I found the above Blue Bubble Font.

            Note also how the "+append" operator was done as the last operation, after all the images that you want to append have been added to the current image sequence.

            This is great for appending a label to an image, for example...


              convert rose:  -background LawnGreen label:Rose \
                      -background white  -append append_label.jpg

                [IM Output]

            Note that the "-background" color was used to fill in any space that was not filled in. Of course if the all the images are the same width, no space will be left for this fill.

            From IM v6.4.7-1 the "-gravity" setting can be used to specify how the images should be added together. As such in a vertical append, a setting of 'Center' will center the image relative to the final resulting image (so will a setting of either 'North' or 'South').


              convert rose:  -background LawnGreen label:Rose \
                      -background white -gravity center -append \
                      append_center.jpg

                [IM Output]

            Naturally any 'East' gravity setting will align the images on the right side.


              convert rose:  -background LawnGreen label:Rose \
                      -background white -gravity east -append \
                      append_east.jpg

                [IM Output]

            Similar vertical alignment can be achieved when using "+append"

                Before IM v6.4.7 it was much more difficult to align appended images, and generally involved using a "-flop" for right alignment. Or using "-extent" or "-border" to adjust the image width for centered aligned appends.

            For example, this will work with an older 6.3.2 version of IM...


              convert rose:  -background SkyBlue label:Rose \
                      -background White -gravity center -extent 200x \
                      -append -trim +repage   append_center_old.jpg

                [IM Output]

            You can also use multiple append operations, in the same command without conflict or confusion as to the outcome of the operations (which was not the case before IM v6).


              convert font_{0,0,6,1,2}.gif +append  dragon_long.gif \
                      -background none   -append   append_multi.gif

                [IM Output]

            We appended each row of images together, then appende a larger image below that. This is very simple, and straight-forward.

            By using parenthesis, you can append just the numbers after the larger image. For example, here append all the numbers together, before appending them vertically to the dragon image we read in before the numbers.


              convert dragon_long.gif  '(' font_{0,0,6,2,9}.gif +append ')' \
                      -background none   -append   append_parenthesis.gif

                [IM Output]

                The parenthesis in the above must be either quoted, or escaped with a backslashed ('\') when used with an UNIX shell, otherwise they will be interpreted by the shell as something completely different.

                As only two images were involved we could have just used "+swap" or "-reverse" instead of using parenthesis.

            Append an Array of Images
            You can take this further to make a whole array of images, and build them either by rows, or by columns.


              convert \( font_1.gif font_2.gif font_3.gif +append \) \
                      \( font_4.gif font_5.gif font_6.gif +append \) \
                      \( font_7.gif font_8.gif font_9.gif +append \) \
                      \( -size 32x32 xc:none  font_0.gif +append \) \
                      -background none -append   append_array.gif

                [IM Output]

            Technically the first set of parenthesis is not needed, as no images have been read in yet, but it makes the whole thing look uniform and shows the intent of the command, in making an array of images.

            See also Montage Concatenation Mode, for an alternative way of creating arrays of equal sized images.

                The "-append" operator will only append the actual images, and does not make use the virtual canvas (image page) size, or the image offset. However the virtual canvas information seems to be left in a funny state with the canvas sizes being added together and the offset set to some undefined value.

            This may be regarded as a bug, and means either the input images or result should have the virtual canvas reset using "+repage", before saving, or using the image in operations where this information can become important.

            This situation will probably be fixed in some future expansion of the operation. Caution is thus advised, especially if re-appending Tile Cropped images.

            Append with Overlap
            On the IM Forum an user asked for a simple way to Append images with some overlap. Many solutions were offered. This was one of the simplest solutions, with the amount of overlap given in a single location.


              convert granite: rose: -gravity east -background none \
                      \( -clone 1 -chop 30x0 \) \( -clone 0,2 +append \) \
                      -delete 0,2 +swap -composite append_overlap.gif

                [IM Output]

            The above did not need to any image positioning calculations, typically involving image sizes, that would represent a more general solution. See Handling Image Layers below.

            What this did was chop off the part that overlapped, before appending the result to the first image, producing the final image size. The original image is then composed (with gravity) on top to generate the actual overlap.

            It can be easily modified for vertical overlapping, or even right to left overlapping relatively easily.

            Smushing Append
            Another way of appending images is by smushing. The "-smush" operator works much like the Append Operator (see above) does, but it takes an argument of how much space (or anti-space) you want between the images.

            For example, lets use it to so the previous example more simply.


              convert granite: rose: -background none -gravity Center \
                      +smush -20 smush_overlap.png

                [IM Output]

            That works very well, though that is not what the operator is actually designed for, and it is probably a lot slower.

            What smush actually is ment to do is move 'shaped images' as close togther as posible. For example here I generate the letters 'A' and 'V' and 'smush' them together with as little space between them as posible.


              convert -background none -pointsize 72 \
                      -fill red label:A -fill blue label:V \
                      +smush 0 smush_append.png

                [IM Output]

            Notice that how the two letters were appended together far closer than append would, taking advantage of the empty space of the images 'shape'. The gap in the above is caused by anti-aliasing edge pixels of the two letters.

            That is what "-smush" is designed to do, though it requires a lot of calculations, so is a lot slower than Append (see above).

            The argument, is an offset for that final position, and is usually a positive value to generate a gap, but can be negative to create an overlap.


              convert -background none -pointsize 72 \
                      -fill red label:A -fill blue label:V \
                      +smush -15 smush_offset.png

                [IM Output]

            Images may become clipped in undocumented ways if a very large negative value is used.

            Composition of Multiple Pairs of Images
            Composition is the low-level operation that is used to merge two individual images together. Almost all layering techniques eventually devolve down to merging images together two at a time, until only one image is left.

            So lets start by looking at ways of doing low-level composition of image pairs.

            Using the Composite Command
            The traditional method of combining two images together using ImageMagick is though the "composite" command. This command can only combine only two images at a time, saving the results of each operation into a file. This of course does not stop you from using it to layer multiple images, one image at a time...


              convert -size 100x100 xc:skyblue composite.gif
              composite -geometry  +5+10 balloon.gif composite.gif composite.gif
              composite -geometry +35+30 medical.gif composite.gif composite.gif
              composite -geometry +62+50 present.gif composite.gif composite.gif
              composite -geometry +10+55 shading.gif composite.gif composite.gif

                [IM Output]

                As all input images are read in by ImageMagick BEFORE the output image is opened, you can output to one of the input images. This allows you to work on the same image over and over, as shown above, without problems.

            Do not do this with a lossy image format like "JPEG" as the format errors are accumulative, and the base image will quickly degrade.

            You can also resize the overlaid image as well as position it using the "-geometry" setting.


              convert -size 100x100 xc:skyblue comp_resize.gif
              composite -geometry 40x40+5+10  balloon.gif comp_resize.gif comp_resize.gif
              composite -geometry      +35+30 medical.gif comp_resize.gif comp_resize.gif
              composite -geometry 24x24+62+50 present.gif comp_resize.gif comp_resize.gif
              composite -geometry 16x16+10+55 shading.gif comp_resize.gif comp_resize.gif

                [IM Output]

            The "composite" command also has a few other advantages in that you can use to control the way the image is drawn onto the background with the "-compose" option and its relative position is effected by the "-gravity" setting.

            You can also "-tile" the overlay so that it will just cover the background image, without needing to specify tile limits. This is something only available when using "composite".

            The big disadvantage with this method is that you are using multiple commands, and IM has to write-out the working image, either to a pipeline, or to disk, for the next command to read-in again.

            To find more examples of using the "composite" command, to overlay images on top of other images, see "Annotating by Overlaying Images" and "Image Positioning using Gravity".

            Composite Operator of Convert
            The "-composite" operator is available within the "convert" command. For more details see Image Composition in IM. This allows you to do the same as the above, but all in one command.


              convert -size 100x100 xc:skyblue \
                      balloon.gif  -geometry  +5+10  -composite \
                      medical.gif  -geometry +35+30  -composite \
                      present.gif  -geometry +62+50  -composite \
                      shading.gif  -geometry +10+55  -composite \
                      compose.gif

                [IM Output]

            This first creates a Canvas Image which is "skyblue" in color, and then layers each of the later images onto that canvas at the given locations.

            Now the "-geometry" is is a very special operator that not only sets an overlay position for the next "-composite" operation, it will also "-resize" the last image (and only the last image) in the current image sequence.


              convert -size 100x100 xc:skyblue \
                      balloon.gif  -geometry 40x40+5+10   -composite \
                      medical.gif  -geometry      +35+30  -composite \
                      present.gif  -geometry 24x24+62+50  -composite \
                      shading.gif  -geometry 16x16+10+55  -composite \
                      compose_geometry.gif

                [IM Output]

            Note it is recommended that you avoid this 'resize' side-effect of of the "-geometry", even if it is convenient. Basically as it is more of a backward compatibility effect and may in some situations generate other effects.

            Here is the more verbose recommendation...


              convert -size 100x100 xc:skyblue \
                      \( balloon.gif -resize 40x40 \) -geometry +5+10   -composite \
                      \( medical.gif               \) -geometry +35+30  -composite \
                      \( present.gif -resize 24x24 \) -geometry +62+50  -composite \
                      \( shading.gif -resize 16x16 \) -geometry +10+55  -composite \
                      compose_resize.gif

                [IM Output]

            Draw Multiple Images
            Also using "convert" you can also use Draw Primitives to overlay images onto its working canvas.


              convert -size 100x100 xc:skyblue \
                      -draw "image over  5,10 0,0 'balloon.gif'" \
                      -draw "image over 35,30 0,0 'medical.gif'" \
                      -draw "image over 62,50 0,0 'present.gif'" \
                      -draw "image over 10,55 0,0 'shading.gif'" \
                      drawn.gif

                [IM Output]

            You can of course also specify a resize for the overlaid image too..


              convert -size 100x100 xc:skyblue \
                      -draw "image over  5,10 40,40 'balloon.gif'" \
                      -draw "image over 35,30  0,0  'medical.gif'" \
                      -draw "image over 62,50 24,24 'present.gif'" \
                      -draw "image over 10,55 16,16 'shading.gif'" \
                      drawn_resize.gif

                [IM Output]

            The 'drawn' images can also be Rotated, Scaled, and Affine Distorted during the overlay process. Though that can be tricky to get working the way you want.

            Drawn images are "-gravity" effected, just like text.

            Layering Multiple Images
            True layering of images requires methods to combine multiple images together, without needing to individually compose each pair of images separately. This is where the various -layers operator methods come into their own.

            Ordering of layered images can be important, so it is a good idea to understand the special Image Sequence or List Operators.

            Note that 'layered images' is practically identical to the handling 'animated frames'. As such it is recommended you also look at both Animation Basics and Animation Modifications for techniques involving processing individual 'layers' or 'frames'. Actually animations often use the same -layers operator for processing images.

            Flatten - onto a Background Image
            The "-layers flatten" image list operator, (or its shortcut "-flatten") will basically "Compose" each of the given images on to a background to form one single image. However the image positions are specified using their current Virtual Canvas, or Page offset.

            For example, here I create a nice canvas, and specify each of the images I want to overlay onto that canvas.


              convert -size 100x100 xc:skyblue \
                      -fill dodgerblue -draw 'circle 50,50 15,25' \
                      -page +5+10  balloon.gif   -page +35+30 medical.gif  \
                      -page +62+50 present.gif   -page +10+55 shading.gif  \
                      -layers flatten  flatten_canvas.gif

                [IM Output]

                As of IM v6.3.6-2 the "-flatten" operator is only an alias for a "-layers 'flatten'" method.

            Thus the "-flatten" option can be regarded as a short cut for the "-layers" method of the same name.

            You don't need to create an initial canvas as we did above, you can instead let "-flatten" create one for you. The canvas color will be the current "-background" color, while its size is defined by the first images Virtual Canvas size.


              convert -page 100x100+5+10  balloon.gif   -page +35+30 medical.gif  \
                      -page +62+50        present.gif   -page +10+55 shading.gif  \
                      -background dodgerblue  -layers flatten  flatten_page.gif

                [IM Output]

                While the "-gravity" setting will effect image placement defined using "-geometry" settings, it will not effect image positioning using virtual canvas offsets set via the "-page" setting. This is part of the definition of such offsets. See Geometry vs Page Offsets for more details.

            If placement with "-gravity" is need look at either the above multi-image composition methods, or the special Layers Composition method that can handle both positioning methods simultaneously.

            If any image does not appear in the defined virtual canvas area, it will either be clipped or ignored, as appropriate. For example here we used a smaller canvas size, causing the later images not to appear completely on that canvas.


              convert -page 75x75+5+10  balloon.gif   -page +35+30 medical.gif  \
                      -page +62+50 present.gif   -page +10+55 shading.gif  \
                      -background dodgerblue  -flatten  flatten_bounds.gif

                [IM Output]

            The normal use of Flatten is to merge multiple 'layers' of images together.

            That is you can be generating various parts of a larger image, usually using Parenthesis to limit image operators to the single 'layer' image being generated, and then flatten the final result together.

            For example one typical use is to create a Shadow Image layer, onto which the original image is flattened. For example...


              convert balloon.gif \( +clone  -background navy  -shadow 80x3+5+5 \) +swap \
                      -background none   -flatten   flatten_shadow.png

                [IM Output]

            Note that as I want the shadow under the original image, I needed to swap the two images place them in the right order.

                Using Flatten for adding generated Shadow Images is not recommended, as generated shadow images can have negative image offsets.

            The recommended solution, as given in the section on Shadow Images, is to use the more advanced Layer Merging technique, we will look at later.

            Because the Virtual Canvas consists of just a size, the resulting image will be that size, but have no virtual canvas offset, as such you do not need to worry about any offsets present in the final image.

            This use of the virtual canvas to define the canvas on which to overlay the image means you can use it to add a surrounding border to an image. For example here I set an image's size and virtual offset to 'pad out' an image to a specific size.


              convert medical.gif -set page 64x64+20+20 \
                      -background SkyBlue   -flatten   flatten_padding.gif

                [IM Output]

            Of course there are better ways to Pad Out an Image so that IM automatically centers the image in the larger area.

            Strangely the exact same handling can be used to 'clip' or Crop an image to a virtual canvas that is smaller than the original image. In this case however you want to use a negative offset to position the 'crop' location, as you are offsetting the image and not positioning the crop 'window'.


              convert  logo:  -repage 100x100-190-60  -flatten  flatten_crop.gif

                [IM Output]

            Of course a Viewport Crop would also do this better, without the extra processing of canvas generation and overlaying that "-flatten" also does. It also will not 'expand' the image itself to cover the whole viewport if the image was only partially contained in that viewing window.

            A common mis-use of the "-flatten" operator is to Remove Transparency from an image. That is to get rid of any transparency that an image may have, but overlaying it on the background color. However this will not work when multiple images are involved as as such no longer recommended.

            Mosaic - Canvas Expanding
            The "-layers mosaic" operator (or its "-mosaic" shortcut) is more like an expanding canvas version of the Flatten Operator. Rather than only creating an initial canvas based on just the canvas size of the initial image, the Mosaic Operator creates a canvas that is large enough to hold all the images (in the positive direction only).

            For example here I don't even set an appropriate Virtual Canvas, however the "-mosaic" operator will work out how big such a canvas needs to be to hold all the image layers.


              convert -page +5+10  balloon.gif   -page +35+30 medical.gif  \
                      -page +62+50 present.gif   -page +10+55 shading.gif  \
                      -background dodgerblue  -layers mosaic  mosaic.gif

                [IM Output]

                As on IM v6.3.6-2 the "-mosaic" operator is only an alias for a "-layers 'mosaic'".

            Thus the "-mosaic" option can be regarded as a short cut for the "-layers" method of the same name.

            Note that both "-mosaic" and "-flatten" still creates a canvas that started from the 'origin' or 0,0 pixel. This is part of the definition of an images 'virtual canvas' or 'page' and because of this you can be sure that the final image for both operators will have a no virtual offset, and the whole canvas will be fully defined in terms of actual pixel data.

            Also note that "-mosaic" will only expand the canvas in the positive directions (the bottom or right edges), as the top and left edge are fixed to the virtual origin. That of course means "-mosaic" will still clip images with negative offsets...


              convert -page -5-10  balloon.gif   -page +35+30 medical.gif  \
                      -page +62+50 present.gif   -page +10+55 shading.gif  \
                      -background dodgerblue  -mosaic  mosaic_clip.gif

                [IM Output]

            Merging - to Create a New Layer Image
            The "-layers merge" operator is almost identical to the previous operators and was added with IM v6.3.6-2. It only creates a canvas image just large enough to hold all the given images at their respective offsets.

            Like Mosaic will also expand the canvas, but not only in the positive direction, but also in the negative direction. Basically it means that you don't have to worry about clipping, offset, or other aspects when merging layer images together. All images will be merged relative to each others location.

            The output does not include or ensure the origin is part of the expanded canvas. As such the output of a Layers Merge can contain a 'layers offset' which may be positive or negative.

            In other words.. Layers Merge merges layer images to produce a new layer image.

            As such if you don't want that offset when finished you will probably want to include a "+repage" operator before the final save.

            For example here is the same set of layer image we have used previously...


              convert -page +5+10  balloon.gif   -page +35+30 medical.gif  \
                      -page +62+50 present.gif   -page +10+55 shading.gif  \
                      -background dodgerblue  -layers merge  +repage layers_merge.gif

                [IM Output]

            As you can see the image is only just big enough to hold all the images which were placed relative to each other, while I discarded the resulting images offset relative to the virtual canvas origin. This preservation of relative position without clipping or extra unneeded space is what make this variant so powerful.

            Lets try this again by giving one image a negative offset...


              convert -page -5-10  balloon.gif   -page +35+30 medical.gif  \
                      -page +62+50 present.gif   -page +10+55 shading.gif  \
                      -background dodgerblue  -layers merge  +repage layers_merge_2.gif

                [IM Output]

            As you can see the "balloon" was not clipped, just moved further away from the others so as to preserve its relative distance to them.

            Of course the "+repage" operator in the above examples, removes the absolute virtual canvas offset in the final image, preserving only the relative image placements between the images. The offset was removed as web browsers often have trouble with image offsets and especially negative image offsets, unless part of a GIF animation.

            But if I did not remove that offset, all the images will remain in their correct location on the virtual canvas within the generated single layer image, allowing you to continue to process and add more images to the merged image. Typically you would use a "-background" color of 'None', to make the unused areas of the merged image transparent.

            When applied to a single image, Layer Merging will replace any transparency in the image with the solid color background, but preserve the images original size, as well as any any offsets in that image, The virtual canvas size of the image however may be adjusted to 'best fit' that images size and offset.

            The operators original purpose was allow users to more easily merge multiple distorted images into an unified whole, regardless of the individual images offset. For example when aligning photos to form a larger 'panorama'. You could simply start with a central undistorted base image (without an offset), and use this operator to overlay the other images around that starting point (using either negative or positive offsets) that have been aligned and distorted to match that central image.

            For other examples of using this operator by distorting images to align common control points, see 3D Isometric Photo Cube, and 3D Perspective Box.

            Other examples of using this operator is to generate a simple series of Overlapping Photos.

            The operation "-layers trim-bounds" can be used to ensure all
            images get a positive offset on a minimal canvas size, while retaining there
            relative positions, and without actually layer merging the images into one
            final image.

            This lets you then perform further processing of the images before they are
            actually merged, such as placing more images relative to the that image group
            but looking up the resulting virtual canvas bounds.

            However if images have a transparency, it is probably a good idea to trim
            that transparency from images first, making the ideal usage...

              -alpha set -bordercolor none -border 1x1 -trim -layers trim-bounds

            This minimizes the image layers including any and all transparent areas of
            actual image data, while ensuring everything is contained on a valid
            virtual (positive) canvas of minimal size.

            Coalesce Composition - a Progressive Layering
            The "-layers coalesce" image operator (or its "-coalesce" shortcut) is really designed for converting GIF animations into a sequence of images. For examples, see Coalescing Animations for details.

            However, it is very closely associated with "-flatten" and has very useful effects for multi-layered images in this regard.

            For example using Coalesce on a single image, will do exact the same job as using Flatten with a "-background" color of 'None' or 'Transparency'. That is it will 'fill out' the canvas of the image with transparent pixels.


              convert  -page 100x100+5+10 balloon.gif -layers coalesce  coalesce_canvas.gif

                [IM Output]

            When dealing with an image consisting on multiple layers, Coalesce can be used to generate a 'Progressive Layering' of the image. But to do this we need to take a few precautions, to disable any 'GIF animation' handling by the operator.


               convert -page 100x100+5+10 balloon.gif   -page +35+30 medical.gif  \
                       -page +62+50       present.gif   -page +10+55 shading.gif  \
                       -set dispose None  -coalesce  miff:- |\
                 montage - -frame 4 -tile x1 -geometry +2+2 \
                         -background none -bordercolor none  coalesce_none.gif

            [IM Output]

            In the above, we "-set" all the "-dispose" settings to 'None'. This effectively tells "-coalesce" to just overlay each frame on top the results of the previous overlays.

            The result is the first image is just a 'fill out' of the images canvas, with a transparency background. The next image is the previous image with that layer overlaid. And so on. A 'progressive' flatten of the image sequence.

            The last image in the sequence will thus be the same as if you did a normal "-flatten" with a transparent background.

            You can get a completely different sort of effect if you had used a "-dispose" setting of 'Background'. In this case "-coalesce" will just 'fill out' the canvas of each image, as if they were completely separate images!


              convert -page 100x100+5+10 balloon.gif   -page +35+30 medical.gif  \
                      -page +62+50       present.gif   -page +10+55 shading.gif  \
                      -set dispose Background  -coalesce  miff:- |\
                montage - -frame 4 -tile x1 -geometry +2+2 \
                        -background none -bordercolor none  coalesce_bgnd.gif

            [IM Output]

            Please note however that unlike Flatten, Mosaic, or Merge the "-coalesce" operator does not make use of the current "-compose" alpha composition setting. It only uses an 'Over' compose method, as this is what is required for GIF animation handling.

            Using different "-compose" methods with the more standard image layering operators is the subject of the next set of examples.

            Compose Methods and Layering
            The three Layering methods: Flatten, Mosaic, and Merge; will make use of the "-compose" setting to determine the composition method used to overlay each image in sequence. As such you could think of these functions as a multi-image "-composite" operator with the ability to set an initial "-background" canvas of a specified color.

            However using anything but the default Alpha Composition of 'Over' requires some thought before applying or you will get unexpected results. You may also may need to think about the effect of the "-background" color that is used by these operators to generate a starting canvas, onto with each image (including the first) in composed.

            For example lets place each successive image under the previous images using a 'DstOver'...


              convert -page 100x100+5+10 balloon.gif   -page +35+30 medical.gif  \
                      -page +62+50       present.gif   -page +10+55 shading.gif  \
                      -background none  -compose DstOver  -flatten  flatten_dstover.gif

                [IM Output]

            Here the background was set to be transparent, otherwise you will only see the background canvas in the result as all the other images will have been placed 'under' this initial canvas! This does provide a way of 'blanking' an image with a particular color, as shown in Canvases Sized to an Existing Image.

            Here is a more practical example. Rather than layering the images with the background canvas first, which awkward and un-natural in some image processing situations, you can just generate the images top-down or foreground to background order.


              convert rose: -repage +10+10 \
                      \( +clone -background black -shadow 60x3+5+5 \) \
                      \( granite: -crop 100x80+0+0 +repage \) \
                      -background none  -compose DstOver -layers merge layer_dstover.gif

                [IM Output]

            Each of the first three lines generates one layer image, with the final line merging all the layers under the previous layers, effectively reversing the order.

            As you can see the image processing for the above was simpler and cleaner than you normally would see with shadow generation, just by underlaying each image in sequence (with a transparent starting canvas)
            Of course I could have just as easily Reverse the image list instead.


              convert rose: -repage +10+10 \
                      \( +clone -background black -shadow 60x3+5+5 \) \
                      \( granite: -crop 100x80+0+0 +repage \) \
                      -reverse -layers merge layer_reverse.gif

                [IM Output]

            However remember that this only re-orders the existing images, and does not effect the 'starting background canvas' that the layering methods create. The compose methods can also be used to produce some interesting effects. For example, if you draw three circles, then by overlaying them using the 'Xor' compose method, you get an unusual and complex looking symbol, for minimal effort.


              convert -size 60x60 \
                      \( xc:none -fill blue   -draw 'circle 21,39 24,57' \) \
                      \( xc:none -fill red    -draw 'circle 39,39 36,57' \) \
                      \( xc:none -fill green  -draw 'circle 30,21 30,3'  \) \
                      -background none  -compose Xor   -flatten  flatten_xor.png

                [IM Output]

            Layers Composite - Merge Two Layer Lists
            With IM v6.3.3-7 the "-layers" method, 'Composite' was added allowing you compose two completely separate sets of images together.

            To do this on the command line a special 'null:' marker image is needed to define where the first destination list of images ends and the overlaid source image list begins. But that is the only real complication of this method.

            Basically each image from the first list is composed against the corresponding image in the second list, effectively merging the two lists together.

            The second list can be positioned globally relative to the first list, using a Geometry Offset, just as you can with a normal Composite Operator (see above). Gravity is also applied using the canvas size of the first image, to do the calculations.

            On top of that 'global offset', the individual virtual offset of image is also preserved, as each pair of images is composited together.

            One special case is also handled. If one of the image lists contains only one image, that image will be composed against all the images of the other list. Also in that case the image meta-data (such as animation timings) of larger list is what will be kept, even if it is not the destination side of the composition.


            This laying operator is more typically used when composing two animations, which can be regarded as a sort of time-wise layered image list. Because of this it is better exampled in the Animation Modifications section of the examples. So see Multi-Image Alpha Composition for more details.

            Handling Image Layers
            Laying multiple images using the various layer operators above is a very versatile technique. It lets you work on a large number of images individually, and then when finished you combine them all into a single unified whole.

            So far we have shown various ways of merging (composing or layering) multiple images in many different ways. Here I provide some more practical examples on just how to make use of those techniques.

            Layering Of Thumbnail Images
            You can also use this technique for merging multiple thumbnails together in various complex ways.

            Here I add a Soft Edge to the images as you read and position them, you can generate a rather nice composition of images, on a Tiled Canvas.


              convert -page +5+5    holocaust_tn.gif \
                      -page +80+50  spiral_stairs_tn.gif \
                      -page +40+105 chinese_chess_tn.gif \
                      +page \
                      -alpha Set -virtual-pixel transparent \
                      -channel A -blur 0x10  -level 50,100% +channel \
                      \( -size 200x200 tile:tile_fabric.gif -alpha Set \) -insert 0 \
                      -background None -flatten  overlap_canvas.jpg

            [IM Output]

            Calculated Positioning of Images.
            The Virtual Canvas Offset (page) can be set in many ways. More specifically you can "-set" set this per-image Attribute, and even calculate a different location for each and every image.

            For example here I read in a big set of images (small icon images all the same size) and arrange them in a circle.


              convert {balloon,castle,eye,eyeguy,ghost,hand_point,medical}.gif \
                      {news,noseguy,paint_brush,pencil,present,recycle}.gif \
                      {shading,skull,snowman,storm,terminal,tree}.gif \
                      \
                      -set page '+%[fx:80*cos((t/n)*2*pi)]+%[fx:80*sin((t/n)*2*pi)]' \
                      \
                      -background none -layers merge +repage image_circle.png

            [IM Output]

            The key to the above example is the "-set page" operation that uses the normalized image index (the FX Expression 't/n' ) to create a value from 0.0 to not quite 1.0 for each individual image. This value is then mapped to position the image (by angle) in a circle of 80 pixels radius, using FX Expressions as a Percent Escape.

            The position calculated is of the top-left corner of the image (not its center, though that is a simple adjustment), which is then Merged to generate a new image. The positioning is done without regard of the offset being positive or negative, which is the power of the Merge Laying Operator. That is we generated a new image of all the images as they are relative to each other.

            The final "+repage" removes the final resulting negative offset of the merged layer image, as this is no longer needed and can cause problems when viewing the resulting image.

            Note that the first image (right-most in result) is layered below every other image. If you want the layering to be truly cyclic so the last image was below this first one, you may have to divide that first image in half and put the top half at the end of the sequence so the top half of the first image layers over last image, while the lower half remains below the second image.

            This technique is powerful, but it can only position images to an integer offset. If you need more exact sub-pixel positioning of images then the images will need to be distorted (translated) to the exact sub-pixel location rather than simply adjusting its virtual offset.

            Incrementally Calculated Positions
            You can access some image attributes of other images using FX expressions, while setting the attribute of images as they are processed. This means that you can set the location of each image, relative the calculated position of the previous image.

            For example this sets the position of each image to be to the right of the previous image. That is the previous image's position plus its width.


              convert  rose: netscape: granite: \
                      \
                      +repage -set page '+%[fx:u[t-1]page.x+u[t-1].w]+0' \
                      \
                      -background none -layers merge +repage append_diy.png

            [IM Output]

            Each image is appended to the location of the previous image, by looking up that location and adding that images width. This previous location was in fact just calculated, as IM looped through each image setting the 'page' (virtual offset) attribute. The result is a DIY Append Operator equivalent, and from which you can develop your own variations.

            You should note that the whole sequence is actually shifted by 'u[-1].w' set during the position calculation of the first image. This should be the width of the last image in the current image sequence. That overall displacement however is junked by the final "+repage". You can use some extra calculation to have it ignore this offset, but it isn't needed in the above.

                When using an image index such as 'u[t]' all image selectors 'u', 'v', and 's', all references the same image, according to the '[index]' given. As such it is better to use 'u' (the first or zeroth image) as a mnemonic of this indexing behaviour (and in case this changes).

            For more information see FX, The DIY Image Operator.

            Here is another example. Each image is offset relative to the previous image, using both position and width of that image, so as to calculate a Overlapped Append.


            convert font_[0-9].gif \
                    -set page '+%[fx:u[t-1]page.x+u[t-1].w-8]+%[fx:u[t-1]page.y+4]' \
                    -background none -layers merge +repage append_offset.gif

            [IM Output]

            This ability to access attributes of other images, also includes the pixel data of other images. That means you could create a special image where the color values represent the 'mapped positions' of the other images. Of course that 'mapping' image would also be positioned, and would need to be removed before the overlay is performed. How useful creating special 'mapped position' images is another matter. It is just another possibility.

            Two Stage Positioning of Images
            You can simplify your image processing, by separating them into two steps. One step can be used to generate, distort, position and add fluff to images, with a final step to merge them all together. For example, lets create Polaroid Thumbnails from the larger original images in Photo Store, processing each of them individually (keeping that aspect separate and simple).


              center=0   # Start position of the center of the first image.
                         # This can be ANYTHING, as only relative changes are important.

              for image in ../img_photos/[a-m]*_orig.jpg
              do

                # Add 70 to the previous images relative offset to add to each image
                #
                center=`convert xc: -format "%[fx: $center +70 ]" info:`

                # read image, add fluff, and using centered padding/trim locate the
                # center of the image at the next location (relative to the last).
                #
                convert -size 500x500 "$image" -thumbnail 240x240 \
                        -set caption '%t' -bordercolor Lavender -background black \
                        -pointsize 12  -density 96x96  +polaroid  -resize 30% \
                        -gravity center -background None -extent 100x100 -trim \
                        -repage +${center}+0\!    MIFF:-

              done |
                # read pipeline of positioned images, and merge together
                convert -background skyblue   MIFF:-  -layers merge +repage \
                        -bordercolor skyblue -border 3x3   overlapped_polaroids.jpg

            [IM Output]

            The script above seem complicated but isn't really. It simply generates each thumbnail image in a loop, while at the same time center pads (using Extent) and Trims each image so that the images 'center' is in a known location on the virtual canvas. It could actually calculate that postion, though that may require temporary files, so it is better to ensure it is in a well known location, for all images.

            The image is then translated (using a relative "-repage" operator, see Canvas Offsets), so that each image generated will be exactly 60 pixels to the right of the previous image. That is, each image center is spaced a fixed distance apart, regardless of the images actual size, which could have changed due to aspect ratios and rotations.

            The other major trick with this script is that rather than save each 'layer image' into a temporary file, you can just write the image into a pipeline using the MIFF: file format. A method known as a MIFF Image Streaming.

            This works because the "MIFF:" file format allows you to simply concatenate multiple images together into a single data stream, while preserving all the images meta-data, such as its virtual canvas offset.

            This technique provides a good starting point for many other scripts. Images can be generated, or modified and the final size and position can be calculated in any way you like.

            Another example is the script "hsl_named_colors" which takes the list of named colors found in ImageMagick and sorts them into a chart of those colors in HSL colorspace. You can see its output in Color Specification.

            Other possibilities include...

                Use any type of thumbnail (or other Fluff), or just simply use a raw small thumbnail directly.
                Generate images so the first image is centered and the other images are arrange to the left and right under that first image, like a pyramid.
                Position images into Arcs, Circles and spirals, by placing them at specific X and Y coordinates relative to each other. For example: PhD Circle, Sunset Flower, Fibonacci Spiral.
                Position images according to their color. For example: Book Covers.
                Position images by time of day or time submitted. For example: Year of Sunsets 

            Basically you have complete freedom in the positioning of images on the virtual canvas, and can then simply leave IM to sort out the final size of the canvas needed to whole all the images.

            Pins in a Map
            Here is a typical layering example, placing coloured pins in a map, at specific locations.

            [IM Output] To the left is a 'push pin' image. The end of the pin is at position +18+41.

            I also have an image of a Map of Venice, and want to put a pin at various points on the map. For example 'Accademia' is locate at pixel position, +160+283.

            To align the push-pin with that position you need to subtract the location of the end of the pin from map position. This produces an offset of +142+242 for our 'pin' image.

            Here is the result, using layered images


              convert map_venice.jpg    -page +142+242 push_pin.png \
                      -flatten  map_push_pin.jpg

            [IM Output]

            This example was from an IM Forum Discussion, Layering Images with Convert.

            Lets automate this further.

            We have a file listing the locations and colors for each of the pins we want to place in the map. The location name in the file is not used and is just a reference comment on the pixel location listed.
            [Data File]

            Lets read this text file, to create 'pins' in a loop.



              pin_x=18  pin_y=41

              cat map_venice_pins.txt |\
                while read x y color location; do

                  [ "X$x" = "X#" ] && continue   # skip comments in data

                  x=$(( x - pin_x ))    # convert x,y to pin image offsets
                  y=$(( y - pin_y ))

                  # convert 'color' to settings for color modulate (hue only)
                  # assumes a pure 'red' color for the original push pin
                  mod_args=$(
                     convert xc:$color -colorspace HSL txt: |
                       tr -sc '0-9\012' ' ' |\
                         awk 'NR==1 { depth=$3 }
                              NR==2 { hue=$3;
                                      print  "100,100,"  100+200*hue/depth
                                    }'; )

                  # re-color and position the push pin
                  convert push_pin.png -repage +${x}+${y} -modulate $mod_args miff:-

                done |\
                  # read pipeline of positioned images, and merge together
                  convert  map_venice.jpg  MIFF:-  -flatten  map_venice_pins.jpg

            [IM Output]

            Note it assumes the original pin color is red ( which has a hue of 0 ) and uses the Modulate Operator to re-color it to other colors, with the appropriate scaling calculations. Note that the modulate argument for a no-op hue change is 100, with it cycling over a value of 200 (a sort of pseudo-percentage value).

            FUTURE: perspective distort map, adjust pin size for 'depth' on the map calculate change in pin position due to distortion, and 'pin' it to the distorted map.

            The above used a method known as a MIFF Image Streaming, with each image generated individually in a loop, then 'piped' into the 'layering' command to generate the final image.

            The alternative method (commonly using in PHP scripts) is to use a 'generated command' technique, that uses a shell script to generate a long "convert" command to be run. The scripts in Image Warping Animations use this technique.

            Both methods avoid the need to generate temporary images.

            Layers of Shadows
            Correctly handling semi-transparent shadow effects in a set of overlapping images is actually a lot more difficult than it seems. Just overlaying photos with shadows will cause the shadows to be applied twice. That is two overlapping shadows become very dark, where in reality they do not overlay together in quite the same way that the overlaying images do.

            The various parts of the image should be simply shadowed or not shadowed. That is shadows should be applied once only to any part of the image. You should not get darker areas, unless you have two separate light sources, and that can make things harder still.

            Tomas Zathurecky < tom @ ksp.sk > took up the challenge of handling shadow effects in layered images, and developed image accumulator technique, to handle the problem.

            Basically we need to add each image to the bottom of stack one at a time. As we add a new image the shadow of all the previous images needs to darken the new image, before it is added to the stack. However only the shadow falling on the new image, needs to be added. Shadows not falling on the new image needs to be ignored until later, when it falls on some other image, or the background (if any).

            Here is an example...


              convert \
                \( holocaust_tn.gif -frame 10x10+3+3 \
                      -background none  -rotate 5 -repage +0+0 \) \
                \
                \( spiral_stairs_tn.gif -frame 10x10+3+3 \
                      -background none -rotate -15 -repage -90+60 \) \
                \( -clone 0   -background black -shadow 70x3+4+7 \
                   -clone 1   -background black -compose DstATop -layers merge \
                   -trim \) \
                \( -clone 2,0 -background none  -compose Over -layers merge \) \
                -delete 0--2 \
                \
                \( chinese_chess_tn.gif -frame 10x10+3+3 \
                      -background none -rotate 20 -repage +60+90 \) \
                \( -clone 0   -background black -shadow 70x3+4+7 \
                   -clone 1   -background black -compose DstATop -layers merge \
                   -trim \) \
                \( -clone 2,0 -background none  -compose Over -layers merge \) \
                -delete 0--2 \
                \
                \( +clone -background black -shadow 70x3+4+7 \) +swap \
                -background none -compose Over -layers merge +repage \
                layers_of_shadows.png

                [IM Output]

            The above program seems complex, but is actually quite straight forward.

            The first image is used to start an accumulating stack of images (image index #0).

            Note we could have actually started with a single transparent pixel ("-size 1x1 xc:none"), if you don't want to use that first image to initialize the stack.

            Now to add a new image to the bottom of the image stack, we apply the same set of operations, each time...

                First the thumbnail image is read into memory, and any rotations, relative placements (may be negative), is applied. You could also do apply other thumbnailing operations to the image at this point if you want, though for his example that have already been performed. The new image forms image index #1.
                We now grab the previous stack of images (#0), generate a shadow with appropriate color, blur, offset, and ambient light percentage.
                This shadow is overlaid on the new image (#1) so only the shadow that falls 'ATop' the new image is kept. We also (optionally) apply a Trim Operation the result to remove any extra space added from the shadowing operation, to form image #2.
                Now we simply add the new image (#2) to the accumulating stack of images (#0).
                and delete all the previous working images, except the last. 

            To add more images we basically just repeat the above block of operations.

            After all the images has been added to the stack, it is simply a matter of doing a normal shadowing operation on the accumulated stack of images. removing any remaining image offsets (which many web browsers hate).

            Using Merge I can automatically handle virtual offsets, especially negative ones, allowing to to simply place images anywhere you like relative to the previous image placements. It also make applying shadows which can generate larger images with negative offsets properly.


            Now the above handles multi-layered image shadows properly, but while the shadow is offset, it is actually offset equally for all the images!

            What really should happen is that the shadow should become more offset and also more blurry as it falls on images deeper and deeper in the stack. That is an image at the top should case a very blurry shadow on the background, compared to the bottom-most image.

            This is actually harder to do as you not only need to keep a track of the stack of images, you also need to keep a track of how 'fuzzy' the shadow has become as the stack of images becomes larger. Thus you really need two accumulators. The image stack (as above), and the shadow accumulation, as we add more images.

            For example here is the same set of images but with shadows that get more blurry with depth.


              convert xc:none xc:none \
                \
                \( holocaust_tn.gif -frame 10x10+3+3 \
                      -background none  -rotate 5 -repage +0+0 \) \
                \( -clone 1   -background black -shadow 70x0+0+0 \
                   -clone 2   -background black -compose DstATop -layers merge \
                   -clone 0   -background none  -compose Over    -layers merge \) \
                \( -clone 2,1 -background none  -compose Over    -layers merge \
                              -background black -shadow 100x2+4+7 \) \
                -delete 0-2 \
                \
                \( spiral_stairs_tn.gif -frame 10x10+3+3 \
                      -background none -rotate -15 -repage -90+60 \) \
                \( -clone 1   -background black -shadow 70x0+0+0 \
                   -clone 2   -background black -compose DstATop -layers merge \
                   -clone 0   -background none  -compose Over    -layers merge \) \
                \( -clone 2,1 -background none  -compose Over    -layers merge \
                              -background black -shadow 100x2+4+7 \) \
                -delete 0-2 \
                \
                \( chinese_chess_tn.gif -frame 10x10+3+3 \
                      -background none -rotate 20 -repage +60+90 \) \
                \( -clone 1   -background black -shadow 70x0+0+0 \
                   -clone 2   -background black -compose DstATop -layers merge \
                   -clone 0   -background none  -compose Over    -layers merge \) \
                \( -clone 2,1 -background none  -compose Over    -layers merge \
                              -background black -shadow 100x2+4+7 \) \
                -delete 0-2 \
                \
                \( -clone 1 -background black -shadow 70x0+0+0 \
                   -clone 0 -background none -compose Over -layers merge \) \
                -delete 0-1 -trim +repage \
                layers_of_deep_shadows.png

                [IM Output]

            Look carefully at the result. The offset and blurriness of the shadow is different in different parts of the image. It is very thin between images in adjacent layers, but very thick when it falls on an image, or even the background much deeper down.

            Of course in this example, the shadow offset is probably too large, but the result seems very realistic giving a better sense of depth to the layers.

            Note how we split the operation of shadow into two steps. When applying the accumulated shadow (image index #1) to the new image (#2), we only add the ambient light percentage, without any blur, or offset ('70x0+0+0' in this case).

            The new image is then added to the accumulating stack of images (#0).

            But after adding new images (#2) shadow directly to the accumulated shadow (#1), again without blur or offset, only then do we blur and offset ALL the shadows, to form the new accumulated shadow image.

            In other words, the accumulated shadow image becomes more and more blurry and offset as the stack gets thicker and thicker. Only the shadow of deeper images has not accumulated the effect as much.

            This program essentually separates the application of the shadow, from the incremental shadow accumulator. This allows you control things like...

                Realistic Shadow (as above): 70x0+0+0 and 100x2+4+7
                Constant Shadow (as basic example): 70x2+4+7 and 100x0+0+0
                constant blur, but cumulative offset: 70x2+0+0 and 100x0+4+7
                both constant and progressive offset: 60x0+4+7 and 100x0+1+1
                cumulative ambient light effect: 80x0+0+0 and and 95x2+4+7 

            Most of them are probably unrealistic, but may look good in another situations. Also setting the "-background" color before the "-compose ATOP" composition will let you define the color of the shadow (actually a colored ambient light).

            You can even even use a different color for the shadow that eventually falls on the final background layer (the last "-background black" setting), or leave it off entirely to make it look like the images are not above any background at all (that is floating in mid-air).

            It is highly versitile.


            Tomas Zathurecky went on to develop another method of handling the shadows of layered images, by dealing with a list of layered images as a whole. Something I would not have considered posible myself.

            The advantage of this method is that you can deal with a whole list of images as a whole, rather than having to accumulate one image at a time, and repeating the same block of operations over and over.

            First lets again look at the simplier 'contant shadow' problem.


              convert \
                \( holocaust_tn.gif -frame 10x10+3+3 \
                      -background none  -rotate 5 -repage +0+0 \) \
                \( spiral_stairs_tn.gif -frame 10x10+3+3 \
                      -background none -rotate -15 -repage -90+60 \) \
                \( chinese_chess_tn.gif -frame 10x10+3+3 \
                      -background none -rotate 20 -repage +60+90 \) \
                \
                -layers trim-bounds \
                \
                \( -clone 0--1 -dispose None -coalesce \
                   -background black -shadow 70x2+4+7 \
                   xc:none +insert null: +insert +insert xc:none \) \
                -layers trim-bounds -compose Atop -layers composite \
                \
                -fuzz 10% -trim \
                -reverse -background none -compose Over -layers merge +repage \
                coalesced_shadows.png

                [IM Output]

            The first block of opertors is just generating the list of layered images. It could be a separate programmed loop, as shown previously.

            The the operation starts with a "-layers trim-bounds", a Bounds Trimming operation that expands the virtual canvas of all images so as to contain all the images, and also ensure all offsets are positive.

            This is then cloned, Coalesced and shadowed to create a separate progressing list of shadows.

            Now we can use Layer Compostion to merge the shadows and the original list of images together. The complication here is that before merging we need to not only add a special 'null:' marker image to divide the two lists, but also add a special blank image 'xc:none' so as to offset the shadow list. that way each shadow image will be overlaid 'ATop' the next image of the original list.

            All that is left is to merge the now correctly shadowed images from bottom to top (Reverse) order.


            To handle 'deep shadows' requires Layer Calculations.


              convert \
                \( holocaust_tn.gif -frame 10x10+3+3 \
                      -background none  -rotate 5 -repage +0+0 \) \
                \( spiral_stairs_tn.gif -frame 10x10+3+3 \
                      -background none -rotate -15 -repage -90+60 \) \
                \( chinese_chess_tn.gif -frame 10x10+3+3 \
                      -background none -rotate 20 -repage +60+90 \) \
                \
                \( -clone 0--1 \
                   -set page '+%[fx:page.x-4*t]+%[fx:page.y-7*t]' -layers merge \) \
                -layers trim-bounds +delete \
                \
                \( -clone 0--1 \
                   -set page '+%[fx:page.x-4*t]+%[fx:page.y-7*t]' \
                        -dispose None -coalesce \
                   -set page '+%[fx:page.x+4*t]+%[fx:page.y+7*t]' \
                        -background black -shadow 70x2+4+7 \
                   xc:none +insert null: +insert +insert xc:none \) \
                -layers trim-bounds -compose Atop -layers composite \
                \
                -fuzz 10% -trim \
                -reverse -background none -compose Over -layers merge +repage \
                coalesced_deep_shadows.png

                [IM Output]

            You can see the same set of blocks that was used previously, but with much more complicated caculations to set the initial Bounds Trimming, and later calculate the offsets needed for the 'progressive shadow list'.

            However the shadow currently does not become more blurry with depth.

                The above will be a lot simplier using the IMv7 "magick" command, which would allow you to use 'fx calculations' directly the argument to "-shadow", that would let you not only calculate a larger offset for the shadow with depth, but also let you mak ethe shadow more blurry with depth.

            Positioning Distorted Perspective Images
            Aligning distorted images can be tricky, and here I will look at aligning such images to match up at a very specific location. Here I have two images that highlight a specific point on each image.
            [IM Output] [IM Output]

            The second image is 65% semi-transparent, which allow you to see though it when it is composed onto the blue image, so you can see if the marked points align. The marked control points themselves are at the coordinates 59,26 (blue) and 35,14 (red) respectively.

            If you are simply overlaying the two images, you can just subtract the offsets and 'compose' the two image on top of each other, producing an offset of +24+12.


              convert align_blue.png align_red.png -geometry +24+12 \
                      -composite align_composite.png

                [IM Output]

            Note that this offset could be negative! And that is something we will deal with shortly.

            This only works as the coordinates are integer pixel coordinates. If the matching coordinates are sub-pixel locations (as is typically the case in a photo montage), simple composition will not work. It will also not work well if any sort of distortion is involved (which is also common for real-life images). And this is the problem we will explore.


            When distorting the image, you will want to ensure the two pixels remain aligned. The best way to do that would be to use the points you want to align as Distort Control Points. This will ensure they are positioned properly.


              convert align_blue.png \
                      \( align_red.png -alpha set -virtual-pixel transparent \
                         +distort SRT '35.5,14.5  1 75  59.5,26.5' \
                      \) -flatten  align_rotate.png

                [IM Output]

            As distort generates a 'layer image' with a 'canvas offset' you can not simply use Composite to overlay the images (too low level), instead we need to use a Flatten operator, so that it will position them using the distort generated offset.

            Note how I also added a value of 0.5 to the 'pixel' coordinates. This is because pixels have area, while mathematical points do not, as such if you want to align the center of a pixel, you need to add 0.5 to the location of the center 'point' within the pixel. See Image Coordinates vs Pixel Coordinates for more information.

            The other problem with the above was that the overlaid image was 'clipped' by the blue background canvas image, just as the Composite Operator does. That is to say the 'blue' image provided the 'clipping viewport' for the result during the composition. To prevent this we use Layer Merge instead which automatically calculates a 'viewport' canvas that is large enough contain hold all the images being composted together.


              convert align_blue.png \
                      \( align_red.png -alpha set -virtual-pixel transparent \
                         +distort SRT '35.5,14.5  1 75  59.5,26.5' \
                      \) -background none -layers merge +repage  align_rotate_merge.png

                [IM Output]

            As the result of the 'merge' the image will have a 'negative' offset (so as to preserve layer positions of the images). To display the results I needed to junk that offset as many browsers do not handle negative offsets in images. I do this using "+repage" before saving the final image. If I was going to do further processing (without displaying the result on the web) I would keep that offset (remove the "+repage"), so the image positions remains in their correct and known position for later processing.


            Now the same techniques as shown above would also apply if you were doing a more complex distortion such as Perspective.


              convert align_blue.png \
                      \( align_red.png -alpha set -virtual-pixel transparent \
                         +distort Perspective '35.5,14.5  59.5,26.5
                                   0,0 32,4    0,%h 14,36    %w,%h 72,53  ' \
                      \) -background none -layers merge +repage  align_perspective.png

                [IM Output]

            The problem with this technique is that you position the perspective distortion using an internal control point. That is one point in the inside of the image, and 3 points around the edge. That can make it hard to control the actual perspective shape, as a small movement of any control point can make the 'free corner' move wildly.

            This situation can be even worse if you are using a large list of 'registered points' to get a more exact 'least squares fit' to position images. In that case the point you are interested in be no wehere near one of the control 'registered' points used to distort the image.

            The alternative is to simply distort the image the way we need to, then figure out how we need to translate the resulting image to align the points we are interested in. To make this work we will need to know how the 'point of interest' moved as a result of the distortion. This is real problem with distorting and positioning images, especially real life images.

            For example, here I distort the image using all four corners to produce a specific (suposedally desired) distortion shape, but I will not try to align the control points at this point, just apply the distortion...


              convert align_blue.png \
                      \( align_red.png -alpha set -virtual-pixel transparent \
                         +distort Perspective '0,0  10,12  0,%h 14,40
                                           %w,0 68,6  %w,%h 63,48 ' \
                      \) -background none -layers merge +repage  align_persp_shape.png

                [IM Output]

            As you can see while the red image was distorted, the position of the red control point is no where near the blue control point we want to align. You can not just simply measure these two points as the red point is unlikely to be at an exact pixel position, but will have a sub-pixel offset involved. We will need to first calculate exactly where the red point is.

            To do that we can re-run the above distortion with verbose enabled to get the perspective forward mapping coefficients. These can then be used to calculate as described in Perspective Projection Distortion.


              convert align_red.png  -define distort:viewport=1x1  -verbose \
                      +distort Perspective '0,0  10,12  0,%h 14,40
                                            %w,0 68,6  %w,%h 63,48 ' null:

            [IM Text]

            All we want is just the calculated coefficients used by the distortion. As such we don't need the destination image, so we just the output using a "null:" image file format. We also tell the distort that the new image it is generating is only one pixel is size using a Distort Viewport. That way it does the distortion preparation and verbose reporting, but then only distorts a single 'destination' pixel, which is then junked. This can save a lot of processing time.

            Actually if the distortion did not use source image meta-data (needed for the percent escapes '%w' and '%h') as part of its calculations, we would not even need the source image "align_red.png". In that case we could have used a single pixel "null:" image, for the input image too.

            We are also not really interested in the virtual pixels, backgrounds, or anything else for this information gathering step, so we don't need to worry about setting those features.


            Now we can get the distort information, we need to extract the 8 perspective coefficients, from the 3rd and 4th line of the output. These can then be used to map the red control point to its new distorted position, and from there subtract it from the blue control point, so as to get the actual amount of translation that is needed, to align the marked red coordinate with the blue coordinate.


              bluex=59; bluey=26
              redx=35; redy=14

              convert align_red.png  -verbose \
                         +distort Perspective '0,0  10,12  0,%h 14,40
                                           %w,0 68,6  %w,%h 63,48 ' null: 2>&1 |\
                tr -d "',"  |\
                  awk 'BEGIN   { redx='"$redx"'+0.5;   redy='"$redy"+0.5';
                                 bluex='"$bluex"'+0.5; bluey='"$bluey"'+0.5; }
                       NR == 3 { sx=$1; ry=$2;  tx=$3; rx=$4; }
                       NR == 4 { sy=$1; ty=$2;  px=$3; py=$4; }
                       END { div =  redx*px + redy*py + 1.0;
                             dx = ( redx*sx + redy*ry + tx ) / div;
                             dy = ( redx*rx + redy*sy + ty ) / div;
                             printf "red point now at %f,%f\n", dx, dy;
                             printf "translate shape by %+f %+f\n", bluex-dx, bluey-dy; }'

            [IM Text]

            The above used the "tr" text filter to remove extra quotes and commas from the output. It then uses the "awk" program to extract the coefficients, and do the floating point mathematics required to 'forward map' the red marker to match the blue marker.

            Note that I again added 0.5 to the 'pixel coordinates' of the control points to ensure that the center of the pixel is what is used for the calculations. See Image Coordinates vs Pixel Coordinates.

            Now we know the amount of translation needed by the distorted image, we have two ways you add that translation to the distortion. Either by modifying the coefficients of the perspective projection appropriately (not easy). Or we could just add the translation amounts to each of the destination coordinates of the original (very easy).

            Here is the result of the latter (add translations to destination coordinates)...


              convert align_blue.png \
                      \( align_red.png -alpha set -virtual-pixel transparent \
                         +distort Perspective '0,0   31.408223,15.334305
                                               0,%h  35.408223,43.334305
                                               %w,0  89.408223, 9.334305
                                               %w,%h 84.408223,51.334305 ' \
                      \) -background none -layers merge +repage  align_persp_move.png

                [IM Output]

            To the right I have cropped and scaled the result around the control points to show they are perfectly aligned!


              convert align_persp_shape.png -crop 19x19+50+17 +repage \
                      -scale 500%   align_persp_shape_mag.png

                [IM Output]

            As you can see we have a perfect alignment of the two pixels, without any sub-pixel overflow to any one side. Even the smallest miss-alignment would show as an asymmetrical coloring on either side of the central pixel.

            This scaling even shows a slight asymmetrical difference between left and right sides of the red cross due to the perspective distortion. That is how accurate this pixel level view test is.


            A similar but simpler problem is looked at in Text Positioning using Distort.


            Evaluate-Sequence - Direct Mutli-Image Merging Methods
            The "-evaluate-sequence" methods, are designed to merge multiple images of the same size together in very specific ways.

            In some ways it is a blend of the Evaluate and Function Operators combined with multi-image Composition techniques we have seen above. Many of the methods provided can even be performed using normal multi-image layering composition techniques, but not all.

            The operator uses the same methods as "-evaluate" so you can get a list of them using "-list Evaluate". Though some of these (such as 'Mean' and 'Medium') are really only useful when used with this operator.

            Mean (Average) of multiple images
            Essentially both the older "-average" and the newer "-evaluate-sequence mean" will create an average of all the images provided.

            For example, here is an average of the rose image using all its Flipped and Flopped versions.


              convert rose: -flip rose: \( -clone 0--1 -flop \) \
                      -evaluate-sequence mean  average.png

                [IM Output]

            Averaging hundreds of images of the same fixed scene, can be used to remove most transient effects, such moving people, making them less important. However areas that get lots of transient effects may have a 'ghostly blur' left behind that may be very hard to remove.

            As video sequences are notoriously noisy when you look at the individual frames, you can average a number of consecutive, but unchanging, frames together to produce much better cleaner and sharper result.

            Matt Leigh, of the University of Arizona, reports that he has used this technique to improve the resolution of microscope images. He takes multiple images of the same 'target' then averages them all together to increase the signal/noise ratio of the results. He suggests others may also find it useful for this purpose.

            An alternative for averaging two images together is to use a "composite -blend 50%" image operation, which will work with two different sized images. See the example of Blend Two Images Together for more detail.

            The IM Discussion Forum had a discussion on Averaging a sequence 10 frames at a time, so as to average thousands of images, without filling up the computers memory (making it very slow). Related to this, and containing relevent maths is the discussion Don't load all images at once.

            Another alternative to using 'mean' is to use the newer Poly Operator, which can individually weight each image.

            Max/Min Value of multiple images
            The 'Max' and 'Min' methods will get the maximum (lighter) values and minimum (darker) values from a sequence of images.

            Again they are basically equivalent to using a Lighten and Darken Composition Methods, but with multiple images. With the right selection of background canvas color, you could use Flatten Operator with the equivelent compose method.


              convert rose: -flip rose: \( -clone 0--1 -flop \) \
                      -evaluate-sequence max  max.png

                [IM Output]


              convert rose: -flip rose: \( -clone 0--1 -flop \) \
                      -evaluate-sequence min  min.png

                [IM Output]

            WARNING: This is not a selection of pixels (by intensity), but a selection of values. That means the output image could result in the individule red, green and blue values from different images, resulting in a new color not found in any of the input images.

            If you need the pixels selected by their max/min by intensity, see the Lighten by Intensity Compose Method.

            Median Pixel by Intensity
            The "-evaluate-sequence Median" will look for the pixel which has an intensity of the middle pixel from all the images that are given.

            That is for each position it collects and sorts the pixel intensity from each of the images. Then it will pick the pixel that falls in the middle of the sequence.

            It can also be used as an alternative to simply averaging the pixels of a collection of images.

            This could be used for example by combining an image with two upper and lower 'limiting' images. As the pixel will be the middle intensity you will either get the pixel from the original image, or a pixel from the 'limiting' images. In other words you can use this to 'clip' the intensity of the original image. Strange but true.

            For an even number of images, the pixel on the brighter side of the middle will be selected. As such with only two images, this operator will be equivalent to a pixel-wise "lighten by intensity".

            The key point is that each pixel will come completely from one image, and sorted by intensity. The exact color of each pixel will come completely from one of the given images, as such no new colors are generated.

            For example, here is pixels of median intensity of the rose image using all its Flipped and Flopped versions. Note how it isn't as smooth, but could get sharp boundaries, as it is basied on intensities of the pixels.


              convert rose: -flip rose: \( -clone 0--1 -flop \) \
                      -evaluate-sequence median  median.png

                [IM Output]

            Add Multiple Images
            The 'Add' method is will of course simply add all the images together.


              convert ... -evaluate-sequence add ...

            Which is a faster (more direct) version of using Flatten to Plus Compose all the images together...


              convert ... -background black -compose plus -layers flatten ...

            Be warned that adding images in this way can very easilly overflow the Quantum Range of the image, and as such it may get 'clipped', unless you use a HDRI version of IM. This is why an Average, or Mean is generally used instead, as this will divide all images equally to ensure the resulting image is not clipped. Another alturnative is to use the newer Poly Operator, which can individually weight each image.

            Subtract Multiple Images
            The 'Subtract' method subtracts each image from the first. Or at least that is what it should do. Internally it has arguments swapped and it is subtracting the previous results from the next image. Arrggggg!

            However by using a quirk of the Linear Burn Compose Method you can subtract the second and later images from the first. Basically by Negating all but the first image, and setting a 'white' (negated zero) as a the starting background color you can then use Flatten to subtract all the images from the first.


              convert  ...  \
                     -negate \( -clone 0 -negate \) -swap 0 +delete \
                     -compose LinearBurn -background white -flatten \
                     ...

            Multiple/Divide Multiple Images
            'Multiply' and 'Divide' are accepted as methods by "-evaluate-sequence" but they generate unexpected and odd results, as they are using the actual color value of the images rather than the normalised color value, just as "-evaluate" does. As a result the scale of the multiply and divide is too large.

            This could be classed as a bug.

            In the meantime, you are better using the equivelent 'flatten' method for Multiply, which does work as expected.


              convert ... -background white -compose multiply -layers flatten ...

            Poly - Merge Multiple Images Using a Polynomial
            Closely related to "-evaluate-sequence" and specifically to the 'mean' method (image averaging), is the "-poly" operator (added IM v6.8.0-5).

            This operator is given a list of two numbers for each image in memory, one to provide a multiplicative weight for each image, but also a power-of exponent to each image. This lets you merge a list of images as if each image was the variable input to a polynomial equation. The color values from each image is treated as if they were a normalized 0 to 1 value.

            With each pair of values the image color (normalized) is first powered by the second 'power-of' exponent, then it is weighted (multiplied) by the first number.

            If the exponent is '1' then the value is just multiplied by the given weighting. However if the exponent is '0' the weight becomes the final value, producing a normalized color constant addition (value from 0.0 to 1.0).

            A single pixel image can be provided in the current image sequence, and can be used to add a specific color, with a different normalized color value for each channel. (using a weight and exponent = 1.0). Or you can provide a "NULL:' image (or any other junk image), and use an exponent of 0.0. This will will only add the given weighting factor as constant.

            The final image is generated from the first image (and its size and other meta-data), just as it is with FX DIY Operator.

            For example...


              convert rose: granite: null: -poly '1,1 2,1 -1.0,0' poly_rose.png

                [IM Output]

            This takes a 'rose:' (unmodified using a weight of 1 and power-of 1), adds to this twice the color values from the 'granite:' image (weight=2), and finally subtracts a value of 1 using a 'null:' image, using an exponent of 0 (ignore image input) and a weighting value of -1.0.

            The resulting image is equivalent to...
            rose + 2.0*granite - 1.0
            or
            rose + 2.0*(granite-0.5)

            In other words the rose image is given a noisy granite texture overlay (with a 50% grey bias). This is in fact exactly like a very strong 'Hard_Light' composition lighting effect but with very explicit weighting of the granite overlay.

            The key difference to this over other multi-image operations is the ability to weight each image individually, but perform all calculations in a single image processing operation without the need for extra intermediate images. This avoids any quantum rounding, clipping or other effects on the final results, in a non-HDRI version of ImagMagick. (See Quantum Effects). It can for example be used to perform a weighted average of large numbers of images, such as averaging smaller groups of images, then averaging those groups together.
https://legacy.imagemagick.org/Usage/anim_basics/
            These examples continue the previous example page on Layers of Multiple Images but instead of layering multiple images on top of each other to produce a single image, here we display each image for a short period of time so as to produce an animation of images.

            The following section provides a basic understanding of the complexities of animations and specifically GIF animations. It looks at the basic methods used to generate animations, and how you can study existing animations to get an understanding of how they work.

            This is recommended reading before going further in any of the later animation sections.

            GIF Animations and Animation Meta-data
            The default way ImageMagick handles the output of an image list is to generate a multi-page image. For the GIF image format, however, this takes the special form of a 'GIF animation'.


              convert -delay 100  -size 100x100 xc:SkyBlue \
                      -page +5+10  balloon.gif   -page +35+30 medical.gif  \
                      -page +62+50 present.gif   -page +10+55 shading.gif  \
                      -loop 0  animation.gif

                [IM Output]

            Here is a more advanced 'sparkle' example that uses a shell script "star_field". This script was developed from my experiments in generating random star fields.


              star_field 70x46  stars1.gif
              star_field 70x46  stars2.gif
              star_field 70x46  stars3.gif
              convert rose:   -compose Screen \
                      \( -clone 0 stars1.gif -composite \) \
                      \( -clone 0 stars2.gif -composite \) \
                      \( -clone 0 stars3.gif -composite \) \
                      -delete 0 -set delay 25 -layers Optimize rose_sparkle.gif
              rm stars[123].gif

                [IM Output]

            Basically three random star fields are generated, at the right size, then overlaid onto our image, the IM built-in "rose:", using a 'Screen' alpha composition to brighten the image with the given star patterns. The whole thing is then run though the IM general GIF animation optimizer.

            The above may seem complex as it is using some advanced IM features I have yet to introduce, but the result is a relatively simple, but well optimized three frame animation.

            You can also look at some of the more complex animations that were created using simple shell scripts for Distortion Animations.

            There are a few extra IM settings which were created specifically for use in GIF animations, and knowing about these is the first step into the world of GIF animations...

            -dispose {method}
                What the following images should do with the previous results of the GIF animation. Valid options are 'Undefined', 'None', 'Previous', and 'Background. (See below for explanation of the settings)

            -loop {number} 	Number of times the GIF animation is to cycle though the image sequence before stopping. It is an output 'image write' setting, so can be set anywhere on the command line, though only the last such setting will be used.

            Usually this set by default, to zero (infinite loop), however if any image read in has a different value, then this setting will be set to that images value. As such I recommend that you always set "-loop" when creating a GIF animation, after all the images has been read in.

            For more information see The End of the Loop below.

            -delay {time}   	Set the time delay (in 1/100th of a second) to pause after drawing the images that are read in or created after this setting has been defined.

            You can specify a different scale for the time delay by specifying a 'x' scaling (giving in ticks per second). For example '10x1' is 10, 1 second ticks, while '10x100' is 10, one hundredth of a second ticks.

            Basically the 'x' is equivalent to a fraction '/' sign. For example if you specify '1x160' will set a delay that is appropriate for 160 frames per second.

                GIF animation delays must be specified in hundredths of a second for correct working, which is why that is the default time unit. The 'x' factor is used more for generating other more movie like formats, such a MNG's, and AVI's.

            -set dispose {method}
            -set delay {time}
                While the previous option settings will set image attributes on newly created, or image that are read in, after that option is given, the "-set" option is an operator, that will allow you set image attributes on all images that have already in the current image sequence. This allows you to change the setting over a whole animation, or just a single frame, after the images have been loaded or modified.

            -page {w}x{h}+{x}+{y}
                This lets you set the offset position of the image about to be read in. As this is a setting option, it only applies the geometry you give to images that follow the setting. It does not effect images already read into memory.

            If not given, or turned off using "+page" the offset for the image read will be preserved. If the image does not have an offset it will be positioned at '+0+0' or the top left corner of the working canvas or 'page'.
            It can also be used to define a larger working canvas, by specifying a width 'x' height. Only the width and height page setting of the first image in the sequence will be used to set the overall GIF animation canvas size, all other page size settings will be ignored when the animation is finally written. When a GIF animation is read in the canvas size is set on all the frames in the animation.

            MNG animations can save frame offsets, but does not save canvas sizes. The size of the first image defines the canvas size of the whole animation.

                The GIF image format can not specify a negative offset for images on a canvas. If you try to use a negative offset IM will reset it to zero when that image (or animation frame) is written to a GIF file.

            Positive offsets larger than the image canvas are quite acceptable but may result in the image not appearing in the canvas drawing area when displayed. How a GIF animation display program handles this is undefined. Caution is advised.

            -repage {w}x{h}+{x}+{y}
                This is exactly like "-page" except that it is an image operator instead of a setting. That means you can use this to change or reset the 'page geometry' of an image or animation frame that has already being read into memory.

            The simpler "+repage" form, just resets the 'page geometry' of all images to the actual image in each frame in the current image sequence to a zero offset, and the images actual size. This operation is vital when you are extracting the individual frames from an animation, (See the Adjoin Examples below).

            However "+repage" will destroy a lot of positioning information stored in each image, as such you should also probably extract this information into a separate file for later re-use. See Animation List Information below.

            Important Point
            DO NOT save the intermediate, animations which you are not finished processing, directly to GIF. You can use the IM internal format MIFF, as a temporary file format, if you want to work on an animation in series of separate processing steps.

            I repeat...
            Do not use GIF as an intermediate file format, use MIFF instead

            If you made the big mistake of saving to GIF you would have just made the resulting animation worse, as IM would have now performed an automatic Color Quantization, to reduce the number of colors present. Not only that but it did so on each frame completely independently to every other frame, making any further processing, particularly any GIF optimizations just that much harder.

            Solving this is a complex, multi-level problem, which is looked at in the next section Animation Optimization.

            Frame Disposal Methods
            The first thing people creating GIF animation have trouble with is the "-dispose" setting. This is not surprising as it is a complex setting. Worse still a lot of animation programs, including many web browsers, don't always handle the GIF disposal meta-data setting correctly. However using the right disposal can make a big difference to how well your animation works and optimizes.

            The first thing to remember in ImageMagick is that almost all the special animation options, are settings for image reading. That is they are applied to images that are read in, after, the setting has been given. The "-loop" setting is the only one typically used after the animation has been completed, just before the the animation is saved.

            The basic task of the "-dispose" defines how an image is to be removed, after it has been displayed for its "-delay" time period. That is, you need to give an image's "-dispose" and "-delay" settings before reading the image for that frame. But the action is applied after that image is displayed. This is a little counter intuitive but does make sense in the way IM operates on images.

            If you remember this, you should have no problems.

            The 'plus' forms of these options, like most other settings in IM stops the setting being applied to any images being read in. That means if you don't specify a setting, the frame image will continue to use the setting that was read in with the image (if any).

            This can be important later when you want to read in a GIF animation for further processing. Or when merging one GIF animation into another (the most difficult animation technique).

            Dispose None - each frame overlaid in sequence
            The default "-dispose" setting for GIF animations is 'Undefined' which most animation programs treats the same as a 'None' disposal setting. Basically this tells the computer to just leave whatever is overlaid by this specific frame. Or more precisely, 'do nothing'.

            However please note that the whole canvas is always cleared at the end of the animation sequence, before it loops and repeats.

            Here for example is a standard 'None dispose' animation...


              convert -delay 100 -dispose None \
                          -page 100x100+5+10  balloon.gif  \
                          -page +35+30 medical.gif  \
                          -page +62+50 present.gif  \
                          -page +10+55 shading.gif  \
                      -loop 0  anim_none.gif

                [IM Output]

            This disposal technique is ideal for animations which involve no form of transparency, such as animations drawn on a solid, or patterned background.


              convert -dispose none  -delay 100 \
                            -size 100x100 xc:SkyBlue +antialias \
                            -fill DodgerBlue -draw 'circle 50,50 15,25' \
                            -page +5+10  balloon.gif  \
                            -page +35+30 medical.gif  \
                            -page +62+50 present.gif  \
                            -page +10+55 shading.gif  \
                      -loop 0  canvas_none.gif

                [IM Output]

            Note that this technique can only add visible colors to an animation. It can never actually make any part of an animation transparent again. (See Overlay Animations below).

            To also handle transparency need to use one of the other sorts of disposal methods.

            Dispose Previous - preserve background canvas
            The 'Previous' disposal method is relatively simple. When the current image is finished, return the canvas to what it looked like before the image was overlaid. If the previous frame image also used a 'Previous' disposal method, then the result will be that same as what it was before that frame.. etc.. etc.. etc...

            For example in this animation each of the later frames will return to the very first frame of the image, which has a 'None disposal setting, before overlaying the image associated with that frame.

            The result is a background canvas that has just each frame image overlaid for just the duration of that image...


              convert -dispose none  -delay 0 \
                            -size 100x100 xc:SkyBlue +antialias \
                            -fill DodgerBlue -draw 'circle 50,50 15,25' \
                      -dispose previous -delay 100 \
                            -page +5+10  balloon.gif  \
                            -page +35+30 medical.gif  \
                            -page +62+50 present.gif  \
                            -page +10+55 shading.gif  \
                      -loop 0  canvas_prev.gif

                [IM Output]

            Note the "-dispose" method 'None' used for the first image. This is important, otherwise the 'previous' frame will go all the way back to the original empty canvas that was present before the first frame.

            Also note that I used a "-delay" of '0' in the above animation. This says not to wait before overlaying the first frame onto this 'background canvas'. Without it you will see a short delay, showing just the canvas image with nothing on top of it.

            Of course I need to still set a longer "-delay" for the later images, or they will appear and disappear in the wink of an eye, and incidentally use up a lot of the viewers CPU cycles.

            The use of the 'Previous' disposal method can be prone to a slight flickering, or pause in some web browsers, especially on slower machines. Though that is quite rarely seen these days, the flicker itself is still present, and something I consider to be a bug. See Zero Delay Frames below for more specifics.

            Few animations make use of a dispose previous style of animation, the reason is that it is very difficult for computers to optimise. The problem is just what frame should the computer pick to become the background image? Simple for us humans to figure out the best image to use, but difficult for a computer decide. The best background image to use in an animation may not even be meant to be displayed, such as in the current example, and as such may not exist in an un-optimized version of that animation.

            Dispose Background - clear to background
            While the first two "-dispose" methods are relatively simple, the 'Background' is probably the hardest to understand.

            When the time delay is finished for a particular frame, the area that was overlaid by that frame is cleared. Not the whole canvas, just the area that was overlaid. Once that is done then the resulting canvas is what is passed to the next frame of the animation, to be overlaid by that frames image.

            Here for example we just replace each frame with the next frame.


              convert -delay 100 -dispose Background \
                          -page 100x100+5+10  balloon.gif  \
                          -page +35+30 medical.gif  \
                          -page +62+50 present.gif  \
                          -page +10+55 shading.gif  \
                      -loop 0  anim_bgnd.gif

                [IM Output]

            So you can see exactly what is going on, lets add an initial canvas image to the animation, so you can see how a 'Background' actually 'disposes' that frame from the animation display.


              convert -delay 100 -dispose none \
                            -size 100x100 xc:SkyBlue +antialias \
                            -fill DodgerBlue -draw 'circle 50,50 15,25' \
                      -dispose background \
                            -page +5+10  balloon.gif  \
                            -page +35+30 medical.gif  \
                            -page +62+50 present.gif  \
                            -page +10+55 shading.gif  \
                      -loop 0  canvas_bgnd.gif

                [IM Output]

            As you can see as each overlaid frame is disposed of, that frames area is cleared to transparency, before the next image is overlaid. This is the importance of this GIF disposal method as it is the only way GIF animations can clear any pixel regardless of an animations frame history.

            The only other way to clear pixels is to use 'Previous' to go back to a frame in which those pixels were clear. But that relies on knowing the history of the animation sequence which makes it much more difficult for computers to optimize.

                There is some thinking that rather than clearing the overlaid area to the transparent color, this disposal should clear it to the 'background' color meta-data setting stored in the GIF animation. In fact the old "Netscape" browser (version 2 and 3), did exactly that. But then it also failed to implement the 'Previous' dispose method correctly.

            On the other hand the initial canvas should also be set from the formats 'background' color too, and that is also not done. However all modern web browsers clear just the area that was last overlaid to transparency, as such this is now accepted practice, and what IM now follows.

                Before IM version 6.2.6-1, the IM "-coalesce" and "-deconstruct" operations did not handle animations that used 'Background' disposal to make pixels transparent, as per all the major web browsers. See Animation Bugs for examples and details.

            These functions however did work fine when no pixel clearing was applied or intended. This has now been fixed for "-coalesce" and the "-layers OptimizeFrame' method was created to replace the use of "-deconstruct" as a GIF animation frame optimizing function.

            Studying Animations
            Before we can continue with the basics of GIF animation, their types, optimizations, and handling techniques, we need some techniques for studying existing animations.

            Identify - information about and animation
            Now an animation consists of a lot of information packed into each individual frame. You can see some of this information using the default IM "identify" command.


              identify canvas_prev.gif

            [IM Text]

                If you did not see output like the above your IM is a little old, and you really should upgrade your installed version of ImageMagick, to the latest version. If you don't you will be missing out on a lot of the new advances in IM's handling and control of GIF animations.

            As you can see the actual image saved for the second and later frames is only 32x32 pixels, but all the frames sits on a 100x100 pixel 'virtual canvas' with a 'virtual offset' on that larger canvas.

            To see more of the various bits of meta-data that is present you need to use some of the more specialzed percent Escape Formats to get IM to output it.


              identify -format "%f canvas=%Wx%H size=%wx%h offset=%X%Y %D %Tcs\n" \
                       canvas_prev.gif

            [IM Text]

            Which clearly shows not only the canvas size, image size and offset, but also the disposal and time delays used for each individual frame. Note how the first frame has the different disposal and time delay that was needed for proper use of the later 'Previous' disposal method.

            Adjoin - splitting an animation into frames
            Now as you saw above, ImageMagick will by default try to save multiple images into one file if that file format allows it. However as discussed in Writing a Multi-Image List IM will let you use the "+adjoin" setting to tell it to save each image to disk as a separate individual image.

            For example, here we read in one of the GIF animations and output the individual frame images in the animation sequence.


              convert canvas_prev.gif -scene 1 +adjoin  frame_%03d.gif

            [IM Output] [IM Output] [IM Output] [IM Output] [IM Output]

            If you were to examine the actual images above you will find that although most web browsers show a larger 100x100 area, on which each sub-frame appears. In fact most of the actual images show are really only just 32x32 pixels, just as show in the previous 'identify' commands above.

            That is most of the area is just a canvas on which nothing is drawn, known as the images 'page geometry' or 'virtual canvas'. The first image of the animation defines that larger 'canvas' and every other frame defines an 'offset' position on this larger canvas.

            This extra information is preserved in the frames that was saved by the "+adjoin" setting. As as such you can easilly re-build the GIF animation. Not only is the page information preserved in each separate frame image, but also any delay, looping and GIF dispose settings, is also preserved.

            This means that to rebuild the animation you only need to read all the images in.


              convert frame_???.gif  anim_rebuilt.gif

                [IM Output]

            Sometimes however you don't want to preserve this page geometry information. For example if you want to use the individual frames for other projects. You can reset the page size and offset using the "+repage" option, to remove the 'virtual canvas' information, leaving just the actual image.


            Normally when extracting animation sub-images you also generally reset the images delay and dispose settings too to ensure they don't interfer with the editing and display.

            For example here I remove the unwanted virtual canvas and offset and reset the timing delays and disposals.


              convert canvas_prev.gif  +repage  -set delay 0   -set dispose None \
                      +adjoin  repage_%03d.gif

            [IM Output] [IM Output] [IM Output] [IM Output] [IM Output]

            Of course if you junk that meta-data, you need some way of recording and editing that data. See Animation List Information (below) for a script that extracts both the sub-images and saves the animation meta-data, in a form that can be used to re-build the animation.

            Coalesce - fill out frames completely
            Viewing an animation in the form of the sub-frames, however is usually not very useful, in a typical animation.

            For one thing, a highly optimized animation can consist of lots of very small parts, without any visual indication of how they fit together. It can also have a lot of other 'noise' that was added for Compression Optimization to reduce the overall file size of the animation.

            For example, it is very difficult to figure out what this animation actually did, just by looking at the individual sub-frames of the animation.


              convert script_k.gif  +repage  +adjoin  script_k_%02d.gif

            [IM Output] [IM Output] [IM Output] [IM Output] [IM Output] [IM Output] [IM Output] [IM Output] [IM Output] [IM Output] [IM Output]

            The "-coalesce" operation basically converts an image into exactly what the animation should look like after the previous frame has been correctly disposed, and the next sub-frame overlaid.

            That is instead of an animation sequence where each frame only represents the overlaid changes to the previous 'disposed' frame. This operator creates a complete view of the animation at each point, a bit like a true film strip, rather than an animation sequence. Such a sequence, known as a Coalesced Animation is much easier to study, edit, modify and re-optimize.

            Here for example will generate a montage of the same 'confusing' animation sequence I showed above, but this time we'll "-coalesce" the sequences, so you can see what is really happening.


              montage script_k.gif -coalesce \
                      -tile x1 -frame 4 -geometry '+2+2' \
                      -background none -bordercolor none coalesce_k_montage.gif

                [IM Output]
            [IM Output]

            As you can see the result is like a film strip of the animation, allowing you to clearly see how the previous pieces fit together to form a hand drawn letter 'K'.

            As of IM version 6.2.6, the "montage" command understood the use of "-coalesce", allowing you to create 'film strip' like image of the animation frames, exactly as shown above. This version also contained fixes for coalesce, and any GIF animation work should be at least this version (or better still the latest version).

                An even better montage technique for examining animations is given in the next example section.

            The "-dispose" setting of a coalesced image sequence is actually irrelevant, in a Coalesced Animation. However for users piece of mind the "-coalesce" operator will set the "-dispose" setting of each frame to either 'None' or 'Background' as appropriate, so that the coalesced image sequence will continue to animate correctly (as shown above).

                A frame with a 'Background' disposal means the next frame needed to clear at least one or more pixels, to be displayed correctly.

            As such animations in which "-coalesce" added a 'Background' dispose, means that the animation can not be saved as a simple Overlay Animation (see below).

            Technically, you can set all dispose settings of a coalesced image sequence to either 'Background' or 'Previous' to generate a Cleared Frame Animation (see below). Though not all animations will optimize well in that form.

            Their are also some non-animation uses of the "-coalesce" operator. See Coalesce, and Progressive Flattening examples of these uses.


            Animation Frame Montage - the "gif_anim_montage" script
            While "+adjoin" operator will let you extract the actual images from an animation and "-coalesce" will let you see the resulting frames of the animation, both methods leave out a lot of information about the animation.

            By using some very careful manipulation of the animation images, you can display the frames so as to show not only the actual frames, but also the placement of those frames on the larger canvas. Here is one such method of displaying an animation.


              convert -dispose Background   script_k.gif  -matte \
                      -compose Copy -bordercolor black -border 1x1 -compose Over \
                      -coalesce  -bordercolor none   -frame 4x4+2+2 \
                      -bordercolor none -border 2x2 +append  script_k_parts.gif

            [IM Output]

            Here you can clearly see how the animation works. Each sub-frame image is positioned so as to add to all the previous overlays. The result is a slowly growing picture. Each frame is also a lot smaller than the 'virtual canvas' on which it is positioned.

            I use this display technique a lot during the development and debugging of GIF animations, as such I converted it into a shell script "gif_anim_montage", and expanded it to also list some of the details above each frame in the animation.


              gif_anim_montage   script_k.gif   script_k_frames.gif

            [IM Output]

            Note the variations in the timings used in various frames, to pause as if the pen is being lifted from the page and repositioned. Animations with variable timing can be some of the most interesting, but also more difficult to handle, as you will see in later IM Example pages.

            The "gif_anim_montage" script also the special option '-u' which will also underlay a semi-transparent copy of the coalesced animation. This lets you see how the new sub-frames modifies the displayed animation.


              gif_anim_montage  -u  script_k.gif  script_k_frames.png

            [IM Output]

            Of course this has semi-transparent pixels so a 'PNG' image format was needed, OR you could use one of the many 'background' options that script also provides, allowing you to use GIF or even JPEG formats for the resulting summery image of the animation.

            Other options, lets you define the number of rows or columns to use, as well as set various non-transparent backgrounds, or use a red box rather than the default black.

            This script will be used a lot during the next few pages of IM Examples. Suggestions and comments are welcome.


            Animation List Information - options used to build an animation
            As I noted, using "+adjoin" and "-coalesce", as well as "+repage", are all useful methods of extracting and looking at GIF animations. However they all destroy information about the original animation in the process.

            You can see this extra information on framing, time delays, frame dispose, etc., using the IM "identify" command with a "-verbose" option. However I, and probably most other users, find the output from this command, overwhelming and not really directly usable.

            This is where another special shell script I wrote comes in. The "gif2anim" script will separate the individual frames of the animation, but will also figure out exactly what IM "convert" options you would need in order to re-build the animation from those images.

            You can think of "gif2anim" as an animation disassembler, producing a summary of the animation in terms of IM options.

            For example, lets decode the animation example we have been using to recover the original "convert" settings used to create it, as well as individual images used...


              gif2anim canvas_prev.gif

            [IM Text]
                [IM Output]
            [IM Output]
            [IM Output]
            [IM Output]
            [IM Output]

            By default the "gif2anim" script uses the same base file name for the individual images and ".anim" options file. As such the animation sequence file generated by the above command is named "canvas_prev.anim", with the individual frame images "canvas_prev_001.gif" to "canvas_prev_005.gif".

            If you examine the results more closely you will see that it actually did manage to re-create the original options I used when I first created this GIF animation (See Dispose Previous Animation). Also while it is not important to actually generating an animation, the size, and timings of the overlaid frames is also listed as a comment, to make it easier to study.

            Rather than save the results to a file you can just list the animation sequence options to the screen using a "-l" flag. That is just output the animation sequence file, rather than save it, or the individual frame images of the animation.


              gif2anim -l canvas_prev.gif

            Given a ".anim" file and the individual framing images, a complementary script "anim2gif" can be used to re-build the animation.


              anim2gif canvas_prev.anim

                [IM Output]

            The "anim2gif" by default will re-create the GIF animation with a "_anim.gif" suffix. You can see that the resulting "canvas_prev_anim.gif" animation generated, looks and works exactly like the original animation.

            This script simply replaces the special string "BASENAME" used in the "animation sequence file", strips all comments, then just pass the convert options that is left into the "convert" command. In other words it treats the above file as a type of 'convert' script with comments.

            The reason a special string was used, is because this then allows you to specify a different base filename than the name of the ".anim" file itself. That way you can use a completely different set of frame images, such as modified versions of the original, to recreate a different animation from the old one. This is very useful feature, which will used in more complex animation processing. (See Appending Animations Side-By-Side for an example).

            Like "gif2anim", the "anim2gif" script has quite a number of useful options, to help you process and modify animations. Some of these options will be used later. For example see Appending Animations.

            Also as the ".anim" file is plain text you can use it take the decoded images of an animation to adjust the GIF's meta-data, such as the timings, positions, repeating sections of an animation, or adding new frames and images to an animation. This was after all why I originally wrote the scripts, long before I got involved with IM examples.

            For now the "gif2anim" will be most useful for examining an animation sequence to see just what is happening, and the timings that is being applied between frames.

            Dispose Images - the GIF dispose form of the frames
            This special "-layers" method, 'Dispose' shows what the frame should look like after the time delay is finished, and the GIF dispose method has been applied, but before the next frames image is overlaid.

            In other words this show exactly what the GIF "-dispose" method setting actually does to the frame, allowing you figure out exactly what is going wrong with your animation.

            For example here is how each of our three Dispose Method Example Animations look like after the individual frame dispose method was applied. Remember each of these animations consist of a 'canvas image' that was set with a 'None' "-dispose" setting, then followed by four smaller images overlaid then disposed of by the various GIF dispose methods.

            'None' dispose animation...


              convert  canvas_none.gif -layers Dispose canvas_none_dispose.gif
              gif_anim_montage canvas_none_dispose.gif canvas_none_dispose_frames.gif

            [IM Output]

            'Previous' dispose animation...


              convert  canvas_prev.gif -layers Dispose canvas_prev_dispose.gif
              gif_anim_montage canvas_prev_dispose.gif canvas_prev_dispose_frames.gif

            [IM Output]

            'Background' dispose animation...


              convert  canvas_bgnd.gif -layers Dispose canvas_bgnd_dispose.gif
              gif_anim_montage canvas_bgnd_dispose.gif canvas_bgnd_dispose_frames.gif

            [IM Output]

            If you study the above you can see exactly how each of the three GIF dispose methods clear the animation of that frames overlaid image. Note that the first frame of these three animations is always set to a dispose of 'None' so will remain unchanged. It is the effect of the dispose method in the later frames that is imporant.

                The "-layers Dispose" operation only generates the 'coalesced' sequence of the disposal frames. It does not reset the disposal setting itself, and as such the result may not animate properly. To make the above animate correctly set all disposal methods to 'previous' or 'background' or you can optimize the animation, before saving.

                The look of the final frame after the GIF dispose method is normally of no consequence to a GIF animation, as the whole canvas is completely cleared before the animation repeats (loops). If it does not 'loop' but stops at the end of the animation sequence, then the final frames disposal is not applied.

            In other words the appearance of the last frame (after disposal) as shown above, or even the actual dispose setting of the last frame, does have any effect on a GIF animation. IM generally sets this to same as the previous frame when it trys to work out an appropriate disposal method, during a Frame Optimize an animation.

            Deconstruct - report areas of frame differences
            The traditional way in ImageMagick to optimize an animation, making the result smaller and faster to download and animate, is to "-deconstruct" its "-coalesce" form. This is no longer recommended. Instead you use should use the General GIF Optimizer.

            This operator will take a coalesced sequence of images (the animation frames as they actually appear when displayed), and compare the second and later images with that of the previous image. It then replaces that image with the smallest rectangular area of the pixels that had changed. Any pixel change, will count, regardless of if it is a color change (overlay) or cleared (erased).

            This is quite simple, and for a typical Overlay Animations will generate an optimal Frame Optimization for that animation. An Overlay Animations animation however only use a 'None' dispose method only.

            For example lets take the coalesce previous animation we generated above, which happens to form a Overlay Animation, and run it though the "-deconstruct" operator.


              convert  canvas_prev.gif   -coalesce     coalesce.gif
              convert  coalesce.gif     -deconstruct   deconstruct.gif
              gif_anim_montage  coalesce.gif     coalesce_frames.gif
              gif_anim_montage  deconstruct.gif  deconstruct_frames.gif

                [IM Output]
            [IM Output] ==>
            ==> [IM Output]

            A 'previous dispose animation' if you remember clears each frame to the last non-previous disposed frame, in this case the initial background canvas. As you can see "-deconstruct" returned the area that changed from one coalesced frame to the next. Resulting in an optimized Overlay Animation, that requires no special dispose setting.

            This is nowhere near as optimal as the original hand generated animation I started with, but is useful in itself.

            Unfortunately "-deconstruct" has absolutely no understanding of the GIF animation "-dispose" settings. Consequently if you try this on an animation that clears pixels from one frame to the next, such as the 'background disposed' animation we created above (and shown left), it will fail badly. 	[IM Output]
            Here we take the just shown animation, and run it though a "-coalesce" and "-deconstruct" cycle.


              convert canvas_bgnd.gif  -coalesce  -deconstruct  deconstruct_erase.gif

                [IM Output]

            As you can see "-deconstruct", slowly destroys the animation. Basically "-deconstruct" is designed to simply find the differences between image layers. It was never designed to correctly optimize animations, and will fail for animations that need to use various disposal techniques to clear (erase or make transparent) previously overlaid pixels.

            Frame Comparisons - more detailed comparing of frames
            With IM v6.2.6-2, a number of extra GIF frame comparison methods were added.

            These were needed internally for proper optimization of animations, but was deems useful enough to make them available to the command line and other API interfaces.

            Compare_Any
            The "-layers" method 'CompareAny' is actually exactly the same as "-deconstruct". In fact the "-deconstruct" operator is only a functional alias for the 'CompareAny' method.

            Again lets look at the actual image results of a 'deconstruct' or 'CompareAny' of the 'background disposed' animation.


              convert canvas_bgnd.gif  -coalesce  canvas_bgnd_coal.gif
              gif_anim_montage canvas_bgnd_coal.gif canvas_bgnd_coal_frames.gif

              convert canvas_bgnd_coal.gif  -layers CompareAny   compare_any.gif
              gif_anim_montage compare_any.gif compare_any_frames.gif

            [IM Output] ==>
            ==> [IM Output]

            As you can see the second and later images, is the minimal rectangular area that contains all the pixels that have changed, whether it is an overlay of a new pixel color, or a clearing of an old pixel to transparency.

            Compare_Clear
            The "-layers" method 'CompareClear' will show the smallest rectangular area that contains all the pixels that needed to be cleared from one frame to the next.


              convert canvas_bgnd_coal.gif -quiet -layers CompareClear compare_clear.gif
              gif_anim_montage compare_clear.gif compare_clear_frames.gif

            [IM Output]

            Notice that as no pixels were cleared between the first and second frame, a special Missed Image was generated. The "-quiet" setting was used to tell IM not to give any warning about this image.

            If all the later frames all become 'missed' images, then the GIF animation never clears pixels, and the animation can be classed as a Overlay Animation.

            Compare_Overlay
            The last "-layers" comparison method, 'CompareOverlay', returns the area of pixels that were overlaid (added or changed in color, but not cleared) since the previous frame.


              convert canvas_bgnd_coal.gif  -layers CompareOverlay  compare_overlay.gif
              gif_anim_montage compare_overlay.gif compare_overlay_frames.gif

            [IM Output]

            This is similar to the special IM specific 'ChangeMask" Alpha Composition Method. However, that returns just the pixels that change the image, rather than the rectangular area that was changed. See also Transparency Optimization.

                None of the "-layers" comparison methods, nor the "-deconstruct" operator, look at or modify the image GIF dispose method that is used. The results is just a list of images, and not expected to be used as animations themselves.

                While the operators are designed to work with a coalesced image sequence, they will accept a non-coalesced sequence of image layers, without producing an error.

            In this case each frame is overlaid onto the previous overlaid frames using a 'Copy' alpha composition method, before the frames are compared. This alpha composition method ensures that any transparency in a layer will also be added to the destination image. Without this the above would not find pixels that get cleared to transparency in a coalesced image sequence.

            Note that this is different to the more normal 'Over' composition method that the "-coalesce" operator would use for handling the 'dispose/overlay' cycle needed to display a GIF animation.

            Types of Animations
            Most GIF animations you find fall into some basic types of animation. Knowing about these types allows you understand how that animation is being displayed from one frame to another, and can allow you to take shortcuts in how you handle and modify the animation.

            Coalesced Animations
            A 'Coalesced Animation' is basically an image sequence that shows what an animation should look like when displayed to an user after each 'dispose/overlay' cycle. The images are basically as you would see them if you were looking at an actual 'film strip' of the animation. It is the simplified and completely un-optimized form of any animation.

            This naming convention is from the name of the IM "-coalesce" operator that is used to convert GIF disposal animations, into an un-optimized 'Coalesced Animation'.

            Most video formats (MPEG, AVI etc) are actually also 'Coalesced Animations' by their very nature. However these also tend not to have any transparent pixels, and generally have a constant time delay between the frames of the animation. A coalesced GIF animation however can have transparent pixels, and widely varying time delays from immediate '0' delays, to very fast, or very very very slow.

            Any GIF disposal setting in a coalesced animation does not have any meaning, however the "-coalesce" operator will set the disposal appropriately so the resulting image sequence can still work as a valid GIF animation.

            Video formats which always replaces every pixel from one frame to the next can generally just use a 'None' or 'Undefined' GIF disposal setting.

            Here is an example of an animation that is also by its nature a Coalesced Animation, plus a "gif_anim_montage" display of the animations individual frames.
                [IM Output] 	[IM Output]

            Most animations that do not contain, or use, transparency, and which animate the entire canvas, are usually saved and distributed as Coalesced Animations.

            Overlay Animations
            An 'Overlay Animation' is one in which each frame of an animation only overlays new pixels to the animation currently displayed. In other words at no point in the animation does it need to clear a pixel to transparency. The individual frames can contain transparency, either as a background, or as part of its optimization, but it never clears a pixel back to transparency.

            Of course if no transparency is used at all, then the animation is guaranteed to be able to be turned into a simple Overlay Animation.

            This is probably the simplest type of Frame Optimized animation, and one that requires no special handling by clients. Each frame that is shown to the user can be viewed as simply as 'flattened' image of all the previous frames.

            Any animation that only uses a 'None' GIF disposal method is an 'Overlay Animation'. The last example for instance is not only a 'Fully Coalesced Animation' but also a 'Overlay Animation', though not all such 'Fully Coalesced Animations' are 'Overlay Animations'.

            You can test if an animation can become an overlay animation by using the 'CompareClear' layers method on a Coalesced animation, and checking if all the second and later images are 'missed images'. That is no pixel needed to be cleared or erased from one frame to the next.

            In fact if an animation can become an overlay animation, without modification, then the IM "coalesce" operator will only use 'None' disposal methods for all the frames. If this is not the case then "coalesce" will have used 'Background' disposal for at least some of the frames. This then gives you with another test for 'overlay only' capability.

            Overlay animations can use transparency, but they do not have any moving parts on a transparent background. For example, the animation of a hand drawn letter 'K', is an overlay animation, as each part only adds or changes existing parts on a transparent background. It never adds new transparency to the resulting image (except as part of the first frame).
                [IM Output] 	[IM Output]

            [IM Output] That is not to say an moving object can't be handled by an overlay animation, it just means you need a non-transparent background so you can also 'erase' the old positions of the moving parts without needing transparency. For example look at the frames of this "download the world into a folder" animation...
            [IM Output]

            Of course by needing to 'erase' old parts by overlay the original background means that overlaid sub-images are generally bigger, and hence a generally larger GIF animation file size.

            Unfortunately using the IM's Optimize Frame operator, can, and most probably will, turn a 'Coalesced Overlay Animation' into into something that is not a 'Overlay Animation', in its attempt to find smaller GIF file size.

            However by using Deconstruct on the animation instead of using Optimize Frame, you can ensure the animation remains a simple 'Overlay Animation', but only if the animation is really a 'Overlay Animation'. If the animation isn't a 'Overlay Animation', then Deconstruct operation can go badly wrong (See Deconstruct above).

            With some human skill you can still optimize an overlay animation better, for example using Split Frame Updates, and applying some form of Compression Optimization without destroying the 'Overlay Only' requirement of the animation.

            Typically 'Overlay Animations' display no transparency at all (they can use it as part of optimization, but they don't display it). And if no transparency is displayed, then the animation is guaranteed to be a 'Overlay Animation'.

            Why is 'Overlay Animations' so important? Because there is software out there that are limited to this type of animation. It is much simplier to handle as only overlay is performed without need to handle transparency, or save the previous frame to handle GIF disposal methods. Such software is rare but does exist.

            Cleared Frame Animations
            When an animation only uses just 'Previous' or 'Background' GIF disposal, you get a very special type of animation.

            Note that if only 'Background' disposals is used, all the frames of an animation are displayed then cleared before the next frame is displayed. Also when only 'Previous' are used, the animation is always returned to the initial cleared canvas before the next frame is displayed, resulting in the same effect. Same happens if you only use a mix of those two disposal settings.

            That is, animations that only uses these disposal methods will have frames that are complete copies of what is to be displayed. That is, the frame contains everything that will be displayed to the user at that point in time.

            That is not to say that the animation is a 'Fully Coalesced Animation'. As the sub-frame may be a lot smaller than the virtual canvas area of the animation, but everything outside that frame will be regarded as transparent (or background), containing nothing of importance.

            For example take a look at this running bunny animation...
                [IM Output] 	[IM Output]

            Note that each and every sub-frame is the complete image that is displayed. No more, no less. Also notice that none of the frames actually needs to use the whole virtual canvas of the animation. And finally note how all the frame disposals are set to 'Previous', which for reasons you will see below is the more logical disposal setting to use. All the disposal settings could however have been set to 'Background' disposal or any mix of the two without changing the final result.

            For want of a better name I call such an animation a 'Cleared Frame Animation', but I have also seen it called a 'Previous or Background Disposal Animation'.

            The only time that an animation is not of this type is if at least one non-blank frame in the animation used a 'None' or 'Undefined' (same thing) disposal method.

            This animation is very special, as it can handle any amount of transparency clearing, anywhere within the animation sequence, unlike a Overlay Animation. But it can also be overlaid onto ANY static background image really quickly.

            To do this we need to tighten the definition of a 'Cleared Frame Animation' slightly. Specifically we need to make sure all the disposals are set to 'Previous' (which is already the case in our example). If that is done, then you can just pre-pend an image (with a zero delay) to underlay a background.

            For example lets place our bunny on some grass....


              convert bunny_grass.gif bunny_anim.gif -loop 0  bunny_on_grass.gif

                [IM Output]

            As you can see this is so simple that many applications use these types of GIF animations to add symbols or other indicators (file locks, smileys, stars, etc) to larger objects.

            Animating such a GIF animation is also easy, as the application can just clear the area to some simple constant background image, and overlay the next frame in the sequence. No need to calculate disposals, or keep track of a 'previous' display, other than the static unchanging background display.

            This is also the reason why a 'Previous' disposal is the preferred disposal for a Cleared Frame Animation.

            Unlike a Overlay Animation which are only a special sub-set of GIF animations, ALL animations can be saved as a Cleared Frame Animation. Just coalesce the animation, and optionally trim any surrounding transparent edges to frame optimize it, and reset the disposals.


              convert any_animation.gif -coalesce -trim \
                      -set dispose previous   cleared_frame_animation.gif

            You can even re-position the animation on that background...


              convert bunny_grass.gif \( bunny_anim.gif -repage 0x0+5+15\! \) \
                      -loop 0  bunny_on_grass2.gif

                [IM Output]

            As such a Cleared Frame Animation typically consists of a small, constantly changing or moving object on a transparent background. These are directly usable on web pages, or as animated symbols, or can be merged with other animations to produce much more complex animations.

            In summery this type of animation is a good style to use in a library of animated parts, for use in creating larger more complex animations.


            There is however a problem with adding background like this for GIF animations. If you look at the previous examples, you would probably have notice a significant and disturbing pause in the fast moving animation. That is the bunny vanished for a moment, when the animation looped, and the background image is re-loaded. (See notes in Zero Delay Frames )

            Though this is not a problem for applications that use this technique, for adding animated symbols to displayed objects, as they just don't display that 'intermediate' frame, anyway.

            As such if are adding a non-transparent background to the GIF animation, then it is generally a good idea to convert the simple Cleared Frame Animation into a Overlay Animation. That is add that background to every frame of the animation, rather than give an initial canvas.

            You can do that by either, Coalescing the above animation, then deleting the Zero Delay Background frame, OR Layer Composite the original animation onto a Static Background.

            For example...


              convert bunny_grass.gif \( bunny_anim.gif -repage 0x0+5+15\! \) \
                      -coalesce -delete 0 -deconstruct -loop 0  bunny_bgnd.gif
              gif_anim_montage  bunny_bgnd.gif  bunny_bgnd_frames.gif

                [IM Output]

            [IM Output]

            Now that all the frames are displayed equally well, no pause can be seen as the background is reset. The animation however is now an Overlay Animation with background being 're-drawn' due to the movement of the animation object, as such it is probably a bit larger in file size.

            See Transparency Optimization for a continuation of the optimization of the above result.

                The IM forum member el_supremo, Pete, has contributed a MagickWand equivelent script, Cleared Frame onto Background example.

            This example is also discussed in detail in the IM Forum Creating a Cleared Frame GIF Animation in the MagickWand.

            Mixed Disposal Animations - multi-background animations
            There is nothing preventing you from mixing the various disposal methods in a single GIF animation. If fact adding a background to a Cleared Frame Animation, does exactly that.

            Using mixing disposal methods not so simple for us humans, but doing so can allow you to generate some very complex animated displays. In general they are created as part of automatic Frame Optimization for a particular animation.

            Just remember the result will not be directly usable as the previous animation types for specific purposes. In fact do not be surprised if some GIF handling programs, just do not handle a 'Mixed Disposal Animation' properly. That includes some of the GIF optimizers available.

            A typical example of a 'Mixed Disposal Animation' is a small moving object that causes some semi-permanent but temporarilly static change in the animations background. A ball hitting a lever would be one example.

            Simple Example wanted

            Similarly animations involving two very small moving objects on a larger transparent display can only be optimized well by mixing up the disposal techniques, so that each object is moved using separate animation frames.

            FUTURE,
            A more complex animation for study.
             * Start with a semi-transparent canvas
             * run a little 'previous' disposal
             * leave one frame as a new 'canvas'
             * more previous animations
             * erase that 'addition' using a 'background' disposal set as new canvas
             * continue back to start point.
            This animation should thoroughly test out not only IM disposal methods
            but also various browser disposal methods.

            If you like to contribute an IM example of such an animation you can get your name, and home page link here!

            The End of the Loop - when an animation stops
            It is often regarded as a good idea not to make animations loop forever, as client machines have to continually work while the animation is still animating. As such it is a good idea to think about how many times your animation actually loops.

            Basically..
            Add a loop limit to your animations (if practical)

            This is especially the case for large animations used as a logo at the top of a web page. Depending on the overall time for which an animation runs, 10 to 30 loops is usually enough for large logos. And you should add a loop limit for all such animations, to be kind to your users.

            A "-loop" save setting of 0, means to loop forever. This is typically what is used, and that is okay, for small animations. Some browsers however enforce a stop when an animation reaches some internal loop limit (often 256 loops).

            For IM Examples I have generally used a '0' "-loop" save setting, meaning 'loop forever', because the animations can appear anywhere on a page. That means it may be some time between when the user loaded a page to when they finally look at and read about a particular GIF animation. If I did use a smaller number of 'loops', the animation would no longer be doing what it should be demonstrating, loosing its effectiveness.

            For large animations on top level flash pages, a "-loop" of '1', the normal GIF animation default, can be used. This means run though the animation once only and then stop.

            Which brings us to an all important question.. Stop where?

            Some browsers, like the old "Netscape" browser, re-displayed the first frame of the animation. Most modern browsers however will just stop on the last frame, ignoring that frames useless dispose setting.

            What a specific application does however is up to the application as there is no true standard. Actually even the use of the 'loop' meta-data, is itself non-standard, just something that the old "Netscape" browser implemented, and all later browsers copied.

            Because of this, if there is some specific frame that you want your animation to stop on, say the frame with your company name or logo on it, then it is a good idea to make that frame both the first and last frame of an animation One of those frames however should be given a 'zero delay', so as not to effect the overall loop time length of the animation.

            So just to summarize...
            If loop limited, add the 'stop' frame as BOTH first and last frames.

            Zero Delay Intermediate Frames
            We have already seen use of a frame that has a 'zero delay', with regard to a Cleared Frame Animations. I also used them to explain Previous and Background Disposals.

            These special frames are actually a lot more common then people would probably think. They represent not only methods to prepend a background 'canvas' to an animation (such as I have used them for above). But they are also a must for some of the more complex Frame Optimization techniques, such as Frame Doubling and Splitting Frame Updates.

            Another (very old pre-PNG format) usage was to allow you to create static GIF images that contained more than the 256 color limit! That is each frame provides 256 colors, and the next frame the next set of 256 colors, all with zero delay and no looping at the end. Thanks to TLUL in the discussion Creating unquantized GIFs for pointing this out.

            These 'zero delay intermediate frames' are not meant to be displayed to an user. They are just used to create special effects in GIF images that are otherwise not posible or better optimized than you would get without them.

            In summary...
            Zero Delay Frames are Intermediate Frames,
            They are not meant to be visible to users.

            ImageMagick not only will create such frame in animations as part of its automatic 'OptimizePlus', but also provides a way to remove them using the 'RemoveZero' layers method.

            Watch out for them, as they will often complicate your handling of Animations.

            Okay so they are important, what of it? Because many applications don't like them, or incorrectly handle them. They consider 'Zero Delay Frames' as a bad thing, even when you purposely add them to animations, for some reason or another.

            Here is summary of applications that I know about or have been told, 'do the wrong thing'...

            Gimp 	Will not save a 'Zero Delay Frame', they always add a minimal time delay to any frame that has a zero time delay. :-(
             
            FireFox 	Will give a slight non-zero pause on such frames. This presumably is so that animations that have no time delays at all, do use up all the computers CPU cycles. But "firefox" still doesn't relax that restriction if an animation has an overall non-zero display time.
             
            Internet Explorer 	Has a minimum time delay of 6 centi-seconds, and ignores any delay smaller than this.

            Internet Explorer version 8 also fails (immediately restarts the loop) if any image frame extends beyond the animation bounds set by the first frame. This I would class as a major bug.

            On the other hand ImageMagick 'RemoveZero' layers method does do the right thing and will NOT remove any frame if ALL the images have a 'zero time delay'. In fact this layers method will give a warning if it sees an animation with no time delays at all.

            This brings us to another rule-of-thumb...
            Never save a GIF (looping) animation that has no 'delays' at all

            Doing so is very bad practice, and the reason most of the above 'buggy' applications, do what they do, rather than what they should. Complain to the owners if you see them.

            Also complain to application developers, so that they handle Zero delay frames correctly. Even if it means not displaying that frame at all, just using them as preparation for the next frame to display. They are after all on screen for ZERO time!
https://legacy.imagemagick.org/Usage/anim_opt/
            These examples start to make use of the Basic Animation Handling, to try to optimize the final display and file size of an animation. This is especially important for complex GIF animations where smaller sub-frame overlays can be used, as well as three types of disposal methods controlling how an animation is handled.

            Introduction to Animation Optimization
            Optimizing an animation is not easy, especially a GIF animation that has color restrictions, as well as a choice of different frame disposal techniques, and the ability to use smaller 'sub-frame' overlays from one frame to the next.

            When optimizing animation you should try to optimize them in the following order.

                Minor Optimizations
                Semi-Transparency Handling
                Color Optimizations
                Frame Optimizations
                Compression Optimizations
                Single Global Color Table 

            That however is not the order we will look at these optimization techniques. For GIF animations Frame Optimization is the most basic optimization technique, and where the most gains can be made. As such it will be looked at first.

            Probably the hardest aspect of optimization that users have trouble with is Color Optimizations caused by the color limitations of the GIF animations. One aspect of this Single Global Color Table has to be done as a the last step before saving to GIF or you may loose the operators effect on the final GIF file save.

            General Purpose GIF Optimizer of ImageMagick
            The "-layers" method 'Optimize' will use a number of the techniques, that we will discuss in detail below, to attempt to optimize a GIF animation in a single reasonable step.

            Currently this option is equivalent to (in order)...

                A Coalesce the Animation.
                Basic Frame Optimization
                and Transparency Optimization 

            At which point you can immediately save the GIF animation.

            These are reasonably safe optimization steps that can be applied to most animation sequences, however there is no guarantee, that it will result in a smaller GIF animation. This is particularly true of an raw video sequence where a Transparency Optimization will generally result in a worsening of the LZW compression ratio.

            However for most GIF animations, involving cartoon like images, the 'Optimize' operator should produce a good well optimized animation.

            The operator however is still in development, and in future is likely to also include extra standard optimization steps, such as...

                A 50% Threshold of the alpha channel, just as the IM does normally does when saving to the GIF file format, to remove semi-transparent pixels. You can still do the semi-transparency handling yourself before hand to override this, if you like. See GIF Boolean Transparency for more detail.
                Some type of Color Optimization technique. Exactly what, is still to be decided, and may be selected depending on the animation and the number of colors involved. Suggestions Welcome.
                A Single Global Color Table, "+map" operation. 

            In other words, it is hoped that 'Optimize' will eventually become the IM generic GIF animation optimizer, for quick and easy use by IM users. Until then be careful of its use, especially in scripts as it will change.

            Of course as many optimization steps may not be worth the effort for a specific animation. This option will also likely become quite slow.

            This is the plan, and the goal that this IM Examples section, was looking toward.

            Frame Optimizations
            Frame optimization is based on overlaying a smaller sub-image rather than a complete overlay of the whole image. This obviously produces a smaller number of pixels and thus a smaller file on disk, to being sent across the network. Also overlaying a smaller frame means the client computer does not have to do as much work in changing pixels on screen.

            However there are different disposal methods available in the GIF format to handle the last frame displayed, and that can result in different size overlays. Not only that but it is possible to split up the overlays into multiple parts, or update actions, bring about a more complex but more optimized animation.

            Because of the complexity of doing frame optimizations, any existing frame optimizations are typically always removed first by using "-coalesce" operation. See Coalesce Examples.

            Naturally that means any hand optimizations that may have existed are also removed, so some caution is advised.

            Basic Frame Optimization
            The "-deconstruct" method will produce a basic frame optimization for a GIF animation. However as was shown in the Deconstruct Examples of the previous section, this operator does not work with all GIF animations when transparent pixels are involved. Specifically when an animation clears any colored pixel to transparency.

            That is it will only work with Overlay Animations.

            The "-layers" method 'OptimizeFrame' is designed to be a GIF Frame Optimizer, which will try to find the smallest sub-frames overlay images, using any GIF disposal method.

            The result is generally a Mixed Disposal Animation though often it will also generate a Cleared Frame Animations or Pure Overlay Animations, if that was determined to be the best solution for the specific animation.

            Remember the input animation must be a 'coalesced animation', so it consists of a sequence of complete image frames, all the same size, without any canvas offsets. Of course any existing dispose methods in coalesced animation is completely irrelevant, and will be ignored by the 'OptimizeFrame' method.

            For example, lets try this with a Dispose Previous Animation, created in the previous section.
                


              convert  canvas_prev.gif -coalesce  -layers OptimizeFrame  optframe.gif
              gif_anim_montage optframe.gif optframe_frames.gif

                [IM Output]
            [IM Output] ==>
            ==> [IM Output]

            As you can see "-layers OptimizeFrame' correctly returned our animation back into its original frame optimized form, using Previous Disposal.

            This optimization even works properly for the trickier to handle Background Dispose Animations...
                


              convert  canvas_bgnd.gif -coalesce  -layers OptimizeFrame  optframe_bgnd.gif
              gif_anim_montage optframe_bgnd.gif optframe_bgnd_frames.gif

                [IM Output]
            [IM Output]

            The animation is perfectly frame optimized using Background Disposal.

            This operator will work correctly for all GIF animations, and will generally return the best possible simple 'dispose and frame optimization' possible.


            Now for some bad news about any type of simple frame optimization, such as what IM provides...

            While 'OptimizeFrame' returns the best possible frame optimization for a given animation that IM can figure out, there are is a number of special cases where it does not do well.

            These include...

                Animations where pixel clearing (returning to transparency) is needed, but the frame overlays are too large to efficiently clear the small areas of pixels that needs to be cleared (see the move hole animation below).

                Animations involving two or more small areas of change that are distantly separated. These are actually quite common, and horrible to frame optimize. (See Splitting Frame Updates below)

                Animations with very complex backgrounds that remain static for long periods (more than 3 frames), but then change slightly before remain static for another long period, etc., etc., etc... Or a static background that becomes greatly obscured for a very short period.

                It can be near impossible for any computer algorithm to figure out the 'best' frame optimization in this complex situation (IE: What should be regarded as a static background?). Only humans with their intuitive grasp on what they see, can generate a good optimally frame overlay sequence in these cases.

            Examples of difficult to optimize animations wanted, please contribute.

            If you find an example of an animation which IM fails to produce a good optimization, please mail it to me for further study. This is how new techniques and possible automatic solutions can be developed. I will naturally publish your name as a contributor.

            No Pixel Overlay - repeated image every second frame
            [animation] Sometimes the best optimization for an image involves not overlaying any pixels at all!

            For example to the right is a simple animation, contributed by nixscripter. If we look at its frames you can see it is not very optimized. But notice that every second frame of the animation is simply repeated.


              gif_anim_montage paddleball.gif paddleball_frames.gif

            [IM Output]

            After frame optimizing it we get a very special GIF disposal sequence.
                


              convert  paddleball.gif -coalesce -layers OptimizeFrame  paddleball_opt.gif
              gif_anim_montage paddleball_opt.gif paddleball_opt_frames.gif

                [IM Output]
            [IM Output]

            What is happening is that rather than overlaying the original frame IM chose to recover the first image using a 'Previous GIF disposal. As that recovered frame is left as is, there are no changed pixels. So the sub-frame overlay gets reduced nothing.

            Unfortunately, neither IM or the GIF format allow you have a zero sized image, so a special one transparent pixel minimal image is used instead. This image is known as a Missed Image as it is also extensively used when "-crop" 'misses' the actual image data, producing the same result.

            This image, in effect, only preserves the frames meta-data, such as: Dispose Method, Time Delay, and Loop Iterations. As such it is an essential part of the animation, even though it is 'empty'.

            So by overylaying a bare minimal single transparent pixel, IM saved a huge amount of space (and time) in this animation.
            Moving Hole Animation - difficult to frame optimize
            Here is one extreme case of GIF animation that does not frame optimize very well by any normal optimization method.

            This animation basically consists of a simple unchanging background image but with a transparent 'hole' through that background that changed position from frame to frame.

            To create it I need to make a coalesced image sequence, where I cut up a hole in a fixed background image, using Layer Alpha Composition. I also used a "+antialias" switch to ensure only four colors are used three blues and the transparency. So we don't need to deal with Color Optimization Problems.
                


              convert +antialias -size 100x100 -delay 100 xc:SkyBlue -loop 0 \
                      -fill DodgerBlue -draw 'circle 50,50 15,25' \
                      -fill RoyalBlue  -draw 'circle 50,50 30,25' \
                      null: \( -size 100x100 xc:none -draw 'circle 40,25 27,22' \) \
                            \( +clone -rotate 90 \) \( +clone -rotate 90 \) \
                            \( +clone -rotate 90 \) -compose DstOut -layers Composite \
                      -set dispose background  moving_hole.gif
              gif_anim_montage moving_hole.gif moving_hole_frames.gif

                [IM Output]
            [IM Output]

            As you can see the animation works, with a round 'hole' showing the background color of this page, producing an animation file of [IM Text] bytes in size.

            So lets try a straight-forward frame optimization for this animation.
                


              convert moving_hole.gif  -layers OptimizeFrame  moving_hole_opt.gif
              gif_anim_montage moving_hole_opt.gif moving_hole_opt_frames.gif

                [IM Output]
            [IM Output]

            Hang on, nothing happened! The best optimization IM could achieve was no change at all! Is the above coalesced version of this animation its most optimal?

            Well for the animation as it stands... Yes, this really is the best simple optimization that can be achieved by pure frame disposal optimization! Not good.

            The problem is that for a GIF animation to 'clear' or 'erase' the pixels drawn by previous frames, it needs to use a 'Background' dispose method. Though in some special situations a 'Previous' dispose method can also be used.

            However 'Background' dispose only can clear areas that were just overlaid. As the first frame was a complete overlay of the whole image, the whole image will be cleared. Even though only a small section of the animation needs to have its pixels cleared.

            As a consequence the whole of the second frame needs to be overlaid, even though most of that frame was just previously displayed! This horrible catch-22 situation continues all the way across the rest of the animation, producing no basic frame optimizations.

            I did say this animation would be difficult to frame optimize.

            Frame Doubling - a method to frame optimize 'holes'
            All is not lost however. By adding some extra frames to the animation, you can give the 'OptimizeFrame' method some room in which to make better use of the GIF disposal methods available.

            Here for example we add an extra frame by doubling up the first image, but giving it a zero time delay so as not to change the overall timings of the animation.
                


              convert moving_hole.gif[0] -set delay 0   moving_hole.gif \
                      -layers OptimizeFrame    moving_hole_dup.gif
              gif_anim_montage moving_hole_dup.gif moving_hole_dup_frames.gif

                [IM Output]
            [IM Output]

            By doubling the first frame the animation was now reduced from [IM Text] bytes down to [IM Text] bytes in size. So even though the animation now has five frames, it is now much smaller in overall size, because of the massive reduction in the size of the sub-frame image overlays.

            Doubling essentially separates the pixel clearing function of the dispose method, from the pixel overlaying function performed by the next frame. Both the dispose and the overlay are done as part of the same frame update by GIF animation programs, so no loss of speed or quality should be noticeable.

            This is a complex and tricky technique, and one that is rarely seen or understood by GIF animation designers or GIF optimization programs, but its benefits are well worth it then it is needed.

            However the reduction in sub-frame image sizes only lasts for a short time, as later frames having to also clear out pixel for the next frame, so the frames become large again to continue to clear out later pixels. That is because pixel clearing always result in larger frames, never smaller.

            So lets try and double all the frames (except the last which never needs doubling) to see how that affects the final image...
                


              convert moving_hole.gif  \( -clone 0--1 -set delay 0 \) \
                      +delete -insert 2 -insert 1 -insert 0 \
                      -layers OptimizeFrame  moving_hole_double.gif
              gif_anim_montage x2 moving_hole_double.gif moving_hole_double_frames.gif

                [IM Output]
            [IM Output]

            As you can see while we have almost twice as many frames, all the image sizes are much smaller, producing an animation that is [IM Text] bytes in size, a smaller result, though not nearly as big a saving as the first single frame doubling we performed.

            So that you can follow what is happening, the 'Background' frame is an exact duplicate of the previous frame, making no change to what is being displayed. However, it defines the area of the animation that needs to cleared before the next frame image is overlaid.

            The following 'None' frame then fills in the pixels that need to be changed, as well as the pixels that the previous frames disposal also cleared. In the above animation that means the pixels that was needed to shape the new hole, and well as the pixels that was used to fill-in the previous 'hole'.

            The result is smaller but not nearly as much, as adding extra frames does have its own cost. At least each of the added frames also does not have its own color table, or this animation would have in fact become larger, due to the size of the extra color tables!

            Layer Optimize Plus - Automatic frame doubling Optimization
            I am please to say that as of version 6.2.7, IM can now do frame doubling optimization automatically, as part of its normal frame optimization handling. However as adding frames to make an animation smaller is so radical a move, it was given its own separate "-layers" method 'OptimizePlus'.

            For example, lets get IM to do the frame doubling optimization...
                


              convert moving_hole.gif  -layers OptimizePlus   moving_hole_oplus.gif
              gif_anim_montage x2 moving_hole_oplus.gif moving_hole_oplus_frames.gif

                [IM Output]
            [IM Output]
            That is IM gave you the same result as our previous frame doubling example. Thus the GIF file is still [IM Text] bytes in size. However 'OptimizePlus' will only frame double if the number of pixels in the current and next frame of the resulting animation (3 frames) is reduced, so we can let IM decide whether to frame double or not.

            As "-layers" method 'OptimizePlus' adds extra frames as it creates an frame optimized GIF animation, it also will remove any unneeded or extra frames that make no change to the final animation (merging delay times as appropriate). That is it will also do an automatic 'RemoveDups' (see next). The 'OptimizeFrame' method will not do this.

            Remove Duplicate Frames - merging consecutive duplicate images
            Unfortunately if you coalesce" this animation, you will also get all the extra frames that the above added.


              convert moving_hole_oplus.gif -coalesce gif:- |\
                 gif_anim_montage x2 - moving_hole_oplus_cframes.gif

            [IM Output]

            To let you remove such useless duplicate frames from a coalesced animation, a 'RemoveDups' method has been provided. This compares each frame with the next frame in the animation, and removes the first frame if they are identical (with color similarity set by the current Fuzz Factor).

            Also to ensure that any timings in the animation are not lost, the Timing Delays of the two frames are also merged.

            For example..


              convert moving_hole_oplus.gif -coalesce -layers RemoveDups  gif:- |\
                 gif_anim_montage - moving_hole_oplus_rmdups_frames.gif

            [IM Output]

            And we now have our original coalesced form of the animation.

            For another method of removing the extra frames see the 'RemoveZero' method below.

            Splitting Frame Updates - separately updating two distant changes
            As you have seen with frame doubling, by separating the 'clearing of pixels' from the overlaying of new pixels, we can reduce the overall size of a single frame overlay.

            However this animation still produces some very large overlays, which mostly consist of pixels that don't actually change from one frame to the next. That is, the main overlay frame is only updating two rather small areas that are quite distant from each other thereby producing a single large overlay image.

            Rather than trying to update both changes simultaneously while will also includiing all those the unchanged pixels in-between the two area, we instead update each area separatally. That is we split the frame update into two phases, one for each of the separated areas that changed. In this case we can fill in the hole first, then create the new hole as a separate update.

            It does not actually matter (except with possible regard to disposals) which of the two separate changes happen in which order, but you should try to be logical about it. It may also be that one change is easier to create than another.

            For example, here I insert extra frames to fill in the old hole as a separate update to the 'digging' of the new hole. This is the easier intermediate frame to generate as well as the most logical ordering of actions. Of course you do not need to do this for the last frame, as that frame is just junked before the animation loops.
                


              convert moving_hole.gif \
                      \( +antialias -size 100x100 -delay 0 xc:SkyBlue \
                         -fill DodgerBlue -draw 'circle 50,50 15,25' \
                         -fill RoyalBlue  -draw 'circle 50,50 30,25' \) \
                      \( +clone \) -insert 1 \( +clone \) -insert 3  +swap \
                      -set dispose background  moving_hole_split.gif
              gif_anim_montage x2 moving_hole_split.gif moving_hole_split_frames.gif

                [IM Output]
            [IM Output]

            Remember the added intermediate frame is different from the surrounding user displayed frames (the ones with a non-zero time delay). This is not simple 'frame doubling', but the separating two distant small changes.

            This addition of intermediate frames is not a simple step that can be automated. Although it is possible that a smart heuristic could be developed to generate these intermediate frames, it is not always obvious what should be done, let alone if it should be done. If you like to try to generate such an heuristic, please mail me.

            So lets try a standard frame optimization after adding these extra frames...
                


              convert moving_hole_split.gif \
                           -layers OptimizeFrame     moving_hole_split_opt.gif
              gif_anim_montage x2 moving_hole_split_opt.gif \
                                  moving_hole_split_opt_frames.gif

                [IM Output]
            [IM Output]

            The addition of these 'zero delay intermediate frames', allows this animation frame optimize better than the original unoptimized animation, producing a [IM Text] byte animation. However for this specific case it isn't as good as using an automated Frame Doubling technique (See the 'OptimizePlus' layers method above).

            However adding 'zero delay intermediate frames' does not stop you from also doing that 'frame doubling' technique as well...
                


              convert moving_hole_split.gif \
                           -layers OptimizePlus moving_hole_split_oplus.gif
              gif_anim_montage x2 moving_hole_split_oplus.gif \
                                  moving_hole_split_oplus_frames.gif

                [IM Output]
            [IM Output]

            This animation now has two extra 'zero delay intermediate frames' per frame update. The first fills in the old hole, the second clearing an area that will contain transparent pixels, before finally the pixels that should not have been cleared is restored.

            The result is the most optimal frame optimization possible for this specific problem animation, resulting in [IM Text] bytes in the final file size.

            That is, our 4 frame animation was made smaller, by adding 6 extra zero time delay frames! More than double the original number of frames. Weird but true!

            Of course it would also be nice if GIF animation programs actually recognise Zero Delay Intermediate Frames for what they are, namely, intermediate updates between the real frames of the animation. But even so when the updates are highly separated, and very small, the slight pause caused by the extra frames is rarely visible.


            Of course, if the two separated parts of the animation are not actually related, then they do not need to be time synchronized. Another alternative is that instead of adding extra frames, to split the animation to two completely separate animations that you can displaying together on a web page. See Splitting up an Animation.

            This particular animation however cannot be split up into separate time disjoint animations. First the distant changes need to be time synchronised. and second the four areas that do change, overlap in both the horizontal and vertical directions. This means a simple HTML 'table' cannot rejoin the sub-animations into a complete whole, without some type of CSS trickery. Can you prove me wrong?

            FUTURE: reference to a better example of animating 'two distant objects'. in 'Animation Handling', say involving two separately moving objects.

            Remove Zero Delay Frames - removing intermediate updates
            Of course sometimes you are not interested or want to remove these added intermediate frames from an animation, leaving just the frames that will actually be shown to an user for some period of time.

            You can't just coalesce the animation and use the 'RemoveDups' method as not all 'Intermediate Frames' are similar to the surounding frames, and are thus not duplicates.

            However as these types of frame have a Zero Time Delay you can use another special "-layers" method, 'RemoveZero' which will remove any frame that has a zero time delay.

            This same method will also remove the frames added using Frame Doubling and 'OptimizePlus' techniques as well.

            For example...


              convert moving_hole_split_oplus.gif -coalesce -layers RemoveZero gif:- |\
                 gif_anim_montage - moving_hole_split_rmzero_frames.gif

            [IM Output]

            Which again returns the animation back to just the user viewable frames, simplifying the animation.

            Of course after removing Zero Delay Intermediate Frames, it is very difficult to re-add them as the change information is contained is lost. Consequentially the animation may not frame optimize very well afterward. Optimization is one of the main purposes of such frames after all.

            Frame Optimization Results and Summary
            Lets summarize our optimizations of the moving hole animation...
            [IM Text]

            As you can see by using some complex frame handling, with the help of IM and some human intervention, we were able to frame optimize the 'moving hole' animation to almost half its original size, though with just under three times the number of frames of the original.

            Of course results can vary greatly from animation to animation, but the techniques we used for frame optimization are the same. It just needs a little care and fore-thought, which humans are good at, and computers are not.

                There is the point, that IM should not only account for the number of pixels in current set of frames being looked at, but also the overall size of the extra frame added, and perhaps the overall compression results obtained, when making the decision about how to frame optimize the image.

            On the other hand IM also does not look at the resulting savings in the number of pixels that may result, beyond the frames that are directly involved. That is, later frames sizes may also be smaller as a result of frame doubling, or the disposal method used. This is especially true when the choice is whether to use 'previous image dispose' method, which can have substantial pixel count reductions later in an animation sequence, rather than immediately in the very next frame. A good choice here often requires human input.

            As such I can make no guarantee that IM will produce the best optimization choices, for a specific animation. However it certainly gives it a good try, without the use of recursion, to make that choice. That is only using immediate pixel counts for its decision.

            A recursive algorithm, one that makes a choice, then see what the best final size of the animation that results from that choice, (including recursive choices further along) can produce a guaranteed best optimization. However it could also be an extremely slow operator, and for a large animation could take years to make the final decision. It would also need to include compression optimization choices, as these could effect the final outcome. In other words, while such an algorithm could guarantee the best optimization, it does so at a heavy computational cost.

            Of course a human being with an intimate knowledge of what the animation is trying to achieve, will generally do better in complex animations, as you saw above with splitting frame updates.

            If you would like to try an create a recursive GIF optimization operator please do. I will help in any way I can. It would beat just about every other GIF optimization program on the market. Also most GIF animation developers will probably be very grateful of your efforts (money-wise).

            Semi-Transparency Handling
            The GIF file format does not allow the use of semi-transparent pixels (See GIF Boolean Transparency). This is a fact, and before you can properly optimize an animation, or even save it to GIF format, you need to handle any semi-transparent pixels that may be present, in a way that is suitable for the animation.

            By default if you don't handle these pixels, IM will use a 50% threshold to convert these pixels into either fully-transparent or fully-opaque. However that may not be the best way to handle the problem, particularly in images that contain large areas of semi-transparent pixels, such as shadow effects.

            For example, I wanted to create a Stargate Asgard Teleport animation that could take just about any sub-image as the object being teleported.


              convert -channel RGBA -fill white \
                      \( medical.gif -repage 100x100+34+65 -coalesce -set delay 200 \) \
                      \( +clone -motion-blur 0x20+90 -blur 0x3 -colorize 100% \
                            +clone -colorize 30%  +swap  -composite  -set delay 10  \) \
                      \( +clone -roll +0-20 -blur 0x3 -colorize 30% \
                         -motion-blur 0x15+90 -motion-blur 0x15-90 -set delay 10 \) \
                      \( +clone -colorize 30% \
                         -motion-blur 0x30+90 -blur 0x5 -crop +0+10\! \) \
                      \( +clone -motion-blur 0x50+90 -blur 0x2 -crop +0+20\! \) \
                      \( +page -size 100x100 xc:none -set delay 200 \) \
                      -set dispose background -coalesce   -loop 0     teleport.miff
              gif_anim_montage teleport.miff teleport_frames.png

            [IM Output]

            I purposely left the animation in the IM internal MIFF: file format as this ensures that the original image is preserved without modification, and used a PNG: file format to display the frames so that you can see all the semi-transparent pixels contained in it!

            This is not only important for animations with semi-transparent pixels, but also ones with lots of colors. Once the image sequence has been saves into GIF, your chances of generating a good color optimization goes from good, to difficult.

            Okay I have an animation sequence. If I attempt to save this directly as GIF, IM will just threshold all those semi-transparent pixels.


              convert teleport.miff teleport_thres.gif
              gif_anim_montage teleport_thres.gif teleport_thres_frames.gif

                [IM Output]
            [IM Output]

            The result doesn't really look anything like what we wanted. The default 50% transparency handling makes the animation look like a look like a shrinking 'egg'. Definitely not what I want to achieve with this animation..

            If this type of transparency handling is acceptable this is the way to apply it, before continuing with your other optimizations...


              convert teleport.miff -channel A -threshold 50% +channel \
                             ...do further processing now...       teleport.gif

            An extra advantage of using the above DIY, is that you can control the threshold level. Say '10%' to remove almost every semi-transparent pixel present, to '90%' to make them all opaque.


              convert teleport.miff -channel A -threshold 90% +channel teleport_thres90.gif
              gif_anim_montage teleport_thres90.gif teleport_thres90_frames.gif

                [IM Output]
            [IM Output]

            But applying a threshold for animations, like this one, is not a good solution, as it really spoils the transparency effect I am trying to achieve.

            The best overall solution to preserving all the special effects in the above animation is to just Add a Solid Color Background.


              convert teleport.miff -bordercolor skyblue \
                              -coalesce -border 0 teleport_bgnd.gif
              gif_anim_montage teleport_bgnd.gif teleport_bgnd_frames.gif

                [IM Output]
            [IM Output]

            This removes ALL the transparency from the animation, but at the cost of only allowing the animation to work on specific background color. But if you are creating the animation for a specific web page, that may be quite acceptable.

            Note however for images with sharp outlines, using a dither pattern like this can produce a 'dotty' outline to the sharp edges. As such, it is not recommended for the general case.

            The other solution is to try and generate some pattern of transparent and opaque pixels so as to try and preserve the images semi-transparency. And for this IM offers a large range of dithering options that can solve this problem.

            FUTURE: some link to a to be created section on transparency dithering, such as Quantization and Dithering.

            Note that the obvious first solution of using a Monochrome Dithering of the alpha channel is not simple, probably requiring some advance Multi-Image Composition to do correctly.

            A simple solution is to use a Diffused Pixel Ordered Dither technique, which can be restricted to just the alpha channel, to remove the semi-transparent pixels.


              convert teleport.miff -channel A -ordered-dither o8x8  teleport_od.gif
              gif_anim_montage teleport_od.gif teleport_od_frames.gif

                [IM Output]
            [IM Output]

            The result is reasonable, but looks like a dissolving object than teleporting.

            Using a Halftone will produce a much nicer effect by making the transparency pattern bolder.


              convert teleport.miff -channel A -ordered-dither h8x8a teleport_htone.gif
              gif_anim_montage teleport_htone.gif teleport_htone_frames.gif

                [IM Output]
            [IM Output]

            But for this specific animation, I found that using a User Designed Dither Map to produce vertical lines (from a horizontal line dither pattern) produces an effect that enhances the teleporting animation while removing semi-transparent pixels.


              convert teleport.miff -rotate 90 \
                      -channel A -ordered-dither hlines -rotate -90 teleport_lines.gif
              gif_anim_montage teleport_lines.gif teleport_lines_frames.gif

                [IM Output]

            [IM Output]

            So as you can see there are quite a number of possibilities to handling the semi-transparency in a GIF animation.

            Color Optimization
            Handling semi-transparent pixels is only the first limitation of the GIF file format. The next one is a 256 color limit for each color table in the animation. You are allowed to have a separate color table for each frame. This means a single animation can have more than 256 colors. However, even that may not always be a good idea.

            If you just like a quick summary of the color optimization options available, I suggest you jump to the examples on Video to GIF conversion where the color problems of an animation is at its worst.

            GIF Color Problem
            GIF animations in particular have problems in handling colors, as you it first does not allow semi-transparent colors, then has a 256 color limit per frame, or a 256 global color limit.

            Finally your best frame optimization will not work very well unless the colors used for a pixel in one frame also match the same color, in the next frame, when that part of the image did NOT change! This may seem like an easy problem but Color Reduction is itself an extremely complex field, which required its own full section in IM Examples.

            Color problems are actually why most GIF animations you find on the World Wide Web are of the cartoon variety, or are very bad looking. Especially if resized from a larger version of the animation. In Resizing Animations will probably require more effort in color optimization, than in the actual resize process itself.

            Here I will assume you have the original source of the animation. But that is not always possible, so if you are optimizing a modified GIF animation, some extra caution may be needed. However if you have an animation with to many colors, the first thing you need to remember is...

            Do not save directly to GIF format,
            use the MIFF file format,   OR   separate PNG images.

            As soon as you save to GIF, you have lost control of your GIF color optimization efforts, and you probably have a very bad looking GIF animation that will not optimize very well using various Frame Optimization techniques.

            Speed Animation - an Animation with too many colors
            First we need to generate a GIF animation with a vast number of colors, so that we can really test out the problems involved in color optimization.
                


              convert -dispose none -channel RGBA \
                      \( medical.gif -repage 100x60+5+14  -coalesce -set delay 100 \) \
                      \( medical.gif -repage 100x44+34+6  -coalesce -set delay 10 \
                         -motion-blur 0x12+0  -motion-blur 0x12+180 -wave -8x200 \) \
                      \( medical.gif -repage 100x60+63+14 -coalesce -set delay 100 \) \
                      \( medical.gif -repage 100x44+34+6  -coalesce -set delay 10 \
                         -motion-blur 0x12+0  -motion-blur 0x12+180 -wave +8x200 \) \
                      null: \( +page  -size 120x15 xc:SkyBlue xc:RoyalBlue \
                               -size 120x70 gradient:SkyBlue-RoyalBlue \
                               +swap -append -blur 0x3 -background white -rotate -25 \
                            \) -gravity center -compose DstOver -layers Composite \
                      -loop 0   speed.miff

              convert   speed.miff  speed.gif
              gif_anim_montage  speed.gif  speed_frames.gif

                [IM Output]
            [IM Output]

            Note that I did not save the animation directly to the GIF format but saved it in a MIFF format file, "speed.miff" first. This preserves all aspects of the originally created (or modified) animation, including GIF meta-data, timing delays, as well as all the colors of the image without distortion.

            Only after preserving the original animation, did I directly convert the original animation to GIF format. That way I could show what the above code is meant to achieve, and why I called it 'speed'. This was done also to provide a base line GIF animation for study and later comparison.

            So lets look at various details of our original animation..


              identify -format "Number of Frames: %n\n" speed.miff | head -1

            [IM Text]


              identify -format "Colors in Frame %p: %k\n"  speed.miff

            [IM Text]


              convert speed.miff +append  -format "Total Number of Colors: %k"  info:

            [IM Text]

            As you can see, each image in the animation has a very large number of colors. Not only does each frame have a different number of colors, but the first and third frames are very similar color-wise, though not quite exactly the same.

            However the GIF file format can only save a maximum of 256 color per frame, the ImageMagick saved this to GIF format it did so in the fastest, and dumbest way possible...

            It reduced the number of colors of each frame in the animation (a process called Color Quantization)...


              identify -format "Colors in Frame %p: %k\n"  speed.gif
              convert speed.gif +append  -format "Total Number of Colors: %k"  info:

            [IM Text]

            Because the reduced number of colors in each frame is slightly different, IM also needed to supply a separate colormap for each frame in the animation. This means that the GIF file has one 'Global Color Table' and it always does, but also three separate 'Local Color Tables'.

            The "identify" command cannot tell you how many such local color tables a GIF file has, as the information is too format specific, and not important to the image processing IM normally does. However the more specific "Giftrans" program can tell you how many low level local color tables were used...


              giftrans -L speed.gif 2>&1 | grep -c "Local Color Table:"

            [IM Text]

            As you can see this animation has [IM Text] local color tables, one less than the number of frames present in the image, just as I predicted.

            Not only does each frame have a different set of colors, but also a slightly different pattern of colors (the image dither pattern), as described in Problems with Error Correction Dithers.

            Normally this default operation of IM Color Quantization and Dithering is very good, and perfectly suited for pictures, especially real life photos. In fact the individual frames of an animation will generally look great. All the problems are when we try to later string those individually color reduced frames into an single animation sequence.

            Frame Opt before Color Opt?
            As you saw above saving an animation directly to a GIF format, works, but you will get quite a lot of color differences from one frame to the next, which s bad for later Frame Optimization (as you will see later).

            To prevent color differences causing such problems you can do the Frame Optimization before saving the animation, and thus avoiding the introduced color differences from one frame to another. However be warned that doing frame optimization before color reducing however change the dynamics of the color reduction. Often less of the static unmoving areas will appear in the optimized sub-frame, which means that the color quantization for that frame can give those colors less importance, and therefor less colors.

            Fuzzy Color Optimization
            However sometimes you don't have access to the original animation before it was saved to GIF format. This is especially true if you downloaded the original animation from the WWW. That means you already have an animation with all those GIF color distortions already present, producing problems with later optimizations.

            Now because a slightly different set of colors are used from one frame to the next, and a different pattern of pixels are used for each frame in the animation, each frame can be regarded as a completely different image.

            For example lets compare the first and third frames, which share large amount of the same background image....


              compare  speed.gif'[0,2]' speed_compare.gif

                [IM Output]

            The red areas of the above example shows two solid square areas of the areas that are different, just as you would expect. But it also shows bands of color differences outlining the background of the two frames. These represent the 'churning' dither pattern along the edges of the background gradient where different color pixels were used to represent the exact same background.

            This was also the frame pair showing least background disturbances caused by using different sets of colors, and dither patterns. The actual consecutive frame differences are far worse, producing near a near solid red difference.

                Image differences like this are also a problem if your source images were stored using the JPEG image format. This format uses a lossy-compression method that (even at 100% quality) causes slight color differences, in the images. However the differences are generally confined to a halo around the actual areas of difference, rather that throughout the image.

            All I can say is, avoid JPEG images for use in animations unless you plan to use one single image as a static background image for ALL your frames.

            As so many pixels in the animation are different from one frame to the next it is not surprising then that when we try to Frame Optimize the animation, we get no optimization at all...


              convert speed.gif  -layers OptimizeFrame  speed_opt2.gif
              gif_anim_montage  speed_opt2.gif  speed_opt2_frames.gif

            [IM Output]

            However most the pixel color differences between unchanging parts of the animation frames are actually rather small. It wouldn't have been a very good Color reduction, if this wasn't the case. That means that by asking IM to relax its color comparisons a little, you can ask it to ignore minor color differences. This is done by setting an appropriate Fuzz Factor.


              convert speed.gif  -fuzz 5%  -layers OptimizeFrame  speed_opt3.gif
              gif_anim_montage speed_opt3.gif speed_opt3_frames.gif

            [IM Output]

            As you can see with the addition of a small Fuzz Factor, IM will now ignore the pixels that are only slightly different, producing a reasonable Frame Optimization. How much of a fuzz factor you need depend on just how much trouble IM had in color reducing the original images. In this case not a lot, so only a very small factor was needed.

            If a small fuzz factor produces an acceptable result, then just set it for your Frame Optimization and Transparency Optimization. Just remember you still have a separate color table for each frame to take care of, which is the next point of discussion.

            Note also that the Frame Optimization decided to use a 'Previous Disposal for the second frame. That is after displaying the second frame return the image to the previous frame disposal (the first image) before overlaying. This resulted in a smaller overlay image size, than if no disposal was used thoughout.

            If you wanted just a simple Overlay Animation, only using None Disposal thoughout, you could have used the old Deconstruct operator (also known as Layers CompareAny) to generate it instead.


              convert speed.gif  -fuzz 5%  -deconstruct  speed_opt4.gif
              gif_anim_montage speed_opt4.gif speed_opt4_frames.gif

            [IM Output]

            Generating a Single Global Color Table
            Now as each and every frame has a different set of colors, IM was forced to save the image, with a separate color table for every frame: one global one for the first frame, and 3 local color tables for the later frames.

            For example, here I used the very simple program "Giftrans" program to report how many frame color tables were created.


              giftrans -L speed.gif 2>&1 | grep -c "Local Color Table:"

            [IM Text]

            For a fully-coalesced (or film strip like) animation, having separate color tables for each frame is perfectly fine and reasonable, and in such situations this is not a problem. That is for slide shows of very different images, separate color tables will produce the best looking result. As such this is the normal working behaviour of IM.

            All these extra color tables is however very costly as each colortable can use a lot of space. Up to 768 bytes (256 colors × 3 bytes per color or 3/4 kilobytes) for each frame in the image. Not only that, but the GIF compression does not compress these color tables, only pixel data!

            If having this much file space for separate color tables is a problem, especially for an image that doesn't change color a lot, as is the case with most GIF animations, then you can get IM to only use the requires global color table, and not add any local color tables.

            ---

            To remove local color maps all the image must become type palette and all use the same palette, For the command line you can do this by setting a "-map image" to define the command palette, You cannot use -colors as that works of individual images.

            The command line solution is a special "+map" option, that does a global color reduction to a common palette that is added to all images.

            NOTE any change to the image will likely invalidate the palette, so while color reduction should be done BEFORE you do GIF frame and/or compression optimizations, the common palette needs to be last, just before saving. If "+map" does not need to reduce the number of colors in an image it will not do it or dither colors, just add a common palette across all images.

            ---

            IM can generate a single global color table, if all the frames use the same color palette. In IM color palettes are only assigned to an image either by reading them in from an image format that is using such a palette, or by assigning it one using the "-map" color reduction operator. See Dither with Pre-defined Colormap for more details.

            One way to generate this single color table is to simply "-append" all the frames together, then using the "-colors" command to reduce the number of colors to a minimal set (less than 256, or smaller if you want an even smaller color table). The resulting color table can then be applied to the original image using "-map".

            For example here reduce the image to a single set of 64 colors. This uses the special MPR in-memory register to assign the generated color map to the "-map" command.


              convert speed.gif \
                      \( -clone 0--1 -background none +append \
                          -quantize transparent  -colors 63  -unique-colors \
                         -write mpr:cmap    +delete \) \
                      -map mpr:cmap      speed_cmap.gif

                [IM Output]

            Now if you examine the resulting animation using "Giftrans" you will find that the image now uses a single 'global' color table, rather than a separate color table for each frame.

                I use a "-background" color of 'None' before appending the images together, allowing you to use this on un-coalesced animations, and not have the possibility adding extra unneeded colors.

            The special "-quantize" setting of 'transparent' colorspace was used to ensure that IM does not attempt to generate semi-transparent colors in its colormap. An useless thing as we are saving the result to GIF which cannot handle semi-transparency.

            Finally I color reduce to 63 colors, to leave space for a transparent color. Some animations need transparency, while others (like this one) may still need it later for Compression Optimization.

            To make this easier, IM also provides a special option "+map" which will generate a common color map (of 256 colors) over all the frames, applying it globally. This is a lot simpler than the DIY method above.


              convert speed.miff  +matte +map   speed_map.gif

                [IM Output]

            This resulted in [IM Text] 'local' (or extra unwanted) color tables in the resulting image.

            I will be using the single color table version of the animation for the next optimization sections, though you could actually do this at any point in your animation optimizations and especially before the final save.

            As a result of color table optimization, the animation which was [IM Text] bytes for our directly converted GIF, is now [IM Text] bytes, after using the "+map" operator. The more frames (and 'local color tables') an animation has, the larger the saving.

            Now as any modification to an animation will generally remove the saved palette for each of the images, it is important that the "+map" operator be the last operation before saving the animation to GIF.

            Remember
            Removal of local color maps should be the last optimization, before saving to GIF format.

            Ordered Dither, removing the 'static'
            Under Construction

            Note however that in all the techniques we have looked at so far all can have a dither pattern that changes from one overlay to another. A churning of the pixels that can look like TV static.

            ... small number of colors ...

            With a frame optimization of a smaller unmoving area, you can even get a rectangular areas of static that looks even worse.

            ... Ordered Dither ...

            For now refer to the more practical and less detailed Video to GIF, Optimization Summary.

            Compression Optimization
            Once you have your animation saved into a GIF format, by handling semi-transparent pixels and using color and frame optimizations, you are also able to get some smaller file size reductions by catering to the GIF compression algorithm.

            The LZW compression or Run-length Compression that the GIF file format can use will compress better if it finds larger areas of constant color, or pixel sequences that repeat over and over.

            Transparency Optimization
            As you saw in Frame Optimization an overlaid image will often be just repeating what is already being displayed. That is it is overlaying the same colored pixels that is already present after the GIF disposal methods have been applied.

            But why bother repeating those pixels. If you are already using transparency in an image, you have a transparent pixel color available. But converting those areas into transparency, get larger areas of uniform transparent pixels. That can compress better, than using a mix of different colors, needed to match the same area being overlaid.

            For example here is a simple Frame Optimized, Overlay Animation...
                [IM Output] 	[IM Output]

            Lets now use the "-layers", method 'OptimizeTransparency' (Added IM v6.3.4-4) to replace any pixel that does change the displayed result with transparency.
                


              convert bunny_bgnd.gif -layers OptimizeTransparency \
                                                +map   bunny_bgnd_opttrans.gif
              gif_anim_montage bunny_bgnd_opttrans.gif bunny_bgnd_opttrans_frames.gif

                [IM Output]
            [IM Output]

            As you can see the sub-frames now have large transparent areas, which do not effect the final resulting animation. Areas that need the pixels changed are still overlaid, but the areas that does not change have been made transparent. That includes within the object being animated as well, leaving rather horible looking 'holes'.

            As the larger constant transparent colored areas will (in theory) compress better, the resulting 'messy' animation is a lot smaller, reducing the file size from the frame optimized result of [IM Text] bytes down to [IM Text] bytes. This is quite a big savings for a very small effort.

            Note that the optimization method did not need to be a Coalesced Animation, and that the size of the sub-frames is left unchanged, so as to preserve the disposal needs of this and later frames. As such any savings is just in terms of improved compression ratios for the same number of pixels in the animation, and not in that actual number of pixels saved into the file. It should thus be done after you have completed any Frame Optimization needed, as one of your final optimization steps.

            FUTURE: link to a 'remove background' from animation

            Of course like most of the other "-layers" methods (comparison or optimization) you can specify a Fuzz Factor to adjust, 'how similar' colors are thought to be. That lets you handle animations that were badly color dithered, though if you had studied the Color Optimization above you should not have that problem.

            The free animated GIF tool "InterGIF" also provides this same type of transparency compression optimization shown above, but without the ability to also support a 'fuzz factor' to also make 'close' color changes transparent. I do not recommend it, except as an alternative when IM is not available.

            LZW Optimization - (non-IM)
            Some applications can further optimise the compression ratio of the images in an animation to make it them even smaller. However to do this requires a specialized knowledge of the LZW compression that the GIF image file format typically uses.

            Basically, if a specific sequence of pixels has already been handled by the LZW compression algorithm, it will not bother to convert them into transparent pixels as doing so will not improve the images compression.

            It sounds weird but it works.

            Unfortunately ImageMagick will not do this, as it is such a complex process that takes a great deal of skill and resources to get a reasonably good heuristic to produce a good result in the general case.

            I can however give you a practical example of this technique using the "Gifsicle" application at its highest '-O2' optimization level.


              gifsicle -O2 bunny_bgnd.gif -o bunny_bgnd_lzw_gifsicle.gif
              gif_anim_montage bunny_bgnd_lzw_gifsicle.gif bunny_bgnd_lzw_frames.gif

                [IM Output]
            [IM Output]

            LZW compression optimization reduced the image from [IM Text] bytes with simple transparency optimization, to [IM Text] bytes for "Gifsicle". Not a large improvement.

            The more important aspect however is that while LZW optimization converted unchanged pixel to transparency (as we did using Transparency Optimization above), it did not change a sequence of pixels that had already been seen. That is, only groups of pixels that have not already been repeated within the animation were changed, as those pixel would (presumably) already compress well using LZW compression patterns.

            Note that the selection of what pixels should be made transparent, to generate repeated pixel patterns, is very complex and difficult, and can even depend on the exact LZW implementation as well. It is a heuristic, not a perfectly predictable algorithm. As such different programs will generally produce different results depending on the specific image being compressed. One program may produce a better compression ratio for one image, and another may be better for a different image.

            Lossy LZW Optimization - (non-IM)
            Another compression improvement method involved the slight modification of the pixel colors themselves to 'close color matches' so as to increase the repetition of the color references in the image. A repeated pattern naturally compresses better, and as such can produce a higher compression ratios.

            A fork of the previous "Gifsicle" application, known as giflossy, also generats a 'gifsicle' program, but one with the option to modify the image in minor ways (it is 'lossy') to reduce the size of GIF images, especially in animation, much further.


              gifsicle -O3 --lossy=80 bunny_bgnd.gif -o bunny_bgnd_giflossy.gif
              gif_anim_montage bunny_bgnd_giflossy.gif bunny_bgnd_lossy_frames.gif

                [IM Output]
            [IM Output]

            This resulted in a size of [IM Text] , which is amazing 1/3 reduction in size.

            Unfortunately this method involved changing the resulting image, and as such the optimization is lossy, as it can loose subtle color information. On the plus side it allows you to compress the individual frames, rather than the frame-to-frame optimization. Here for example I generated a difference image of the previous non-lossy LWZ compression against a lossy LWZ compression.


              compare bunny_bgnd_lossy_frames.gif bunny_bgnd_lzw_frames.gif \
                      bunny_bgnd_diff_frames.gif

            [IM Output]

            As you can see almost all the color modifications was in the original 'grass' background image, rather than the cartoon bunny. Basically it slightly modified things just enough to make a huge difference, and for this image not a real noticable difference in look.

            Of course Color Quantization and Dithering is itself a lossy operation and is usually needed anyway, so using a lossy compression method for GIF images, and GIF animations is not regarded as very bad.

                Another example of such an algorithm that was patented for use by Photoshop see US Patent 7031540 - Transformation to increase the lempel-ziv compressibility of images with minimal visual distortion. It is heavy reading but details the methods it uses to achieve better compression.

            Ordered Dithered LZW Optimization
            As the dithering process is usually a more lossy process than LZW optimizations, a better solution may be to try to introduce the repeatable patterns as part of the dithering process. That can be achieved by using Ordered Dithering to produce such patterns, and thus much stronger LZW compression savings than all the previous LZW Optimization method.

            As a bonus it can also improve the Frame Optimization of real life animations with static backgrounds. That would be especially true if you artificially clean up the background so it does become a static unchanging background.

            Of course Ordered Dither Compression Optimization only works for images that have not previously been dithered or otherwise color optimized. As such it only works for animations that have yet to be optimized for the GIF image format.

            Also currently IM Ordered dither only works for an uniform color palette. IM has yet to have a 'best color' or 'user supplied' palette implementation of ordered dither, though I have seen programs that use such an algorithm for very limited (and fixed) color pallets. Do you know of such an algorithm?

            For a practical example of using ordered dither for improved LZW compression optimization, see Ordered Dithered Video.

            Other LZW Optimization
            Other improvements in LZW optimization can also be achieved by other re-arragements of the 'dither pattern' in the image. And some GIF tools can do exactly that.

            However any such optimization should always be checked by a human eye before being approved, as sometimes a subtile but bad color changes can result.

            Compression Optimization Summary
            Here is a complete summary of the final file sizes achieved using compression optimizations.
            [IM Text]

            As you can see only slight improvements in final animation size was achieved by using the very complex LZW Optimization, over the built-in Transparency Optimization.

            However the results are also highly variable between the many GIF optimization application programs available, and the specific animation that is being optimized.

            If you really need to get the very last byte from a file size, then a LZW Optimization may be just what you need. And if you really need the very best results, you should try a number of different programs (and thus heuristic implementations) to see which one compresses your specific animation better, including what other optimization features they provide.

            Typically a Transparency Optimization is good enough for most purposes. With LZW Optimization only producing a slightly better result, producing a very minor saving for network transmission sizes, rather than disk storage size, as the latter uses larger 'chunks' or 'blocks' of storage. Because of this I feel the LZW Optimization, overkill, and I don't think it is worth the effort, or the money (most of these tools are commercially sold).

                Unfortunately I have found that these GIF optimizers do not handle ALL types of pre-optimized animations very well.

            For example, my tests show that "Gifsicle" fails to handle an animation that was already optimized using a 'background disposal' technique.

            On the other hand I found that "InterGIF" will not handle animations that have already been optimized to use an initial canvas and 'previous disposals' technique. It also is limited to the use of Transparency Optimization, which IM now provides.

            I thus recommend you do not mix GIF optimization utilities by feeding one utilities output into another. At least not without first coalescing the animation to remove any previous frame optimizations.

            IM, Gifsicle and InterGIF, all provide such coalescing options to remove their own optimizations, though I cannot guarantee the non-IM applications will coalesce ALL animations correctly. IM will.

            Because you can't use these programs reliably with IM's advanced Frame Optimization techniques (which selects and switches to using different GIF disposal techniques automatically), I have often found that IM will often produce an overall better result that just using these LZW compression optimizers.

            I also suggest you also Coalesce the result again afterward and compare its frames against the original un-optimized animation, to ensure that the non-IM program did not somehow stuff up the animation entirely (see note above). Believe me I have seen it happen, and scripts should double check animations remain valid.


            Another tutorial (using windows tools) about this type of optimization is WebReference Frame Optimation. Note that the site is mis-named as it is about compression optimization.

            Minor Optimizations
            There are a few other optimization techniques that you can use with GIF animations that are often so obvious that they are overlooked.

                Remove GIF comments.
                Many GIF animations have a large text comment added. Often these were added automatically by graphical editors as a form of advertising. For example, "Gimp" by default adds "Created with The GIMP" to images. If the comment is not needed, it is a waste of space. Remove them by adding a "+set comment" operator to the IM "convert" command before the GIF is saved.

                Please note however that if the comment is a copyright notice, it may not be a good idea to remove it for legal reasons.

                Reduce the number of colors.
                If animation looks okay with fewer colors, use a smaller color table. The color tables are always a power of two, so if you can use less than 32 colors, that is a lot smaller than using 256 colors. This is especially important as color tables are not compressed by the LZW compression used for the GIF image data.

                Also using fewer colors will generally produce better LZW compression as more common pixel sequences are found. This is not always the case however as color dithering (due to the color reduction) can also make the compression worse. Turning of dithering or using an ordered dither can be important here.

                Half the number of user visible frames.
                If you can handle a less smooth animation, then halving the total number frames can produce a good improvement in the final file size. Of course you don't get a file half the size, and the animation quality is reduced. But it can produce a very large file size reduction.

                Crop/Resize the animation.
                A smaller image size means a smaller file size. So if you don't need a big animation, don't use a big animation. A small thumbnail to represent a larger animation or video, is often preferable in a listing that the real thing.

                Alternative Compressions.
                If you do not plan to use the animation as an animation, that is you just want to store it, turn off the LZW compression, and "gzip" or "bzip2" compress the WHOLE file for storage!

                The result is a lot smaller, though it requires web servers to give the right 'content' and 'compression' hints to browsers for it to be directly usable by client browsers. The "Apache" web server, doesn't do this by default, but can be made to do so.

                Better still, archive the whole directory of uncompressed animations into a single file, for even better storage compression.

            If you have any other optimization ideas, please let me know.

            Other Sources of Information on GIF Optimization
            The above completes the various basic methods and techniques for handling animations. However to form a complete picture. You should continue into the next IM examples page, detailing techniques for handling actual problems with real Animations of Images. Also many of the above techniques are demonstrated in the practical examples of Video to GIF Optimization.

            I also recommend you thoroughly read about Color Quantization, if you are really serious about dealing with GIF animations, as color reduction is often the key to good GIF animation handling.

            Other useful sources for GIF Animation Optimization techniques that I have found on the WWW include...

                Dr Dobb's - Optimizing GIF Animations
                Optimizing Animated GIFs 

            Mail me if you think you have a page I should list here. I will only add pages of useful content, so no guarantees about adding your link.
https://legacy.imagemagick.org/Usage/anim_mods/
            This page contains practical examples of working with GIF animations. It is highly recommended that you read and understand the Basics of Animations and at least the overall handling of Optimizing GIF Animations, before trying to understand these examples.

            Simple Modifications of Animations
            First an Important point
            DO NOT save the intermediate, animations which you are not finished processing, directly to GIF, especially images that you have yet to perform any sort of Semi-Transparency Handling or Color Optimization.

            If you made the big mistake of saving to GIF you would have just made the resulting animation worse, as IM would have now performed an automatic Color Quantization, to reduce the number of colors present to fit the images into the limited GIF format. Not only that but it did each frame completely separately to every other frame, producing different color selections and dither patterns. That is turn makes any further processing, particularly any Frame Optimization just that much harder.

            This is especially important for resized GIF animations, or ones you have added a multi-color overlay or underlay, as this can add a lot of extra colors.

            You can use the IM internal format MIFF, as a temporary file format if you want to work on an animation in steps or use individual PNG format images for each of the frames being edited. Just do not do the final save to GIF unless you are now sure you will not have color problems.

            I repeat...
            Do not use GIF as an intermediate file format, use MIFF, or PNG images.


            Annotating - add a copyright notice over ALL frames
            As of IM version 6.2.6, you can "-annotate" an animation, in similar way to that detailed in Annotating on top of Images, simply by doing so.

            For example here we annotate the previous dispose animation created in Animation Basics.


              convert canvas_prev.gif -gravity center \
                      -fill black     -annotate +1+1 "Copyright" \
                      -fill white     -annotate +0+0 "Copyright" \
                      annotate.gif
              gif_anim_montage annotate.gif annotate_frames.gif

                [IM Output]
            [IM Output]

            The reason this works, is that "-annotate" will position text relative to the virtual canvas of an image, and not relative to the actual image data. As such the position of the text on each frame is correct for an animated image.

            Before version 6.2.6 however "-annotate", like many other image operators, positioned information, and overlays, relative to the actual image, and ignored any page or virtual canvas offset a sub-frame may have.

            One word of warning, drawing on an animation like this, without first Coalescing the animation, can cause some unusual effects, due to an animations existing optimization scheme (see next set of examples). As such (and as you will see) removing any existing frame and transparency optimizations by Coalescing it first is recommended.
            Drawing - modify a coalesced animation
            Now while "-annotate" places text relative to the virtual canvas of each frame, many other images operations do not. This includes all "-draw" operations, which only draw things relative to the actual image, and completely ignore any offset it may have on a larger canvas.

            For example, here we draw a fancy green circle near the top left corner of the previous dispose animation.


              convert canvas_prev.gif -fill LimeGreen -stroke SeaGreen \
                      -draw 'circle 35,35 20,30'  draw_circle_fail.gif
              gif_anim_montage draw_circle_fail.gif draw_circle_fail_frames.gif

                [IM Output]
            [IM Output]

            Well as you can see "-draw" drew the circle relative to the 'actual image', rather than the larger virtual (page) canvas the image is part of. The result is, as is typical in this sort of situation... a mess.

            The simple solution to this is to first Coalesce the animation, before drawing, then re-optimise the GIF animation afterwards. See Optimizing Animations for details.


              convert canvas_prev.gif -coalesce \
                      -fill LimeGreen -stroke SeaGreen -draw 'circle 35,35 20,30' \
                      -layers Optimize  draw_circle.gif
              gif_anim_montage draw_circle.gif draw_circle_frames.gif

                [IM Output]
            [IM Output]

            Note how the IM animation optimizer actually decided to just not overwrite the part that was drawn on. This is actually more optimal than if it had drawn on the actual sub-frame images themselves.

            This method will let you overlay any sort of annotation, copyright notice, or watermark you like. Of course you may need to use the special Layers Composition technique to actually overlay an image onto every frame in an animation.

            If you get really good you can even do so far as doing Animation Merging to overlay an animated copyright notice on your animation.

                While this 'coalesce-optimize' technique will work with most operations involving animations, especially with IM's optimizer, there are some operations that do such drastic changes to images, such as major color changes, and shadings, and with semi-transparency, that the resulting animation failing to optimize very well.

            For example just about any "-resize" operation is likely to produce an animation that will optimize very badly afterward due major color changes. See Resizing Animations below for solutions to this.

            Frame by Frame - modifying one frame at a time
            By using the IM Image List or Sequence Operators you can modify each frame of the animation separately. The trick is to extract each frame in parenthesis, modify it, then replace the original image with the modified version.

            For example here we add text as a copyright watermark into the animation, as an animation itself, making it even harder to remove. So as not to completely destroy the animation, I also used semi-transparent colors.


              convert canvas_prev.gif -coalesce -gravity center \
                      -font Ravie -pointsize 24 -fill '#FFF8' -stroke '#0008' \
                      \( -clone 0 -annotate 0 'This'        \) -swap 0 +delete \
                      \( -clone 1 -annotate 0 'This'        \) -swap 1 +delete \
                      \( -clone 2 -annotate 0 'image'       \) -swap 2 +delete \
                      \( -clone 3 -annotate 0 'is'          \) -swap 3 +delete \
                      \( -clone 4 -annotate 0 'Copy\nright' \) -swap 4 +delete \
                      -layers OptimizeFrame   frame_mod.gif
              gif_anim_montage frame_mod.gif frame_mod_frames.gif

                [IM Output]
            [IM Output]

            Note the use of Parenthesis, to limit the effect of the "-annotate" operation to just a simple 'clone' of one frame of the animation. The modified image is then returned to its proper position in the image sequence using the Swap and Delete operators.

                The single number usage in the "-swap" operator was added in IM v6.3.4-3. before this you would need to specify "-swap 3" as "-swap -1,3", for it to work properly.

            This technique of modifying individual frames will probably be one of the most important techniques in manipulating image animations you will encounter.

            You will also notice that I actually added the same text to both the first and second image. The first image in the above animation is a Zero Delay Intermediate Frame, which is used to define the background for the rest of this animation. That is it flashes by so fast, it is not usually visible to the users, nor is it meant to be visible.

            Thus the first two actual frames in the above animation should be regarded as a single visible frame, rather than two separate frames.. The frame with a non-zero time delay is the last frame of a 'display' frame sequence.

            Similarly for other fast running animations, you may need to modify a number of frames to make your change visible for any appreciable length of time. This is not a problem for a static annotation that was drawn over all the frames (see previous Annotating example above).

            This brings us to an important point about GIF animations.
            Study an animation before attempting to modifying it.
            It can make a BIG difference to the final result.

            Cropping - limit the area of animation
            IM has endeavored to make the "-crop" image operation work correctly relative to an images virtual canvas rather than to the actual image (IM version 6.1.1 onward). This in turn allows you to do things previously not directly possible.

            For example crop the images of a GIF animation and still have it work as expected for all animations.


              convert  canvas_prev.gif -crop 50x50+3+30  cropped.gif
              gif_anim_montage cropped.gif cropped_frames.gif

            [IM Output]
                [IM Output]

            As you can see the crop worked, just like it would for a cropping a single image, preserving the appropriate offset and page size, so the image data is still positioned correctly, even though the area involved has been reduced.

            As you can see this did not change the overall virtual canvas size!

                Do not use "+repage" to remove the crop offsets from a frame optimized GIF animation. Doing do will also remove the needed frame offsets that the position the sub-frames on the virtual canvas, and which later frames may rely on to animate correctly.

            The above "-crop" operation did however produce a warning message...
            [IM Text]

            As the crop of one of the frames in the animation missed the sub-frame overlay image used for that frame. that is one frame did not update the area that was cropped from teh animation. As a result that frame now does not contain any real image!

            To compensate, IM not only produces a warning message, but generates a special 'Missed Image' as a placeholder in the animation to keep everything in order, and preserve any 'delay' or 'disposal' methods attached to that frame. You can leave that placeholder, or fix it as you like.

            In this case the 'Missed Image' is needed for the animation to run as expected. However if multiple consecutive missed images are generated, you can probably merge them together into a single missed image using the "-layers" method 'RemoveDups'.

            Caution and study of the animation is however still recommended. (See Splitting up an Animation below, for a more detailed example of this.

            Crop the Canvas Too - viewport crop of the animation
            Just as a normal crop, preserved the virtual canvas of the original images, so did a crop of an animation. This is probably not the intent in this case.

            Because of this, in IM version 6.2.4-5, a special flag '!' was added to the "-crop" argument. This flag will cause crop to not only crop the individual image frames, but also adjust the page or canvas information about the image to that same area.

            This is known as a 'viewport crop', as the result will be as if you are looking at the image though a 'window' or 'viewport' of the size and position of the crop argument.

            Not only is the size of the virtual canvas set to the size of the crop area, but the offset of each frame in the animation is adjusted to keep things correct. (See Viewport Crop with Canvas/Page Adjustments).

            For example lets repeat the previous crop, but also crop the canvas information using the '!' flag...


              convert  canvas_prev.gif -quiet -crop 50x50+3+30\!  crop_viewport.gif
              gif_anim_montage crop_viewport.gif crop_viewport_frames.gif

            [IM Output]
                [IM Output]

                The '!' character has special significance to some UNIX shells, like "csh", and must be escaped with a backslash, even when placed inside quotes. IM will ignore backslashes, in geometry arguments so it does not hurt to always backslash it.

            As you can see the result is more like what you probably really wanted to achieve when cropping an animated image.

            Note that I included a "-quiet" setting to ask IM not to give the warning message about the Missed Image, that we generated in the previous crop attempt. This is recommended whenever cropping animations, as the warning does not really apply.

            Note that a Viewport Crop will also allow you to increase the canvas area or even re-position everything within the canvas. However it is dangerous as any images which fall partially or completely outside the crop area will be cut down to only show the part of the image that appears within that area.

            Just one final word of warning. When using a 'viewport crop' the frame images are moved in the negative direction to the offset given for the 'viewport'. This can appear illogical, unless you remember that the offset in the crop operator is the position of the viewport, and not a direct re-position of the images themselves.

            Bounds Trimming - automatic canvas size correction
            As with the previous operations trimming an animation can be tricky. If the animation consists of a simple Cleared Frame Animation, then you can trim an animation simply by working out the maximum bounds of all the individual frames within the animation.

            As of IM v6.3.4-8 you can do this very easily using a 'TrimBounds' layer method.


              convert  anim_bgnd.gif -layers TrimBounds anim_trim_bounds.gif

            [IM Output] ==> [IM Output]

            For users before this version of IM you can still do the same thing, but only in a two step process (which also performs other unwanted processing). To do this you would use a Layers Merge to merge all the frames of an animation down to a single layer, and then have IM report the size and offset of that layer...


              convert  anim_bgnd.gif -layers merge -format '%wx%h%X%Y' info:

            [IM Text]

            Now that you know the bounds of all the frames, you can just Viewport Crop the whole animation to this size.


              convert  anim_bgnd.gif -crop 89x77+5+10! anim_trim_crop.gif

            [IM Output] ==> [IM Output]

            If you also want to trim a static background from an animation then your best bet is to delete the first frame from a Frame Optimized animation, before using the Layers Merge step. You can then use the returned bounds for the Viewport Crop on the original animation.

            Repositioning Frames
            A similar and related operation is the 'relative repage' operator. This will add the given offset to all the individual sub-frame layers of the animation, allowing you to adjust their positions relative to the whole canvas. To make a "-repage" operation relative, you also add a '!' flag to its argument.

            For example here we displace the second an later frames of an animation 30 pixels down and right, returning the first 'background' frame in its normal '+0+0 position.


              convert  canvas_prev.gif -repage 0x0+30+30\! \
                       \( -clone 0 -repage +0+0 \) -swap 0,-1 +delete \
                       repage_offset.gif

              identify repage_offset.gif

                [IM Output]
            [IM Text]
                The above animation will fail (show only the first two frames) for Windows Internet Explorer version 8. This happens any time a frame attempts to draw an image beyond the bounds of the animation canvas.

            Notice that none of the images have been 'cropped' or cut down. Only their positions have been changed, relative to the original background image, even if the image was moved 'off canvas'.

            If you like, you may also like to expand the canvas to match these new bounds, either by adjusting the canvas size directly...


              convert  repage_offset.gif -repage 130x130  repage_canvas.gif

                [IM Output]

            By using the Bounds Trim Layers Method you can automatically expand the animations bounds just enough to include the images which were now being placed 'out-of-bounds'...


              convert  repage_offset.gif -layers TrimBounds repage_bounds.gif

                [IM Output]

                Using "-repage" to move images left or up, especially with a small canvas, is likely to fail for GIF animations. This format basically cannot use a negative image offset.

            For that you may be better off also applying a 'viewport crop', or using the 'trim bounds' to shift all the offsets into a larger positive canvas. Either method will guarantee a positive offset to all the image frames.

            The PNG and MNG formats can handle negative offsets, but many web browsers and other programs may not understand such offsets, producing weird effects. One version of the "Firefox" web browser for example produces extremely large images, when attempting to display a PNG with a negative offset.

            Reversing Animations - making animations run backward, or cycle
            As of IM v6.3.3, the "-reverse" image sequence operator was added (see Reverse Operator for more details). This allows you very simply reverse the order of a coalesced animation sequence.

            For example here I make a 'hand draw k' animation become undrawn!


              convert script_k.gif -coalesce -reverse \
                      -quiet -layers OptimizePlus  -loop 0 reversed.gif

                [IM Output]

            I had to re-add the "-loop" option to the above as this needs to be attached to the first image, which is now the last image! The result could also use some timing adjustments, but as you can see it now 'undraws' the letter!

            Be sure to "-coalesce" the image sequence before reversing it, as any Frame Optimizations present are dependant on the image order. Better to remove those optimizations first.

            Patrol Cycles - cycle back and forth between two ends
            A similar technique is to add a reversed order of frames to the end of the animation, so the resulting animation cycles between the first and last frames of the original animation. It's a bit like a guard walking a patrol between two points, and is called a 'Patrol Cycle'.

            Here I use the image Duplicate Operator (added to IM v6.6.8-7) to generate the extra frames (reversed).


              convert script_k.gif -coalesce   -duplicate 1,-2-1 \
                      -quiet -layers OptimizePlus  -loop 0 patrol_cycle.gif

                [IM Output]

            Notice that I didn't just copy all the images of the animation, but skipped copying the very first and last image of the original sequence. If I had copied all the images, the first and last images would appear for twice the expected period of time, and make the animation file larger than is needed.

            Even so, you should again watch out for Zero Delay Intermediate Frames at the start and end of the animation, as these can result in unexpected problems. Basically do not do this without studying the animation first, or you are asking for trouble.

            Also to allow better optimization of the result, you may even need to add some extra Zero Delay Intermediate Frames, between the forward and reverse cycles, to improve optimization. These extra frames were probably not provided in the original animation optimization as the whole animation normally resets when it loops. See Splitting Frame Updates for more details of how these extra frames help optimize and improve the animation.

            Here is an older method using the Clone Operator to generate duplicate frames.


              convert script_k.gif -coalesce \( -clone -2-1 \) \
                      -quiet -layers OptimizePlus  -loop 0 patrol_cycle_2.gif

                [IM Output]

            Color Morphing - animated change between two images
            The "-morph" operator is an especially interesting operator. It will take a list of images, and insert extra frames between them, so as to do a soft color change from one image to the next.

            This operator is not however a true 'morph' as it only modifies the pixels color creating a sequence of Blended Images. A true movie like 'morph' also involves image Distortion to transform the outline of the object in the image to the objects in the other image.

            For example here I create a Patrol Cycle using a color morph to generate the extra frames between the rose image and its flipped form.


              convert -delay 20 rose: \( +clone -flip \)  -morph 5 \
                      -duplicate 1,-2-1  rose_flip.gif

                [IM Output]

            This is not particularly good as all the images have the same delay. The result is that the animation never seems to 'rest' or pause between the two end points of the cycle.

            A better solution would be to have a pause on the original and its 'flipped' form. That however requires you adjust the delays of the original images to be different to the morphing images.


              convert rose: \( +clone -flip \)  -morph 5 -set delay 10 \
                      \( -clone 0 -set delay 240 \) -swap 0 +delete \
                      \( +clone   -set delay 240 \) +swap   +delete \
                      -duplicate 1,-2-1 rose_flip_pause.gif

                [IM Output]

            As you can see the timing delays can become very important for generating a good animations, allowing the animation to 'rest' at just the right points.

            As of IM v6.6.9 you can set the delay using a FX Percent Escapes calculating based on the index of the image. Here the FX expression says use a delay of 10 if the image ingex is not the first (t=0) or the last (t=n-1), otherwise use larger value.


              convert rose: \( +clone -flip \)  -morph 5 \
                      -set delay '%[fx:(t>0&&t<n-1)?10:240]' \
                      -duplicate 1,-2-1    rose_flip_anim.gif

                [IM Output]

            For a whole range of different methods of 'morphing' or doing a 'transition' from one image to another see Fred Weinhaus's "transitions" and "fxtransitions" ImageMagick shell scripts. The Example page includes the basic algorithm that the script uses to generate the animation.

            Resize Morphing - animated change in size
            The Color Morph Operator actually will not only do color blending between two images, but also does image resizing at the same time. For example here I use "-morph" on two images that are different sizes, and even different aspect ratios.


              convert rose: medical.gif -morph 10 \
                      -layers TrimBounds -set dispose previous -coalesce \
                      -background black -alpha remove \
                      -set delay '%[fx:(t>0&&t<n-1)?10:60]' \
                      -duplicate 1,-2-1  -loop 0  morph_resize.gif

                [IM Output]

            Only the first line does the resize morph. If you were to look at the actual images each frame will have a different size! The next two lines 'fills out' the images to be the same size, and filling the unused parts with black. Specifically the operations is designed so the order of the image does not matter. The rest is to just setup a Patrol Cycle and associated timing delays.

            The 'resize' is only performed from the top-left corner. At the time of writing the Color Morph Operator does not understand layer offsets, or any other spatial morphing (distorted morphing). As such if you want the resize to be centered, you may need to use much more complex techniques shown in later sections.

            Here is a similar example, this time resizing the image with a smaller version of the same image (aspect ratio preserved)...


              convert rose: \( +clone -resize 10 \) -morph 10 \
                      -layers TrimBounds -set dispose previous -coalesce \
                      -background black -alpha remove \
                      -set delay '%[fx:(t>0&&t<n-1)?10:60]' \
                      -duplicate 1,-2-1  -loop 0  morph_resize_self.gif

                [IM Output]

            Note that the 'between' images are more blurry than they probably should be. This is because the larger image is not only being resized smaller, but it is also being color blended with the smaller image which was resized larger.

            Wipe - creating a wipe from one image to another
            This is actually very easy to do. Just overlay 'slivers' of the new image. These are directly generated using a simple Tile Crop.

            For example here we 'wipe' from one image to its flipped version, and just for fun, wipe back again.


              convert rose: \( -clone 0 -flip -crop 3x0 \) \
                            \( -clone 0 -crop 3x0 \) \
                            -set delay 10 -loop 0  wipe.gif

                [IM Output]

            Here is a version from GeeMack on the IM Forums, that implements wipes from all four directions...


              convert -size 100x60 -delay 100 \
                  gradient:green-yellow gradient:blue-purple \
                  gradient:orange-white gradient:red-black \
                  -write mpr:stack -delete 0--1 \
                  \
                  mpr:stack'[0]' \( mpr:stack'[1]' -set delay 5 -crop 4x0 \) \
                  mpr:stack'[1]' \( mpr:stack'[2]' -set delay 5 -crop 0x4 \) \
                  mpr:stack'[2]' \( mpr:stack'[3]' -set delay 5 -crop 4x0 -reverse \) \
                  mpr:stack'[3]' \( mpr:stack'[0]' -set delay 5 -crop 0x4 -reverse \) \
                  -loop 0 wipe_all.gif

                [IM Output]

            Animated Distorts - distorting multiple image based on image index
            Many operators can use Percent Escapes in their arguments. This means you can actually modify the operator so that it performs slightly differently for each image that is being processed.

            The method involves first Duplicating Images to create 30 (or however many you like) identical copies of the rose image. You then modify each image differently using FX Percent Escapes to calculate distortion values, based of the images index '%[fx:t]' and the number of images in the list '%[fx:n]'.

            For example here I translate the image by a calculated amount.


              convert rose:  -duplicate 29  -virtual-pixel tile \
                      -distort SRT '0,0 1, 0, %[fx:w*t/n],%[fx:h*t/n]' \
                      -set delay 10 -loop 0     rose_diagonal_roll.gif

                [IM Output]

            And here I rotate the image, depending on the index, but generate a longer pause if the image index is 0 (the first image).


              convert rose:  -duplicate 29  -virtual-pixel Gray \
                      -distort SRT '%[fx:360*t/n]' \
                      -set delay '%[fx:t==0?240:10]' -loop 0     rose_rotate.gif

                [IM Output]

            Note that the image index ('t') has a value from '0' to 'n-1', as such the formula '%[fx:t/n]' will have a value from '0.0' to a value just short of '1.0'.

            This is perfect for a repeating or cyclic animation such as above, but may not be very good for generating transitions from one image to a new image. In that case you want the final frame to have a multiplier of '1.0' for the final frame, use the formula '%[fx:t/(n-1)]'.

            This is only a sample of what can now be done easily using image indexes in '%[fx:...]' calculations. Imagine what is possible with a more complex distortions.

            Without the use of image index calculations, the above would have required an external shell loop, to generate each frame individually, and a separate step to collect the frames to form the final animation. Examples of such looped shell scripts are given in Simple Warped Image Animations as these operators do not allow the use of Percent Escapes in their arguments.

                Before IM v6.6.9-0 Percent Escapes and FX Percent Escapes involving image indexes, such as '%p', '%n', '%[fx:t]' and '%[fx:n]' were broken. Typically they would only return unhelpful values of either '0' or '1', and not the actual index and number of images in the current image sequence.

            Append a Label - add a label to whole animation
            As always there are a number of ways to actually append a label to an image.

            For example, for animations that has an initial background canvas, or one that only overlays new color to previous frames, then you can just append the label to the first frame of the image. The other frames will not remove it.

            Here we just add some extra space with "-splice", and "-annotate" some text in it.


              convert canvas_prev.gif \
                      \( -clone 0 -coalesce -gravity South -background white \
                         -splice 0x18 -annotate 0 'Label First' \) \
                      -swap -1,0 +delete   label_first.gif

                [IM Output]
            However this only works for some animations, It would not work for a common Cleared Frame Animation which clears or replaces all the pixels after each frame has been displayed.

            For a more general method that works for all animations, we need to first "-coalesce" the animation to the un-optimized Coalesced Animation. Then we can add the label to each and every coalesced frame of the animation, before re-optimizing it.


              convert canvas_prev.gif -coalesce \
                      -gravity South -background white -splice 0x18 \
                      -annotate 0 'A Better Label' \
                      -layers Optimize labeled_anim.gif

                [IM Output]
            Rather than using "-annotate" to draw text into the added extra space, you can use a composition method (see next sections) to compose an image into the added space. That way you can prepare a much fancier label to add to the animation.

            Of course doing this can cause some animations not to optimize very well afterward, especially Cleared Frame Animations, but that is the price you pay for adding labels. One solution for that type of animation is to prepend a 'initial background canvas' that contains the label, as shon in the section explainging Cleared Frame Animations.

            Also note that adding a label to an animation can result in many extra colors being added. This could overflow the GIF color limits, as such you may have to be prepared to color optimize your animation as well. A very difficult task that is best to avoid if possible (see Color Optimization). This can be a problem for any general modification to any animation.

            Remove Transparency - add a solid color background
            A large number of animations you find on the web have a transparent background. These are very useful as you can place them on web pages without needing to worry about any background pattern that may be present.

            However when processing animations, especially when applying other image operators such as "-resize" and "-blur", such an animation has problems. The general solution is Remove Transparency from the image, generally by somehow overlaying them onto a specific color, such as the specific color that us used as the background to a web page. [IM Output]

            For example here I have a simple transparent overlay animation of a letter 'K' being drawn as if by an invisible hand.

            As this GIF animation is drawn with transparency, and only overlays images onto the previous frames (adding pixels, never removing them), a simple way of setting a background color (or image) is to add it to just the first frame of the animation. All the other frames contain a transparent color for the background, so will not effect the result.

            Here we use the Flatten Operator to overlay the first frame of the animation onto a 'LimeGreen' background color. We can use "-flatten" for this as we are only applying it to a single image, and NOT the whole animation.


              convert script_k.gif \( -clone 0 -background LimeGreen -flatten \) \
                      -swap 0,-1 +delete      script_k_flatten_0.gif

                [IM Output]

            It is also important to not that the original first frame was only a single pixel in size. The Flatten Operator not only colored the background, but also expanded that frame to its full size. that is it 'filled out' the frame as well.

            Note however that as only the first frame of the animation has been colored. This method is preferred, as any optimization (such as the heavy optimization that this animation contains) is preserved.

            Coloring the first frame will not work for all GIF animations. It only works for simple Overlay Animations.

            For a general method of removing the transparency from an animation, you need to first "-coalesce" the animation, and then actually Remove Transparency from all the frames, using the Alpha Remove Operator. This time lets do this using a 'Tomato' background color.


              convert script_k.gif -coalesce   -background Tomato -alpha remove \
                      -layers Optimize   script_k_alpha_rm.gif

                [IM Output]

            Of course the resulting optimization may not be the as optimal as the original, but the animation no longer has any transparency in it. As an additional side-effect, any 'Background' dispose settings in the animation will have been converted to either 'None' or 'Previous', by the Frame Optimization process, as transparency is no longer an issue.

                Alpha Remove was added to IM v6.7.5. If your IM version is older you will need to use an alternative method such as using a side effect of the Border Operator. See Remove Transparency for details of this and other methods.

            A more complex background handling such as underlaying a background image or pattern, requires a much more complex handling of animations, than the simple modifications we have looked at so far. This is what we will look at next.

            Multi-Image Alpha Composition
            The next level of animation handling requires you to be able to compose single static images either over, or under an existing animation. That is general Alpha Composition. This gets even trickier when two separate sets of images are being merged.

            Before IM v6.3.3-7 multi-list composition was only possible using specially designed API scripts, or shell scripts that saved and merged individual frames of the animation. Neither was very nice techniques, but that was all that was possible. That is now changed.

            Draw Images - draw an image onto a list of images
            The "-draw" operator has the ability to compose a source image on top of a list of images. It is also the only multi-image alpha composition method that you could use in the "mogrify" command, or against multiple images, before IM v6.3.3-7.

            The reason this Alpha Composition technique was so important was because it allowed you to specify an image as a separate argument to the current image list. That is within the quoted Magick Vector Graphic language of "-draw".

            Because of its historical importance, I will show its use in detail, especially for users which still have older versions of IM.

            For example here I overlay rose image over the whole animation.


              convert canvas_prev.gif -coalesce \
                      -gravity NorthEast  -draw 'image over 5,5 0,0 "rose:"' \
                      -layers Optimize   draw_over.gif

                [IM Output]

            This allows you to Compose an external source image over every image in the current image sequence.

            This is good enough for most purposes. For example by using the 'Dst_Over' composition method you could also place an image 'under' the animation as a static background.

            For example here we 'underlay' a "netscape:" built-in image, though it could have been any external image file...


              convert script_k.gif -coalesce \
                          -draw 'image DstOver 0,0 0,0 "netscape:"' \
                      -layers Optimize   script_k_netscape.gif

                [IM Output]

            Note that the size of the animation has not changed, as it is the destination images define the final size of the alpha composition.

            If you did want to create a larger canvas, you had to adjust the size and offsets of the animation appropriately to accomidate the background. For example using a Relative Repage of the animation before coalescing.


              convert script_k.gif  -repage 100x100+20+20\!   -coalesce \
                          -draw 'image DstOver 0,0 0,0 "granite:"' \
                      -layers Optimize   script_k_granite.gif

                [IM Output]

            Also if you wanted to use an image that had already been read-in, created, or modified, then you need to use a "MPR: Memory Program Register to provide you with a 'read source' for that image.


              convert -size 53x54 xc:SkyBlue -fill DodgerBlue \
                      -draw 'circle 26,27 24,8' -write mpr:bgnd +delete \
                      \
                      script_k.gif -coalesce \
                      -draw 'image DstOver 0,0 0,0 "mpr:bgnd"' \
                      -layers Optimize   script_k_mpr_bg.gif

                [IM Output]

            That is about the limit of Draw Alpha Composition methods. No overlaying the animation images 'over' a destination image of unknown size, and no way to merge two separate multi-image sequences together.

            That was until...

            Layers Composition - alpha composition for image lists
            With IM v6.3.3-7 the "-layers" method, 'Composite' was added allowing you compose two completely separate sets of images together. (For a short summary see Layering Images, Layer Composite)

            To do this on the command line, a special 'null:' marker image is needed to define where the first destination list of images ends and the overlaid source image list begins. But that is the only real complication of this method.

            So lets try it out by creating a set of shadows from set of images, then overlaying the original image over those shadow images...


              convert script_k.gif -coalesce  coalesced_k.gif

              convert coalesced_k.gif  -background black -shadow 100x3+2+5 \
                      -background SkyBlue -alpha remove    shadows_k.gif

              convert shadows_k.gif  null:  coalesced_k.gif \
                      -layers Composite          compose_shadow.gif

              gif_anim_montage compose_shadow.gif compose_shadow_frames.gif

                [IM Output]
            [IM Output]
            [IM Output]
            [IM Output]

            The above example is very important, so I will explain it in detail.

            First we generate a Coalesced version of our animation so as to remove any Optimizations that may be present to make the animation ready for some serious processing, without any GIF optimizations interfering with the processing.

            Next we created an animated shadow image from our coalesced animation, and Remove Transparency, as GIF cannot handle semi-transparent shadows. This is the animation that want to add 'under' our original animation. It has the same number of frames, and even the same timings as the original animation. This correspondence is important, so don't forget it.

            Now we read in the two animation or layer sequences, but we add a special 'null:' image separator between them, so that ImageMagick knows when one sequence ends and the next sequence begins. This image separator is automatically removed by the next all important "-layer composite" operation. Other API's should be able to use separate 'Wands' of images, rather than a single sequence with a special separator.

            The layers composition is then performed just as if these two animations or image sequences were just a simple single image, rather than a sequence of multiple images. Each pair of images, one destination, and one source, are composited together, to generating a merged (composited) sequence on images.

            The final result is that we have added shadows to our original animation sequence, which is ready for GIF optimizations, or just direct use.


            Now you can do all the above steps in a single command. However you can't just use "-clone" to create a copy of the original sequence, since we don't really know (or want to know) how many images are in the sequence. Instead you can use a "MPR: Memory Program Register to save a whole list of images. It's sort of like taking a snapshot of the whole image sequence currently in memory, and then reading it in again later.

            The result is a command like this, though I used a different colored background.


              convert script_k.gif -coalesce -write mpr:images \
                      -background black  -shadow 100x3+2+5 \
                      -bordercolor Wheat -border 0 \
                      null:    mpr:images    -layers Composite \
                      composite_shadow.gif

                [IM Output]

            This version actually works better as we did not loose the offset information that the Shadow Operator generates (GIF's cannot save a negative offset, so resets it to zero). We could fix that in the above by using a MIFF file format for the intermediate images rather than GIF, or, as you will see in the next example, by using a "-geometry" composition offset.

            Basically these examples shows that the Layers Composite Operator actually understands the individual Virtual Canvas Offset ("-page") settings and will handle them, just like a Layers Flatten or better still Layers Merge operators would handle them.

            But the Layers Composite Operator also understands the use of a Composite Geometry ("-geometry") offset (zero by default), to control the overall placement of the whole overlay image sequence. It even understands the effects of "-gravity" on that global offset.

            For example.. let's overlay our original 'K' animation 'South' of the generated shadow animation...


              convert shadows_k.gif  null:  coalesced_k.gif  \
                      -geometry +0-10 -gravity South  -layers Composite \
                      composite_south.gif

                [IM Output]

            The above also shows that just like normal two image Alpha Composition, it is the destination image sequence that controls the final output image size, and any composition overlay will be clipped to the destination canvas image. As such you should ensure all the destination images is large enough to contain your final results.

                The resize capability of "-geometry" is not strictly part of the composite operation, it only resizes the last image of the current image sequence. As such it will not do what you expect if used with multi-image Layers Composition. See Resize Geometry for details.

            Basically Layers Composition is very much like normal composition.
            Quite simple really. Did I say simple?


            Layers Composition details......

            As you saw above the command line version of "-layers Composite" uses the first 'null:' image found in the current image list as a marker to separate the two lists. The two image lists are separated and the 'null:' junked before the two lists are Alpha Composited together, two images at a time.

            Only an image generated from the special 'null:' image source can be used for the marker, and if not found an error will be reported. You currently cannot read this 'null:' marker image from a pipeline (at least not at this point), only generate it when needed.

            Layer composition is also rather more complex than a simple, two image Alpha Composition, as the images virtual canvas of the image list also accounted for. Normally alpha composition ignores any virtual canvas size and offset for positioning purposes, using only the images actual size. This special layers method uses the virtual canvas information, for geometry positioning, so as to align the two image sequences.

            To this end any virtual canvas offset a sub-frame has is also added to the normal "-gravity" adjusted, "-geometry" composition offset, to work out the position of the image overlay.

            Only the virtual "-page" canvas size of the first image of each list is used to work out the "-gravity" adjustment to the "-geometry" composition offset. The canvas size of later images is ignored, with only the individual virtual "-page" offset being added to the calculated "-geometry" offset.

            In other words "-layers Composite" is designed for alpha composition of 'layers' or 'animations', and the special requirements of such image lists.

            Caveats...

            You do however still need to be careful with image lists you are overlaying.

            If for example if the destination list images are not large enough, or positioned incorrectly to contain the overlaid source image, the overlaid image will be clipped, or miss the destination image completely. For this reason it is a good idea to Coalesce the destination images to the full canvas size, before overlaying smaller source images. For example see Side-by-Size Animation Append examples below where canvas size needed to be expanded to provide space for the appended images.

            Also if the source image list is an GIF animation, then you may need to be sure that the sub-frames are clean of things like: Compression Optimizations, and fancy Frame Optimizations; or you may have problems. On the other hand a Cleared Frame Animation or Coalesced Animation can be directly 'Composite' without any problems.

            Just remember that Layers Composition does not understand any existing GIF Disposal Methods that may be present in the images, though it preserves the destination GIF animation meta-data, such as: Dispose Method, Frame Delay, and Iteration Loop Limits.

            The one exception to this is given in a special case below.

            Single Image Composition - compose images with a single image
            Normally two lists of images of equal length are composed together, one image pair at a time until either of the image lists runs out. Neither list of images will be repeated. The composition will just stop. You are left with just the original destination image list with the added compositions. The 'null:' separator image, and all the source images are deleted from the current image list.

                An API interface to this layers method, should allow you produce two separate image lists, and it will be left up to you to delete both input image lists that was used to generate the resulting list of images. The 'null:' separator should not be needed.

            However if one of the lists only contains a single image, that image will be composed against all the images in the other list. It does not matter if that single image is a source image or a destination image. The method will do the composition against the other image list, and preserve the GIF meta-data of the image list, rather than the single image, even if that image is the destination image.

            This 'compose against a single image' is a special case for Layers Composition, and is very useful for adding a background to an animation (see next), or inserting a static object into an animation.

            Static Background - compose over a larger background
            For example using this special Single Image Layer Composition method we can compose an animation over a a static background...


              convert -size 100x100 plasma:fractal null: \( script_k.gif -coalesce \) \
                          -gravity Center   -layers Composite \
                      -layers Optimize   composite_background.gif

                [IM Output]

            As the background image is the destination, it defines the final size of the animation, but all the meta-data (delays, labels, comments, etc) will come from the source image list. Normally that information comes from the destination image list. This is only time the source image provides the meta-data information during an image composition.

            Also note that as Layers Composition understands "-gravity", the image is properly centered, without you needing to do the calculations yourself. However if the source frames contained offsets, these will also be added to the gravity defined position, so that the relative position of all the sub-frames remains correct.

            Note that as the animation "script_k.gif" is actually a type of Overlay Animation their are alturnative methods of adding a static background to the animation. See the section above on Remove Transparency for an example (onto a solid color, but can be any image).

            The same is true for the even simpler Cleared Frame Animation. In that case you don't even need to Coalesce the animation first, but can directly compose it onto a background image. However you may need to "-set" the 'dispose' method being used afterward or better still Optimize the Fully Coalesced Animation.

            However any other type of optimized animation, will require that "-coalesce" operation, and full composition with all the animation frames. As such it is probably better to to use the above method, just to be sure all GIF animations are handled correctly.

            All that Glitters...
            Glitter Animations
            The above Layers Composition methods makes it a lot easier to generate simple animations, such as glitter.

            First we need some glitter that is large enough to cover the image being processed. Here I will generate a three image glitter animation from some Random Specks Images.

            First this is a raw black and white glitter on pure transparency, generating 3 frames of glitter by separating the three color channels into black and white Channel Images. It is basically a raw starting point for generating any other type of glitter. The '30%' threshold controls how many 'dots' there are per frame.


              convert -size 100x100 xc: +noise Random -separate \
                      null: \( xc: +noise Random -separate -threshold 30% -negate \) \
                          -compose CopyOpacity -layers composite \
                      -set dispose background -set delay 20 -loop 0   glitter_overlay.gif

                [IM Output]

            From this 'raw' glitter you can overlay it using a 'Screen' alpha composition to only brighten some color, to generate a glitter of a specific color. I use the Border Flatten Method (above). Just a plain color...


              convert glitter_overlay.gif \
                      -compose Screen -bordercolor GoldenRod -border 0x0  glitter_gold.gif

                [IM Output]

            Using the Layer Composition, you can also use a single image, or even multiple images to provide a variable colored background. For example here I generate three Fractal Plasma images, to provide a slightly randomised coloring to the glitter pattern.


              convert glitter_overlay.gif null: -size 100x100 \
                      plasma:red-firebrick plasma:red-firebrick  plasma:red-firebrick \
                      -compose Screen -layers composite    glitter_plasma.gif

                [IM Output]

            Of course there are lots of other glitter styles and movement patterns. You can find and download many such glitter tiles from the WWW.

            To apply a glitter like this to an image, there are a number of different methods. Typically you mask the glitter to a specific shape and or background.

            For this can either use a transparent shape (composited using DstIn)


              convert -size 100x100 -fill white -background none -font Candice \
                      -gravity center -pointsize 90 label:A   glitter_mask_trans.gif
              convert glitter_plasma.gif null: glitter_mask_trans.gif -matte \
                      -compose DstIn -layers composite        glitter_masked_trans.gif

            [IM Output] ==> [IM Output]

            Or a black and white mask image (composited using CopyOpacity)


              convert -size 100x100 -fill white -background black -font Candice \
                      -gravity center -pointsize 90 label:A    glitter_mask.gif
              convert glitter_plasma.gif null: glitter_mask.gif +matte \
                      -compose CopyOpacity -layers composite   glitter_masked.gif

            [IM Output] ==> [IM Output]

            Ok we have an area that has been masked, you can complete the image, generally by overlaying the masked glitter on the original image.

            However in our case I'll underlay a background, and overlay an border.


              convert glitter_masked.gif -size 100x100 \
                      null: gradient:gold1-gold4 -compose DstOver -layers composite \
                      null: \( -fill none -background none -stroke white -strokewidth 2 \
                               -font Candice -gravity center -pointsize 90 label:A \) \
                          -compose over -layers composite      glittered_letter.gif

                [IM Output]

            This last example also cleaned up any GIF transparency problems by the removal of all transparency from the final image and the overlay of a smooth border around the glittered region.

                While I may have used GIF format images in the above to allow me to display individual steps of the process, in practice you would either combine all the steps into a single command, or use a better intermediate image file format such as MIFF. That is done to avoid the inherent problems of the GIF format, until we have finished.

            Glitter Tiles - 'hole in the image' underlays
            As mentioned there are a lot of pre-prepared animated glitter tile images available on the WWW (do a search for "glitter tiles"). One source is a IM Studio user, scri8e and his web site Moons Stars. Be warned however that I find most glitter tiles to be rather horrible looking, or too fast.

            For this example I found and modified a blue glitter tile with some small star patterns in it. I thought it would be useful for giving the IM wizard a glittering clothing, making him look really magical.

            Probably the easiest ways to glitter an existing image is to cut holes in the image rather than trying to mask out the glitter pattern. This however only works for images that do not contain transparency to start with. Alternatively, you could remove the transparency from an image, and when finished, re-add the original transparency.

            So lets take the IM Examples logo, and use Color Replacement to cut out all the blue parts of the image. Sort of giving our wizard a cloak of invisibility ;-)


              convert logo.gif -matte -fuzz 33% -transparent blue logo_holed.gif

            [IM Output] ==> [IM Output]

            Note the use of the Fuzz Factor to adjust just how much of the blue color should be removed. Be warned however that this is not a nice way to cut out an area of an image as it produces Aliased Edges. But no simple feathered cut-out feature is currently available as yet.

            Okay we have an image with a hole (or lots of holes). The next step is to underlay glitter tile image. The problem is the above tile is too small, it will not cover the whole image!

            The following uses a tricky technique to tile the multi-image glitter tile. However you still need to give a size that is larger than the original image to ensure that you can cover it completely.


              convert glitter_blue.gif -virtual-pixel tile \
                      -set option:distort:viewport 180x180 -distort SRT 0 \
                      glitter_blue_tiled.gif

                [IM Output]

            Now lets dress our wizard in his new cloths, by placing the above tiled glitter under the 'holey' image.


              convert logo_holed.gif null: glitter_blue_tiled.gif \
                      -compose DstOver -layers composite \
                      -loop 0 -layers Optimize logo_glittered.gif

                [IM Output]

            You can of course do all these steps all in the one command. Here I limit the hole generation to just the wizards cloak, which has two separate specific parts.


              convert logo.gif -matte -fuzz 10% -fill none \
                      -draw 'matte 120,150 floodfill  matte 150,120 floodfill' \
                      null: \( glitter_blue.gif -virtual-pixel tile \
                        -set option:distort:viewport 300x300 -distort SRT 0 \) \
                      -compose DstOver -layers composite \
                      -loop 0 -layers Optimize logo_glitter_cloak.gif

                [IM Output]

            The holes in the above were created using Matte Fill Draw primitives to select an actual point and color from the image for the color replacement. This means I don't need to use such a high Fuzz Factor as I did originally, as my comparison color came from the specific areas selected.

            Also I used a larger tiling 'viewport' so as to ensure I completely cover the image being tiled, without needing to know its exact dimensions.

                The use of the General Distortion Operator and its special "viewport' option (added to IM 6.3.6-0), also gives you the opportunity to modify the distortion pattern in other special ways. Such as give it a 'perspective' look or rotate the pattern into a non-rectangular angles. Doing this can enhance the tiling so it does not have such an uniform look about it.

            For some example see Affine Tiling.

            Sparkles - overlay mostly transparent glitter
            The major problem with the two previous glitter animation techniques is that it is an all or nothing type of replacement. You cannot use the original shading or background of the image.

            Also the glitter is completely restricted to the area that was masked. It can not extend beyond the bounds of the area involved. As such some small areas, such as the wizards 'hat' in the previous example, does not handle glitter very well.

            Sparkles are different, in that the animation added is mostly transparent. as a consequence the original image, can still show through. Such animations are usually added to an image one of two ways. Either the animation overlay itself is transparent, or it is of the form of black background with white 'sparks' where the image should be brightened.

            Under Construction

            Here is an example of a mostly transparent 'sparkles' overlay.

            Example Here

            As you can see you can have colorful sparkle overlays when this form is used.

            The major problem with this is that a GIF animation was used to save it, (which is typically the case), so the overlay is heavily aliased. That is, it can not contain any semi-transparent pixels to smooth out the look of the overlaid image. If it did, you would have get horrible black halos around the 'sparkles' in the final result.

            Lets mask out and overlay this onto the wizard. Example Here

            The other form of sparkles is white sparkles on a black background (a gray-scale image). These are masked and overlaid so as to brighten the image to add the sparkle.

            For example... Example Here

            One of the best things about sparkles is you can generate a sequence of frames where sparkles slowly appear and then disappear. This can get quite complex, but is no very hard to do. Example Here

            Adding Flares and Stars Animations
            Where glitter consists of single points of brightness, and sparkles can overlay some areas of an image, flares are usually added individually.

            A 'flare' is basically a point that flashes to cover a large area for just a moment. A 'star' is similar except the coverage is more in the form of 'rays' of brightness.

            These usually are 'seeded' from specific points, but the result often extends, at least momentarily well beyond the seeding area. For example a flare that is mask limited to a specific area looks very very stupid and unnatural.

            The more difficult aspects of flares is locating good 'seed' points and timing of multiple flares appropriately.

            Under Construction

            Final example I want to create...  A 'sparkle' the travels up the wizards
            wand, then flares, and dissolves into a number of small sparkle flares over an
            area.  Then the sequence repeats.

            Resizing Animations
            Problems with Resizing Animations
            The biggest problem with resizing GIF animations is that the "-resize" operator is designed specifically to make the resulting images as close to ideal (after the resize) as possible. It does this by merging and generating lots of additional colors in the image to make it look better.

            The resulting images are far from ideal for saving to the limited GIF file format. With GIF's limited color table, this results in heavy Color Reductions in the resized images. For a single GIF image that is not so bad, but for a GIF animations, the default Error Correction Dithering of the reduced color set produces problems, in 'dither noise' between frames, and in turn a bad frame optimization for final file size.

            It is even worse when transparent colors are also being used, which is a common practice for typical GIF animations used for web pages. Transparency is also commonly used for Compression Optimization techniques, for animations that would otherwise not need it.

            What happens is that "-resize" produces semi-transparent pixels in the overlay images. Then when the images are saved back to a GIF file format, these pixels are then converted to either fully-transparent or fully-opaque, both producing major color distortions in the resulting animation.

            If any form of optimization is used... frame, transparency or LZW... then the transparency effects will basically result in a disastrously resized GIF animation. That is the facts, Jack! So you will need to live with it.

            Even if you avoid using "-resize", by using "-sample", you will still have major problems unless you "-coalesce" the animation first.

            Resizing Animation Techniques
            As shown above, there are are serious problems in resizing GIF animations, none of which are easily resolved. The solution also generally depends on just what type of image was resized in the first place, be it cartoon like, or a real-world video image.

            Here are the methods I know about, or have been contributed...

            Avoid resizing
            If it is at all possible, DO NOT RESIZE.

            You can for example Canvas or Viewport Crop your animation to just trim it down to fit in the space you need it for.

            Or you can generate the GIF animation at the right size in the first place.

            Neither technique is typically the best option, but if you can, consider it, as it will save you a lot of problems and hair pulling.

            Direct resizing
            As mentioned about directly using "-resize" will have problems, either with number of colors for each frame, or with semi-transparent colors.

            For example this goes really bad...


              convert script_k.gif -resize 20x20 script_k_direct.gif

                [IM Output]
            ==> [IM Output]

            Now that did not work very well, and that is because the original image has some heavy frame optimizations. Each 'frame' of the animation is not the same size, and the "-resize" will resize each and every frame image completely separately from the other images.

            That is the above resized the actual frame images, and not the virtual canvas of the animation to the size given. Actually I am surprised the resulting animation wasn't more 'crazy' than just the blank area shown.

            That brings us to the first point about resizing animations. First ensure that all the frames are fully defined, and ALL optimization has been removed. In other words Coalesce the animation before attempting to resize it. For example...


              convert script_k.gif -coalesce  -resize 20x20  script_k_direct2.gif

                [IM Output]
            ==> [IM Output]

            The next problem is one of transparency colors. If you look at the result above you will see that the edges of the smaller animation are horribly aliased ('staircased'). That is because GIF cannot save the semi-transparent colors the "-resize" operator generated.

            The colors within the animated object will also have had the colors merged together to produce new colors, but that is usually not nearly so bad as the edge aliases.

            Resize with Flatten, A General Solution.
            The best idea when generating a GIF thumbnail is to avoid the problems of transparency entirely. That is Flatten the Animation, either before or after resizing the animation. That way you do not loose the 'anti-aliasing' of edges in resized images.

            In fact I have found most good GIF animation websites do exactly that when generating their GIF animation thumbnails. Of course the thumbnail will then be limited to use on a specific colored background, usually 'white', but sometimes 'black', or 'silver' (web page grey) though that last is less common these days.

            For example, here I create a smaller thumbnail on a background color appropriate for this web page.


              convert script_k.gif -coalesce \
                      -bordercolor LightSteelBlue -border 0 \
                      -resize 20x20  -layers Optimize   script_k_thumbnail.gif

                [IM Output]
            ==> [IM Output]

            This is the recommended solution for general GIF thumbnail handling. Any other method requires either human control, or a very sophisticated GIF thumbnail handling logic.

            Color Table Blowout
            The biggest problem (as I mentioned at the start of this section) is that huge number extra colors are generated in the image, especially near lines, and the edges of adjoining color areas. You also get resize-halo of semi-transparent colors around the edges of images.

            This in turn enlarges the size color table needed for a simple minimal colored animation, which in turn means a larger file size when a resize simple animation is saved. Worse still each and every frame in the resizes animation, probably generates a different set of colors, further enlarging the file size for your 'thumbnailed' animation.

            There is also the problem that after Color Quantization, you may no longer have the same specific colors as the original animation (see Quantization does NOT Preserve Colors). That is instead of having a simple area of pure white, you may now have an off white area.

            Resize using Sample
            To avoid generating extra colors when resizing the simplest way is to "-sample", the animation, rather than resizing it. This will preserve the current colors in the animation and allow you to easily re-optimize the animation at the new size.


              convert script_k.gif -coalesce  -sample 20x20  script_k_sample.gif

                [IM Output]
            ==> [IM Output]

            However while this works, you are basically removing rows and columns of pixels from the image, loosing image data and hence quality in the process. With cartoon-like images, that often leaves 'dotty' borders, and missing or distorted details.

            If your resize is more than 50% of the animations original size, as is the case above, the result is often quite horrible, especially when texture or a other color pattern is used in the animation.

            It is not surprising then that many GIF animation libraries are filled with such horrible sample-resized animations that they have copied from all over the net. I often wish they would clean out this sort of crap, but that means a reducing the number of GIFs on offer, and that in turn reduces the marketing statistics of the number of GIFs available, which the advertising department does not like. As a consequence, crappy GIF animations are common.

            Resize using Liquid Resize
            A similar method to using the Sample method above is to use Liquid Rescale, which is also known as Seam Carving.

            This also removes or added whole pixels from the images involved, but tries to do so in a way that preserves as much of the image complexity as possible. Look at the above links to see how you can use it to generate nicer resized images.

            Unfortunately at this time there is no way to use this on a general animated image, as it does not have an understanding of an images complexity, and we cannot currently extract the rescaling method to apply it to each frame of an animation in a consistent way.

            Hopefully this will change at some point in the future.

            Resize and Restore Colors
            Sampling an animation just results in removing rows and columns of pixels, and the possible removal of thin lines and other important details. But merging pixels together using "-resize", produces far too many new colors for the GIF format.

            So the obvious solution is to do the "-resize" but then use the original animations colors to restore the resized animations colors, by using a colormap.

            FUTURE: example with original color table restored

            This has the added advantage of not generating local color tables.

            Results however may be better with dither turned off, so as to avoid any 'dither noise'. This is especially true for cartoon like images that has large smoothly colored areas.

            FUTURE: non dithered color table restored example

            Full Color Optimize
            If a horrible sampled thumbnail is not to your liking, then you are faced with the prospect of going through a full Color Optimization of the resized GIF Animation. To sort out just what 'new' colors you want the animation to keep.

            However this is often not so bad, for most animations, but it can be a major effort for more complex animations like when converting a Video to GIF Animation.

            That is, if you dealing with a cartoon like animation, you will now have heavily anti-aliased lines and edges.

            For animations that involve a transparent background, you will also have to properly deal with semi-transparent pixels around the edge of your animation, also caused by the anti-aliasing features of resize. See the section on GIF Boolean Transparency for the many methods you can use to handling this.

            Large Resize Reductions
            When you plan to resize a large animation to a much smaller animation, you face the problem of important parts of the animation disappearing. This is actually a problem for static images as well as animations.

            See Resizing Line Drawings for any known solutions for this.


            Any further suggestions, ideas, or techniques are most welcome.

            Merging Multiple Animations
            I said it before, but it becomes especially important when merging animations...
            Know as much as you can about the animation you are working with!
            The "gif2anim" script is ideal for this purpose. Its sister script "anim2gif", is also commonly used here to re-create an animation using its original settings. (See basic usage of the script in Animation List Information.)

            Without knowledge of how an animation works it is next to impossible to merge them in various ways. Programs can be developed (the ultimate goal of these examples) to do this. But, such programs are often very complex and can produce unexpected results.

            Because of this you should still follow these examples, as they will give you a major insight into how animations should be handled and merged.

            Serial or Time-wise Append
            Appending two GIF animations together so that one sequence follows another time-wise is simple with IM. You basically just list them on the command line and they will follow each other. But it may not be quite as easy as it looks.

            For example, after some searching of the web, I found (well stole and heavily modified for this example) a couple of animations of some letters being drawn. Now I'd like to join these images so when one animation completes the next one starts, as if someone is writing the word 'OK'.

            Here are the letters, the 'animation sequence' and the details of the internals of these two animations.
                


              gif2anim -n script_o.gif
              gif2anim -n script_k.gif

                 
            [IM Text]
                    
            [IM Text]
                [IM Output]
            [IM Output]

            These sequences start with an empty canvas then just slowly add and modify pixels to this canvas. They never remove, clear or make transparent any pixels added by previous frames. For our purposes however it does not matter if they do or not as it will have little bearing on the results.

            Nor will the number of the frames in the animation have a bearing on this operation.

            What is important to know is the timings of the frame, as this could produce problems. In particular note the timed delay on the first, or in this case the final frame. This technique is very common, giving the viewer time to see the final result before the animation clears and re-starts. It is these delays and frames that will cause use problems when doing time-wise appends.

            Also notice that the 'k' animation has a slight delay in the middle of the animation sequence. This delay represents the end of the first brush stroke in this animation and the second brush stroke. This delay will also need to be preserved, meaning we can't just change all the time sequences in the animation to a constant value.

            Something that is not shown in the above, is that the first frame of both animations is actually blank canvas. We will probably want to junk that canvas on the second animation as an useless waste of time, though it should be kept on the first animation as a starting delay.

            Now that we have examined the two animations, lets try to join them together so one follows the other in time.

            Time appending animations is actually a very simple operation, just append the two animated images on the command line. So lets just try that...


                convert script_o.gif script_k.gif   script_ok_try1.gif

                [IM Output]

            Well the result was far from perfect. The letters get drawn in the right sequence, but on top of each other!

            Not only that but as the first 'o' animation is thinner (40 pixels) than the second 'k' animation (53 pixels), so the very last bit of the final 'k' letter gets clipped by that smaller framing canvas size.

            The position of the second animation can be moved by using a relative repage, as shown above. This method of re-positioning will preserve any existing offsets that may be present in that animation, just move them all as a single related group. In this case almost all the frames have and existing offset, as this is a highly optimised animation.

            To accommodate this shifted position and avoid 'clipping' the second animation we also need to enlarge the canvas size for the whole animation. Changing the the canvas size before reading the first animation or frame will enlarge the canvas area in which the animation runs, and prevent the 'K' from being clipped.


                convert -page 90x54 script_o.gif \
                        \( script_k.gif -repage +37+0\! \)   script_ok_try2.gif

                [IM Output]

            The result is a vast improvement. Though now the delays between the drawing of the letters, is definitely noticeable.

            What we want is a much smaller delay for the last frame of the first 'O' animation. Just large enough to look like the invisible artist is re-positioning the pen.

            To do this we make a copy of that last frame of the first animation, then change the delay of just that frame using the "-set" operator. We then re-add that frame back into the image sequence by deleting the original un-modified image.

            Also as we have now set a good delay between the drawing of the letters, the initial blank canvas (just representing an initial start delay) in the second animation is now redundant, so we can just delete that frame, without problems. If this frame actually contained part of the image, then we may need to adjust its delay, instead of removing.


                convert -page 90x54 script_o.gif \( +clone -set delay 20 \) -delete -2 \
                        \( script_k.gif -delete 0 -repage +37+0\! \)     script_ok.gif

                [IM Output]

            And our serial or time-wise appending of two animations is complete and all the little problems associated with these two particular animations are fixed.

            Notice that at no time did I try to globally change ALL of the individual frames, or their timing delays. That is I preserved as much of the original animations as I could while achieving my goal. This is important as not all animations use a constant timing delay between frames and changing this can make an animation look very bad.

            Side by Side Appending (time synced)
            Suppose you want both animations to be appended side-by-side, but have both parts of the animation animating at the same time. This is not so easy, as you need to append (or composite together) each pair frames in the the two animations together, so the animation also works together..

            The real problem to doing this is the IM command line only works with a single sequence of images. It does not have the luxury of an API where you can keep two separate image sequences, to loop through and append them together into a third. I can think of three basic techniques in which to do this appending. Before be start however you should first study the two animations, to check on the time sequences, and other details of the animation. The "gif2anim" script is good for this, and the generated ".anim' file can be useful later.

                


              gif2anim -n bag_left.gif
              gif2anim -n bag_right.gif

                 
            [IM Text]
                    
            [IM Text]
                [left]
            [right]

            If you look at the information summaries you will see that the two animations have the exact same number of frames, and almost exactly the same time sequence. It is the similarity of the timing that is important here, and you can say the animations are already 'time synchronised'.

            However while the timings may be correct, the animations are frame optimized, rather than fully-coalesced. But the canvas area height are the same, making appending the two frames side-by-side practical.

            Actually this animation was badly 'split' (see splitting animation in the next example set) so that the 'cat' animation was cut in two, and the original lost. Other modifications resulted in a very slight timing difference, which only made the division more obvious. This was a problem that was presented to me by gmabrys in a discussion on IM Forums, though the actual problem he gave was far, far, worse.

            [left][right] Now browsers usually animate each of the separate GIF images, without any synchronization. As such the two animations may become out-of-sync with each other, producing a 'cat' that appears to have been part of a chainsaw massacre. You may be able to see this effect to the right where I placed two animations side-by-side on the browser's page, especially if you are on a distant server via slow links.

            Now lets attempt to append them together into one, properly synchronized animated image.

            Appending separate files
            The simplest way is to just coalesce the two animations and separate them into separate image files, one frame per image. The separate images can then be append together (or otherwise modify the frames) as appropriate. When done the new frames can then be used to re-build the animation.

            This however requires you to save a lot of extra information about the animation that could very easily be lost during this processing.


              # Separate animations into coalesced frames (plus a ".anim" file)
              gif2anim -c bag_left.gif
              gif2anim -c bag_right.gif

              # Append the separated frames them together
              for i in `seq -f '%03g' 1 11`; do \
                convert bag_left_$i.gif bag_right_$i.gif +append bag_append_$i.gif; \
              done

              # Rebuild the animation (using one of the ".anim" files)
              anim2gif -c -b bag_append  bag_left.anim

              # Cleanup
              rm -f bag_left.anim bag_right.anim
              rm -f bag_{left,right,append}_???.gif

                [IM Output]

            As you can see this is quite an involved process, generating many individual temporary images, and thus requiring quite a bit of clean up when finished. Of course if you are debugging the above, the individual temporary files make it easier to figure out what is going wrong with your processing.

            It also shows the power of the "gif2anim" script and is inverse the "anim2gif" script in separating, and saving the animation meta-data, and then later re-building GIF animations. Basically it lets you preserve the original timings of the animations, without needing to code them into your script directly.

            The final image also still needs to be re-optimized, though in this case you will get very little optimization as a lot of things are happening simultaneously throughout the animation between each and every frame

            Layered Composition
            A better technique is to overlay animations using a multi-image list Layer Composition. This involves just enlarging one set of images, and overlaying the other set to join them together. In fact this is what the normal "-append" operator does internally, so it isn't that different.

            Here I just tell IM how big to make the canvas, and the fill it out using "-coalesce". I then overlay other coalesced animation with an appropriate offset.


              convert bag_left.gif -repage 97x92 -coalesce \
                      null: \( bag_right.gif -coalesce \) \
                      -geometry +50+0 -layers Composite    bag_append.gif

                [IM Output]

            Of course the above technique means I needed to know just how big the final animation will be, as well as the offset needed for the overlaid animation. But the process is fast, works very well, and a scripted command can pre-read the images to determine that information.

            To make a more universal animation appending method, we need to do some fancy image handling to automatically determine the final size and offset of the append. To do this without pre-reading the animation, requires some jumping though some hoops, but a single command general animation append is possible.

            First we need to append the first coalesced frame of each animation to create a canvas that is the right size and this is then cleared. The first animation is coalesced and overlaid into left half of this canvas, then the second animation is then coalesced and overlaid with a "-gravity East" to place it in the right-most half of the pre-prepared canvas, to avoid the need for an offset.


              convert bag_left.gif'[0]' -coalesce \( bag_right.gif'[0]' -coalesce \) \
                      +append -channel A -evaluate set 0 +channel \
                      bag_left.gif -coalesce -delete 0 \
                      null: \( bag_right.gif -coalesce \) \
                      -gravity East  -layers Composite    bag.gif

                [IM Output]

            And there you have a general technique to append two time synchronized animations together.

            Double Append, Appending - or Appending Animated Fonts
            Before finishing with appending animations, there is one other technique I would like to show you. This technique can append multiple animations at the same time, but at the cost of loosing all the timing information that was present. Often (but not always) those timings is not a big loss.

            Basically we append all the frames of each animation together vertically into a single image, and then append or overlay the whole animation as two simple images. This is sort of like taping the two film strips together side-by-side to produce a wider film strip.


              convert \( bag_left.gif  -coalesce -append \) \
                      \( bag_right.gif -coalesce -append \) \
                      +append  -crop x92 +repage \
                      -set delay 30     bag_dbl_append.gif

                [IM Output]

            This did not require any temporary files, but as I mentioned at the start, all the original time delays have been lost. For this example I just set all the animation delays to a constant value, producing a reasonable, though different result. Also to re-build the animation we needed to know the frame height of the original animation, to correctly divide (Tile Crop) the widened 'film strip'.

            Though it is possible to recover those timings using the "gif2anim" scripts, doing so sort of defeats the purpose of using this method, and you may as well just used the first animation append technique, by appending the individual frames as temporary files.

            As you are appending the animations as simple images, you can append together a whole series of animations all at the same time, (producing an even wider 'filmstrip') and that is what makes this technique such an useful one.

            For example you can use it with animated fonts that all use the same timings. Though I have found that while a lot of animated fonts have the same number of frames, they usually have slightly different timings for each letter so as to de-synchronize the animated letters (see Splitting up an Animation for reasons why that is desirable).

            A neon sign on the other hand should have synchronized animation timings, so I'll use it as an example...


              convert \( neon_h.gif -coalesce -append \) \
                      \( neon_e.gif -coalesce -append \) \
                      \( neon_l.gif -coalesce -append \) \
                      \( neon_l.gif -coalesce -append \) \
                      \( neon_o.gif -coalesce -append \) \
                      +append  -crop x60 +repage  -set delay 100  neon_hello.gif

            [IM Output] [IM Output] [IM Output] [IM Output] [IM Output] ==> [IM Output]

            You could also do something a little fancier, by adjusting timings and the number of loops in the resulting animation.


              convert neon_h.gif'[0]' neon_e.gif'[0]' neon_l.gif'[0]' neon_l.gif'[0]' \
                      +append \( +clone \) -append \
                      \( neon_o.gif -coalesce -append \)    +append \
                      \( +clone \) -append \( +clone \) -append \( +clone \) -append \
                      -crop x60 +repage   -set delay 3 \
                      \( -clone 0  -set delay 300 \) -swap 0,-1 +delete \
                      \( -clone 1  -set delay  10 \) -swap 1,-1 +delete \
                      \( +clone    -set delay 200 \) +swap      +delete \
                      -quiet -layers OptimizeFrame   neon_hell.gif

            [IM Output]

            The first two lines makes the 'always lit' part of the sign (first frame of each of the previously animated letters). After this the last 'broken' letter is added and the whole animation is doubled up a couple of times to produce about 16 frames. The timings are set to complete the desired effect with the first and last frame being displayed for a long period, while the rest of the frames flash by past really fast ( "-delay 10" ).

            Actually this GIF animation optimizes a lot smaller than you would probably think for the number of frames involved. Basically the IM GIF optimizer found that it only needed to re-overlay the 'O' animation every second frame, and used a 'Previous' disposal to just restore the previous lit 'O'. The animation is thus only about 50% larger than the basic flashing un-optimized 'hello' image. Check it out yourself.

            Can you improve the neon animation? Make it more realistic? It is a shame GIF animations don't have sound.

            Splitting up an Animation
            Now that we have the animation rejoined together, lets attempt to split it up correctly for use on a web servers, so that the individual parts can animate separately, without interfering with each other.

            This is actually reasonably hard, and I will not attempt to completely automate the process. There are however tools on the WWW that can do this.

            First of all we need to study the animation to find what parts of the animation changes over the whole period. For that we need to find the differences from one frame to the next, add them all together into a map showing the areas that are being animated, verses though that remain completely static.

            This is tricky. Basically a Multi-Image Alpha Composition is used to find a 'Difference' image between each frame of the animation. These greyscale difference images, are added together, then the channels are separated and also added together. A final threshold then makes any non-zero change between any frame of the animation, pure white.

            The result is a black image with white anywhere the image changed, highlighting the areas of change.


              convert    bag.gif   -coalesce  -set delay 0 \
                      -bordercolor red -border 0 +matte    null: \
                      -duplicate 1,1--2 -compose difference -layers composite \
                      +delete -compose plus -background black -flatten \
                      -separate -flatten -threshold 0 bag_areas.gif

            [IM Output] ==> [IM Output]

            Now we can see that this animation could be divided into at least three areas: a 'cat' area at the top, a small 'bear' to the left, and a flapping 'wing' to the right. All with simple orthogonal (vertical or horizontal) cuts.

            So lets just do this, with some simple Viewport Crops of the Animation.


              convert bag.gif -coalesce  -crop 97x39+0+0\!   bag_cat.gif
              convert bag.gif -coalesce  -crop 50x54+0+39\!  bag_bear.gif
              convert bag.gif -coalesce  -crop 47x54+50+39\! bag_wing.gif

                
            [IM Output]
            [IM Output] 	[IM Output]

            These three images can be displayed by the browser together and not have the 'Texas Chainsaw Massacre' look about it, as at no point does a sub-animation cross the boundaries of another.

            Now technically, you can make a couple more cuts so as to separate the areas that are not animated from the animated areas, splitting this animation into about six or more areas, though you will not gain much from optimization doing this. All it would really do is complicate your web page, and create more files for the user to download.

            Now unlike the larger animation, these smaller areas will animate quite independently from each other. We can even also change the timings of these simple sub-animations without adversely affecting the result so as to completely de-synchronize them from the other sub-animations. The result is a nicer less repetitive animated image (see below).

            If you study the 'bouncing bear' and the 'flapping wing', you will find they form a simple two frame cycle that simply repeats a number of times, to match the timing of the waving cat. We can thus junk the extra repeats to simplify these animations.

            Also the first two frames of the 'cat' are also exactly the same. However unlike the 'bear' and 'wing' you can't just remove one of them, as each frame contains time delays to allow the 'bear' and 'wing' to animate without the cat being present.

            To correctly remove these duplicate frames, you need to use the "-layer" method 'RemoveDups' to locate and merge the timings of such duplicate frames in a coalesced animation.

            And here are the final optimizations, of all three separated animations with the timing changes to improve the overall de-synchronization of the sub-animations. I have also displayed all three animations side-by-side on the page, just as they should be displayed.


              convert bag_cat.gif -layers RemoveDups \
                                       -quiet  -layers Optimize  bag_cat_opt.gif
              convert bag_bear.gif -delete 2--1 -set delay 47 \
                                               -layers Optimize  bag_bear_opt.gif
              convert bag_wing.gif -delete 2--1 -set delay 33 \
                                               -layers Optimize  bag_wing_opt.gif

                 
            [IM Output]
            [IM Output] 	[IM Output]
             

            As a final summary: The two original (badly split) images totalled [IM Text] bytes, which is about the same as the appended version. After correctly splitting the animation, which allows good optimization of the sub-animations, we get a total of [IM Text] bytes over three image. Quite a good saving.

            Distant Change Frame Splitting
            Under Construction

            Example of splitting up frame updates of 'two changing objects that are far apart', without involving transparency (fixed background), but preserving the timing syncronization between the parts.

            Then repeat with a transparency background, (needing 'OptimizePlus' to generate the 'cleared' pixels.

            See Splitting Frame Actions for the general example.

            Merging Time Disjoint Animations
            Before any two animations can be merged together to run synchronously, you need to make all animations use the same number of frames, and use the same set of time delays.

            How difficult the merger is really depends on how disjoint the timings of the animation is. If the time delays are basically constant, you can simply ignore them and fix the timings latter. An example where time could be ignored in merging a 2 frame animation with a 6 frame animation was given in a IM Forum Discussion.

            Also if the total cycle time is very different, you may need to adjust things so that one animation loops 2 or 3 times so as to fill the cycle time of the other animation. Basically timing is what matters.

                Probably something like...
                + Figure out and adjust animations to a common total loop cycle time
                + Coalesce both animations to remove any frame optimizations.
                * Convert frame time delays into, time-since-start of animation.
                * Double up frames as appropriate to time-synchronize.
                * Convert time-since-start back into frame time delays.
                + Overlay the coalesced time-synchronized frames as desired.
                + Optimally merge and remove any 'zero delay' frames.
                + Re-optimize the new animation. 

            The '*' parts could be turned into a single new "-layer" method to time synchronize the two animations with similar total cycle time durations.

            Under Construction


            Example, time disjoint, but same cycle time...

            For example suppose you have two animations of three frame with time delays of
                10  10  10
                5    5  20

            Both animations are 30 time units long already so that is not a problem.

            Now convert the above to the time index when each frame should appear...
            and show the overall time line at which frames appear...
               0        10    20   |__ NOTE that both animations
               0   5    10         |   end or loop at 30

            From this you can see that you need to insert some extra frames to make them
            match.  The first frame of the first animation needs to be repeated at time
            index 5

            0->5  10  20
            0  5  10

            And the last frame of the second animation also needs to be duplicated at
            time index 20

            0->5  10  20
            0  5  10->20

            The arrow '->' in the above means the same frame is just repeated (duplicated)
            into the next time index. They are actually the same image.

            Now that the timings of the frames in both animations are the same, you can
            simply merge (composite) the frames together, to get final animation that is
            4 frames long.

            The four frame will thus have time delays of
            5  5  10  10
            which still add up to 30 time units (overall time per loop cycle)

            Current state of development....

            While IM can help gather time delay information (try the '-t' option for
            "gif2anim") and build the animation. IM can't perform the time synchronization
            needed for two separate coalesced animations.  This may become a special
            built-in option.

            That is, you will need figure out and double up appropriate coalesced
            animation frames so as to change two time-disjoint animations into two
            time-synchronized animations.

            Once you have the animations time synchronized, you can then simply use the
            new "-layers Composite" method, to overlay or merge the two time-synchronized
            animations  together very easily.

            All the above however assumes the total loop time of the two animations
            are at least roughly equal, or not a major concern.


            Simplified Solution

            A simplified limited solution has been Discussed on IM Forums, for use with fast changing animations (similes).

            The solution takes each animation and expand it so that the animation has
            a fixed frame rate.  That is all frames are duplicated so that each frame is
            shown for a conatant 6 centi-seconds each.  As such one frame with a 22cs
            delay may be replaced by 4 x 6cs frames (24cs total).

            After this the animations are further modified so that short animations are
            looped multiple times so that the two animations are finally of equal length.
            That is the two animations are made the same overall length in terms of both
            time, and number of frames.

            Once both animations has the same frame-rate and the same length, Layer Composition can be used to merge/overlay the two
            animations, in the right position.

            The result can then be optimized using Remove Duplicate Frames to remove any extra unwanted frames (with
            appropriate timing adjustments and other Optimizations applied before saving.

            This method of having all your component animations in a fixed frame length
            form is especially well suited to animation libraries.


            -----
            Other example to create....
              * Overlay two moving equal time animations into a single animation
                (dancing butterflies, circling atoms, or birds?)
                This should be a straight layers composition.

              * Overlaying a moving animation on a fix background.
                (displace animation linearly with time)

              * Overlay two animations with different numbers of frames but constant time
                delays (see IM Forum Discussion).

              * Oveylay two time disjoint animations (as outlined above)

              * Overlay a simple animated figure, on an animated background.
                (full animation merge)
https://legacy.imagemagick.org/Usage/video/
            ImageMagick is not particularly suited to the handling of Digital Video handling, but it is commonly used for this purpose, especially in the Linux environment.

            Here I explore techniques and examples that are specific to handling of real life (and raytraced) video sequences.

            Video to GIF, Optimization Summary
            A software developer who uses IM to create Movie GIFs, Benoit Rouleau, in discussion with me, gave me an AVI video of a plane flying over, to help us mutually explore IM video conversion techniques.

            However while the AVI itself is quite small, the uncompressed video is a massive [IM Text] bytes in size, and involves [IM Text] colors, over [IM Text] frames.

            IM however has no real trouble converting this video into a GIF animation. However be warned that you will probably get some unsupported 'AVI chunk' errors, which can be ignored by using a "-quiet" control setting.


              convert -quiet -delay 1 plane.avi plane.gif

                [IM Output]

            This used ImageMagick's the default Color Quantization and Dithering methods, to produce a very reasonable conversion of the video. Very few color problems exist, because the video uses very few colors to start with. This is not always the case, especially as GIF has 256 colors per frame limit.

            However the animation file is [IM Text] bytes in size, which while only 1/5th the size, due to color reduction and GIF pixel data compression, it is still rather large.

            Also if you study the resulting animation further you will find that of the [IM Text] frames in the image, [IM Text] frames had their own own separate local color table added. That is each and every frame in the GIF animation required there own color index table. That is while each frame has less that 256 colors (due to the GIF format limitations), the whole animation is using a total of [IM Text] colors.

            Unfortunately the GIF format does not compress color tables, so all those extra color tables could be using up to:   256 colors * 3 byte per color * 106 frames;   or 81,408 bytes of file space. Not a lot for a 1Gbyte video but still an appreciable amount of space, especially as we optimize the video further.

            Added to this is that the animation will not GIF frame optimize very well. Not only because the background is moving (due to the camera panning upward), but also because IM used a Error Correction Dither (Hilbert Curve Dither), which produces a pseudo-random pattern of colors that is different from frame to frame. A later example will make this 'dither noise' much more visible.

            Common Global Color Table
            Here I Generate a Single Global Color Table for all the frames of the video.


              convert -quiet -delay 1 plane.avi  +map   plane_cgc.gif

            This naturally results in [IM Text] local color tables, and a file size of [IM Text] bytes. 	[IM Output]

            As you can see the resulting animation has no extra local colortables. Instead IM generated a single global color table of [IM Text] of the 'best' colors based on all the frames in the animation.

            Unfortunately this also resulted in the pixel data not compressing as well as it did before, as a stronger dither was required. The result is a slightly worse looking animation, that is roughly the same size as the previous.

            For this specific video of limited colors, I could even reduce the number of colors used even further say to only 64 colors without too many problems, producing an even smaller animation file size. This however is very dependent on the video sequence used, and may not look very good.

            Your own video may have a better result or worse result, especially when dealing with a video that uses a lot more colors and possibly multiple scenes.

            Universal Global Color Table
            The better way to generate a 'smaller' GIF animation is to just supply a general universal range of colors rather than generate the 'best' global color table for an animation. Use one that should work well regardless of what colors are present in the original video.

            Another reason for doing this is that you can make you video longer without serious detrimental effects on the color selection, or resorting local color tables for each frame. Each frame is dithered to the same color map, completely independently of what other frames are in the animation.

            Here I use a '332' color map which is usually regarded as being a very good standard colormap when no transparency is needed. I have often seen this colormap (or a 219 color 'web-safe' colormap) used often in various video formats.


              convert -quiet -delay 1 plane.avi -map colormap_332.png plane_ugc.gif

                [IM Output]

            This animation has [IM Text] local color tables, and as a result the animation is smaller or [IM Text] bytes in size.

            The problem however is that you will often see an obvious and annoying 'noise' in areas of constant color. This noise was also present in ALL the previous video animations. It is only now visible due to the use of a more universal, and thus more widely spread out color mapping.

            The noise is actually caused by the dithering of the reduced color set when regenerating the image. However, this produces a pseudo-random pattern of colors that changes from frame to frame, resulting in the appearance of background noise in the image. See Problems with E-Dithers for more detail as to why this happens.

            We could just turn off the color dithering to remove the 'dither noise'...


              convert -quiet -delay 1 plane.avi \
                      +dither -map colormap_332.png plane_ugc_nd.gif

            Which has [IM Text] local color tables, and is [IM Text] bytes in size. 	[IM Output]

            The resulting animation is a very small 1/60th the size of the original animation, generally because of the large expanses of solid color producing extremely good pixel compression. But while it fixes the dither noise, and make for a very small file size, you get color banding instead, which is generally regarded as a very bad trade-off.

            Ordered Dithered Video
            The real solution is to use a different color dithering technique, which does not produce a different pattern from one frame to the next.

            For example here I used a Ordered Dither using Posterized Color Levels to dither the same universal '332' colormap.


              convert -quiet -delay 1 plane.avi \
                      -ordered-dither o8x8,8,8,4 +map plane_od.gif

            Which has [IM Text] local color tables, and is [IM Text] bytes in size. 	[IM Output]

            The above also used the "+map" operator, to ensure that all the images use the exact same global color map (which the ordered dither already reduced to a maximum of 256 colors). As the number of colors is already optimal, the "+map" operator does no dithering, or color reduction.

            The resulting dither pattern is not random, and does not change greatly from one frame to the next. Thus the 'dither noise' has been remove from the animation resulting in a fixed color pattern from from to frame.

            The pattern is also very repetitive allowing much better compression.

            And finally as the color map is fixed, it should work reasonably well regardless of what video is used.

            Higher Quality Ordered Dithered Video
            This specific video however only uses a small range of colors, mostly various shades of blue, so it doesn't actually use a lot of the colors provided by a general uniform colormap.

            In fact only [IM Text] colors were used in the last video animation!

            This is extremely low, and as such also quite visible. But it also means that this particular animation can benefit from using a large number of 'color levels' in the ordered dither operation, so as improve the overall quality.

            First however we need to determine how many color levels the animation can handle before it reaches the 256 color limit imposed by both the GIF file format and the global colormap re-mapping.

            The tricky part however is that you must determine these BEFORE you save the animation to the limited GIF format. And here is the command I use...


                convert -quiet plane.avi -ordered-dither o8x8,23 -append -format %k info:

            [IM Text]

            Basically I increased and decreased the number of color levels to use, until I had a figure that was just within the required 256 color limit.

            I can then apply the discovered 'color level' choice to the plane animation.


              convert -quiet -delay 1 plane.avi \
                      -ordered-dither o8x8,23 +map plane_od2.gif

            Which has [IM Text] local color tables, is [IM Text] bytes in size, and [IM Text] colors. 	[IM Output]

            As you can see a very high quality, ordered dithered video was generated, which is on a par with the 'best colormap' global color map version we generated earlier, but also 1/3 smaller in size, while the 'dither noise' is now much harder to see.

            Of course as the quality is so much higher, it does require a larger file size, as it doesn't compress as well as the low quality version.

            On the other hand you now actually have a good control over the quality vs file size trade-off in the form of the number of 'color levels' used.

            Just remember this technique is a special case, for an animation that does not use too many colors. And making the video longer by adding more frames will also add more colors, and thus require a reduction in the 'color level' quality control.

            This is about the best method of color optimization I have yet seen for general GIF animations. It removes 'dither noise', provides some quality control, and retains the ability to use other GIF animation optimization methods, such as Frame Optimization.

            Compression (Transparency) Optimization
            Because this video uses a panning camera, the background of the video changes from frame to frame. This means the GIF animation will not Frame Optimize very well.

            However we can still use a simple Transparency Optimization to further reduce the final size of the GIF animation.


              convert plane_od2.gif  -layers OptimizeTransparency +map plane_opt.gif

            The result is [IM Text] bytes in size, and [IM Text] colors. 	[IM Output]

            That is one extra color, a transparent color index, was added to the image, and any pixel that does not change the currently displayed color was made transparent. This in turn generates large segments of transparent areas in the original animation, as well as repeats of similar pixel sequences, which generates an improved LZW compression in the final GIF image.

            Not bad, the animation is now half that of the direct conversion to GIF, and still a reasonably high quality.

            If you like to add to the above, discuss the techniques to further improve them, please contact me, or the IM forum. I am more than happy to hear about your views, techniques and discussions, or look at a specific video/animation problem you may have.

            One such discussion is Finding the "right levels" for quantization with anim GIF.

            Giflossy Compression LZW Optimization
            A new tool, GifLossy which is a fork of the original Gifsicle program modifies the colors of each frame so as to allow LZW to compress the image much more.

            For example, here I applied it to the original GIF animation, asking it to reduce the colors to a single 256 color table.


              gifsicle -O3 --lossy=80 --colors 256 plane.gif -o plane_giflossy.gif

            Which has an absolutely amazing size of [IM Text] bytes. It isn't nearly as high a quality as what we achieved using ordered dither but it is less than 1/2 the size.

                [IM Output]

            Emboldened by that above result I decided to use GifLossy on the best ordered dither result we got, to see if it can make it even smaller.


              gifsicle -O3 --lossy=80 plane_od2.gif -o plane_od2_giflossy.gif

            And we did get an even smaller size of [IM Text] bytes. Unfortunately we basically lost the high quality ordered dither result we works so hard to achieve before. Which is disappointing.

                [IM Output]


            De-Interlacing a Video Frame
            Not all images are from digital cameras. It is very common to extract images from a digital video feed from a non-CCD video camera. These images are interlaced for direct display on a TV, resulting in every second line being a different frame of the image (interlacing).

            For two frames where things aren't moving, the interlacing is usually not very noticeable. Perhaps producing only a slight edge blurring of the image. But when a fast moving object is involved, the resulting interlaced image is very disconcerting, as two frames have been merged together.

            Wolfgang Hugemann <Auto@Hugemann.de> (Germany), had this problem and sent me a snapshot of a crash test, that Wolfgang took himself. But for demonstration I will use a smaller image cropped from this one. The techniques however will work on the full sized image.


                convert video_frame.png  -crop 100x100+200+470 +repage  interlaced.png

                [IM Output]

                Wolfgang Hugemann used a TIFF format for the original video frame, I converted this to PNG for use on IM Examples. Do NOT be tempted to use JPEG for these images, until you have finished processing as it will destroy the low level quality needed for this process.

            As you can see the interlacing shows two separate frames, as it comes from a interlaced PAL digital video sequence, (approx 50 half frames per second). Yes the car was moving very fast and the camera is using a high speed shutter, producing a very high quality video image. The resulting image is two interwoven half-frames with the car's side mirror moving quite a distance during the intervening 1/50 second time period between half frames.

            Here we just replace one of the interlaced half-frames (every second line) with white. This is the standard de-interlacing method, known as a 'BoB' filter. This was contributed by Wolfgang for IM Examples.


              convert interlaced.png  -fx "floor(j/2)==j/2 ? u : 1"  deinterlace_1.png

                [IM Output]

            Now the FX operator is slow, so an alturnative is to create a 'striped image'. Such an image can be generated from the special "pattern:Horizontal2" built-in image.

            That image can then be overlaid with the original, using a 'Screen' composition method to overlay white lines, or use 'Multiply' or overlay black lines. For example...


              convert -size 100x100 pattern:Horizontal2 \
                      interlaced.png -compose Multiply -composite  deinterlace_2.png

                [IM Output]

            Negating the pattern can be used to select the other half of the interlaced image. Or if you change the 'Multiply' to 'Screen' you can extract frames with a white background.

            As an alternative I tried to fill in the missing frame lines by just duplicating the previous line.


                convert interlaced.png  -fx "u.p{i,j-j%2}"  deinterlace_3.png

                [IM Output]

            You can also use a Pixelization Technique to shrink and expand an image so as to double up every second line.


                convert interlaced.png -sample 100%x50% \
                                       -sample 100%x200%  deinterlace_4.png

                [IM Output]

            And with a slight variation you can combine the lines on both sides to vertically smooth the half-frame image as part of the resize expansion.


                convert interlaced.png -sample 100%x50% \
                                       -resize 100%x200%  deinterlace_5.png

                [IM Output]

            The result is a particularly nice extraction of one frame of the interlaced video image.

            If you want to extract the other half-frame from the image you can adjust the 'sampling:offset (as of IM v6.8.4-7)


                convert interlaced.png -define sample:offset=75 \
                        -sample 100%x50%  -resize 100%x200%    deinterlace_6.png

                [IM Output]

            Before this version of IM you would need to "-roll" the image by one pixel, to achieve the same result.
https://legacy.imagemagick.org/Usage/compare/
            The ability to compare two or more images, or finding duplicate images in a large collection, is a very tricky matter. In these examples we look at comparing images to determine how they similar they are, and where they differ.

            This may involve classifying or grouping images into various types for better handling. Discovering some metric to simplify and group similar images. And clustering similar images together based on such metrics.

            However such comparisons, and or studies while difficult can be rewarding, with the ability to find image duplicates, copies, and even removal of 'spam' or other text or notices from images.

            Methods of Comparing Images
            Compare Program
            The "compare" program is provided to give you an easy way to compare two similar images, to determine just how 'different' the images are.

            For example here I have two frames of an animated 'bag', which I then gave to "compare' to highlight the areas where it changed.


              compare bag_frame1.gif bag_frame2.gif  compare.gif

            [IM Output] [IM Output] ==> [IM Output]

            As you can see you get a white and red image, which has a 'shadow' of the second image in it. It clearly shows that three areas that changed between the two images.

            Rather than saving the 'compare' image, you can of course view it directly, which I find more convenient, by output to the special "x:" output format, or using the "display" program. For example..


              compare bag_frame1.gif bag_frame2.gif  x:
              compare bag_frame1.gif bag_frame2.gif  miff:- | display

            As of IM v6.4 you can change the color of the differences from red to some other more interesting color...


              compare bag_frame1.gif bag_frame2.gif \
                      -highlight-color  SeaGreen  compare_color.gif

                [IM Output]

            As of IM v6.4.2-8 you can specify the other color as well.


              compare bag_frame1.gif bag_frame2.gif \
                      -highlight-color  SeaGreen  -lowlight-color PaleGreen \
                      compare_colors.gif

                [IM Output]

            If you don't want that 'shadow' of the second image, from IM v6.4.2-8 you can add a "-compose src" to the options to remove it.


              compare bag_frame1.gif bag_frame2.gif \
                      -compose Src compare_src.gif

                [IM Output]

            By using all three extra settings we can generate a gray-scale mask of the changed pixels...


              compare bag_frame1.gif bag_frame2.gif \
                      -compose Src -highlight-color White -lowlight-color Black \
                      compare_mask.gif

                [IM Output]

            Note however that this mask is of ANY difference, even the smallest difference. For example you can see all the minor differences that saving an image to the Lossy JPEG Format produces...


              convert bag_frame1.gif  bag_frame1.jpg
              compare bag_frame1.gif bag_frame1.jpg   compare_lossy_jpeg.gif

            [IM Output] [IM Output] ==> [IM Output]

            As you can see even though you can't really see any difference between GIF and the JPEG versions of the image, "compare" reports a lot of differences.

            By using a small Fuzz Factor you can ask IM to ignore these minor differences between the two images.


              compare -metric AE -fuzz 5% \
                      bag_frame1.gif bag_frame1.jpg   compare_fuzz.gif

            [IM Text]
                [IM Output]

            Which shows that most of the actual differences are only minor.

            The special "-metric" setting of 'AE' (short for "Absolute Error" count), will report (to standard error), a count of the actual number of pixels that were masked, at the current fuzz factor.

            Difference Images
            To get a better idea of exactly how different the images are, you are probably better of getting a more exact 'difference' composition image....


              composite bag_frame1.gif bag_frame1.jpg \
                        -compose difference  difference_jpeg.gif

                [IM Output]

            As you can see while "compare" showed that JPEG created a lot of differences between the images, a 'difference' composition was quite dark, indicating that all the differences were relatively minor.

            If the resulting image looks too black to see the differences, you may like to Normalize the image (using the more mathematically correct "-auto-level", so as to enhance the results.


              convert difference_jpeg.gif  -auto-level  difference_norm.gif

                [IM Output]

            This still shows that most of the differences are still very minor, with the largest difference occurring along the sharp edges of the image, which the JPEG image file format does not handle very well.

            On the other hand getting a difference image between the two original frames of the animation shows a very marked differences between the two images, even without any enhancement.


              composite bag_frame1.gif bag_frame2.gif \
                        -compose difference  difference_frames.gif

                [IM Output]

            Note that as the 'difference' compose method is associative, the order of the two images in the above examples does not matter, although unlike "compare", you can compare different sized images, with the destination image determining the final size of the difference image.

            The different method is even more useful when used with the "convert" program, as you can process the resulting image further before saving or displaying the results. For example you can threshold and merge each of the color channels to to generate a mask of any pixel that changed color between the two images.


              convert bag_frame1.gif bag_frame2.gif -compose difference -composite \
                      -threhold 0 -separate -evaluate-sequence Add \
                      difference_mask.gif

                [IM Output]

            This is basically what the "compare" program does, but with more controls as to the color and output style.

            However as you can see it tends to find even the smallest minor change between two images. If the images are from a lossy image file format, such as JPEG, or a GIF image that required color reduction and dithering (color quantization), then that would probably match everything in the image. As such it it typically not very useful.

            For better results you can try to figure out just how different the pixel colors are. For example we can gray-scale the result, so as to get a better comparison image, than a colorful one.


              convert bag_frame1.gif bag_frame2.gif -compose difference -composite \
                      -colorspace Gray   difference_gray.gif

                [IM Output]

            Now unlike "compare", the difference image shows a mixture of both images combined in the final result. For example look at the weird 'talisman' seems to appear in the forehead of the cat. This was originally the handle of the bag from the first image. This merger can make it confusing as to exactly what differences you are seeing, and you see a megere of both the additions and removals from the image.

            Because of this confusion of details, the "compare" is usually the better way for us humans to view, while the 'difference' image is the better method for further processing the image.

            However grayscaling a difference image will simply average (actually a weighted average) the RGB distances together. As a result a single bit color difference could be lost though Quantum Rounding Effects.

            If even the smallest difference between images is important, a better method is to add the separate color channels of the difference image, to ensure you capture ALL the differences, including the most minor difference.


              convert bag_frame1.gif bag_frame2.gif -compose difference -composite \
                      -separate -evaluate-sequence add   difference_add.gif

                [IM Output]

            The difference values produced in the above is known as a 'manhattan distance' metric. That is the distance between the two colors of each image when you are restricted to orthogonal (or axial) movement. Be warned however that large differences may become clipped (or burned) as it can exceed the pixel data 'Quantium Range', or integer limits, unless using a HDRI version of IM.

            To take this further you can get the color vector distance, by using some squares and square roots to implement a Pythagorean or Euclidean distance.


              convert bag_frame1.gif bag_frame2.gif -compose difference -composite \
                       -evaluate Pow 2 -separate -evaluate-sequence Add -evaluate Pow 0.5 \
                       difference_vector.gif

                [IM Output]

            This is in fact similar what a 'fuzz' factor actually measures as part of its thresholding (when no transparency is involved). However 'fuzz' also divides the squared values by 3, before adding, to ensure the results do not exceed the image color range limits. Doing this means you would only get a pure 'white' pixel in the result for difference between opposite primary and secondary colors, such between a blue and yellow pixel.

            So lets do that scaling too...


              convert bag_frame1.gif bag_frame2.gif -compose difference -composite \
                      -evaluate Pow 2 -evaluate divide 3 -separate \
                      -evaluate-sequence Add -evaluate Pow 0.5 \
                      difference_vector_scaled.gif

                [IM Output]

            This is actually very similar to what you would get for a "-colorspace Gray' difference image (as above), but it is much more accuriate representation of color difference.

            You could leave of the second 'Pow 0.5' modification in which case you will get a Squared difference Image.

            There are other color distance metrics, which you can read about on the Color Difference, Wikipedia page. Most of these involve generating vector differences (see last) but using a different colorspace, such as LAB or LUV. This would however be more important in comparing real world color differences (EG: human vision difference measures).

            Also see Background Removal, where difference images like the above are used to perform background removal. You may also like to look at this external page on Change Detection as a practical example of its use.

            Flicker Compare
            An alternative to the "compare" program to see differences between images is to do a flicker comparison between the similar images at a reasonably fast rate.


              convert -delay 50 bag_frame1.gif bag_frame2.gif -loop 0 flicker_cmp.gif

                [IM Output]

            To make this easier I wrote a script to display an animation of two given images called "flicker_cmp" which flips between the two images, just like the above example. It also adds a label at the bottom of the displayed image so as to detail which image you are seeing at any particular moment.

            Comparing Animations
            You can also compare the differences in two coalesced animations using a special 'film strip' technique. See a similar 'append' technique in Side by Side Appending.

            Basically we append all the animation frames together to form one large, and long image. The two images are then compared and a new animation is created by splitting up the animation into separate frames again. For example...


                convert \( anim1.gif -coalesce -append \) \
                        \( anim2.gif -coalesce -append \) miff:- | \
                  compare - miff:- |\
                    convert - -crop 160x120 +repage anim_compare.gif

            The result is an animation of the 'compare' images, producing a 'dimmed' version of the second animation, overlaid with a highlight showing the parts which are different.

            Note that for this to work the "-crop" size much match the original size of the animation. Also the animation will lose any variable time delays that it may have had, using a constant time delay based on the first frame of the original animation.

            Another image comparison technique useful for animations is used to locate all the areas in which an animation changes, so as to divide the animation's unconnected parts. This way you can separate a large animations into a number of smaller animations. See Splitting up an Animation.

            Comparison Statistics
            Just how different are two images?
            Under Construction


            Statistics from difference image...

              The following outputs verbose information and extracts just the
              section containing the channel statistics of the image....

                convert image1 image2 -compose Difference -composite \
                        -colorspace gray -verbose  info: |\
                   sed -n '/statistics:/,/^  [^ ]/ p'

              The numbers in parenthesis (if present) are normalized values between
              zero and one, so that it is independent of the Q level of your IM.
              If you don't have these numbers, you should think of upgrading your IM.

              To get the average (mean) grey level as a percentage you can use this
              command...

                 convert image1 image2 -compose Difference -composite \
                       -colorspace gray -format '%[fx:mean*100]' info:

              For non-percentage you can use the even simplier..

                 convert image1 image2 -compose Difference -composite \
                       -colorspace gray -format '%[mean]' info:


            Compare  Program  Statistics...

               You can get an actual average difference value using the -metric

                 compare -metric MAE image1 image2 null: 2>&1

               Adding -verbose will provide more specific information about each separate
               channel.

                  compare -verbose -metric MAE rose.jpg reconstruct.jpg null: 2>&1

                  Image: rose.jpg
                  Channel distortion: MAE
                    red: 2282.91 (0.034835)
                    green: 1853.99 (0.0282901)
                    blue: 2008.67 (0.0306503)
                    all: 1536.39 (0.0234439)

               Their are a number of different metrics to chose from.
               With the same set of test images (mostly the same)

               Number of pixels
                  AE ...... Absolute Error count of the number of different pixels (0=equal)

                            This value can be thresholded using a -fuzz setting to
                            only count pixels that have a larger then the threshold.

                            As of IM v6.4.3  the  -metric AE  count is -fuzz effected.
                            so you can discount 'minor' differences from this count.

                            convert -metric AE -fuzz 10% image1.png image2.png null:

                            Which pixels are different can be seen using the output
                            image (ignored in the above command).

                            This is the ONLY metric which is 'fuzz' effected.

               Maximum Error (of any one pixel)
                  PAE ..... Peak Absolute Error   (within a channel, for 3D color space)
                  PSNR .... Peak Signal to noise ratio (used in image compression papers)
                            The ratio of mean square difference to the maximum mean square
                            that can exist between any two images, expressed as a decibel
                            value.

                            The higher the PSNR the closer the closer the images are, with
                            a maximum difference occurring at 1.  A PSNR of 20 means
                            differences are 1/100 of maximum.

               Average Error (over all pixels)
                  MAE ..... Mean absolute error    (average channel error distance)
                  MSE ..... Mean squared error     (averaged squared error distance)
                  RMSE .... (sq)root mean squared error -- IE:  sqrt(MSE)


               Specialized metrics
                  MEPP .... Normalized Mean Error AND Normalized Maximum Error
                            These should directly related to the '-fuzz' factor,
                            for images without transparency.

                            With transparency, makes this difficult the mask should
                            effect the number of pixels compared, and thus the 'mean'
                            but this is currently not done.

                  FUZZ      fuzz factor difference taking transparency into account

                  NCC       normalized cross correlation (1 = similar)

               I produced the following results on my test images...

                _metric_|__low_Q_jpeg__|__black_vs_white__
                 PSNR   | 29.6504      | 0
                 PAE    | 63479        | 65535
                 MAE    | 137.478      | 65535
                 MSE    | 4.65489e+06  | 4.29484e+09
                 RMSE   | 2157.52      | 65535


               The first column of numbers is a compare of images with low-quality JPEG
               differences, where the test image was read in and saved with a very low
               -quality setting.

               The second "black vs white", is a compare of a solid black image verses
               a solid white image.  If the 'average color' of the image is ignored
               by the comparision then the resulting value will be very small.  This
               seems only to be the case with the PSNR metric, as all others produced
               a maximum difference value.

               The e+06 is scientific notation, on how many places to shift the
               decimal point.  EG:   4.65489e+06  -->  4,654,890.0
               Thus is equal to about 4 million, and is the square of 2157.52

               WARNING: numbers are dependant on the IM Quality (Q) levels set at compile
               time. The higher the quality the larger the numbers. Only PSNR should be
               unaffected by this.  For this reason IM also gives you a 'normalized'
               result that is uneffected by the compile time quality setting, though may
               still have minor 'quantum' or 'interger rounding' effects.

               I have NOT figured out if there are any of the existing "-define" options
               usable the "compare" function.


               NOTE for opaque colors AE -fuzz  and RMSE distances are equivelent.
               HOWEVER,  when transparent colors are involved AE fuzz factor testing
               will treat two different fully-transparent colors as being the same
               while RMSE will treate them as being different!

               For example...
               To AE fully-transparent white and fully-transparent black are the same.

                 compare -metric AE xc:#0000 xc:#FFF0 null:
                 0

               But to RMSE they are VERY different

                 compare -metric RMSE xc:#0000 xc:#FFF0 null:
                 56755 (0.866025)

            Dissimilarity-threshold

              If you get a 'too different' error,  you can disable that using...
                  -dissimilarity-threshold 1.0

              But what is this threshold?

            For more info, see my very old raw text notes... Image Comparing, Tower of Computational Sorcery

            Matching Sub-Images and Shapes
            Under Construction

            Using "compare -subimage-search" option...

              compare -subimage-search  large_image.png  sub-image.png  results-%d.png

              This produces two images
                results-0.png
                    which displays the matching location
                results-1.png
                    which is a map of possible top-left corner locations showing how well
                    the sub-image matches at that location.

              Note the second image is smaller, as it is only top-left corner locations.
              As such its size is   large_image - small_image + 1

              The search however is based on a difference of color vectors, so produces
              a very accurate color comparison.

              The search basically does a compare of the small image at EVERY possible
              location in the larger image.  As such it is is slow! very very slow..

              The best idea is to compare a very very SMALL sub-image to find possible
              locations, than use that to then do a difference compare at each possible
              location for a more accurate match.

              Have a look at the script
                https://legacy.imagemagick.org/Usage/scripts/overlap
              and associated discussion
                Overlapped Images
              Which looks at locating 'high entropy' sub-images of one image to search
              for posible matches in a second image so the overlap offset between the
              two images can be discovered, and the images merged into a larger image.

              Another discussion uses sub-image searches to find tiling patterns in
              larger images, with the goal of generating tilable images
                Stitching image over a canvas


              Example using RMSE and the new -grayscale function to merge the
              separate color difference channel results into a final image

                convert large_image.png small_image.png miff:- |
                  compare -metric RMSE -subimage-search - miff:- |
                    convert - -delete 0 -grayscale MS show:


            Similarity Threshold

              As many time people are only interested in the first match that matches.
              As soon at this 'good' match is found, there is no need to continue
              searching for another match.  The -similarity-metric defines what you
              would regard as a good match.

              A "-similarity-threshold 0.0" will abort on the very first 'perfect' match
              found, while "-similarity-threshold 1.0"  (the default) will never match and
              will search every posible point.  A value between will set a color only
              'fuzz' factor on what you would find an acceptable match.

              Note that if the sub-image search is aborted, the second 'map' image will
              only contain a partial result, only showing the results up until the comapre
              aborted its search).


            Some Basic Sub-Image Search Examples....

              Grab a screen shot of a terminal window ("screen.png"),
              and crop out an image of a single letter or word ("letter.png").

              Just report first match.... for speed,
              immeditally abort after finding that first match.
              Don't bother outputing the incomplete image results.

                 compare -subimage-search -metric AE -similarity-threshold 1.0 \
                               screen.png letter.png null: 2>&1

              NOTE speed will be highly dependant on where in the image that first
              match is found.

              Find all occurances of exactly that image,
              as an image (white dots on matches, black elsewhere)

                 compare -subimage-search -metric AE \
                               screen.png letter.png miff:- 2>/dev/null |
                   convert - -delete 0 show:

              Extract a list of the coordinates of all matching letters (white dots)
              (as an enumerated pixel list, ignoring anything black)

                 compare -subimage-search -metric AE \
                               screen.png letter.png miff:-  2>/dev/null |
                   convert - -delete 0 txt:- | grep -v '#000000'

              Just the coordinate list

                 compare -subimage-search -metric AE \
                               screen.png letter.png miff:-  2>/dev/null |
                   convert - -delete 0 txt:- | sed -n '/#FFFFFF/s/:.*//p'



            NON-ImageMagick sub-image search solutions...

              "visgrep" from the "xautomation" package.

                This is much simpler sub-image search program, that only outputs a
                list of coordinates for the matches (or even multiple sub-image matches).
                Because it is so much simpler (for near exact matching) and not trying
                to generate 'result images' for further study, it is also a LOT FASTER.

                For example...
              
                  visgrep screen.png letter.png

                Timed results
                  using "compare" to get just the first match        0.21 seconds
                  using "compare" to get a 'results image'           1.56 seconds
                    ditto, but extracting the coordinate list        1.76 seconds
                  using "visgrep" to get all matching coordinates    0.09 seconds



            Other Methods of sub-image searching....

            HitAndMiss Morphology

              This is essentually a binary match, where you define what pixels much be
              'background' and what must be forground.  However it also allows you to
              define areas where you don't care if the result is a foregorund or
              background.

              Basically a binary pattern search method.

            Correlate (a Convolve variant)

              This is similar to Hit and Miss but using greyscale values.  Positive values
              for forground and negative values for background, and zero for don't care.
              It is however limited to grayscale images.

              See Correlation and Shape Searching.

              Both of these are basically just as slow as the previous sub-image compare,
              but less accurate with regards to colors.  However it's ability to specify
              specify a shape (don't care areas) to the sub-image makes then useful as
              a search method.

              However you need to convert the sub-image into a 'kernel', or array of
              floating point values, rather than as an actual image.


            FFT Convolve (NCC)

              Fast Fourier Transforms is a slow operator, but usually many orders of
              magnitude faster than the previous two methods use.  The reason is that
              a convolution in the frequency domain is just a direct pixel by pixel
              multiplication.

              The 'Convolve' method, can be converted into a 'Correlate', simply by
              rotating the sub-image being searched for by 180 degrees.
              See Correlate.

              Basically by converting images into the 'frequency' domain, you can do
              a sub-image search, very very quickly, compared to the previous, especially
              with larger sub-images that can be the same size as the original image!

              This I believe has been added as a NCC compare metric.



            Peak Finding and extracting (for near partial matches)...

              Once you have compared the image you will typically have a 'probably map'
              of some kind which defines how 'perfect' the match was.

              What you want to do now is to find the best match, or perhaps multiple
              matches in the image.  That is you want to locate the major 'peaks'
              in the resulting map, and extract actual locations.

              * Using a Laplacian Convolution Kernel

                To get results you need to find the 'peaks' in the image, not
                necessarily the brightest points either. You can get this by convolving
                the image so as to subtract the average of the surrounding pixels from
                the central pixel.  As we only want positive results, a bias removes the
                negative results.

                  convert mandril3_ncc1.png \
                          -bias -100% -convolve Laplacian:0 result.png

                Thresholding and using it as a mask, and we can extract just those pixels.

                  convert mandril3_ncc1.png \
                          \( +clone -bias -100% -convolve Laplacian:0 -threshold 50% \) \
                          -compose multiply -composite \
                          txt:- | grep -v black

                The problem is you can get a cluster of points at a peak, rather than
                a definitive pixel, especially for two peak pixel surrounded by very low
                values.

              * Using a Peaks Hit and Miss Morphology Kernel

                  convert mandril3_ncc1.png \
                          -morphology HMT Peaks:1.5 result.png

                The problem is that this may produce no result if you get two peak pixels
                with exactly the same value (no gap between foreground and background)

                However there are other 'peak' kernels that will still locate such a peak
                cluster.

              * Dilate and compare

                Dilate (expand maximum values) the image 3 times then compare it to the
                original image.  Any peak within the area of dilated kernel size (7 pixel
                square) will remain the same value. Set all pixels that show a
                difference to pixels to zero.

                Method by HugoRune  (IM discussion topic 14491)

              * Looped match and remove.

                Basically find the highest pixel value, note it. Then mask all pixels in
                an area around that peak, and repeat until some limit (number points or
                threshold) is reached.

                See a shell script implementation of this in  Fred Weinhaus's script
                "maxima"

                This does not look at finding the center of large 'cluster' of near equal
                valued pixels, though this would be very rare in real images.

              * Sub-pixel locating

                If the peak is not an exact pixel, but could conceivably be a sub-pixel
                location (between pixels) then some form of pattern match (gaussian curve
                fit) in the area of the peak may let you locate the peak to a sub-pixel
                coordinate.

                This may be more important in image registration for parorama stitching,
                especially when you are not using a large number points to get a best-fit
                average of the perspective overlay.

              * Finding a tile pattern in an image

                When you have all the points, a search for a repeating pattern (similar
                vector distances between multiple peaks) should point out some form of
                tiling structure.


            Improving the Sub-Image Matching...

              The major problem with Correlate, (or the fast  FFT correlate, which is the
              same thing) is that it has absolutely no understanding of color.

              Correlation (or convolve) is purely a mathematical technique that is used
              against a set of values.  With images that means it is only applied
              against the individual channels of an image, and NOT with vector color
              distances.


              While compare actually does real comparing of color vectors.  This will find
              shapes better than correlate but is much much slower.

              As such to make proper use of correlate you should convert your images
              (before hand for speed, or afterward against results) to try and highlight
              the color differences in the image as a greyscale 'correaltion' image.

              ASIDE: Use -channel to limit operations to one greyscale channel will
              improve speed.  In IMv7 greyscaling will reduce images to one channel so
              will gain speed improvements automatically.

              For example instead of intensity, you may get a better foreground
              / background differentiation, by extracting the  Hue of an image.
              Though you may need to color rotate the hue's if there is a lot of red
              in the sub-image being searched for.

              See the examples of HSL and HSB, channel separation, to see this problem.
                https://legacy.imagemagick.org/Usage/color_basics/#separate

              Another greyscaling method that should work very well is to do edge
              detection on the two images.  This will highlight the boundaries and shape,
              which is typically much more important than any smooth gradient or color
              changes in the image.

              For examples of Edge detection methods see
                https://legacy.imagemagick.org/Usage/convolve/#edgedet

              You may like to also look at directional or compass type edge detection.

              Basically Anything that will enhance the shape for your specific case is
              a good idea.  Just apply it to BOTH images before correlating them.


            Scale and Rotation Invariant Matching...

              * position independence...
              * matching rotated sub-image (angle independent)
              * matching resized sub-images  (size independent)
              * Both size and angle independence


            --------------

            Other more specific image matching..

            Matching Lines...

              Hough Algorithm

            Matching Circles...

              Hough Algorithm Variant

            Matching Faces

              A combination of the above.



            Finding Duplicate Images
            Identical files
            Are the files binary identical that is they are exactly the same file and probably just exact copies of each other. No ImageMagick required.

            Don't discount this. You can compare lots of files very very quickly in this way. The best method I've found is by using MD5 check sums.


              md5sum * | sort | awk {'print $2 " " $1'}  | uniq -Df 1

            And that will list the md5's of images that are identical.

            Using this technique I created scripts that can generate and compare md5sum lists of files returning the files that are md5 identical.

            Note however that any change to an image file other than a direct copy, will be classed by this as being different, even if the image data itself is the same. It only takes a date change or other minor meta-data difference in the file to make the image different.

            IM Image Signatures
            You can have IM generate a 'signature' for each image...


              identify -quiet -format "%#" images...

            The generates a hash string much like MD5 and SHA256 do. However unlike the latter, it uses the actual image data to generate the signiture, not the images metadata.

            Thus, if you have two copies of the same picture but with different creation/modification timestamps, you should get same signature for both files, whereas MD5 and SHA256 will produce two signatures even though the image itself is the same.

            WARNING: reading and writing a JPEG image will generate different image data and thus a different signature. This is simply due to the lossy compression JPEG image format uses.

            Direct Comparison
            You can directly compare two images (using the "compare" program) if they are the same size, to see how well they match. (See above)

            This is very slow, and in my experience not very useful when used against a full sized image, because it is so slow. However it is probably the best way to get an idea of just how similar two images are.

            Image Classification
            In my attempts to compare images I have found that Color, Cartoon-like, and Sketches all compare very differently to each other.

            Line drawings and gray-scale images especially tends to have smaller differences that color images, with just about every comparison method. Basically as the colors are all in a line any color metric tends to place such images 3 times closer together (1 dimentional colorspace verses a 3 dimentional colorspace)

            Basically this means that separating your images into at least these two groups can be a very important first step in any serious attempt at finding duplicate or very similar images.

            Other major classifications or image types can also make comparing images easier, just by reducing the number of images your are comparing against.

            See Image classification below.

            Thumbnail Compares
            You have a program create (in memory) lots of small thumbnails (say 64x64 pixels) of images to compare looking for duplicates, which you proceed to do by direct comparison.

            It is typically the first thing that people (myself included) attempt to do, and in fact this is the technique most image comparing programs (such as photo handling software) does.

            In fact this works well and does find images that exactly match. Also with a little blur, and loosing of the difference threshold, it can even find images that have had been been slightly cropped, and resized

            However attempting to store in memory 10,000 such thumbnails will often cause a normal computer to start thrashing, becoming very slow. Alternatively storing all those thumbnails (unless the program does this for user viewing reasons) uses a lot of disk space.

            One method of improving the disk thrashing problem, is to only have a smaller number of images in memory. That is by comparing images in groups, rather than one image to all other images. A natural grouping is by directory, and comparing each directory of images with other directories of images.

            In fact this is rather good, as images tend to be grouped together, and this group of images will often match a similar group. Outputting matching images by directory pairs, is thus a bonus.

            Also how acceptably similar two images are depends on their image type. Comparing two line drawings needs to have very small 'threshold' to discount images that different, while comparing images with large areas of color often needs a much larger threshold to catch similar images that were cropped.

            Real world images have a bigger problem in that a texture can produce a very serious additive difference between images that has a very slight offset. Because of this you may need to simply such images, into general areas of color, either by using median filters, blurring, color reduction, or color segmentation. After such a process a real world image, generally can be compares in a similar way to cartoons.

            Image Metrics
            Create a small metric for each image is a linear ordered (O) operation. While comparing all images with all other images is a squared ordered (O^2) operation.

            A metric is not ment to actually find matching images, but group similar (likely matching) images in such a way that you can do a more intensive comparison on smaller groups. As such any metric comparison should be lenient, and accept images that have a low probably (but still a probably) of a match. But it should not so lenient as to include too many miss-matches.

            Also you may like to consider multiple metrics, as some metrics may match up images that another metric may 'just miss' as they fall in different neighbouring regions (threshold miss-match).

            In the next section (Metrics) is a number of different IM generated metrics I have experimented with, or theorized about, including: average color, predominant color, foreground background, edge colors, matrix of colors, etc.

            Günter Bachelier, has also reported the possibilities of using more exotic metrics for image comparison, such as: Fourier descriptors, fractal dimensions, convex areas, major/minor axis length and angles, roundness, convexity, curl, solidity, shape variances, direction, Euler numbers, boundary descriptors, curvature, bending energy, total absolute curvature, areas, geometric centrum, center of mass, compactness, eccentricity, moments about center, etc, etc.

            My current effort is in generating and using a simple 3x3 matrix of color averages to represent the image (See Color Matrix Metric below). As these are generated (or requested) the metric is cached (with other file info) into special files in each directory. This way I only need to re-generate a particular metric when and if no cached metric is available, or the image changed.

            Similarity or Distance
            The metrics of two images (or the actual images) can be compared using a number of different methods, generally producing a single distance measure or 'similarity metric' that can be used to cluster 'similar' images together.

                Direct Threshold, or Maximum Difference, (Chebyshev Distance)
                Just compare images by the largest difference in any one metric.
                The threshold will produce a hyper-cube of similar images in the multi-dimensional metric space. Of course the image difference is only based on one metric and not over all metrics.

                Average Difference (Mean Distance, Averaged Manhattan Distance)
                Sum all the differences and optionally divided by the number of metrics.
                This is also known as the Manhattan Distance between two metrics, as is is equivalent to the distance you need to cover to travel in a city grid. All metrics contribute equally, resulting in things appearing 'closer' than you expect. In space a threshold of this metric will produce a diamond like shape.

                Euclidean (Pythagorean) Difference
                Or the direct vector distance between the metrics in metric space.
                The value tends to be larger when more metrics are involved. However, one metric producing a big difference, tends to contribute more than the other metrics. A threshold produces a spherical volume in metric space.

                Mathematical Error/Data Fit or (Moment of Inertia???)
                Sum all squares of all differences, then get the square root
                This is more typically used to calculate how close a mathematically curve fits a specific set of data, but can be used to compare image metrics too.
                This is seems to provide the best non-vector distance measure.

                Vector Angle
                Find the angle between the two lines from the center of the vector space created by the images metric. This should remove any effect of contrast or image enhancements that may have been applied to the two images.
                Yet to be tested

                Vector Distance
                For images that are line drawing or greyscale images, where all the individual color vectors in a metric are in the same direction, the relative distances of the metrics from the average color of the image is probably more important. Normalizing the distances relative to the largest distance may reduce the effect of contrast.
                That is this is a line drawing image, comparison method.
                Yet to be tested

                Cluster Analysis
                All the metrics are plotted and grouped into similar clusters within the multi-dimensional space. A good clustering package may even be able to discover and discount metrics that produce no clustering.
                Yet to be tested

            At the moment I am finding that the "Mathematical Error" technique seems to work well for both gray-scale and color metrics, using a simple 3x3 averaged "Color Matrix Metric" (see below).

            Human Verification
            After the computer has finished with its attempts to find matching images, it is then up to the user to actually verify that the images match.

            Presenting matches to the user can also be a difficult task, as they will probably want the ability to...

                See the images side-by-side
                Flick very very quickly between two images, at their original size, and optionally a common 'scaled' size.
                Flick between, or overlay, differently scaled and translated images. to try to match up the images.
                See other images in the same directory (source) or prehaps the same cluster (other near matches) as the matching image, so as to deal with a whole group rather than each image individually.
                Rename, Move, Replace, Delete, Copy the Images between the two (or more) directories, to sort out the images, and reject others.
                and so on... 

            . Currently I group matches into sets and use a combination of programs to handle them under the users control. These programs include IM's "display" and "montage", as well as image viewers "XV" and "GQview".

            However I am open to other suggestions of programs that can open two or more directories simultaneously, and display collections or image groups from multiple directories. Remote or control by other programs or scripts can be vital, as it allows the image groups to be setup and presented in the best way for the user to look at and handle.

            No program has yet met my needs.

            For example "gqview" has collections, and a single directory view, but does not allow multiple directory views, or remote / command line control of the presentation. However the collections do not show what directory each image is from, or flip the single directory view to some other directory. It also has no remote program control.

            On the other hand the very old "xv" does allow multiple directory views (its using multiple 'visual schnauzer' windows), and a collection list in its control window, but only one image can be viewed at a time, and only one directory can be opened and positioned from its command line. Of course it also has no remote control.

            These are the best human verification programs I have found, which I use a script to setup and launch for each image group, matching pairs, or all group matched images. But none are very satisfactory.

            A light table and associated software seems to me to be the better method of sorting out images, but for that you need larger touch sensitive screeens, and there in lies great expense.

            Cross-type Image Comparison
            One of the harder things I would like to do is find images that were created from another image. For example, I would like to match up a line drawing that someone else has colored in, or painted, to produce cartoon or even ultra realistic images. A background may also have been added.

            These things are very difficult and my experiments with edge detection techniques have so far been inconclusive.

            Finding the right metric in this is the key, as humans can make the 'similarity' connection much better, but you still have to find possible matches to present to the user.

            Summary of Finding Duplicate Images
            In summary, my current procedure of finding and handling duplicate images is a pipeline of programs to find and sort out 'similar' images.

               Generate/Cache  Image Types and Metrics
                 -> Compare metrics and cluster images.
                   -> compare images in cluster for matches
                     -> group into sets of matching images (by source directory)
                       -> human verification

            As you can see I am looking a highly staged approach.

            Mail me your ideas!!!

            Sorting Images by Type
            Determining what type of image is important as most methods of comparing images only work for a specific type of image. It is no good comparing an image of text against an artists sketch, for example. Nor is it useful to use a color image comparison method on image which is almost pure white (sketch).

            Usually the first thing to do when comparing images is to determine what type of image, or 'colorspace' the image uses. Basic classifications of images can include...

                Black and white line drawing or text image (almost all one color)
                Images consisting of two basic colors - equally (pattern images?).
                Gray-scale artists drawings (lots of shades)
                Linear Color images (colors form a gradient but not from black and white)
                Cartoon like color image with large areas of solid colors.
                A real life image with areas of shaded colors
                Image contains some annotated text or logo overlay. (a single spike of color) 

            After you have basic categories you can also attempt to sort images, using various image metrics, such as...

                Average color of the whole image
                predominant color in image
                Foreground/Background color of image. 

            What is worse, is that JPEG, or resized images are often also color distorted, making such classifications much more difficult as colors will not be quite as they should be. Greys will not be pure greys, and lines may not sharp and clear.

            An ongoing long term discussion on sorting images by type is on the IM Users Forum... How to check image color or black and white.

            Gray-scale Images
            The simplest way to check if an image is greyscale is to look at the color saturation levels of the image. That is easilly done by converting the image into a 'Hue' image colorspace and getting the average and maximum values of the color (typically green) channel. For example..


              convert rose:  granite: -colorspace HCL \
                      -format '%M  avg=%[fx:mean.g] peak=%[fx:maxima.g]\n' info:

            [IM Text]

            The numbers are normalized to a 0 to 1 range. As you can see the "rose" is very colorful (30% average), with a strong peak (approaching 1) The "granite" image however has a very low saturation (2% or so) and low peak value. Though it is not pure greyscale it is very close to it.

            A low average and high peak will indicate small patches of strong color. Thresholding the same channel can generate a mask of the colorful areas of the image.

            PROBLEM: The above does not find images that are linear in color. That is images which only contain colors that form a linear color gradient, such as a yellowed (sepiatone) photos, or blue prints. These are essentially colorful greyscale images. See next image type.

            Is Image Linear Color
            Another technique is to do a direct 'best fit' of a 3 dimensional line to all the colors (or a simplified Color Matrix of metrics) in the image. The error of the fit (generally average of the squares of the errors) gives you a very good indication about how well the image fits to that line.

            The fitting of a line to the 3 dimensional image generally involves some vector mathematics. The result will not only tell you if the image uses a near 'linear' set of colors, but works for ANY scale of colors, not just light to dark, but also off-grey lines on yellow paper.

            The result can also be used to convert the image into a simpler 'grey scale' image, (or just convert a set of color metrics to grey-scale metrics) for simpler comparisons, and better match finding.

            My trial test program does not even use the full image to do this determination, but works using a simple Color Matrix Metric below of 9 colors (27 values) to represent the image).

            However be warned that this test generally does not differentiate an unshaded line drawings very well. Such images are almost entirely a single background color (typically white) and as such my not show any form of linear gradient of colors. They should be separated out first using a different test (see next, it is actually much easier).

            Mail me if interested, and let me know what you have tried.

            Pure Black and White images
            To see if an image is near pure black and white image, with little in the way any color or even greys (due to anti-aliasing), we can make a novel use of the "-solarize" option (See the IM example on Solarize).

            Applying this operation on any image results in any bright colors becoming dark color (being negated). As such any near white colors will become near black colors. From such an image a simple statistical analysis of the image will determine if the image is purely (or almost purely) black and white.


               convert wmark_dragon.jpg  -solarize 50% -colorspace Gray  wmark_bw_test.png
               identify -verbose -alpha off wmark_bw_test.png | \
                   sed -n '/Histogram/q; /Colormap/q; /statistics:/,$ p'  > wmark_stats.txt

            [IM Output] ==> [IM Output] ==> 	
            [IM Text]

            If you look at the statistics above you will see that the color 'mean' is very close to pure black ('0'), while the 'standard deviation' is also very small, but larger than the 'mean'. Thus this image must be mostly pure black and white, with very few colors or mid-tone greys.

            For general gray-scale and color images, the 'mean' will be much larger, and generally the 'standard deviation' smaller than the mean. When that happens it means the solarized image has very little near pure black in it. That is very few pure black or white colors are present.

            Lets repeat this test using the built in granite image.


               convert granite: granite.jpg
               convert granite.jpg -solarize 50% -colorspace Gray  granite_bw_test.png
               identify -verbose -alpha off granite_bw_test.png | \
                 sed -n '/Histogram/q; /Colormap/q; /statistics:/,$ p' > granite_stats.txt

            [IM Output] ==> [IM Output] ==> 	
            [IM Text]

            Note how the 'mean' is now much larger, toward the middle of the color range, with a 'standard deviation' that is much smaller than the size of the 'mean'.

            As of IM v6.4.8-3 you will also see two other statistic values that can be helpful in determining the type of image. Both 'Kurtosis' and 'Skewness', are is relatively large (and positive) in the first Black and White image also reflects the fact that very few grays are involved when compared to a Gray image. However 'mean' vs 'standard divination' is still probably the better indicator for comparison purposes.

            Note that this comparison does not differentiate between 'black on white', or 'white on black' but once you know it is not really a gray-scale image a simple check of the images normal mean will tell you what the background color really is.

            Spot Colored Images
            These images fail the greyscale test above, but are still, black and white but with a small area or patch of color in it.

            Small patches of color could easily be swamped by the overall average of a large image, can could be mis-typed as being greyscale. We are not interested in an images with just say a single pixel of color, which is likely to be a bit error, or a speckling of such pixels across the image. But say an image with a color arrow or a small colored object. In other words a concentrated spot of color.

            In a discussion on the IM Forum False positive for greyscale images using the "saturation test" It was thought to break up images into smaller sections, and then look for a high saturation in any one of those areas. This lead to the following method.

                convert image into a colorspace with a Saturation or Chroma channel
                Resize Image smaller by a 1:50 (2%) ratio (EG a 'spot size' for color)
                Threshold on the get the maximum saturation/chroma value 

            Individual or very small spots will be removed, but a larger color spot will have at least one colorful pixel in the resized image.

            Midtone Colored Images
            [IM Output] Images which are sepia-toned, or with midtone grays colored to some highlight color (for example the image to the right) can prove to be much more difficult to distinguish. Generating such images is easy, as shown in Midtone Color Tinting, though are not very common.

            The colors still form a gradient (line) of colors in the color space, but that gradient falls along a curved path, typically a parabola of some kind, in a plane. But distinguishing such images can be very difficult.

            One technique is to get a standard deviation of any hues, that does not have an extremely small saturation. All hues in a midtoned color image should be very similar even if there are not many of them. This technique was presented in the specific post in How to check image color or back and white.

            Just a reminder that the Hue is a cyclic value, and wraps around the the color 'red'. To test properly you may have to do it twice, with the hues shifted by 180 degrees. Also Hue has no real meaning for any color with a very low saturation (grey), so any such color should be ignored in testing the standard deviation of hues.

            Text vs Line Drawing
            If you have an image that is almost purely a single color (typically white) then you can try to see if the image contents could be classified as either text, or a line drawing.

            Text will have lots of small disconnected objects, generally grouped into horizontal lines. On the other hand, line drawings should have everything mostly connected together as a whole, and involving many different angles.

            Note that cartoon-like color images could also be turned into a line drawing for simpler image comparing, so a line drawing comparison method would be a useful thing to have. Anyone?

            To find out more about the text, a number of techniques has been discussed in the IM forums, Check if image contains text.

            Real Life vs Cartoon Like
            Basically cartoons have very specific blocks of color with sharp bordered regions, often made sharper by using a separating black line. They also usually have a minimal gradient or shading effects. Real life images however have lots of soft edging effects, color gradients, and textures, and use lots of different colors.

            This is of course not always true. A real life image could have a very cartoon like quality about it, especially a very high contrast is used, and some modern cartoons are so life-like that it can be difficult to classify them as cartoons.

            Generally the major difference between a real life image and a cartoon is textures and gradients. As such to determine what type of image it is requires you to compare the image, to the same image with the fine scale texture removed. A large difference means the image is more 'realistic' and 'real world' like, rather than than 'cartoonish' or 'flat'.

            Also remember a line drawing, artist sketch, and text can also be very cartoon like in style, but have such a fine texture and detail to it that the above could think of the image as real world. As such line drawings and sketches should be separated out before hand.


            Jim Van Zandt offers this solution...

                write out the color of every pixel
                sort by color
                write out the pixel count for every color
                sort by pixel count
                Work your way through the list until you have accounted for half the pixels in the image.
                If #pixels >>> #colors then it's cartoon like. 

            The initial section can be classed as histogram. See the "histogram:" examples.


            If you have created some sort of image classification scheme.. Even if only roughly, please let us know your results, so others (including myself) can benefit.

            Handling Specific Image Types
            Here are notes and information on more specific image determination techniques.

            Bad Scan or Printouts
            In the real world, things never work quit as perfectly as you would like. Scanners have broken sensors and printer drums have scratches. Both of these problems generally result in scans and printouts containing long vertical lines. Determining if an image has these vertical lines is however fairly easy.

            The idea is to average the pixels of all the rows in an image together. Any 'fault' will appear as a sharp blip in the final pixel row the number of which you can count using a 'threshold histogram' of the pixel row.

            FUTURE -- image example needed for testing
                convert bad_printout.png -crop 0x1+0+0 -average \
                        -threshold 50% -format %c histogram:info:-

            faster method but needs image height (assumed to be 1024)
                convert bad_printout.png -scale 1024x1 \
                        -threshold 50% -format %c histogram:info:-

            When you have determined and removed such 'bad lines' from a fax, printout, or scan, you can then continue with your other tests without needing to worry about this sort of real world fault.

            Blank Fax
            First you will need to "-shave" off any headers and footers that a fax may have added to a page. You can then either to a 'threshold histogram' (see previous) to see how many individual black pixels there are.

            FUTURE -- image example needed for testing
                convert blank_fax.png -threshold 50% -format %c histogram:info:-

            Or you can do a Noisy Trim to see if the image actually contains any more solid area or objects worthy of your attention.

            FUTURE -- image example needed for testing

            Spammed Images
            A spammed image will generally show a predominant pure color spike in the images color histogram. A check on the color in the image will usually show it to be in one of the corners of the image.

            However this will not work with cartoon like images.

            EMail Spam Images
            These are images designed to get past the various spam filters. Basically the text of the ad is hidden in an image using various colors and extra 'dirt' and other noise added to make it harder to detect. And while these are difficult to distinguish from say a logo of a company email header, they are usually also much larger than the typical email logo.

            One discovery technique is to use a large median filter on the image. EMail spam text will generally disappear, while a logo or image will still remain very colorful.

            Image Metrics, quickly finding images to compare
            A metric represents a type of 'finger print' to represent an image, in a very small amount of memory. Similar images should result in a similar metric.

            Note however that a metric is not designed to actually find matching images, but to try to discount images that are definitely not a match. That is a good metric will let you disregard most images from further comparisons, thus reduce the amount of time needed to search all the images.

            Average Color of an image

            You can use -scale to get an average color of an image, however I also suggest
            you remove the outside borders of the image  to reduce the effect of
            any 'fluff' that may have been added around the image.

                convert image.png  -gravity center -crop 70x70%+0+0 \
                        -scale 1x1\! -depth 8 txt:-

            Alternatively to get 'weighted centroid' color, based on color clustering,
            rather than an average, you can use -colors

                convert rose: -colors 1 -crop 1x1+0+0 -depth 8 -format '%[pixel:s]' info:-
                rgb(146,89,80)

            This will generally match images that have been resized, lightly cropped, rotated, or translated. But it will also match a lot of images that are not closely related.

            The biggest problem is that this metric will generally disregard images that have been brightened, dimmed or changed the overall hue of the image.

            Also while it is a great metric for color and real-world images, it is completely useless for images that are greyscale. All such images generally get lumped together without any further clustering within the type.

            This in turn shows why some initial classification of image types can be vital to good image sorting and matching.

            Predominant Color of an image
            The predominant color of an image is a little different, instead of the average which merges the background colors with the foreground, you want to find the most common foreground color, and perhaps a percentage of how much of the image consists of that predominant color.

            As such you cannot just take a histogram of an image, as the image may use a lot of individual shades of color rather than a specific color.

            This can be done using the low level quantization function -segment, then taking a histogram. This has an advantage over direct use of -colors as it does not attempt to merge distant (color-wise) clusters of colors, though the results may be harder to determine.

             FUTURE example 

            After which a histogram will given you the amount of each of the predominant colors.

            However, usually the predominant color of a cartoon or line drawing is the background color of the image. So it is only really useful for real-life images.

            On the other hand, you may be able to use to discover if an image has a true background, by comparing this to the images average border color.

            Please note that a pictures predominant color is more likely to be more strongly influenced by the background color of the image, rather than the object of interest. That is usually in or near the center of the image.

            Border Colors
            By repeatedly cropping off each of the four edges (2 to 3 pixels at most) of an image, and calculating the borders average color, you can determine if an image is framed, and to how deep. Whether there is a definite background to the image. Or if there is some type of sky/land or close-up/distant color separation to the overall image.

            By comparing the averaged side colors to the average central color of the image you can discover if the image is uniform without a central theme or subject, such as a photo of an empty landscape.

            Histogram - General Color Matching
            For a metric concerning the types of colors to be found in an image, a histogram of one sort or another is used. This is done by creating an array of 'color bins' and incrementing the count of each 'bin' as the colors are found.

            Now I can't see you storing a large histogram for every image! So you will either only store the most predominant colors in the histogram or you would use a much smaller number of bin's (with more pixels in each bin).

            An ordinary histogram of 'color bins' does not really work very well. The reason is that each color will always fall into one bin. That is each pixel is added to each bin on an all or nothing bases without any regard to how near that color is an edge of a bin. This in turn does not make for a good metric.

            One solution is to create a histogram that has overlapping bins. That is every color (except maybe black or white) will fall into two color bins. Then later when you compare images a near color will match at least one of those bins.

            Another alternative is to create the histogram by having each color contribute to each 'bin' according to how close it is to the center of the bin. That is a color on the edge of one bin will actually share itself across two bins. This will generate a sort of fuzzy, or interpolated histogram, but one that would more accurately represent an image, especially when only a very small number of color 'bins' are used.

            Also histograms are traditionally either just the gray scale component of an image or three separate RGB component. But this is not a very good representation.

            You could try instead Hue, Saturation and Luminance Histograms to better represent the image.

            Alternatively why limit yourself to a 1 dimensional histogram. How about mapping the colors to a set a set of real colors across the whole color space! That is rather than binning just the 'red' value, why not count it in a 3-dimensional color bin (is what ever colorspace works best). That would generate a histogram that would truly represent the colors found within an image.

            Such a 3-d histogram metric could be a simple array of say 8x8x8 or 2048 bins. That is a 2Kbyte metric. A color search would then locate the correct number of near by bins, and get an interpolated count of the nearby bins. Which would represent the number of colors 'close' to that color within the image!

            Foreground/background Color Separation
            Using -colors you can attempt to separate the image into foreground and background parts, by reducing the image to just two colors.

            Using a -median filter first will remove the effect of minor details, and line edges and noise that may be in the image. Of course that is not very good for mostly white sketch-like images.

              convert rose: -median 5 +dither -colors 2 \
                      -depth 8 -format %c histogram:info:- 

            This shows a red and a grey color as the predominant colors in the image.

            A trim/crop into the center of the image should then determine what is foreground and what is background.

              convert rose: -median 5 +dither -colors 2 \
                      -trim +repage  -gravity center -crop 50% \
                      -depth 8 -format %c histogram:info:- 

            Which shows the red 'rose' color is the predominant foreground color.

            Note that a landscape image may separate differently in that you get a lower ground color and an upper sky color. As such a rough look at how the colors were separated could be very useful for image type determination.

            Also a picture with some text 'spam' will often show a blob of color in one corner that is far more prominent that the rest of the image. If found redo with 3 colors, then erase that area with the most common 'background' color found before doing your final test.

            This technique is probably a good way of separating images into classes like 'skin tone' 'greenery' 'landscape' etc.

            Average Color Matrix
            A three by three matrix color scheme ("-scale 3x3\!") is a reasonable color classification scheme. It will separate, and group similar images together very well. For example sketches (all near white), gray-scale, landscapes, seascapes, rooms, faces, etc, will all be separated into basic and similar groups (in theory).

            This is also a reasonable metric to use for indexing images for generating Photo Mosaics.

            The output of the NetPBM image format is particularly suited to generating such a metric, as it can output just the pixel values as text numbers.

            Remember this would produce a 27 dimensional result, (3x3 colors of 3 value), so a multi-dimensional clustering algorithm may be needed. Do you know of a good 3d clustering program/algorithm?

            For example, here is the 3 x 3 RGB colors (at depth 8) for the IM logo.

              convert logo: -scale 3x3\! -compress none -depth 8 ppm:- |\
                sed '/^#/d' | tail -n +4

              251 241 240 245 234 231 229 233 236 254 254 254
              192 196 204 231 231 231 255 255 255 211 221 231
              188 196 210

            The above can be improved by using 16 bit values, and possibly cropping 10% of the borders to remove logo and framing junk that may have been added...

              convert logo: -gravity center -crop 80% -scale 3x3\! \
                      -compress none -depth 16 ppm:- |   sed '/^#/d' | tail -n +4

              63999 59442 58776 62326 58785 58178 51740 54203 54965 65277 65262 65166
              45674 47023 49782 56375 55648 55601 65535 65535 65535 52406 55842 58941
              44635 48423 52881

            Of course like the previous average color metric, this will also have problems matching up images that have been color modified, such as hue, or brightness changes. (See next section)

            Also this metric can separate line drawings within its grouping, though only in a very general way. Such drawing will still be grouped more by the color of the background 'paper' rather than by content, and generally need a smaller 'threshold' of similarity, than color images.

            Color Difference Matrix
            The biggest problem with using the colors directly as a metric, is that you tie the image to a particular general color. This means any image that has been brightened or darkened, or its hue was changed, will not be grouped together.

            One solution to this is to somehow subtract the predominant or average color of the image from the metric, and using a matrix of colors makes this possible.

            Here for example I subtract the middle or center average color from all the surrounding colors in the matrix.

              convert logo: -gravity center -crop 80% -scale 3x3\! -fx '.5+u-p{1,1}' \
                      -compress none -depth 16 ppm:- | sed '/^#/d' | tail -n +4

              51093 45187 41761 49419 44529 41163 38834 39947 37950 52371 51007 48152
              32767 32767 32767 43469 41393 38587 52629 51279 48521 39500 41587 41926
              31729 34168 35867

            Note that I add .5 to the difference as you cannot save a negative color value in an image. Also the use of the slow "-fx" operator is acceptable as it only 9 pixels are processed.

            Note that the center pixel ("32767 32767 32767" at the start of the second line in the above) will not change much (any change is only due to slight rounding errors), and could be removed, from the result, reducing the metric to 24 dimensions (values).

            Alternatively, you can subtract the average color of the image from all 9 color values.

              convert logo: -scale 3x3\! \( +clone -scale 1x1 \) -fx '.5+u-v.p{0,0}' \
                      -compress none ppm:- | sed '/^#/d' | tail -n +4

              38604 35917 34642 37011 33949 32441 32839 33841 33649 39447 39259 38369
              23358 24377 25436 33538 33174 32426 39612 39434 38605 28225 30576 32319
              22271 24381 27021

            This also could be done by the metric comparator, rather than the metric generator.

            The metric still separates and clusters color images very well, placing similar images very closely together, regardless of any general color or brightness changes. It is still sensitive to contrast changes though.

            This metric modification could in fact be done during the comparison process so a raw Color Matrix Metric can still be used as a standard image metric to be collected, cached and compared. This is what I myself am now doing for large scale image comparisons.

            Unlike a straight color average, you can use this metric to differentiate between different line drawing images. However as line drawing use a linear color scale (all the colors fall in a line in the metric space, the differences between images is roughly 1/3 that of color images. As such a very different threshold is needed when comparing line drawings. Is thus still better to separate line drawings and grayscale images from color images.

            In other words this is one of the best metrics I have yet found for color images. Just be sure to determine what images are line drawings first and compare them separately using a much lower threshold. Lucky for us the metric itself can be used to do the separation of images into greyscale, or linear color image.

            Suggestions welcome.

            Difference Of Neighbours
            The above generates a 3x3 matrix, with the center pixel subtracted, and all the values offset to a perfect gray.

            However a better method is that instead of trying to save the color of the individual cells, to instead generate the differences between each cell and its neighbours (8 neighbours). That is instead of saving the color of the top left corner, save the difference between that corner and the top-middle, center, and left-middle.

            Of course even with a small 3x3 array, you will end up with a signiture containing 12 differences, though you don't need to encode the full difference just a general difference level. such as equal, or large/small positive/negative difference values

            This is much more likely to find images that match even between images which contain wildly different colors, as the actual color play no part in the signature at all.

            The 'libpuzzle' image comparison library does exactly that though it uses a 9x9 matrix, with just the center pixels of each cell being averaged together. It also limits itself to grayscale versions of the image.

            The technique is completely defined in a postscript paper, Image Signature for Any Kind of Image. The paper also goes into methods of storing that signature in a database and how to actuall perform a lookup to find of images with similar (not nessarially the same) signatures. It is the first paper I have discovered that actually goes into detail on how to do this. :-)

            Perceptual Hash
            Reduce the image to an 8x8 and calulate an average intensity. Each bit of the 64-bit hash is then 1 if the pixel is above the average or 0 if its less than average.

            To compare the similarity between two images you simply compare the bitwise hashes, bit by bit, and returning a hamming distance. The closer the hamming distance, the more similar the images are. Anything above 21 / 64 is considered not similar.

            The pHash eems to use YCbCr encoding. Some talk about working directly with the DCT from JPEG and the most promising works with the magnitude / phase and maps it to a log polar coordinate system.

            Matching images better
            Miscellaneous notes and techniques I have either not tried or did not work very well for comparing larger images for more exact image matching.

            Segmentation Color
            As you can see many of the above metrics use a blur/median filter followed by then color reduction techniques are basic attempts to simplify images to better allow them to be classified. However the Color Quantization Operator is not really designed for this purpose. It's job is to reduce colors so as to highlight the important details of the image.

            For image comparison however we don't really want to highlight these features, but highlight areas of comparative interest. This is the job of a related color technique known segmentation...

            ASIDE: from Leptonica: Image segmentation is the division of the image into regions that have different properties.

            This operator blocks out areas of similar colors removing the detail from those areas. Then, when you compare the two images, you are comparing areas rather than low level details in the images.

            IM implements a segmentation algorithm, "-segment", for its implementation details see SegmentImage().

            Example:

              convert logo: -median 10 -segment 1x1 \
                      +dither -scale 100x100\! segment_image.gif

            One problem is that -segment is VERY slow, and it only seems to work for larger images. Small images (like a rose: or a 100x100 scaled logo:) seems to result in just a single color being produced. This may be a bug.

            Of course you can still scale the image after segmenting it, as we did above. that way you can store a larger number of images in memory to compare with each other.

            Also the resulting segmentation does not seem to work very well, when compared to the image segmentation algorithm that Leptonica provides. See Leptonica: Color Segmentation.

            However an alternative to the IM segmentation, is to miss-use the color quantization function to find areas of similar color. Example:

              convert logo: -scale 100x100\! -median 3 \
                      -quantize YIQ +dither -colors 3 segment_image.gif

            The disadvantage is that -color limits the number of color areas that may be present in an image, where segment tries to preserve similar areas, regardless of how many areas are really present in the image (or at least that is what it should do).

            Colorless Edge Comparison
            Image color is notoriously unreliable, particularly for cartoon like images. Different users could quite easily recolor such images, add different colors backgrounds, or even take a sketch and color it in.

            One way to match up such images is to some basic color reduction, as per method above, but then rather than comparing images based on the resulting color you perform an edge detection, and further processing so that only the outlines of the most important color changes are used for the metrics and comparison of the images.

            For example...

              convert logo: -scale 100x100\! -median 3 \
                      -quantize YIQ +dither -colors 3 -edge 1 \
                      -colorspace gray -blur 0x1   outline_image.gif

            An alternative may be to use the -lat (Local Area threshold) for edge detection, which may give you some better control...

              convert logo: -scale 100x100\! -median 3 \
                      -quantize YIQ +dither -colors 3 \
                      -lat 3x3-5% -negate \
                      -colorspace gray -blur 0x1  outline_image.gif

            Of course for comparing you would use a line drawing comparison method.
            ??? how would you compare line drawings in a workable way ???
            Multiply images together and see if resulting image added or reduced the intensity of the lines. Mis-Matching lines will become black.

            Web Cameras
            What has changed in fixed cameras
            Under Construction

            Walter Perry <gatorus13_AT_earthlink.net> reports...

            The project I am working involves processing groups of 20 images sent from a surveillance camera in response to the camera sensing motion.  These cameras are at remote locations and once they detect motion the images are sent to a local server.  Once at the local server, I want to be able to "filter" out those images that do not contain what caused the event.

            I use PerlMagick to compare the first image in the series (which will always not contain anything other than the normal background) with the rest of the images.  I am getting an "average" difference for all the images and then if the individual difference is greater than the average difference I keep the image as it has something in it.

            This approach works great no matter day or night or what the lighting conditions.  I originally was trying to use just a percentage difference above the first image, but that was not too reliable and really depended on the lighting conditions.  Based on this comparison, I will then determine which images have "content" and those images which are empty of any motion. Once I obtain the only those images that contain "motion".
https://legacy.imagemagick.org/Usage/advanced/
            This page provides very large examples where we use multiple techniques to produce some compound image manipulation effects, beyond the basic image operations of IM. The major techniques are summarized in the index above.

            While many techniques are provided on other pages, such as creating font templates, fancy labeling images, and using masks, these pages show how you can combine those techniques together to produce a more complex effect.

            3-D Bullets from Shapes -- A Scripted Approach
            There are a lot of 'bullet' images available on the web for your web listings. But you can generate your own 3d objects, and allowing you to make your whole web site conform to a particular style that ties it all together.

            One of the best ways to do that is to create a 'generate' script that lets you automatically generate a whole range of buttons and shapes of a particular style, but using any color you require. This is one such, very simple script.

            Here we use the "-shade" option to generate 3d looking objects from a plain shaped transparency. The shape has only straight on/off transparency, which is carefully preserved, allowing it to be used as transparent GIF images for general use on web pages.

            The resulting grayscale 'shaded' image is then coloured using the "-tint" operator, to set the mid-tone greys of the image, while leaving the more extreme black and white shadings alone.

            After that the original shape of the image provided is re-added to the colored result. As a bonus if the input image had only a Boolean transparency the result also has a Boolean transparency appropriate for a GIF format image.


                convert {input_image} -matte \
                        \( +clone -channel A -separate +channel \
                           -bordercolor black -border 5  -blur 0x2 -shade 120x30 \
                           -normalize -blur 0x1 -fill {color} -tint 100 \) \
                        -gravity center -compose Atop -composite \
                        {output_image}

            Note that the input image is only read in once by the above script. This allows you to also use the script in a pipeline of commands using '-' as the input and output filenames (with perhaps an IM image format setting). This can be important when writing your own IM scripts.

            The above command was written into a very simple shell script called "create_bullet", and the following commands were executed, to generate a whole range of symbol images in many different colors.


                convert +antialias -size 15x15 xc:none -draw 'circle 7,7 3,3'  ball.gif
                create_bullet ball.gif  grey    ball_grey.gif
                create_bullet ball.gif  red     ball_red.gif
                create_bullet ball.gif  green   ball_green.gif
                create_bullet ball.gif  blue    ball_blue.gif
                create_bullet ball.gif  yellow  ball_yellow.gif
                create_bullet ball.gif  maroon  ball_maroon.gif
                create_bullet ball.gif  cyan    ball_cyan.gif

                convert -size 12x12 xc:black   square.gif
                create_bullet square.gif  grey    square_grey.gif
                create_bullet square.gif  red     square_red.gif
                create_bullet square.gif  green   square_green.gif
                create_bullet square.gif  blue    square_blue.gif
                create_bullet square.gif  yellow  square_yellow.gif
                create_bullet square.gif  maroon  square_maroon.gif
                create_bullet square.gif  cyan    square_cyan.gif

                # retrieve asterix symbol from
                # Anthony's Web Images, Symbols
                create_bullet asterix.gif  grey    asterix_grey.gif
                create_bullet asterix.gif  red     asterix_red.gif
                create_bullet asterix.gif  green   asterix_green.gif
                create_bullet asterix.gif  blue    asterix_blue.gif
                create_bullet asterix.gif  yellow  asterix_yellow.gif
                create_bullet asterix.gif  maroon  asterix_maroon.gif
                create_bullet asterix.gif  cyan    asterix_cyan.gif

                # Use a heart symbol from "WebDings" font (22 point => 16x16 pixel image)
                convert -font WebDings -pointsize 22 -background none \
                        label:Y -trim +repage    heart.png
                create_bullet heart.png  grey    heart_grey.png
                create_bullet heart.png  red     heart_red.png
                create_bullet heart.png  green   heart_green.png
                create_bullet heart.png  blue    heart_blue.png
                create_bullet heart.png  yellow  heart_yellow.png
                create_bullet heart.png  maroon  heart_maroon.png
                create_bullet heart.png  cyan    heart_cyan.png

            [IM Output] 	==> 	[IM Output] 	[IM Output] 	[IM Output] 	[IM Output] 	[IM Output] 	[IM Output] 	[IM Output]
            [IM Output] 	==> 	[IM Output] 	[IM Output] 	[IM Output] 	[IM Output] 	[IM Output] 	[IM Output] 	[IM Output]
            [IM Output] 	==> 	[IM Output] 	[IM Output] 	[IM Output] 	[IM Output] 	[IM Output] 	[IM Output] 	[IM Output]
            [IM Output] 	==> 	[IM Output] 	[IM Output] 	[IM Output] 	[IM Output] 	[IM Output] 	[IM Output] 	[IM Output]
            Only the shape or transparency of the source image is used in generating the bullets, as such any shape can be used. Pick your own shape that is unique to your website. Also note that GIF or PNG can be used, with or without transparency defining the shape. The command makes no distinction.

            If you do use a larger image than that shown here, you may also like to increase the amount of blurring that is applied before the shade operation. Otherwise you may find only the areas close to the edge of the images will be rounded. Also it may be better to blur multiple times rather than use a big blur value (to increase the speed of the blurring).

            Of course if you make some improvements or have other ideas, please let me know, so we can share them with others.

            Making Logos 3-D
            In this example we have a flat colored logo, with a difficult shape, which we what to image process to give it a distinct 3-D look. To do this we use the logo to generate highlights and shadows, and convert them into transparencies to overlay on the original image. It uses a lot different techniques from all of the example pages to achieve this effect, step by step.

            This example makes heavy use of images generated by the Shade Operator. and various Alpha Compositing methods. I suggest you become familiar with these image operators before proceeding, or look them up when you wish to understand better what is going on.

            Before we can start however we will need a simple logo to apply our technique to, and its mask....

            Lets first create a shape for the color background of logo example...


              convert -size 170x100 xc:black \
                      -fill white -draw 'circle    50,50  13,50' \
                                  -draw 'circle   120,50 157,50' \
                                  -draw 'rectangle 50,13 120,87' \
                      -fill black -draw 'circle    50,50  25,50' \
                                  -draw 'circle   120,50 145,50' \
                                  -draw 'rectangle 50,25 120,75' \
                      -fill white -draw 'circle    60,50  40,50' \
                                  -draw 'circle   110,50 130,50' \
                                  -draw 'rectangle 60,30 110,70' \
                      -gaussian 1x1 +matte logo_mask.png

                [IM Output]

            Now we use our mask to cut out the solid color of our logo, and add some text to generate a plain, solid color logo.


              convert logo_mask.png -background red -alpha shape \
                      -font Candice  -pointsize 36  -fill white  -stroke black \
                      -gravity Center  -annotate 0 "Ant" \
                      logo.png

                [IM Output]

            Now lets give it a 3D-look, by using Overlay Highlighting techniques.


              convert logo.png  -alpha extract -blur 0x6  -shade 110x30  -normalize \
                      logo.png  -compose Overlay -composite \
                      logo.png  -alpha on  -compose Dst_In  -composite \
                      logo_3D.png

                [IM Output]

            Adding shadows is also easier thanks to the new Shadow Generation operator provided by IM.


              convert logo_3D.png \( +clone -background navy -shadow 80x4+6+6 \) +swap \
                      -background none  -layers merge +repage logo_3D_shadowed.png

                [IM Output]

            Just for fun lets finish by overlay our logo on a 'rough paper' like background. A huge number of other background canvases can also be created, see Background Examples for a collection of such examples.


              convert logo_3D_shadowed.png \
                      \( +clone +repage -alpha off -fx 'rand()' -shade 120x30 \
                         -fill grey70 -colorize 60 \
                         -fill lavender -tint 100 \) \
                      +swap -composite logo_3D_bg.jpg

                [IM Output]

            Reflections
            Reflections are relatively easy to do, but often it does not seem like it. You have to deal with aspects such as surface color and texture, and also with how any such effect increases with the distance between the surface reflection and the object that is being reflected by that surface. Basically what should be a relatively simple matter, very quickly becomes quite a complex one.

            [IM Output] So lets start with the reflection of a relatively simple image, in this case an image of a Pokemon character, Azumarill (See right). Substitute your own image if you like.

            Now doing a reflection of a perfect mirror you would simply copy and flip the source object, and add some background behind it to make it to give it some context. For example...


              convert pokemon.gif \( +clone -flip \) -append \
                      -size 100x100 xc:black +swap \
                      -gravity North -geometry +0+5 -composite  reflect_perfect.png

                [IM Output]

            Surface Color - General Attenuation
            The thing to note in the above is that the reflection being perfect, does not really look like a reflection in a black surface. It's more like a 'mirror tile' of the original image, which is also true. Even a normal bathroom mirror does not reflect all the light hitting it, and it is about the best mirror you can get. So the first rule of reflections is...

            Reflections are never ever perfect.

            All reflections are never a 100% reflection, and as such are colored by the surface (or the surrounding environment). It is an imperfect world, and reflections enhance and demonstrate these imperfections very well.

            So let use try this again, but this time lets color the reflection by the color of the reflecting surface.

            You can do this in two ways. The simplest method is to simply Colorize the reflection the same color as the surface. The amount of coloring depends on how good the surface is at reflecting, for colored surfaces, that is usually pretty bad, so a large amount of color needs to be added, "65%" is quite good for a black surface.


              convert pokemon.gif \
                  \( +clone -flip -fill black -colorize 65% \) -append \
                  -size 100x100 xc:black +swap \
                  -gravity North -geometry +0+5 -composite  reflect_colored.png

                [IM Output]

            Much better... Now it actually looks like a reflection!

            The other way to make a reflection weaker is to make the reflected image semi-transparent, or translucent. For example multiply the images alpha value, to make only about 35% of the source object visible.


              convert pokemon.gif -alpha on \
                  \( +clone -flip -channel A -evaluate multiply .35 +channel \) -append \
                  -size 100x100 xc:black +swap \
                  -gravity North -geometry +0+5 -composite  reflect_alpha.png

                [IM Output]

            This is actually preferred, as it means the color of the surface can be any color or even some type of color texture or pattern.

            For example, lets generate a horizontal wooden floor, using an infinite tiling technique from Viewing Distant Horizons.


              convert tile_wood.gif   -set option:distort:viewport 100x100 \
                      -virtual-pixel tile     -distort Perspective \
                            '0,0 -20,65  96,0 60,40  96,96 120,55  0,96 50,99' \
                      wooden_floor.png

                [IM Output]

            And now overlay our image with its semi-transparent reflection onto this wooden floor.


              convert pokemon.gif -alpha on \
                  \( +clone -flip -channel A -evaluate multiply .35 +channel \) -append \
                  wooden_floor.png +swap \
                  -gravity North -geometry +0+5 -composite  reflect_wood.png

                [IM Output]

            Without the reflected object the wooden surface looks rather dull and lifeless, but with some object reflected in it, the floor suddenly has a very highly polished look to it!

            Distorted Source
            Okay. Lets try something a little more fancy, and give the image a bit of some 3D Perspective depth to it.


              convert pokemon.gif -alpha on   -virtual-pixel transparent \
                  +distort Perspective '0,0 0,0  0,64 0,64  64,0 54,10  64,64 54,54' \
                  \( +clone -flip -channel A -evaluate multiply .35 +channel \) -append \
                  +filter  -size 100x100 xc:black +swap \
                  -gravity North -geometry +0+5 -composite  reflect_distort_bad.png

                [IM Output]

            Which is obviously wrong. It looks like the image is distorted, but remains flat on to the original user. Why because...

            Object that is in contact the surface will also contact their reflection.

            It seems pretty obvious but I have seen people get this wrong. Of course if the object is floating about the surface then they will not make contact.

            One way to fix this would be to distort the source image and the reflection of that image separately, before Layer Merge the results together.


              convert pokemon.gif -alpha on   -virtual-pixel transparent \
                  \( -clone 0 \
                     +distort Perspective '0,0,0,0  0,64,0,64  64,0,54,10  64,64,54,54' \) \
                  \( -clone 0  -channel A -evaluate multiply .35 +channel \
                     +distort Perspective '0,0,0,128  0,64,0,64  64,0,54,98  64,64,54,54' \
                  \) -delete 0 +swap -background none  -layers merge \
                  +filter  -size 100x100 xc:black +swap \
                  -gravity North -geometry +0+5 -composite  reflect_distort_sep.png

                [IM Output]

            As you can see by the very different set of distortion parameters, distorting a reflection can get very difficult. It is even more difficult as a simple change to the first distortion requires a calculated change to the second distortion for the reflected image.

            There are two more rules that will tell you how the coordinates of the reflected distortion should be calculated.

            Reflections in a horizontal surface are always directly downward.

            That is a reflection is always toward the user, which as an user is directly in front of an image, will mean that any reflection in a horizontal surface will be downward, directly toward the user. This is a law of physics, and that is one thing you do not want to break, if you want your images to be at least semi-realistic.

            And finally one other rule that you should remember.
            Vertical surfaces, reflected in horizontal surfaces have
            reflections that the same height as the reflected object

            It does not matter how 'distant' the object appears to be in an image, the height of its reflection in the final image should be the same height as the object being reflected! It is not obvious, and very easy to get wrong.

            These three rules mean, that the X value of the reflected coordinate remains the same, by the Y value is flipped downward around the 'surface contact point' by the same amount it is above that point.
            As such with some care you can calculate the distortion coordinates for the reflection, based on the coordinates of the distorted source image.

            Now these rules also provide us with a method that can simplify reflections for distorted images. Just append the reflection to the source image first, then distort the source image as if it has no reflection attached, letting its reflection distort along with the main image...


              convert pokemon.gif -alpha on   -virtual-pixel transparent \
                  \( +clone -flip -channel A -evaluate multiply .35 +channel \) -append \
                  +distort Perspective '0,0,0,0  0,64,0,64  64,0,54,10  64,64,54,54' \
                  -gravity North  -crop 100x100+0-5\! \
                  -background black -compose Over -flatten    reflect_distort.png

                [IM Output]

            As you can see this works a lot easier, and you only have one set of distortions to deal with for the object, making changes a lot simpler too.

            It also allows you to use distortions that would be otherwise be impossible to repeat to create a separate reflection. For example, generating a 3D arc from the image...


              convert pokemon.gif -alpha on   -virtual-pixel transparent \
                  \( +clone -flip -channel A -evaluate multiply .35 +channel \) -append \
                  +distort Barrel '0,0,0,1  0,0,-.35,1.5  32,32' \
                  -gravity North  -crop 100x100+0-5\! \
                  -background black -compose Over -flatten    reflect_3Darc.png

                [IM Output]

            One final point before we proceed to the next section...

            Shadows will generally obey the same rules as reflections, except for the last two rules. They may not fall directly downward, but point away from the light source (parallel for distant light sources). Also they will not be a same distance from the 'surface contact point', but they will have the same ratio of distances, just not 1:1 ratio as you get for reflections.

            Gradient Attenuation
            So far we have dealt with a perfectly smooth reflective surface, but most surfaces are not polished to a mirror shine. A seemingly smooth surface is actually not smooth at smaller scales and this in turn effects the light that is reflected off such a surface.

            That effect also grows stronger with the distance the reflected light has to travel between the object and the point of reflection. As such...

            Reflections get weaker and more distorted,
            the further it is from the source image.

            The simplest way to create a distance effect is to make the reflection weaker the further it is from the surface. For this is is usually acceptable to make the reflection a little brighter close to the image.


              convert pokemon.gif -alpha on \
                  \( +clone -flip \
                     -size 64x28 gradient:gray40-black   \
                     -alpha off -compose CopyOpacity -composite \
                  \) -append \
                  -gravity North  -crop 100x100+0-5\! \
                  -background black -compose Over -flatten    reflect_attenuated.png

                [IM Output]

            This works reasonably well, and is so easy to generate that it is a rather common method of generating reflections.

            The technique works as a good percentage of the light being reflected is not a perfect reflection, but more of the global environment. The more distant you are from the original image, less of the original image is reflected.

            Blurred Attenuation
            The component that makes up the real reflection of the source object, does not simply get weaker with distance. In reality reflections get more blurry, fuzzy and distorted with distance, as the reflecting surface is generally not very smooth. This is not a macro distortion, but distortions at very small microscopic levels. The same effect that produces specular lighting reflections. That is close in to the source of the reflection they can be reasonably sharp, but the further you get from the source the more blurred the image becomes.

            Before IM version 6.5.5-0, this was something that was very difficult to achieve (it was possible, but not without a lot of trickiness). However now you can use Variable Blur Map to blur a reflection based on its distance from the source image quite easily.

            However for this to work, it is a good idea to add a transparent border around the object into which to blur. In these examples, I extended the final image so you can see the whole reflection, so you can appreciate its effect.


              convert pokemon.gif -alpha on \
                  -background None -gravity South -extent 100x100 \
                  \( +clone -flip -channel A -evaluate multiply .35 +channel \
                     -size 100x100 gradient:gray5-white \
                     -compose Blur -set option:compose:args 10 -composite -compose Over \
                  \) -append -trim +repage \
                  -gravity North  -crop 100x140+0-5\! \
                  -background black -compose Over -flatten    reflect_blurred.png

                [IM Output]

            The reflection blur can be enhanced further by using a vertically stretched blur ellipse. For example using elliptical blur arguments of '10x30' rather than a simple circluar blur of '20'.

            If you then combine the "Blurred Attenuation" with a "Gradient Attenuation" you will start to get a very realistic reflection of a typical, not-so-polished, but smooth surface reflection.


              convert pokemon.gif -alpha on \
                  -background None -gravity South -extent 100x100 \
                  \( +clone -flip \
                     \( -size 100x64 gradient:'rgba(0,0,0,0.6)-none' \
                        -size 100x36 xc:none  -append \
                     \) -compose Dst_In -composite \
                     \( -size 100x100 gradient:gray5-white \
                     \) -compose Blur -set option:compose:args 4x8 -composite \
                  \) -append -trim +repage \
                  -gravity North  -crop 100x140+0-5\! \
                  -background black -compose Over -flatten    reflect_blur_atten.png

                [IM Output]

            You would be hard pressed to get a better reflection image for flat surfaces than this.

            Future: To add examples of...
              Surface Texture effects
                frosted - or non smooth surfaces (small scale randomised distortions)
                rippled - water reflections
                    (very little blur or attenuation, just stronger macro distortion)

            Jigsaw Pieces
            One of the most interesting things I have been asked to help with was to cut out and enhance an odd shaped 'jigsaw' piece from a larger picture. Actually Theo van Hoesel, also known as "Mr Jigsaw", wanted to generate a lot of separate pieces, at lots of different rotations. The following was developed from our discussion for just one piece, but with the right set of templates, any pattern of pieces can be generated.

            To the right is a thumbnail linked to a 800x600 image of a photo of the Holocaust Memorial, Berlin, Germany. I took this photo during on my European trip in April 2006. It looks like a great image to make a really hard jigsaw puzzle from.

            And below it is a template image of the jigsaw piece I will be extracting from the above image. It was part of a set of such images. The full set of jigsaw pieces contains 192 such masks, in a 16 by 12 array, including edges and corners.

            This specific jigsaw piece is a 100x100 pixel mask, and designed to be used at a +365+96 offset on an 800x600 pixel image. These figures are only important if you have a large set of different pieces that will fit together. If you don't plan to do this then of course you can use any offset you like.

                    [photo]
            [IM Output]

            I myself have collected a number of such jigsaw sets, which can let me make a jigsaw of any image. And this is what Theo van Hoesel, is actually doing on his website.

            If you are making an actual jigsaw puzzle then the offset information is very important, as it identifies the location and placement of that piece from the original image. As such I will try to preserve this information. Note that offsets for masks could in some cases be negative, due to the extra padding around the shape, so you may need to test and adjust image commands to handle this situation.

            The extra padding itself will allow you to easily rotate, add thickness and shadow effects to the final image, without needing to change the size or offset of the cutout jigsaw piece.

            First however lets convert this template into an outline.


                convert jigsaw_tmpl.png -edge .5 -blur 0x.5 jigsaw_edge.png

                [IM Output]

            I can then overlay this onto the image to get a rough idea as to what is going to be cutout to form the jigsaw piece.


                convert holocaust_md.jpg \
                        \( jigsaw_edge.png -negate \) -geometry +365+96 \
                        -compose multiply -composite \
                        -crop 100x100+365+96 +repage jigsaw_outline.png

                [IM Output]

            Normally this is not done when generating a jigsaw, but is useful to do when the position of the piece is not important (as it isn't part of a larger puzzle). If so you can adjust the offset to select better content for that jigsaw piece.
                Due to the way "-edge" works the jigsaw outline generated above is inside the masked (white) area masking image. This can be important if you like to make use of this outline later.

            Okay we have a jigsaw shape, and an offset for the piece to cut out. so lets cut it out and rotate it too.


                convert holocaust_md.jpg \
                        -crop 100x100+365+96\! -background none -flatten +repage \
                        \( jigsaw_tmpl.png +matte \) -compose CopyOpacity -composite \
                        -rotate -20 -gravity center -crop 100x100+0+0 +repage \
                        jigsaw_cutout.png

                [IM Output]

            Note that we cropped the source image to the area covered by out template shape. We will not need the area outside the mask, and removing it early will speed up the image processing.

            Also note the special use of a viewport crop, followed by "-flatten". This method of cropping will ensure that we will be guaranteed a 100x100 pixel image from which to 'cutout' the template, even when using masks of edge or corner pieces, and also handle a negative offset for pieces on or near the top, or left, edges of the image.

            The rotate is also performed at this point as most enhancements will add effects based on a specific direction. The result of that rotate is also center cropped as this operator, normally expands the resulting image size, depending on the rotation angle used, and we don't want it to do that.

            The first enhancement is to give the pieces a slightly beveled, or rounded, highlight around the edges. This is as per Shade Highlight Overlays, which allows fine control (4 separate factors) of way the highlight is produced.


               convert jigsaw_cutout.png \
                       \( +clone -channel A -separate +channel -negate \
                          -background black -virtual-pixel background \
                          -blur 0x2 -shade 120x21.78 -contrast-stretch 0% \
                          +sigmoidal-contrast 7x50%  -fill grey50 -colorize 10% \
                          +clone +swap -compose overlay -composite \) \
                      -compose In -composite jigsaw_bevel.png

                [IM Output]

            In a real jigsaw this bevel is a result of machine press cutting the jigsaw pieces. It also gives the pieces a slight dent, so if the pieces are fitted back together you can still see the impression of the cuts.

            Now lets add some thickness to the piece. This is the best and quickest way I have found, though I don't consired it a very good technique. If you can find something better, then please let me know.


               convert jigsaw_bevel.png \
                       \( +clone -fill DarkSlateGrey -colorize 100% -repage +0+1 \) \
                       \( +clone -repage +1+2 \)  \( +clone -repage +1+3 \) \
                       \( +clone -repage +2+4 \)  \( +clone -repage +2+5 \) \
                      -background none -compose DstOver -flatten \
                      jigsaw_thickness.png

                [IM Output]

            And finally how about some shadow.


                convert jigsaw_thickness.png \
                        \( +clone   -background Black -shadow 50x3+4+4 \) \
                        -background none -compose DstOver -flatten \
                        jigsaw_shadow.png

                [IM Output]

            All the above commands can be easily saved into a single shell script, and I have done this for my own use.

            The script "jigsaw" will take three image parameters: source photo, template, and destination, as well as numerous options to enable the various enhancements shown above. It does not need to use a jigsaw shape either. Any mask template could be used to cut out parts of images, with appropriate added effects.

            The biggest difference between the above, and my script version, is that by default, the script keeps the final image as small as possible, while keeping track of offset of the cutout image. By preserving this offset position you can to use a simple "-mosaic" or "-flatten" to overlay multiple pieces back together to produce interesting effects (see last example below).

            Here is just a few examples of using this script, in a number of ways.


                jigsaw -o +365+96 -m  null: jigsaw_tmpl.png  jigsaw_mask.png
                convert -size 800x600 xc:gray miff:- |\
                             jigsaw -r 30 -l -h -s miff:- jigsaw_mask.png jigsaw_grey.png
                jigsaw -r -60 -h -t 4 -s holocaust_md.jpg jigsaw_mask.png jigsaw_piece.png

                convert jigsaw_cnr.png -resize 50% -flip -flop -repage 120x90 \
                        -background black -flatten -flip -flop jigsaw_cnr_tmpl.png
                jigsaw -t 3 -s  -r 15  -d +15+7 \
                        holocaust_tn.gif jigsaw_cnr_tmpl.png   holocaust_piece_tn.png
                convert jigsaw_cnr_tmpl.png -negate png:- |\
                  jigsaw -t 3 -s holocaust_tn.gif png:-   holocaust_puzzle_tn.png
                convert holocaust_puzzle_tn.png  holocaust_piece_tn.png \
                        -background none  -mosaic    holocaust_jigsaw_tn.png

            [IM Output] ==> [IM Output] [IM Output]
            [IM Output] ==> [IM Output] ==> [IM Output] [IM Output] ==> [IM Output]

            The last image is the beginning of a possible jigsaw thumbnail style...

            It takes a corner jigsaw piece, and with some scaling and expansion converts the mask, into a full sized image template mask. This is then used to not only cut out the corner piece from an existing thumbnail, but also is negated to produce the rest of the image as well. Overlaying these two images then produces quite a fancy looking jigsaw thumbnail.

            Note the use of a '-d +15+7' in the options to the piece creation. This displaces the 'page offset' of the generated PNG image by a small amount relative to its original position in the image, producing the result shown, simply and easily. See the script itself for the other options available.

                As page offsets generated can be negative, and could contain an optional soft shadow effect, it is recommended that only PNG images be used for extracted pieces. GIF images cannot handle negative page offsets, or shadow effects, nor does it produce a smooth looking anti-aliased edges when transparency is involved.

            Generally you should avoid GIF (and JPEG) images for all but your final image. For more information see Common Image Formats examples page.

            You are not limited to jigsaw puzzle templates, but any shaped mask can be used with any image. Let me know what you come up with.

            I am not quite finished with the development of the "jigsaw" script, as I would like some better controls for the highlighting, thickness and shadow effects, and possibly a 'negate mask' option. It is however basically a complete working program you are free to use. Give me a link back if you use it for a web page :-)

            For those with some PerlMagick API skill, try taking the above script and converting it to PerlMagick for speed, then submitting it to me so that everyone else can also use it, and know just how good you are at using IM. Further suggestions and ideas are always welcome.


            If you are just wanting to cut out all the pieces from an image using a collection of masks (with or without virtual pixel offsets), then the following command will let you do ALL of them very quickly.


              convert mask_*.png -set filename:mask %t -alpha shape \
                      null: image.jpg -compose In -layers composite \
                      pieces_%[filename:mask].png

            Each other resulting "pieces_mask_*.png" images, contains not only the appropriate image from the original image at the correct offset, but also preserves that offset in the final image. It does this using the Multi-Layer Composition to merge all the images to the left of the special "null:" marker image, with the single image on the right.

            As an added bonus it will incorporate the filename of the mask that was used into the piece image filename (including its final image file format), making identifying what piece is what much easier. (See Filename Percent Escapes for details.

            Note that the masks do not have to completely cover the whole original image, but should not leave spaces or gaps between pieces. Of course for a proper jigsaw all the masks should Align properly, so as to produce a seamless whole, such as shown in the Dst_Out Composition examples.

            "Gel" Effects
            The 3-D shadings used above is only the start of what you can do with highlight and shaded effects. By doing various histogram adjustments to the output of "-shade" an enormous range of possibilities is available.

            One such effect you can reproduce is known as a 'Gel' effect, such as often see in "Photoshop how-to web sites (Google for "Gel Effects Tutorial"). First lets create the shape we need. This could be a pre-prepared image or extracted from a 'Dings' font, like we did with the 3D bullet shaped "heart" above.

            In this case lets use a simple oval shape for a button...


              convert -size 100x60 xc:none \
                      -fill red -draw 'circle    25,30  10,30' \
                                -draw 'circle    75,30  90,30' \
                                -draw 'rectangle 25,15  75,45' \
                      gel_shape.png

                [IM Output]

            Now lets add the sharp 'Gel' highlight to the colored shape, using a highly modified blurred shade operation...


                convert gel_shape.png \
                        \( +clone -alpha extract  -blur 0x12  -shade 110x0 -normalize \
                           -sigmoidal-contrast 16,60% -evaluate multiply .5 \
                           -roll +5+10 +clone -compose Screen -composite \) \
                        -compose In  -composite  gel_highlight.png

                [IM Output]

            We applied "-shade" to a copy of the transparency (matte) channel after blurring it to round it off. Ths shade used a light source without any 'height' or 'azimith' angle to it, which basically means wer get a grey colored highlight of just one side of the blurred shape, and black for everything else.

            This highlighting greyscale was then adjusted (sharpened) using the "-sigmoidal-contrast" operator to reduce the size the highlighted area (the '60%' threshold level) and sharpen its edges (using a very high '16' exponential factor). With such a high exponential value, the operator is almost acting like a 'fuzzy' "-threshold" operator, to produce a flat region of color basied on the shape of the original image. For more information on this smooth contrast/threshold function see Sigmoidal Non-linearity Contrast.

            And finally the level of the highlight was adjusted using a "-evaluate" to multiply all the colors by the desired highlight level, then a "-roll" is used to shift its position into the shaped area.

            Now, as the highlight is grey on black (black to remain unchanged), a 'Screen' alpha composition is used to lighten the non-black areas by the given grey level.

            Now all that is left is to darken the borders a little...


                convert gel_highlight.png \
                      \( +clone -alpha extract  -blur 0x2 -shade 0x90 -normalize \
                         -blur 0x2  +level 60,100%  -alpha On \) \
                      -compose Multiply  -composite  gel_border.png

                [IM Output]

            Note that this time I used a vertically lit "-shade" for edge darkening, which makes the areas I want to preserve unchanged, a white color. As such after adjusting the greyscale using a Reversed Level Adjustment, and restoring the transparency saved by the Alpha Extract Method, I was then able to use a 'Multiply' alpha composition to darken the effected borders.

            Lets finish of the oval 'Gel' button with some text and shadow effects...


                convert gel_border.png \
                        -font Candice  -pointsize 24  -fill white  -stroke black \
                        -gravity Center  -annotate 0 "Gel"  -trim -repage 0x0+4+4 \
                        \( +clone -background navy -shadow 80x4+4+4 \) +swap \
                        -background none  -flatten    gel_button.png

                [IM Output]

            "Aqua" or "Bubble" Effects
            You can also adjust a full 3-D "-shade" (with a 30 degree lighting) tint to produce a "Aqua" water effect. For this however we need to do a histogram adjustment in a way that is similar to what you do with GUI graphical programs like "Gimp" and "Photoshop".

            I will first do this slowly step by set so you can see the steps I am following.

            First lets create an image to use, in this case a curvy letter A.


              convert -background none -fill DodgerBlue \
                      -font Candice -pointsize 72  label:A  -trim +repage \
                      -bordercolor None -border 1x1 \
                      aqua_shape.png

                [IM Output]

            Note that I added a one pixel transparent border around the image. This makes the next processing steps just that little bit easier.

            Now we need to generate Rounded Shade of this shaped image.


              convert aqua_shape.png \
                      -alpha Extract -blur 0x8  -shade 130x30 -alpha On \
                      -background gray50 -alpha background -auto-level \
                      aqua_shade.png

                [IM Output]

            The funny line that deals with Alpha Background is to reset the hidden color of the transparent areas to a mid-tone grey, so that it does not have an effect on the color normalization. This can be very important.

            Now we convert that shade into a 'lighting effect' that looks vaguely like the way light is distorted by a bubble of water or glass.


              convert aqua_shade.png \
                      -function polynomial  3.5,-5.05,2.05,0.3 \
                      aqua_lighting.png

                [IM Output]

            The Polynomial Function which is used for a Curves Adjustment of the image. It is this function that gives the overall effect, and can be difficult to determine.

            To do I passed the control points needed for this 'curve' to the IM support shell script called "im_fx_curves". This then returns the the 'coefficents' for the polynomial equantion needed for the 'curve that fits these control points.


              im_fx_curves -c -p  0,30  100,80  50,50  80,50  > aqua_coeffs.txt

            [Gnuplot] 	==> 	
            [Coeffs]

            The final adjustment of this lighting effect is make the edges of the lighting effect darker.


              convert aqua_lighting.png \
                      \( +clone -alpha extract  -blur 0x2 \) \
                      -channel RGB -compose multiply -composite \
                      aqua_light+edge.png

                [IM Output]

            And the shading overlay is complete. All that is left is to apply this to the original image, using HardLight Composition.


              convert aqua_shape.png aqua_light+edge.png \
                      -compose Hardlight -composite   aqua_result.png

                [IM Output]

            Notice that the final overall color of the resulting image is actually the original color of the original shape. In fact you coluld even apply this to a multi-colored image, without any problems at all.

            So lets repeat all the steps above, including the creation of the initial shape image, all in one command.


              convert -background none -fill DodgerBlue \
                      -font Candice -pointsize 96  label:'Aqua Text' -trim +repage \
                      \
                      \( +clone -bordercolor None -border 1x1 \
                         -alpha Extract -blur 0x8  -shade 130x30 -alpha On \
                         -background gray50 -alpha background -auto-level \
                         -function polynomial  3.5,-5.05,2.05,0.3 \
                         \( +clone -alpha extract  -blur 0x2 \) \
                         -channel RGB -compose multiply -composite \
                         +channel +compose -chop 1x1 \
                      \) \
                      -compose Hardlight -composite  aqua_text.png

            [IM Output]

            If you study the above you will see that all the steps previously outlined is applied to generate the lighting image which is then composited onto the original image.

            Tilable Stars and Comets
            I wanted to make a tile of random star fields (with the stars of variable intensities) for various purposes. This was the result of my slowly improving attempts at this.

            A random noise image is used to thin itself out generate a speckle pattern.


              convert -size 100x100 xc: +noise Random -channel R -threshold 5% \
                      -negate -channel RG -separate +channel \
                      -compose multiply -composite   speckles.gif

                [IM Output]

            This pattern is the basis for glitter animation effects, but also the start point for other effects.

            For example to make stars we need to modify its random 'speckle' pattern a bit more, so as to make things more realistic.


              convert -size 100x100 xc: +noise Random -channel R -threshold 1% \
                      -negate -channel RG -separate +channel \
                      \( +clone \) -compose multiply -flatten \
                      -virtual-pixel tile -blur 0x.4 -contrast-stretch .8% \
                      stars.gif

                [IM Output]

            Note that I multiply not only the speckle mask ('R' channel) but the star intensity image ('G channel) twice as well. This produces a squared fall-off in the pixel intensities so that more darker stars are present than bright ones, just as it is in the real night sky.

            After this we enlarge the size of the stars based on their intensity by Blurring. This produces an effect similar to the stars burning onto an astronomers photographic plate, making it even more realistic. The larger the blur value the larger the effect. A final "-contrast-stretch" brings the results back to visibility.

            By using two random noise images, (one for the mask, the other for the star color), we can generate randomly colored stars, instead of simple greyscale ones.


              convert -size 100x100 xc: +noise Random -channel R -threshold 1% \
                      -negate -channel RG -separate +channel \
                      \( xc: +noise Random \) -compose multiply -flatten \
                      -virtual-pixel tile -blur 0x.4 -contrast-stretch .8% \
                      stars_colored.gif

                [IM Output]

            This however may need more work, as we need to square the intensity of the colors directly instead of just simply multiplying them against a linear distribution. It does however work, and provides a starting point for further development.

            Note the color does not have to be random but could easily come from some other image for the stars. For example the star color itself could be sourced from the image that will be used as the final background.

            Now that I have a star-scape generator, I can simply use "-motion-blur" to create a field of falling stars!


              convert -size 100x100 xc: +noise Random -channel R -threshold .4% \
                      -negate -channel RG -separate +channel \
                      \( +clone \) -compose multiply -flatten \
                      -virtual-pixel tile -blur 0x.4 -motion-blur 0x20+45 -normalize \
                      star_fall.gif

                [IM Output]

            Of course we want less stars and less of a 'fall-off' in star intensities.

            By Polar Distorting the image we can make the comets flying or spiraling into a point!


              convert -size 250x100 xc: +noise Random -channel R -threshold .4% \
                      -negate -channel RG -separate +channel \
                      \( +clone \) -compose multiply -flatten \
                      -virtual-pixel Tile -background Black \
                      -blur 0x.6 -motion-blur 0x15-90 -normalize \
                      +distort Polar 0 +repage  star_inward.gif
              convert -size 250x100 xc: +noise Random -channel R -threshold .4% \
                      -negate -channel RG -separate +channel \
                      \( +clone \) -compose multiply -flatten \
                      -virtual-pixel Tile -background Black \
                      -blur 0x.6 -motion-blur 0x15-60 -normalize \
                      +distort Polar 0 +repage   star_spiral.gif

                [IM Output]

            [IM Output]

            Here we motion blur the stars in six directions (in pairs) then merge them together to create a field of 'star bursts', such as you get in a glass lens.


              convert -size 100x100 xc: +noise Random -channel R -threshold .2% \
                      -negate -channel RG -separate +channel \
                      \( +clone \) -compose multiply -flatten \
                      -virtual-pixel tile  -blur 0x.3 \
                      \( -clone 0  -motion-blur 0x10+15  -motion-blur 0x10+195 \) \
                      \( -clone 0  -motion-blur 0x10+75  -motion-blur 0x10+255 \) \
                      \( -clone 0  -motion-blur 0x10-45  -motion-blur 0x10+135 \) \
                      -compose screen -background black -flatten  -normalize \
                      star_field.gif

                [IM Output]

            Note how the darker stars only generate a small dot and very little in the way of a 'star burst', while the bigger bright stars generate a very large 'star burst'.

            Now if I can find a way to add a 'sinc()' type blurring so as to produce a flare 'ring' around the brightest stars as well, we will have a great star field generator. Add some plasma background and we can even generate fake astronomical photos of nebula and gas clouds.

            By combining the above with a plasma glitter animation you can make set of stars that look like christmas decorations.


              convert -size 100x100 xc: +noise Random -separate \
                      null: \
                        \( xc: +noise Random -separate -threshold 50% -negate \) \
                        -compose CopyOpacity -layers composite \
                      null: \
                        plasma:red-firebrick plasma:red-firebrick plasma:red-firebrick \
                        -compose Screen -layers composite \
                      null:  \
                        \( xc: +noise Random -channel R -threshold .08% \
                          -negate -channel RG -separate +channel \
                          \( +clone \) -compose multiply -flatten \
                          -virtual-pixel tile  -blur 0x.4 \
                          \( -clone 0  -motion-blur 0x15+90  -motion-blur 0x15-90 \) \
                          \( -clone 0  -motion-blur 0x15+30  -motion-blur 0x15-150 \) \
                          \( -clone 0  -motion-blur 0x15-30  -motion-blur 0x15+150 \) \
                          -compose screen -background black -flatten  -normalize \) \
                        -compose multiply -layers composite \
                      -set delay 30 -loop 0 -layers Optimize       stars_xmas.gif

                [IM Output]

            The above technique is only the start of what can be achieved. Using some simple animations techniques, glitters and random flares can be created which can be added to images. One simple example of this was provided in GIF animation examples, using a simple shell script "star_field" to generate the stars bursts.

            What can you to with this star generator?

            Challenge:

                Generate glitter rather than stars. The initial speckle field should be limited by a mask (say by multiplying). Both glitter and stars can then be overlaid onto an image using 'screen' composition.
                Use a masked 'speckle field' to generate star bursts for overlaying. By masking the seeds rather than the complete star burst, means that 'rays' of the bursts can leave the masked area to overlay other parts of the image. That is rays are not just 'cutoff'.
                Create an animation of a random star bursts. This may require you to animate a single field of star bursts (perhaps with the rays rotating).
                By generating a few star burst animations, you can merge them together to form a series of overlapping star bursts from different locations.
                Find a single 'seed' point on the brightest part of the image by histogram stretching a thresholding. Then picking single pixels until one hits the masked area.
                Creating stars on the edge a flat shaded shape. 

            If you manage any of the above challenge or use the star generator for some other purpose, please let me and the rest of the IM community know.

            Radial Flares
            Experiments in generating radial flares.

            Note that the width of the initial image before polar distorting, basically sets the number of rays that will be produced.


              convert -size 100x1 xc: +noise Random -channel G -separate +channel \
                      -scale 100x100\!                                +write flare_1a.png \
                      \( -size 100x100 gradient:'gray(100%)' -sigmoidal-contrast 10x50% \) \
                      -colorspace sRGB -compose hardlight -composite  +write flare_1b.png \
                      -virtual-pixel HorizontalTileEdge -distort Polar -1 \
                      flare_1_final.png

            [IM Output] ==> [IM Output] ==> [IM Output]

            Note how I use "+write" to save intermediate images for display. this is a debugging technique which is detailed in Complex Image Processing and Debugging.

            Here is another example using multiple overlays to achieve a different looking flare. Note the technique used to generating intermediate debugging and example images showing the steps involved.


              convert -size 100x1 xc: +noise Random -channel G -separate +channel \
                      -size 100x99 xc:black -append -motion-blur 0x35-90 \
                      \( -size 100x50 gradient:'gray(0)' \
                         -evaluate cos .5 -sigmoidal-contrast 3,100% \
                         -size 100x50 xc:'gray(0)' -append \) \
                      \( -size 1x50 xc:'gray(0)' \
                         -size 1x1 xc:'gray(50%)' \
                         -size 1x49 xc:'gray(0)' \
                         -append -blur 0x2 -scale 100x100\! \) \
                      \
                      -scene 10 +write flare_2%x.png \
                      \
                      -background 'gray(0)' -compose screen -flatten +write flare_2f.png \
                      \
                      -virtual-pixel HorizontalTileEdge -distort Polar -1 \
                      -colorspace sRGB flare_2_final.png

            [IM Output] [IM Output] [IM Output] ==> [IM Output] ==> [IM Output]

            The major problem with using polar distort for generating flare images is that the rays become wider with the radius, where really we want them to either remain a roughly constant width as they get dimmer, or at least thinner.

            Ideas and pointers welcome

            Color tinting can also be important in this type of image. For example here I Tint Mid-Tone Colors Blue.


              convert flare_2_final.png  -fill SkyBlue  -tint 100%  flare_2_color.png

                [IM Output]

            The percentage used for the "-tint" operation can also be used to adjust the intensity of the rays and flare ring, though it will not change the white core of the image very much.

            These examples were taken further in the IM Forum discussion Using Radial Flare for a Mask.
https://legacy.imagemagick.org/Usage/backgrounds/
            This is a table of applying various transforms against some 'random' canvases, showing methods of producing interesting random backgrounds at whatever size you desire, whether it is a single large image, or a background tile for a web page.

            The table starts with the method used to generate the initial 'random' image used to generate all the other images shown. Just insert the various image 'transform' into the command, to convert the raw image into something similar to that shown. From there you can adjust the various setting yourself to produce exactly the type of background image you want.

            Be sure to read the notes at the end, before attempting to create your own examples. and please mail any interesting variations you may come across.

            Input Images :- Generator, Transform and Post-processing 	 
            Images results shown here were generated with a "-noop" null transform operator
            Plasma Fractal (non-tiling canvas image)


              convert -size 120x120  plasma:fractal fractal.png
              convert fractal.png   {..transform..} \
                       -shave 20x20 +repage  -auto_level  {result}
             

                [IM Output]
            Random Noise (tilable background image)


              convert -size 80x80 xc: +noise Random noise.png
              convert noise.png -virtual-pixel tile  {..transform..} \
                      -auto_level  {result}
             

                    [IM Output]
            Random Hex Tile (hex tile background image)


              convert -size 50x80 xc: +noise Random -write mpr:rand \
                       -extent 100x80   -page +50-40 mpr:rand \
                       -page +50+40 mpr:rand -flatten  hextile.png
              convert hextile.png -virtual-pixel tile  {..transform..} \
                      -auto_level    {result}
             

                        [IM Output]
                
            Basic Transforms
            blur_raw (no post -auto-level)

              -blur 0x1

                [Fractal] 	[Noise] 	[Noise]
            blur_1

              -blur 0x1

                [Fractal] 	[Noise] 	[Noise]
            blur_3

              -blur 0x3

                [Fractal] 	[Noise] 	[Noise]
            blur_5

              -blur 0x5

                [Fractal] 	[Noise] 	[Noise]
            blur_10

              -blur 0x10

                [Fractal] 	[Noise] 	[Noise]
            intensity

              -blur 0x10  -colorspace Gray

                [Fractal] 	[Noise] 	[Noise]
            channel

              -blur 0x10  -fx G

                [Fractal] 	[Noise] 	[Noise]
            hues

              -blur 0x10 -auto-level -separate -background white \
                 -compose ModulusAdd -flatten -channel R -combine +channel \
                 -set colorspace HSB -colorspace RGB

                [Fractal] 	[Noise] 	[Noise]
            Shade Transforms
            shade_raw (no post -auto-level)

              -shade 120x45

                [Fractal] 	[Noise] 	[Noise]
            shade

              -shade 120x45

                [Fractal] 	[Noise] 	[Noise]
            shade_dimmed (no post -auto-level)

              -shade 120x45 -auto-level -fill grey -colorize 40%

                [Fractal] 	[Noise] 	[Noise]
            shade_1

              -blur 0x1 -shade 120x45

                [Fractal] 	[Noise] 	[Noise]
            shade_2

              -blur 0x2 -shade 120x45

                [Fractal] 	[Noise] 	[Noise]
            shade_5

              -blur 0x5 -shade 120x45

                [Fractal] 	[Noise] 	[Noise]
            shade_10

              -blur 0x10 -fx G -shade 120x45

                [Fractal] 	[Noise] 	[Noise]
            Emboss Transforms
            emboss_1

              -blur 0x5  -emboss 1

                [Fractal] 	[Noise] 	[Noise]
            emboss_1g

              -blur 0x5  -emboss 1  -fx G

                [Fractal] 	[Noise] 	[Noise]
            emboss_0s

              -blur 0x3  -emboss .5 -shade 120x45

                [Fractal] 	[Noise] 	[Noise]
            emboss_1s

              -blur 0x5  -emboss 1  -shade 120x45

                [Fractal] 	[Noise] 	[Noise]
            emboss_1gs

              -blur 0x5  -emboss 1  -fx G  -shade 120x45

                [Fractal] 	[Noise] 	[Noise]
            emboss_5gs

              -blur 0x10 -emboss 5  -fx G  -shade 120x45

                [Fractal] 	[Noise] 	[Noise]
            Edging Transforms
            charcoal

              -blur 0x2  -charcoal 10 -negate

                [Fractal] 	[Noise] 	[Noise]
            charcoal_10s

              -blur 0x2  -charcoal 10 -negate -shade 120x45

                [Fractal] 	[Noise] 	[Noise]
            charcoal_1s

              -blur 0x2  -charcoal 1  -negate -shade 120x45

                [Fractal] 	[Noise] 	[Noise]
            edges

              -blur 0x2  -edge 10

                [Fractal] 	[Noise] 	[Noise]
            edge_grey

              -blur 0x2  -edge 10 -fx G

                [Fractal] 	[Noise] 	[Noise]
            mesas

              -blur 0x2  -edge 10 -fx G -shade 120x45

                [Fractal] 	[Noise] 	[Noise]
            Line Generating Transforms
            lines

              -blur 0x10 -emboss 4 -edge 1

                [Fractal] 	[Noise] 	[Noise]
            loops

              -blur 0x10 -edge 15  -edge 1  -blur 0x1

                [Fractal] 	[Noise] 	[Noise]
            engrave_loops

              -blur 0x10 -edge 15  -edge 1  -blur 0x1 -fx R+B+G -shade 280x45

                [Fractal] 	[Noise] 	[Noise]
            engrave_loop

              -blur 0x10 -edge 15  -edge 1  -blur 0x1 -fx G -shade 280x45

                [Fractal] 	[Noise] 	[Noise]
            color_contours

              -blur 0x10 -normalize -fx 'sin(u*4*pi)*100' -edge 1 -blur 0x1

                [Fractal] 	[Noise] 	[Noise]
            contours

              -blur 0x10 -normalize -fx 'sin(g*4*pi)*100' \
                 -edge 1 -blur 0x1 -shade 280x45

                [Fractal] 	[Noise] 	[Noise]
            Complex Textured Blob Transforms
            (using a strange '-edge 1' effect)
            blobs

              -blur 0x10 -edge 1

                [Fractal] 	[Noise] 	[Noise]
            blobs_grey

              -blur 0x10 -edge 1 -fx '(R+G+B)/3'

                [Fractal] 	[Noise] 	[Noise]
            pits

              -blur 0x10 -edge 1 -fx G -shade 280x45

                [Fractal] 	[Noise] 	[Noise]
            ridges

              -blur 0x10 \( +clone -negate \) -edge 1 -fx u.G+v.G -shade 280x45

                [Fractal] 	[Noise] 	[Noise]
            mottled

              -blur 0x10 -write mpr:save -negate -edge 1 -negate -fx G \
                 \( mpr:save -edge 1 -fx G \) -shade 280x45 -average

                [Fractal] 	[Noise] 	[Noise]
            Paint Transforms
            paint_raw10 (no post -auto-level)

              -paint 10

                [Fractal] 	[Noise] 	[Noise]
            paint_areas

              -paint 10  -blur 0x5  -paint 10

                [Fractal] 	[Noise] 	[Noise]
            paint_raw10s

              -paint 10  -shade 120x45

                [Fractal] 	[Noise] 	[Noise]
            paint_8

              -blur 0x5  -paint 8

                [Fractal] 	[Noise] 	[Noise]
            paint_8s

              -blur 0x5  -paint 8  -shade 120x45

                [Fractal] 	[Noise] 	[Noise]
            paint_3

              -blur 0x10 -paint 3

                [Fractal] 	[Noise] 	[Noise]
            paint_3s

              -blur 0x10 -paint 3  -shade 120x45

                [Fractal] 	[Noise] 	[Noise]
            paint_3d

              -blur 0x10 -paint 3 \( +clone -shade 120x45 \) \
                 +swap  -compose overlay -composite

                [Fractal] 	[Noise] 	[Noise]
            Gradient Transforms
            levels (no post -auto-level)

              -blur 0x12 -fx intensity -normalize \
                 -size 1x9 gradient:navy-lavender \
                 -interpolate integer -fx 'v.p{0,G*(v.h-1)}'

                [Fractal] 	[Noise] 	[Noise]
            levels_3d (no post -auto-level)

              -blur 0x12 -fx intensity -normalize \
                 -size 1x9 gradient:navy-lavender \
                 -interpolate integer -fx 'v.p{0,G*(v.h-1)}' \
                 \( +clone -shade 120x45 -normalize \) \
                 -compose overlay -composite

                [Fractal] 	[Noise] 	[Noise]
            zebra

              -blur 0x12 -normalize \
                 -size 1x19   pattern:gray50   -fx 'v.p{0,G*(v.h-1)}'

                [Fractal] 	[Noise] 	[Noise]
            midlevel

              -blur 0x12 -normalize \
                 \( -size 1x9 xc: -draw 'color 0,4 point' -negate \) \
                 -fx 'v.p{0,G*(v.h-1)}'

                [Fractal] 	[Noise] 	[Noise]
            edged_level (no post -auto-level)

              -blur 0x12 -normalize \
                 \( -size 1x9 xc: -draw 'color 0,4 point' \) \
                 -fx '(.6+.2*v.p{0,G*(v.h-1)})' \
                 \( +clone -normalize -edge 1 \)  -fx 'u+v'

                [Fractal] 	[Noise] 	[Noise]
            layered_levels (no post -auto-level)

              -blur 0x12 -normalize \
                 \( -size 1x9 xc: -draw 'color 0,4 point' \) \
                 -fx '(.5+.3*v.p{0,u*(v.h-1)})' \
                 \( +clone -normalize -edge .3 -fx 'R+G+B' \) \
                 -fx 'intensity+v'  -fill skyblue -tint 100

                [Fractal] 	[Noise] 	[Noise]
            Miscellaneous
            filaments

              -blur 0x5 -normalize -fx g \
                 -sigmoidal-contrast 15x50% -solarize 50%

                [Fractal] 	[Noise] 	[Noise]

            If you have or come up with a nice background generator or image transform, please let me know so it can be added here to share with others.
            Final Important Notes
            The two Random Noise Images, being so 'random' are tilable, and we use "-virtual-pixels" to ensure that they remain tilable during the transformation. However the Plasma Image is not tilable to start with, so a enlarged version with the edges "-shave" off afterward is used to remove the unwanted edge effect of many operations. These technique is discussed further in Modifying Tile Images.

            Note that the final "-auto_level" is applied to most images to enhance the contrast of the results, unless the transform is marked as not requiring it so as to preserve and coloring or shadings that resulted from the transformation.

            Because many image transformations such as, "-blur", "-emboss", and "-edge" are grey-scale transformations, they work on the three color channels, completely independently of each other. As a result, in many of the images, the result looks like three separate images have been overlaid, then shaded.

            The final example "layered_levels" was designed to works on each of the three levels simultaneously, while keeping them separate, until the final step where they are added together and color tinted.

            This triple effect can be removed by either applying an initial gray-scaling operation, or extracting just one of the channels when finished. Typically I extract the 'green' or 'G' channel as it is normally the strongest channel in a grey scale image anyway, though any of the three channels can be used.
https://legacy.imagemagick.org/Usage/scripts/  #=index|repository of shell support-scripts

https://legacy.imagemagick.org/Usage/

http://www.fmwconcepts.com/imagemagick/index.php
  (=fred's scripts (+categories and examples (!!)))

